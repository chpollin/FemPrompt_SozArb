---
source_file: Cvoelcker_2023_Queer.pdf
conversion_date: 2025-11-02T17:22:50.157719
---

## Queer In AI: A Case Study in Community-Led Participatory AI

Organizers of QueerInAI Many Countries

Ashwin Singh Queer in AI India

Davide Locatelli Queer in AI Spain

Hang Yuan Queer in AI United Kingdom

Jaidev Shriram Queer in AI &amp; University of California, San Diego USA

Maarten Sap Queer in AI &amp; Language Technologies Institute, Carnegie Mellon University &amp; Allen Institute for AI USA

Maria Ryskina Queer in AI &amp; MIT USA

Milind Agarwal Queer in AI &amp; George Mason University USA

A Pranav Queer in AI Hong Kong

Sarah Mathew Queer in AI &amp; Georgia Institute of Technology USA

Anaelia Ovalle Queer in AI &amp; University of California, Los Angeles USA

Claas Voelcker Queer in AI &amp; University of Toronto, Vector Institute Canada

Eva Breznik Queer in AI &amp; Uppsala University Sweden

Hetvi J Queer in AI United Kingdom

Kruno Lehman Queer in AI Switzerland

Marc Peter Deisenroth Queer in AI &amp; University College London United Kingdom

Martin Mundt Queer in AI &amp; TU Darmstadt &amp; hessian.AI Germany

Nyx McLean Queer in AI &amp; Rhodes University South Africa

Raj Korpan Queer in AI &amp; Iona University USA

Arjun Subramonian Queer in AI &amp; University of California, Los Angeles USA

Danica J. Sutherland Queer in AI &amp; University of British Columbia Canada

Filip Klubiƒçka Queer in AI &amp; ADAPT Centre, Technological University Dublin Ireland

Huan Zhang Queer in AI USA

Luca Soldaini Queer in AI &amp; Allen Institute for AI USA

Maria Leonor Pacheco Queer in AI &amp; University of Colorado Boulder USA

Anonymous Queer in AI

Pan Xu Queer in AI &amp; Duke University USA

Ruchira Ray Queer in AI USA

Sarthak Arora Queer in AI India St John Queer in AI &amp; Aalto University Finland

| Tanvi Anand                      | Vishakha Agrawal              | William Agnew                    |
|----------------------------------|-------------------------------|----------------------------------|
| Queer in AI                      | Queer in AI                   | Queer in AI & University of      |
| USA                              | India                         | Washington                       |
| Yanan Long in AI & University of | Zijie J. Wang in AI & Georgia | Zeerak Talat Queer in AI         |
| Queer Chicago                    | Queer Tech                    |                                  |
| USA                              | USA                           | Canada                           |
| Avijit Ghosh                     | Nathaniel Dennler             | Michael Noseworthy               |
| Queer in AI & Northeastern       | Queer In AI                   | Queer In AI & MIT                |
| University                       | USA                           | USA                              |
| USA                              |                               |                                  |
| Sharvani Jha                     | Emi Baylor                    | Aditya Joshi                     |
| Queer In AI                      | Queer In AI                   | Queer In AI & SEEK, Australia    |
| USA                              | Canada                        | Australia                        |
| Natalia Y. Bilenko               | Andrew McNamara               | Raphael Gontijo-Lopes            |
| Queer in AI                      | Queer in AI & Microsoft       | Queer in AI                      |
| USA                              | Canada                        | USA                              |
| Alex Markham                     | Evyn DÀá ong                   | Jackie Kay                       |
| Queer in AI                      | Queer in AI                   | Queer in AI                      |
| Sweden                           | USA                           | United Kingdom                   |
| Manu Saraswat                    | Nikhil Vytla                  | Luke Stark                       |
| Queer in AI                      | Queer in AI                   | Queer in AI & Western University |
| Canada                           | USA                           | Canada                           |

## ABSTRACT

Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community's programs over the years. We discuss different challenges that emerged in the process, look at ways this

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

FAccT '23, June 12-15, 2023, Chicago, IL, USA

¬© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0192-4/23/06...$15.00

https://doi.org/10.1145/3593013.3594134

organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization's impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI's work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.

## ACMReference Format:

Organizers of QueerInAI, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubiƒçka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, Anonymous, Milind Agarwal, Nyx McLean, Pan Xu, A Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, St John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael

Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael Gontijo-Lopes, Alex Markham, Evyn DÀá ong, Jackie Kay, Manu Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI: A Case Study in Community-Led Participatory AI. In 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT '23), June 12-15, 2023, Chicago, IL, USA. ACM, New York, NY, USA, 14 pages. https: //doi.org/10.1145/3593013.3594134

## 1 INTRODUCTION

Artificial intelligence (AI) has seen enormous developments in recent years, such as substantial advances in protein modeling, drug discovery, weather prediction, and personalized medicine [66, 101, 127]. The ubiquity of unregulated AI within socio-technical systems, however, often produces discriminatory outcomes and harms marginalized communities globally [8, 10, 65]. For queer people in particular, machine learning models learn brittle, toxic representations that cause representational and allocational harms, from misgendering to healthcare discrimination [32, 37, 69, 123]. Identifying and mitigating harmful outcomes has led to the development of computational and socio-technical methods for achieving fairness [13, 29, 85], including automatic evaluation and unfairness mitigation techniques [16, 41, 85]. While such approaches have the potential to mitigate harms for queer people in domains like fighting online abuse, health, and employment [123], computational techniques generally encode narrow conceptualizations of fairness where queer identities are assumed to be known, observable, measurable, discrete, and static [80]. By locating the source of unfairness in individuals or in specific design decisions [128], computational approaches to fairness can reinforce existing power relations [35, 67], including marginalized communities only in predatory ways [52] or as 'ethics washing' [111] (cf. Appendix for an extended critique of computational approaches to fairness).

Participatory methods address some of these limitations. Involving users as co-designers holds great potential for dismantling power relations and empowering marginalized communities that are disproportionately impacted by AI [9, 73, 118]. Reflexivity in participatory methods encourages transparency during the design process itself, as opposed to a detrimental 'innovate first, fix later' approach to building trustworthy AI [48]. By establishing the valueladen nature of technologies, it can prevent personal biases, beliefs and values from seeping into AI systems unexamined.

Unfortunately, there are many challenges to incorporating participatory approaches across top-down structures, such as corporations that operate within capitalism. Popular modes of participation within AI suffer from extractive and exploitative forms of community involvement or 'participation washing' [111]. For example, a recent report [94] sheds light on how OpenAI used exploitative labor practices to make ChatGPT less toxic, subjecting Kenyan workers to psychologically distressing content 1 without sufficient provision for mental health support. Gray and Suri [55] also uncovers many exploitative labor practices performed by minorities to power AI systems.

We pose a more fundamental question: should marginalized communities engage in designing with the creators of harmful AI systems that prioritize profit over their safety? Even in projects

1 This content included examples of sexual abuse, hate speech, violence, murder, child abuse, rape, animal abuse, torture and self-harm.

where communities are involved, engagement is too often limited in scope and time. Contrary to participation being controlled by the corporations and states the design and own AI, we argue in the favor of shifting power towards marginalized groups and centering their experiences. We call for a culture of participation in AI to address this, one that enables deep and long-term participation in AI research, institutions, and practices.

Over the years, the AI community has witnessed several communityled efforts from marginalized communities, each tackling issues of inequality that arise along various axes of marginalization; these include Black in AI [12], LatinX in AI [76], Women in Machine Learning [132], Masakhane [83], Widening NLP [129], Diversity in AI [36], Indigenous in AI [63], Queer in HCI [34], the Indigenous Protocol and AI Working Group [78], the Deep Learning Indaba [31], Khipu [72], North Africans in ML [90], {Dis}Ability in AI [62], and Muslims in ML [87]. These organizations have worked in AI ethics, advocated against AI harms, provided longstanding venues and visibility for AI ethics research within major ML and NLP conferences, resolved inclusion issues with those venues, and developed community-led datasets, models, and other technology. Most importantly, they have advanced participation by marginalized communities in AI research and development at large, nurturing countless researchers and practitioners with community, mentorship, financial aid, and innumerable other forms of help with the many barriers marginalized people face in AI. These affinity groups have made AI much more diverse, and strengthened the voices of marginalized people within AI.

In this work, we argue that AI ethicists who value participatory methods as a means for making ethical AI should engage with participatory and community-lead AI ethics organizations, and study their organizational, strategic, and administrative work through which they are advancing participation and building cultures of participation. This often difficult process involves navigating the complexities of combining inquiry with praxis, and sheds light on differences between participatory approaches.

To this end, we offer a case study analyzing Queer in AI, a grassroots organization that aims to raise awareness of queer issues in AI/ML, foster a community of queer researchers and celebrate the work of queer scientists. Operating primarily as an online community over Slack, the organization runs various programs and initiatives towards fulfilling its mission. We analyze and critique its principles, methodology, initiatives, and impact over the years as a case study of community-led participatory methods in AI.

The rest of the paper is organized as follows: ¬ß2 documents salient forms of marginalization and oppression that particularly affect queer people; as a response Queer in AI has developed a set of core principles that seek to address the issues: decentralization, intersectionality and participatory design (¬ß3), which is reflected in its methodology; ¬ß4 showcases key initiatives of Queer in AI, highlighting the positive impact they have had on facilitating the participation of queer people at AI conferences; finally, we discuss the challenges and future of Queer in AI in ¬ß5 before concluding in ¬ß6.

Positionality Statement Most authors of this paper are formally trained as computer scientists, with some also having training in gender theory or related fields. All authors have informal training in queer studies through activism and advocacy. Our backgrounds

Figure 1: Overview of Queer in AI's core principles, community responses, programming outcomes, and tensions and challenges.

<!-- image -->

influence this work's design, decisions, and development. We do our best to position our work in a global context, with authors from Asia, Europe, South Africa, South America, and North America.

## 2 MARGINALIZATION OF QUEER PEOPLE IN STEM AND AI

Hegemonic forms of AI focus on classifying complex people and situations into narrow categories at the cost of context, and are often built to support surveillance, prediction, and control - designs which are fundamentally incompatible with queer identities rooted in the freedom of being [70]. The framing and use of common AI systems that interact with gender are thus often problematic, and inherently cisnormative and heteronormative, so that even well-meaning, purportedly inclusive AI projects are prone to 'designing out' certain queer lives [58]. Documented harms across various AI applications are numerous, and sometimes lifethreatening. These include physiognomic and phrenologic applications such as computer vision to (falsely) infer gender and sexuality [4, 69, 71, 79, 106, 107, 117]. AI-enabled surveillance systems, in conjunction with surveillance of online spaces such as dating apps by states, corporations, and even individuals have outed queer people, compromising their privacy and safety [22, 60, 91, 93]. Online spaces, especially social media platforms, have insufficient and poorly explained privacy and security tools, requiring community education and adaptation to meet the needs of queer people [33, 53, 95]. Their moderation enables widespread censorship of queer words and identities [30, 44, 110, 112], while also subjecting queer communities to disproportionate online harassment and hate speech [96, 124]. Some of these harms can be traced to large language models (LLMs) trained on datasets containing hate speech and censored queer words, leading search systems to avoid queer content and content moderation systems to more often tag it as suspect [37, 54]. LLMs also overwhelmingly fail to account for non-binary genders and pronouns, contributing to erasure of these identities [17, 32].

In the US, queer people are (at least) 20% less represented in STEM than in the national population, and experience higher levels of 'career limitations, harassment, and professional devaluation' [19]. Consequently, queer scientists often face 'systematically more negative workplace experiences than their non-LGBT colleagues' [20], and 'leave STEM at an alarming rate' [50]. The exclusion of queer people from science comes with significant consequences, both for queer scientists and queer people further marginalized by fields that do not understand or care about them.

The medical profession's response to the HIV/AIDS crisis was fatally slow until pressured by heroic activism [109]; a medical field that had included and empowered queer people may have saved many queer lives. Similarly, the American Psychiatric Association classified homosexuality as a mental illness until 1973, greatly contributing to the stigmatization of queer people around the world, until queer activists pressured the group for change [38]. Recent initiatives have inverted this dynamics, centering queer communities in descisions about mental healthcare [73].

One hurdle in understanding the marginalization of LGBTQIA+ people in STEM is a lack of demographic data on sexual orientation and gender identity [50]. The US's National Science Foundation has delayed the collection of such data for years, despite the urging of queer scientists [75]. Taking matters into its own hands, Queer in AI administers an annual survey of its global community to uncover the demographics and challenges faced by queer researchers in AI (discussed in detail in Appendix B). In Queer in AI's 2021-22 community survey ( ùëÅ = 252), 74% of members reported a lack of role models and 77% reported a lack of community as obstacles in their journey of becoming an AI practitioner.

There is a dire lack of studies and data on queer scientists' experiences in the Global South, where colonial histories have led to the criminalization of queerness [1-3]. Queer in AI organizers from Turkey, Colombia, and India have shared that much queer activism in these countries focuses on survival and gaining basic human rights, recognition and respect in society, amid high levels of discrimination, violence, and psychological distress [23]. They perceive being out and working towards queer visibility in STEM fields to be beyond luxuries, especially given the dominant (cisnormative, heteronormative) view that identity and profession should be 'kept separate.' Barriers to acceptance are only amplified for queer individuals also marginalized on intersecting axes like class or caste.

## 3 CORE PRINCIPLES OF QUEER IN AI

Three governing principles drive Queer in AI's mission to raise awareness of queer issues in AI and foster a community of queer researchers: (i) decentralized organizing, (ii) intersectionality, and (iii) community-led initiatives. Overall, Queer in AI's decentralized operations allow for swift community-led initiatives towards its mission (¬ß3.1), which center on intersectionality as critical inquiry and praxis (¬ß3.2). In doing so, it acknowledges and continuously works to account for 'the complexities of multiple, competing, fluid, and intersecting identities' [57]. Queer in AI's primary approach

consists of including people with diverse lived experiences in participatory schemes (¬ß3.3).

## 3.1 Participation and Decentralization

For its first two years, Queer in AI had a hierarchical structure, with a president and officers. However, organizing and governance of grassroots communities, and especially queer communities, presents unique challenges. Queer people are incredibly diverse, and choosing one or even a group of queer people to represent the community as a whole is reductive and impossible. This is also difficult for the organizers, with high-profile queer activists and organizers frequently facing targeted harassment campaigns, and Queer in AI organizers frequently reporting lack of time, external support, or recognition for volunteering (Figure A16). Queer in AI thus adopted a decentralized organizing structure, encouraging broad participation. Following the principle that organizing in Queer in AI should be the same as participating in the Queer in AI community with minimal barriers and distinctions between volunteers and community members. Most volunteer coordination occurs in the same Slack channel as is used for community discussion, calls for help or feedback on programs mixed with memes, introductions, personal news, and discussions of travel or pets. Of the 49 active Slack channels only 4, where personally identifiable information is discussed, are not public. Openness and embedding in the community increase transparency and accountability: any community member can view organizing discussions and join in, with no more barrier to entry than joining a Slack channel. It also helps provide the connection and joy for which 75% of its organizers joined Queer in AI (Figure A15). It also makes it easier for community members' areas and levels of engagement to ebb and flow over time without losing their connection to the community.

## 3.2 Participation and Intersectionality

Over five years, Queer in AI's community has grown to about 870 members, geographically distributed across more than 47 countries (cf. Figure A9). The community members have diverse identities across axes such as ethnicity, gender, class, disability, and caste. About 20.3% of respondents identified as transgender, and 34.4% identified as non-cisgender; 34.9% identified as Black, Latinx, indigenous or a person of color; less than 2% identified as intersex. Membership spans academia and industry, with about 16% of members in an undergraduate degree, 21% in an industry role, and 64% in academia, all with varying degrees of seniority (cf. Appendix B for additional details of community demographics). As a result, Queer in AI helps naturally bridge otherwise insular aisles of power and social contexts.

As the queer community consistently experiences discrimination, stigmatization, and inequity [18, 86], Queer in AI uses the lens of intersectionality as a means of critical inquiry to identify how interlocking forms of oppression, such as racism and sexism, co-construct and exacerbate social and structural disparities [26]. To proactively dismantle injustices, Queer in AI centers the experiences of its members so that active participation in the Queer in AI community results in the co-creation of initiatives, which reflect of tackling such barriers, including economic (¬ß5.3), educational (¬ß4.1), and social (¬ß4.2) ones. By prioritizing fighting intersectional oppression, Queer in AI attempts to empower its most marginalized members to shape and control its programming, addressing key challenges of participatory design such as the exclusion of marginalized people from participation [68], community power-sharing [27] and the co-formation of knowledge [46]. In doing so, Queer in AI works towards a system of resistant knowledge firmly grounded in praxis that is crucial in the ability of using intersectionality as a critical theory [25, Chs. 3 &amp; 4].

## 3.3 Participation and Community Leadership

3.3.1 Research. Various forms of community-engaged research guide the dissemination of knowledge both within and outside of Queer in AI and exist across a continuum, from communityinformed to community-involved to community-led. Communityinformed research consists of researchers inviting the community to incorporate lived experience to guide research questions, data collection, or data interpretation [59]. Towards more communityinvolved research, community members may be more involved in decision-making processes and research planning [59, 104]. At the highest level of engagement, community-driven approaches such as community-based participatory action research (PAR) centers shared collaborative decision-making between researchers and community members across research design, knowledge creation, intervention development, and policy-making [28, 81, 125]. In practice, entities outside of the organization may partner with Queer in AI community members to form relationships designed to help objectives oriented towards investigating and supporting 'the pursuit of answers to the questions of their daily struggle and survival' [120]. Individuals are often members of both other entities as well as of Queer in AI so that members may operate from the role of an external entity (e.g. researcher from a company) and at various depths of community engagement. The resulting knowledge production is such that is 'by the people, for the people' in which research is not only seen as a process to create knowledge but to also educate and mobilize for action [28, 56]. By 'putting community first', the distinction between participant and researcher is removed. Community-based participatory action research thus also serves as a decolonizing epistemological framework which inherently interrogates power and privilege [47].

3.3.2 Response &amp; resilience. Within Queer in AI, community resilience operates across dimensions including but not limited to the social, political, and economic. Advocacy efforts operate across domains, tasks, resources, and activities within the organization [74]. Resources and activities are structural means towards tasks and domains that reflect the Queer in AI mission. Specifically, resources and activities are dedicated to raising awareness of queer issues in AI/ML. Financial, educational, and social avenues are created within the organization as a form of creating resilience and advocacy in the face of oppressive sociotechnical barriers. Operating across 47 countries, Queer in AI primarily organizes through Slack, Zoom, a dedicated mailing list, and social media platforms. Doing so makes room for rapid and adaptive situational awareness within the online community [116]. Besides the 'internal' milieu of an organization, Queer in AI is responsive to events in both reactive and proactive forms. Digital volunteer efforts emerge as self-organizing responses to external factors [24, 42]. This work further details examples of

Figure 2: Country of origin of the respondents to the Queer in AI's 2021-2022 demographic survey.

<!-- image -->

Table 1: Self-reported ethnicity, gender, and sexual orientation of the respondents to the Queer in AI's 2021-2022 demographic survey. Write-in responses were aggregated by a team of Queer in AI organizers, with some falling into multiple categories (see ¬ßB). 'Unaggregated' refers to responses that could not be adequately described with any subset of other categories; however, responses in this group may overlap with the remaining categories. For options with fewer than 4 responses, exact values are omitted for privacy.

| Ethnicity                      | Ethnicity   | Gender                | Gender   | Sexual Orientation   | Sexual Orientation   |
|--------------------------------|-------------|-----------------------|----------|----------------------|----------------------|
| Caucasian                      | 127         | Man                   | 108      | Queer                | 90                   |
| South Asian                    | 34          | Woman                 | 95       | Gay                  | 89                   |
| East Asian                     | 17          | Non-binary            | 61       | Bisexual             | 87                   |
| Black/African/African-American | 13          | Genderqueer           | 29       | Pansexual            | 42                   |
| Latinx                         | 13          | Gender non-conforming | 22       | Lesbian              | 30                   |
| Mixed                          | 12          | Genderfluid           | 19       | Asexual              | 26                   |
| Jewish                         | 8           | Agender               | 17       | Unaggregated         | 29                   |
| Middle Eastern                 | 8           | Questioning           | 16       |                      |                      |
| Southeast Asian                | 6           | Unaggregated          | 16       |                      |                      |
| West Asian                     | ‚â§ 3         |                       |          |                      |                      |
| Central Asian                  | ‚â§ 3         |                       |          |                      |                      |
| Hispanic                       | ‚â§ 3         |                       |          |                      |                      |
| Unaggregated                   | 6           |                       |          |                      |                      |

how responses to acute external factors and larger efforts against oppression manifest as Queer in AI initiatives.

## 4 QUEER IN AI INITIATIVES

The structure of Queer in AI is decentralized and includes volunteers, core organizers (extensive organizing experience with Queer in AI) and a diversity, equity and inclusion admin (DEIA, a core organizer who has a more active role in administrative duties). Most of Queer in AI's communication is mediated by its Slack workspace.

Akey aspect of Queer in AI's organizing lies in the transparency of its operations and associated information exchanges, which predominantly take place over public Slack channels. There are only four private channels on the workspace, which exist to preserve privacy while facilitating discussions around personally identifiable information. The workspace has included the exchange of over 133,000 messages (including individuals' one-to-one private messages), of which over 25,000 have been sent in public channels, accounting for the majority (57%) of total views. This transparency, in conjunction with regular updates and outreach on Slack, keeps community members involved in ongoing events and initiatives.

Many of Queer in AI's initiatives have emerged from conversations and threads on public channels about discriminatory experiences with different institutions. For example, discussion around exclusionary gender collection practices on conference registration forms led to the creation of an inclusive conference guide (covered in more detail in ¬ß4.3) and substantial improvements to relevant conferences' practices. Similarly, significant advocacy against deadnaming in citations and conference proceedings (¬ß4.4) began from discourse on public channels. Thus, as a space, Queer in AI's Slack is effective at mobilizing community-led initiatives through decentralized organizing. Moreover, the emergence of these initiatives from diverse yet intersecting shared queer experiences grounds them in global contexts of social inequality and injustice. For instance, Queer in AI's graduate school application financial aid program (¬ß4.1) and workshops and socials (¬ß4.2) target several particular challenges rooted in non-Western contexts, centering otherwisemarginalized experiences. The organizational and volunteer work that constitutes the administration of all these initiatives is thus deeply intersectional.

We now examine four major initiatives in detail; Appendix C further describes efforts in policy advocacy.

## 4.1 Graduate School Application Financial Aid Program

The process of applying to graduate schools can be costly: between the application fees ( ‚àº $50-$150 USD per program in North America and parts of Europe), costs of required tests (e.g. GRE), test results and transcript delivery fees, and test preparation expenses, one round of applications can easily amount to over $1,000 USD. International applicants may be further required to pay for language proficiency tests (e.g. TOEFL), translation services, and third-party credential vetting. Although some schools offer fee waivers, they vary widely from school to school, are often very limited in applicability, and can require onerous documentation. These costs can prevent many low-income and international scientists from accessing graduate programs at all, well before they can benefit from many of the fellowships and need-based scholarships intended to address exclusion.

These financial challenges are particularly likely to be insurmountable for queer scientists, who may be cut off from familial financial support, might pay out of pocket for gender-affirming healthcare, and often incur additional expenses managing oppression and trauma. Queer people thus suffer from increased student loan debt [82] and high rates of housing insecurity [130]. To make graduate education more accessible to such applicants, Queer in AI launched the Graduate School Application Fee Aid Program. Supporting queer and low-income scholars financially helps bring more marginalized voices into STEM academia, creating more opportunities for participatory research and technology design.

4.1.1 Program design. The program aims to address the key elements of mutual aid projects defined by Spade [113]: meeting people's needs, building a shared understanding of why they do not have what they need, building solidarity and movements, and being participatory. This initiative strives to meet the need of all applicants to the extent possible while keeping the barriers to receiving aid to a minimum (i.e. not seeking to decide who is 'deserving' of aid or imposing excessive requirements for documenting eligibility, a hallmark of exclusive programs that only provide superficial aid [43]). Towards the goal of shared understanding, it serves to educate the volunteer organizers about the pitfalls of the existing admissions system: the volunteers, many of whom are in academia themselves, get to hear each applicant's perspective and can use this knowledge to advocate for changing the admissions process at their home institutions.

Like other Queer in AI initiatives, the aid program is decentralized and community-led. The volunteers operating the program come from different parts of the world, and their diverse range of experiences with graduate school admissions shapes what the program looks like. Each aid applicant is also treated as a member of the community with a valuable perspective of their own - the initiative actively seeks feedback from aid recipients and encourages them to volunteer in the future, which would both help improve the program and keep it sustainable.

Some applicants receive pre-approval and then are reimbursed based on receipts, while others unable to pay the fees out of pocket receive their scholarship money upfront. Payments are sent via PayPal or bank transfers; although these methods allow transferring money to most of the world, this pipeline may disadvantage applicants from countries and territories where PayPal is not available or restrictions are imposed on receiving transfers from the US.

Table 2 summarizes the program's financial impact and its funding. The core budget comes in equal proportion from Queer in AI and oSTEM ($10,000 USD each in 2020 and 2022; $20,000 USD each in 2021). In 2022, the program also received a grant for an additional $5,000. More money is then raised in program-specific donations through matching drives and social media campaigns. While much of the funding comes from the Queer in AI community members, the scholarship is open to applicants across STEM, transferring from a field with a lot of available money to a broader community of researchers working on a wide range of important, impactful directions.

4.1.2 People helped. Table 3 and Figures ?? , ?? , ?? , ?? , and ?? show demographics from an optional survey sent to scholarship recepients, which are more diverse along several axes than the Queer in AI organizers (Figures ?? , ?? ?? , ?? , ?? , ?? , Table ?? ) or community (Table 1, Figures 2, ?? , ?? , ?? , ?? , ?? , ?? , ?? ). For example, 61% of the aid recipients identify as Black, Latinx, indigenous, or a person of color, compared to 43% for the organizers and 35% for the community. Fewer applicants identified as trans/questioning, neurodivergent, or disabled (Figure ?? ), however. There is also significant geographic diversity (Figures ?? -?? ), particularly for non-Western countries; this has made the fact that the organizer team lacks members from some parts of the world a key consideration, and the aid program has struggled to account for some needs of the applicants in these areas (e.g. with differing admissions timelines) and encountered further obstacles (e.g. language barriers). As a whole, these statistics show the program serves the goals of justice, equity, and intersectionality, not just in academia but within Queer in AI itself - it helps recruit more diverse volunteers and community members by first directly, meaningfully helping them.

Only 17% of recipients described themselves as completely out about their sexual orientation, while over a half were out only to a limited extent or not at all. Among non-cisgender respondents, under 10% reported being completely out about their gender, and over 60% were out only to a limited extent. Even so, about 80% discussed their queer identity in their application materials. Queerfriendliness was a big factor in school choice, with 72% considering the location's queer friendliness and about 40% looking for queer lab members or campus advocacy groups. 56% said the scholarships allowed them to take admissions tests, 54% to avoid skipping essential expenses, and around 40% each to avoid skipping groceries or bills. The vast majority of recipients reported the scholarship enabled them to apply to additional programs (around 6 on average). The survey illustrates widespread deficiencies in existing admissions fee waivers: 67% of applicants said they were not available at all schools, 14% said they were unable to produce the required documentation, and 10% said they were not comfortable outing themselves to the schools to receive waivers.

4.1.3 Critical reflection. While Queer in AI believes that the program provides great value to applicants, it is important to note the context in which it operates and which necessitates its existence.

Table 2: The Queer in AI Graduate School Application Fee Aid Program budget and impact per academic year, in USD.

| Academic year                  | Aid per applicant   |   No. aid recipients | Total aid   | Budget   |
|--------------------------------|---------------------|----------------------|-------------|----------|
| 2020/2021                      | up to $750          |                   31 | $16,689     | $20,000  |
| 2021/2022                      | up to $1,250        |                   81 | $70,607     | $73,768  |
| 2022/2023 (at time of writing) | up to $1,250        |                   48 | $40,476     | $41,711  |

Table 3: Gender, sexual orientation, romantic orientation and continent of scholarship recipients who filled the optional feedback survey ( ùëõ = 46 out of ùëÅ = 160 total recipients). For options with fewer than 4 responses, exact values are omitted for privacy.

| Gender                | Gender   | Sexual Orientation   | Sexual Orientation   | Romantic Orientation   | Romantic Orientation   | Continent     | Continent   |
|-----------------------|----------|----------------------|----------------------|------------------------|------------------------|---------------|-------------|
| Woman                 | 20       | Gay                  | 18                   | Homoromantic           | 21                     | Asia          | 19          |
| Man                   | 18       | Queer                | 16                   | Biromantic             | 13                     | North America | 14          |
| Genderqueer           | 7        | Bisexual             | 12                   | Demiromantic           | 5                      | Africa        | 5           |
| Non-binary            | 6        | Lesbian              | 9                    | Grayromatic            | 5                      | Europe        | ‚â§ 3         |
| Gender non-conforming | 6        | Asexual              | 4                    | Alloromantic           | ‚â§ 3                    | South America | ‚â§ 3         |
| Agender               | ‚â§ 3      | Pansexual            | 4                    | Aromantic              | ‚â§ 3                    |               |             |
| Genderfluid           | ‚â§ 3      | Demisexual           | ‚â§ 3                  | Heteroromantic         | ‚â§ 3                    |               |             |
| Questioning           | ‚â§ 3      | Questioning          | ‚â§ 3                  |                        |                        |               |             |

The majority of applicants apply to North American schools. This is likely caused by the cultural dominance of Anglo-American schools in the AI/ML space and the common practice of requiring extensive standardized tests and application fees at these schools. 2 The program operates with a tension between opening opportunities to marginalized people from all over the world and reinforcing the exclusionary practices of these powerful institutions.

In addition to funding influential and rich academic institutions, the program also indirectly supports the standardized testing industry. While tests like the GRE claim to level the playing field for applicants, they institute barriers to individuals from the Global South and reify colonialism under a veneer of fairness. Additionally, fees makes these exams wholly inaccessible to many in the Global South: the GRE costs three times the average monthly salary in Ethiopia [11].

A complete critique of the graduate application process and its socio-economical context is out of the scope of this paper; we simply aim to acknowledge the necessary tension faced in setting up programs to aid marginalized communities. Queer in AI believes it is nonetheless important to provide concrete aid right now to applicants faced with the current system, even if doing so reinforces undesirable structures. A just approach to accessing higher education would include abolishing application fees and costly standardized tests, as well as uplifting diverse institutions outside of traditional centers of academic power such as the US, Canada, and Western Europe. Data collected from Queer in AI's surveys have been used to argue that departments should eliminate the GRE and application fees.

## 4.2 Workshops and Socials

In STEM disciplines, conferences can be a hostile setting for minoritized groups [84, 103, 133]. Queer in AI members in 2022 rated how welcome they felt attending AI conferences at 3.38 on average ( ùúá 1 / 2 = 3) on a five-point Likert scale (¬ß ?? ). Recognizing this need, Queer in AI has organized workshops and networking events since

2 While fees and standardized tests are the norms at many prominent institutions, there are examples of alternative paths, such as the ELLIS PhD Program, a European initiative for AI/ML PhD programs, which requires neither [45].

its very first informal meetup at NeurIPS 2017: as of submission, 13 workshops and 35 social events in total (Table 4), with a cumulative attendance of hundreds of participants. 3 These events provide an opportunity to connect and network with other queer scientists, spotlight work by members of Queer in AI, host talks on topics relevant to its members, and arrange panels where experts discuss topics at the intersection of AI, fairness, ethics, and the queer community. The following subsections cover how Queer in AI's principles influence event planning and enable them to overcome challenges in the process.

4.2.1 Workshop Organizing. Queer in AI workshops and socials are typically organized by members of the community planning to attend the conference; no prior academic or organizing experience is required. Junior or new members of the community are often encouraged to lead these initiatives while being mentored by more experienced organizers throughout the process. Organizers, DEIAs, and Queer in AI's financial stewards coordinate to secure logistical, monetary and other miscellaneous needs of the event. These include renting equipment to support accessibility, honoraria for speakers, scholarships for attendees, refreshments for socials, online outreach and promotion of the event, and so on. All of this communication takes place asynchronously over Slack, or in Zoom meetings scheduled across organizers' time zones. This decentralized approach also helps enable Queer in AI members spanning different sub-fields in AI to tailor events to represent and serve the needs of their sub-community. When prompted to rate how welcome they felt at these workshops, the response was overwhelmingly positive, with about 47% of queer attendees rating it five out of five on a Likert scale ( ùúá =4.16, ùúá 1 / 2 =4) (¬ß ?? ).

4.2.2 Panels and Talks at Workshops. Panels and talks at Queer in AI's workshops cover a wide variety of subjects and interests and follow a bottom-up approach for topic selection. Once organizers advertise a call to solicit topics over the Slack workspace, individual community members propose topics and take responsibility for

3 An exact count could not be obtained: to maintain attendees' privacy, Queer in AI does not require signups for most events, and deletes names immediately after events when they are required.

Table 4: Workshop and events organized by Queer in AI in 2017-2022 across conferences in AI. Events marked with p were held in person, v indicates virtual-only events, and h refers to events that occurred in a 'hybrid' format.

| Year                      | 2017 2018     | 2019                                    | 2020                                                                                    | 2021                                                                          | 2022                                                   |
|---------------------------|---------------|-----------------------------------------|-----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|--------------------------------------------------------|
| Workshops                 | - 1 NeurIPS p | 2 ICML p NeurIPS p 2 NeurIPS v ICML v   |                                                                                         | 3 EMNLP v ‚Ä† ICML v NeurIPS v                                                  | 5 FAccT h ‚Ä° ICLR v ICML h NAACL h NeurIPS h            |
| Social Events 1 NeurIPS p | 1 NeurIPS p   | 5 ACL p CVPR p ICML p NAACL p NeurIPS p | 11 AAAI p AACL v ACL v CogSci v COLING v CORL v EMNLP v FAccT p ICLR v ICML v NeurIPS v | 10 AAAI v ACL v CoRL v EACL v EMNLP v ICLR v ICML v NAACL v NeurIPS v SIGIR v | 7 AAAI v AAMAS v ACL h ICLR v ICML h NAACL h NeurIPS h |

‚Ä† at EMNLP 2021, Queer in AI co-hosted a workshop with WiNLP.

‚Ä° at FAccT, Queer in AI hosted two CRAFT sessions.

compiling a list of potential speakers. This encourages a participatory approach to workshop design: instead of limiting selection to a closed organizing committee, Queer in AI workshops act as a space where community members can co-design the theme of the workshop. Similarly, organizers of the workshop are encouraged to select speakers in a transparent and open process and to promote marginalized voices in all workshops. This approach has allowed Queer in AI to host panels and talks on intersectional topics that often do not have a presence at major AI/ML venues (for just one example, a discussion on the intersection of queerness, caste and AI at NeurIPS 2021 [98]). These panels and talks have taken place in online, hybrid, and in-person settings, bringing together marginalized voices from around the world with Queer in AI members, facilitating social serendipity, solidarity and a sense of belonging for community members sharing their identity with the speakers (cf. Figure ?? ). Queer in AI compensates all invited speakers fairly for their efforts, as opposed to the norm of treating it as 'service' or unpaid labor. Their pay is scaled proportionally to the length of their talk or panel, regardless of seniority, and speakers are regularly provided travel funding for in-person events.

4.2.3 Barriers and Challenges in Participation. AI conferences are often not accessible for a sizable portion of queer researchers, especially those belonging to other marginalized backgrounds or from countries with lower purchasing power or higher rates of discrimination towards queer people [126]. Primary reasons includes high registration and travel costs. Out of all Queer in AI members who reported being unable to attend conferences owing to lack of funding, 88% identified as one of Black, indigenous, person of color, transgender, neurodivergent, or disabled (¬ß ?? ). While Queer in AI tries to work with conference organizers to use DEI funds for increasing the attendance of queer scientists, in many cases conference organizers refuse to engage with Queer in AI's requests. Queer in AI thus often provides a combination of travel grants, registration waivers, and reimbursement for conference-related expenses to queer AI researchers. In other cases, unofficial social events 4 near the conference venue and online virtual socials on gather.town are organized to accommodate excluded time zones and overcome both financial and geographical access barriers. Other barriers specific to the conference location, such as unsafe legal and social climates 5

4 These events are not officially included within the conference program but promoted over Queer in AI's Slack and mailing list as well as social media. A recent example is AAAI 2023 where the conference fees was exorbitantly high and negligible effort was put into provision for registration waivers.

5 EMNLP 2022 (in Abu Dhabi) predatorily included Queer in AI to obtain their approval for conference safety measures; Queer in AI rejected this, due to the conference

for queer people or exclusionary visa processes, continue to significantly limit queer participation within AI spaces. Finally, for conferences which are poorly equipped in their support for disabled people, Queer in AI provides live captions for all in-person and virtual events, and secures equipment to create accessible spaces.

## 4.3 Inclusive Conference Guide

As conferences moved online in response to the COVID-19 pandemic, Queer in AI organizers noted a series of operational failures that could cause queer attendees to feel unsafe or unwelcome. Registration platforms demanded attendees to provide their legal names, thus potentially deadnaming them; the use of pronoun badges for speakers and attendees was rarely encouraged, or platforms did not support displaying pronouns; virtual chat software blocked common queer terms such as 'queer' or 'lesbian', thus preventing queer attendees from communicating freely. Queer in AI organizers worked closely with many conferences to resolve these issues, as they had in prior settings (¬ß4.2), and ultimately decided to collect recommendations aimed at highlighting best practices to ensure safety, privacy, and accessibility for queer attendees at academic conferences in AI in a collected guidance document. 6

These recommendations began based on existing best practices and experience with conference organizers, but were refined through extensive iterative feedback from members of Queer in AI and other affinity groups, incorporating many opinions and ultimately achieving consensus among a broad group of contributors. The guide has recently been expanded to also cover in-person events as conferences move to hybrid or in-person formats. Broadly, it covers three aspects of conference planning: operational guidelines to ensure queer attendees feel safe and welcome throughout the event, diversity efforts to establish how to achieve LGBTQIA+ representation among speakers and attendees, and proceeding guidelines particularly related to the names of transgender and gender-diverse authors.

Part 1: Operational Guidelines As in any public space, queer conference-goers might face discrimination based on their gender and sexual orientation. Therefore, it is paramount for attendees to be able to control what information they wish to disclose to the organizers and attendees of a conference. The guide thus describes mechanisms to (i) respect attendees' identities by collecting gender and pronoun information in a manner that does not misrepresent or

operating at a different domain of power for trans people and the power inherent in speaking for the entire queer community.

6 The guide, originally published as [100], is a living document available at queerinai. com/how-to-make-virtual-conferences-queer-friendly.

erase queer identities, by creating forms with inclusive gender categories and disclosing the data usage [105] (ii) minimize the amount of personal information queer individuals have to disclose [7] (for example, only collecting legal names when absolutely necessary, and using responses about the gender and sexuality of attendees only for statistical purposes and in anonymized form); and (iii) ensure that mechanisms to report disruptive or harmful behaviours are swift and effective. The guide explicitly recommends adopting a code of conduct ( e.g. , [99, 131]) to not only establish communication norms, but also describe how policy violations are handled [39].

Part 2: Diversity Efforts Queer researchers's needs are regularly ignored in many aspects of the research community: challenges include lack of academic support, hostility from colleagues and advisors, inflexible name change policies, lack of representation in the research itself, and more [21]. Stronger inclusion efforts, both for representation and participation, can work towards addressing a lack of queer community and role models [108]. To increase representation, the guide strongly encourages conference organizers to invite queer keynote speakers and panelists, particularly those who are also from marginalized backgrounds ( e.g. , BIPOC or non-cisgender) [40]. The guide also recommends fair compensation for all speakers [102], based on effort rather than seniority or session prestige, which is often discriminatory towards members of marginalized groups [51]. Finally, as noted in ¬ß5.2, financial accessibility is a significant barrier that limits conference attendance for queer researchers; to increase participation, the guide recommends ample conference subsidies to cover expenses associated with attending virtual or in-person events.

Part 3: Proceedings Guidelines In its guide, Queer in AI recommends publishers to promptly grant name correction requests in any format, without unnecessary barriers or documentation requirements. Name changes should remove all instances of authors' previous names from all records, or (at the author's discretion) add disclaimers for media that cannot be updated ( e.g. , audio or video recordings). Similarly, the guide encourages that submission processes (calls for papers, submission checklists, automatic formatting checks) enforce automated checks for outdated citation entries to prevent the deadnaming of authors who have updated their publications. The use of platforms that do not properly support author name changes, such as Google Scholar [114, 115], should be actively discouraged.

4.3.1 Critical Reflection. This guide is not without its limitations. Like any decentralized initiative, it is the product of those who championed, and thus focuses on their intersectional identities; for instance, the guide lacks in-depth accessibility recommendations. Because of when the guide was written, most recommendations are still focused on virtual spaces. Most significantly, despite organizers' efforts the guide has seen relatively modest adoption.

## 4.4 Trans-inclusive Publishing Advocacy

For many transgender, non-binary, and gender-diverse scholars (as well as others), the continued circulation of a previous name in publishing is a significant source of trauma [121]. Referring to an author by a previous name without consent (deadnaming) may effectively out their identity against their will. Queer in AI has worked along with the Name Change Policy Working Group [88]

to advocate name change policies in AI venues, helping to establish the name-change policies and procedures now adopted by most AI-related venues [5, 6, 14, 15, 61, 77, 89, 122] (cf. ¬ß ?? for more about Queer in AI's advocacy and impact).

Even publishers with functional name change policies are often woefully slow to implement them, and search engines can index outdated information long after its correction [114, 115]; moreover, authors often use outdated bibliographic entries long after relevant publications and search tools have been updated [119]. It is thus vital to check the correctness of citations in submitted papers to avoid propagating incorrect information. QueerInAI has thus developed a tool to check paper PDFs for mistaken citations. It searches the ACL Anthology, DBLP, and arXiv for a close paper title match, and prompts a correction if the paper's author list disagrees with that source, detecting both deadnaming and incomplete or outdated author lists. DBLP in particular provides better name change support than many other platforms, via ORCID [92]. This toolkit has been integrated into ACL publication camera-ready systems [97], and Queer in AI hopes to expand it to other conferences. A demo is available at qinai-name-check.streamlit.app.

## 5 TENSIONS AND CHALLENGES

As reflexivity is a core tenet of intersectionality [25], this section critically examines the tensions and challenges that emerge in the operationalization of Queer in AI's principles within its initiatives. The three broad themes of hierarchy, accessibility , and funding are critical challenges for any participatory or community-lead AI organization.

## 5.1 Hierarchy

Decentralized organizing plays a vital role in minimizing power distance and distinctions between members of Queer in AI. Even so, there are notable distinctions between members who participate in organizing, core organizers, and the DEIAs as paid contractors. Queer in AI's core organizers and DEIAs help sustain the growth of the organization through mentorship of new volunteers and institutional memory. In addition, they form a relatively large and diverse group for deliberating on rare decisons that cannot be discussed openly, such as those involving PII. Their existence does, however, pose challenges in accessibility for people unfamiliar with navigating unstructured social networks, and can be non-transparent to newer or less involved members. The core organizers also assume a more active role, sharing considerable power in steering the direction of its initiatives. Queer in AI helps address these tensions by setting a fixed one-year tenure for DEIAs, and inducting organizers who have been active throughout the preceding year as core organizers. Resolving tensions between decentralization and hierarchies created by knowledge and experience, or forced by privacy concerns, nonetheless remains an open problem within Queer in AI.

## 5.2 Accessibility

Despite global participation, Queer in AI's structure and operational design can discourage participation for many queer scientists. First, participation in a volunteer-run community not only requires organizers to have income that allows them to perform

free labor, but also have access to computers, internet, and other resources required to even connect with Queer in AI. Second, while Queer in AI strives to be intersectional, it severely lacks access to queer networks in countries from the Global South. It originated and primarily operated within a Western context during its initial years, which led to the inadvertent creation of barriers that limit its outreach. For example, because Queer in AI organizers are best connected with US and European institutions, its events are often co-located at conferences mostly attended by scientists residing in the Global North. Further, its meetings often occur at times best aligned with European and American time zones, at the expense of much of Asia. Finally, all Queer in AI activities require English proficiency.

While recent efforts from the community and focused outreach have reduced some of these barriers, significant work lies ahead in establishing truly global ways of participation, especially for countries where queerness is criminalized. Third, participation in Queer in AI exerts a toll on mental health and exhaustion of its organizers (Figure ?? ). This is partly due to Queer in AI's lack of formal structure, instead relying on individuals self-coordinating on initiatives of their choice. While efficient, this approach can make joining and keeping track of ongoing efforts challenging for newcomers and neurodivergent members of the community. Past organizers have also shared anecdotes of experiencing exhaustion, fatigue and anxiety due to a lack of accommodation of different working styles, and falling behind on personal schedules while undertaking operational work for Queer in AI (see Figure ?? ). This disproportionately impacts disabled and neurodivergent members, and is compounded for those marginalized based on intersecting identities.

Even after years of critical reflection and spending tens of thousands of volunteer hours and hundreds of thousands of dollars on programs to improve accessibility, Queer in AI is still inaccessible to many. While accessibility to everyone should always be the goal, in practice no single community or participatory initiative will be able to include everyone in that community. Participatory researchers aspiring to broad inclusion should consider pluralities of communities and participatory initiatives with radically different structures.

## 5.3 Funding

Funding and payments are where Queer in AI struggles most to meet its commitments to decentralization, intersectionality, and community leadership. Queer in AI relies on sponsorships, donations, and contributions from its parent organization oSTEM to fund its activities. In 2022, Queer in AI expenses totaled US$100,657.69: the graduate application fee scholarship program (¬ß4.1) spent $40,435.42; two DEIA contractors were paid a total of $33,220; speaker honoraria totaled $14,500; $6,941.43 went to travel grants, room and board, and conference registration fees; emergency microgrants for queer people totaled $5,000. Income comprised $78,000 in corporate sponsorship, $13,710.78 in donations, and $5,000 in grant revenue (cf. Appendix ?? provides income and expenses for previous years.).

Queer in AI's reliance on corporate sponsorship may call into question its independence and community-lead ideal. Corporate sponsors receive access to opt-in resume books, short speaking opportunities, and recruiting booths at events. A large part of Queer in AI's funding still comes from big tech corporations that are complicit in oppression and genocide globally, such as the policing of Palestinians. Queer in AI has nonetheless dropped and turned down many sponsors for ethics concerns, including a mutual decision with Black in AI in 2021 to drop Google [64], costing $20,000 in lost sponsorship per year. While Queer in AI has been growing donations, many in the Queer in AI community are students or early in their careers with very limited capacity to give. Opportunities for grants are limited, as many scientific funding bodies such as the US's NSF exclude queer people from many of their D&amp;I initiatives [49].

Payment disbursal in Queer in AI is highly centralized; for reasons of security oSTEM only allows one Queer in AI organizer to send PayPal payments. All wires and credit card payments must be sent by the oSTEM CEO. Additionally, payments strain Queer in AI's intersectional values. PayPal does not work well in China, India, many countries in Africa, and some countries in South America, forcing reliance on slower and more administratively difficult wire transfers. Moreover, U.S. law requires people receiving honoraria and other types of payments to pay US taxes above a certain threshold, which requires a lengthy registration process or significant fees and overhead from Queer in AI. Payments also frequently trigger fraud alerts and investigations, which require even more time from and stress on organizers.

In summary, marginalization prefigures Queer in AI's funding options, legal and security concerns exert a strong centralizing pressure on financial administration, and the financial system regards many payments, especially to non-Western countries and those making them, with suspicion by default.

## 6 CONCLUSION

Participatory methods have the potential to address issues of power and inclusion in AI, but their benefits and challenges in practice are still unclear because few organizations have deeply engaged with them. In this paper we studied Queer in AI as a case study of a grassroots participatory AI organization. We explored how they designed their organization to enable participation, and how initiatives addressing intersectional marginalization arose from and were continuously refined by this participation. We theorized how Queer in AI's numerous socials, workshops, and other events have contributed to a culture of participation in AI by bringing queer people into AI conferences and research and industry settings and resisting predatory inclusion. We hope this case study will inform theoretical study and practical design of participatory initiatives. In particular, we encourage consideration of Queer in AI's reinforcing principles of decentralization, community leadership, and focus on intersectionality, and urge care for mitigating the ways hierarchy, inaccessability, and funding can subvert participatory methods.

## ACKNOWLEDGMENTS

This work would not have been possible without the activism and organizing efforts of the Queer in AI community. We would also like to thank Katta Spiel and Os Keyes for their insightful feedback on the earlier versions of the paper.

## REFERENCES

- [1] 2015. Some African Countries Are Trying to Use Science to Make Homophobic Laws, Now African Scientists are Pushing Back. https://www.smithsonianmag.com/smart-news/africans-scientists-speak-outagainst-homophobic-laws-180955579/
- [2] 2020. A constant uneasy state: Trans people in STEM in India. https:// thelifeofscience.com/2020/11/09/transgender-people-in-science/
- [3] 2022. Brazil LGBTQ activists, HIV/AIDS service providers fear Bolsonaro reelection. https://www.washingtonblade.com/2022/05/19/brazil-lgbtq-activistshiv-aids-service-providers-fear-bolsonaro-reelection/
- [4] Blaise Ag√ºera y Arcas, Margaret Mitchell, and Alexander Todorov. 2017. Physiognomy's New Clothes. https://medium.com/@blaisea/physiognomys-newclothes-f2d4b59fdd6a
- [5] ACL Anthology. (n.d.). Requesting Corrections. https://aclanthology.org/info/ corrections/ [Accessed Feb 2023].
- [6] arXiv. 2021. arXiv Proceedings: Name Change Policy. https://blog.arxiv.org/ 2021/03/11/update-name-change-policy, Name Change Policy blog.
- [7] Alison Barclay and Melissa Russell. 2017. A guide to LGBTIQ-inclusive data collection. https://meridianact.org.au. https://meridianact.org.au/wp-content/ uploads/LGBTIQ-Inclusive-Data-Collection-a-Guide.pdf
- [8] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency . 610-623.
- [9] Abeba Birhane, William Isaac, Vinodkumar Prabhakaran, Mark Diaz, Madeleine Clare Elish, Iason Gabriel, and Shakir Mohamed. 2022. Power to the People? Opportunities and Challenges for Participatory AI. In Equity and Access in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO '22) . Association for Computing Machinery, New York, NY, USA, Article 6, 8 pages. https://doi.org/10.1145/3551624.3555290
- [10] Abeba Birhane, Vinay Uday Prabhu, and Emmanuel Kahembwe. 2021. Multimodal datasets: misogyny, pornography, and malignant stereotypes. arXiv (2021). https://arxiv.org/abs/2110.01963
- [11] Black in AI. 2020. Academic Program. https://blackinai.github.io/#/programs/ academic-program
- [12] Black in AI (n.d.). https://blackinai.github.io
- [13] Su Lin Blodgett, Solon Barocas, Hal Daum√© III, and Hanna Wallach. 2020. Language (Technology) is Power: A Critical Survey of 'Bias' in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 5454-5476. https: //doi.org/10.18653/v1/2020.acl-main.485
- [14] ACM Publications Board. 2019. ACM Publications Policy on Author Name Changes. https://www.acm.org/publications/policies/author-name-changes
- [15] Melisa Bok. 2022. Comment on issue: Transphobic name and email policy. https: //github.com/openreview/openreview/issues/28#issuecomment-1124245541
- [16] Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam Tauman Kalai. 2016. Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings. Advances in Neural Information Processing Systems 29 (2016).
- [17] Yang Trista Cao and Hal Daum√© III. 2020. Toward Gender-Inclusive Coreference Resolution. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics . Association for Computational Linguistics, Online, 4568-4595. https://doi.org/10.18653/v1/2020.acl-main.418
- [18] Logan S Casey, Sari L Reisner, Mary G Findling, Robert J Blendon, John M Benson, Justin M Sayde, and Carolyn Miller. 2019. Discrimination in the United States: Experiences of lesbian, gay, bisexual, transgender, and queer Americans. Health services research 54 (2019), 1454-1466.
- [19] EACechandTJWaidzunas. 2021. Systemic inequalities for LGBTQ professionals in STEM. Science advances 7, 3 (2021), eabe0933.
- [20] Erin A. Cech and Michelle Pham. 2017. Queer in STEM Organizations: Workplace Disadvantages for LGBT Employees in STEM Related Federal Agencies. The Social Sciences 6 (2017), 12.
- [21] Erin A. Cech and Michelle V. Pham. 2017. Queer in STEM Organizations: Workplace Disadvantages for LGBT Employees in STEM Related Federal Agencies. Social Sciences 6, 1 (2017). https://doi.org/10.3390/socsci6010012
- [22] Pia Ceres. 2022. Kids are back in classrooms and laptops are still spying on them. Wired (Aug 2022). https://www.wired.com/story/student-monitoringsoftware-privacy-in-schools/
- [23] Soon Kyu Choi, Shahrzad Divsalar, Jennifer Fl√≥rez-Donado, Krystal Kittle, Andy Lin, Ilan H. Meyer, and Prince Torres-Salazar. 2019. STRESS, HEALTH, AND WELL-BEING OF LGBT PEOPLE IN COLOMBIA. https: //www.ohchr.org/sites/default/files/Documents/Issues/SexualOrientation/ IESOGI/Academics/1912\_Colombia\_Report\_English\_FINAL.pdf
- [24] Camille Cobb, Ted McCarthy, Annuska Perkins, Ankitha Bharadwaj, Jared Comis, Brian Do, and Kate Starbird. 2014. Designing for the deluge: understanding &amp; supporting the distributed, collaborative work of crisis volunteers. In Proceedings of the 17th ACM conference on Computer supported cooperative work
25. &amp; social computing . 888-899.
- [25] Patricia Hill Collins. 2019. Intersectionality as critical social theory . Duke University Press.
- [26] Patricia Hill Collins and Sirma Bilge. 2020. Intersectionality . John Wiley &amp; Sons.
- [27] Susan E Collins, Seema L Clifasefi, Joey Stanton, Kee JE Straits, Eleanor GilKashiwabara, Patricia Rodriguez Espinosa, Andel V Nicasio, Michele P Andrasik, Starlyn M Hawes, Kimberly A Miller, et al. 2018. Community-based participatory research (CBPR): Towards equitable involvement of community in psychology research. American Psychologist 73, 7 (2018), 884.

[28]

Bill Cooke and Uma Kothari. 2001.

Participation

. Zed Books, London, England.

- [29] Sasha Costanza-Chock. 2018. Design justice: Towards an intersectional feminist framework for design theory and practice. Proceedings of the Design Research Society (2018).
- [30] Jakub Dalek, Nica Dumlao, Miles Kenyon, Irene Poetranto, Adam Senft, Caroline Wesley, Arturo Filast√≤, Maria Xynou, and Amie Bishop. 2021. No Access: LGBTIQ Website Censorship in Six Countries. (2021). https://citizenlab.ca/2021/08/noaccess-lgbtiq-website-censorship-in-six-countries/
- [31] Deep Learning Indaba 2017. https://deeplearningindaba.com/2021/
- [32] Sunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Arjun Subramonian, Jeff Phillips, and Kai-Wei Chang. 2021. Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing . Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 1968-1994. https://doi.org/10.18653/v1/2021.emnlp-main.150
- [33] Michael A DeVito, Ashley Marie Walker, and Jeremy Birnholtz. 2018. 'Too Gay for Facebook': Presenting LGBTQ+ Identity Throughout the Personal Social Media Ecosystem. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 1-23.
- [34] Michael A DeVito, Ashley Marie Walker, Caitlin Lustig, Amy J Ko, Katta Spiel, Alex A Ahmed, Kimberley Allison, Morgan Scheuerman, Briana Dym, Jed R Brubaker, et al. 2020. Queer in HCI: Supporting LGBTQIA+ Researchers and Research Across Domains. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems . 1-4.
- [35] Catherine D'ignazio and Lauren F Klein. 2020. Data feminism . MIT press.
- [36] Diversity in AI (n.d.). http://www.diverseinai.org
- [37] Jesse Dodge, Maarten Sap, Ana Marasoviƒá, William Agnew, Gabriel Ilharco, Dirk Groeneveld, Margaret Mitchell, and Matt Gardner. 2021. Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus. arXiv preprint arXiv:2104.08758 (Nov. 2021), 1286-1305. https://doi.org/10.18653/v1/ 2021.emnlp-main.98
- [38] Jack Drescher. 2015. Out of DSM: Depathologizing homosexuality. Behavioral sciences 5, 4 (2015), 565-575.
- [39] Ashe Dryden. 2013. CODES OF CONDUCT 101 + FAQ. Link.
- [40] Ashe Dryden. 2013. Increasing Diversity at Your Conference. Link.
- [41] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S. Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference . https://doi.org/10.1145/2090236. 2090255
- [42] Russell Rowe Dynes. 1970. Organized behavior in disaster . Heath Lexington Books.
- [43] Brenda Eichelberger, Heather Mattioli, and Rachel Foxhoven. 2017. Uncovering Barriers to Financial Capability: Underrepresented Students' Access to Financial Resources. Journal of Student Financial Aid 47, 3 (2017), 5.
- [44] Val Elefante. 2021. Lips. Queer in AI Workshop at International Conference on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml2021#h.lx7wo16mt2ax
- [45] ELLIS. 2022. ELLIS PhD Program: Call for applications 2022. https://ellis.eu/ news/ellis-phd-program-call-for-applications-2022
- [46] Myra Marx Ferree. 2016. The discursive politics of feminist intersectionality. In Framing Intersectionality . Routledge, 55-65.
- [47] Michelle Fine and Mar√≠a Elena Torre. 2006. Intimate details: Participatory action research in prison. Action Research 4, 3 (2006), 253-269.
- [48] Luciano Floridi. 2019. Establishing the rules for building trustworthy AI. Nature Machine Intelligence 1, 6 (2019), 261-262.
- [49] Jon Freeman. 2023. Letter to the NSF Director. https://static1.squarespace. com/static/545d3fabe4b0811b5cc48193/t/63c867aefb89f3761070a5a3/ 1674078140137/Letter+to+NSF+Director+-+LGBTQ%2B+Data\_redacted.pdf
- [50] Jonathan B. Freeman. 2020. Measuring and Resolving LGBTQ Disparities in STEM. Policy Insights from the Behavioral and Brain Sciences 7 (2020), 141 - 148.
- [51] Paolo Gaudiano. 2021. Exposure doesn't pay: Why tech conferences should compensate their speakers. https://www.forbes.com/sites/paologaudiano/2021/ 06/07/how-to-make-conference-speaker-fees-more-inclusive-and-equitable/. https://www.forbes.com/sites/paologaudiano/2021/06/07/how-to-makeconference-speaker-fees-more-inclusive-and-equitable/
- [52] Timnit Gebru and Emily Denton. 2021. Beyond Fairness. https://neurips.cc/ virtual/2021/tutorial/21889
- [53] Christine Geeng, Mike Harris, Elissa Redmiles, and Franziska Roesner. 2021. Queer Security Advice in the US. (2021).

- [54] A Gomes, D Antonialli, and T Dias-Oliva. 2019. Drag queens and artificial intelligence. Should computers decide what is toxic on the internet. Internet Lab blog (2019). https://internetlab.org.br/en/news/drag-queens-and-artificialintelligence-should-computers-decide-what-is-toxic-on-the-internet/
- [55] Mary L Gray and Siddharth Suri. 2019. Ghost work: How to stop Silicon Valley from building a new global underclass . Eamon Dolan Books.
- [56] LW Green, MA George, et al. 2003. Appendix C: Guidelines for participatory research in health promotion. In Community-based participatory research for health , M. Minkler and N. Wallerstein (Eds.). San Francisco, CA, Jossey-Bass.
- [57] Christina E. Gringeri, St√©phanie Wahab, and Ben Anderson-Nathe. 2010. What Makes it Feminist?: Mapping the Landscape of Feminist Social Work Research. Affilia 25, 4 (2010), 390-405. https://doi.org/10.1177/0886109910384072 arXiv:https://doi.org/10.1177/0886109910384072
- [58] Kevin Guyan. 2022. Fixing the Wrong Problems: Queer Communities and the False Promise of Unbiased and Equal Data Systems. European Data Protection Law Review 8, 4 (2022). https://doi.org/10.21552/edpl/2022/4/5
- [59] Karen Hacker and J. Glover Taylor. 2011. Community-Engaged Research 101. https://catalyst.harvard.edu/publications-documents/communityengaged-research-101-2/
- [60] Oliver Haug. 2021. TikTokers Are Using Grindr to Out LGBTQ+ Olympians, Potentially Endangering Their Lives. Them (2021). https://www.them.us/story/ tiktokers-use-grindr-out-lgbtq-olympians/
- [61] IEEE. (n.d.). IEEE Author Name Change Policy. https://conferences. ieeeauthorcenter.ieee.org/author-ethics/guidelines-and-policies/ieee-authorname-change-policy/ [Accessed Feb 2023].
- [62] DisAbility in AI. (n.d.). https://elesa.github.io/ability\_in\_AI
- [63] Indigenous in AI (n.d.). https://indigenousinai.org/
- [64] Khari Johnson. 2021. Black and Queer AI Groups Say They'll Spurn Google Funding. Wired (2021). https://www.wired.com/story/black-queer-ai-groupsspurn-google-funding/
- [65] Khari Johnson. 2022. How Wrongful Arrests Based on AI Derailed 3 Men's Lives. Wired (2022). https://www.wired.com/story/wrongful-arrests-ai-derailed-3mens-lives/
- [66] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin ≈Ω√≠dek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A A Kohl, Andrew J Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. 2021. Highly accurate protein structure prediction with AlphaFold. Nature 596, 7873 (2021), 583-589. https://doi.org/10.1038/s41586-021-03819-2
- [67] Pratyusha Kalluri. 2020. Don't ask if artificial intelligence is good or fair, ask how it shifts power. Nature 583, 169 (2020).
- [68] Michael Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler, Aaron Tam, Corinne Bintz, Daniella Raz, and PM Krafft. 2020. Toward situated interventions for algorithmic equity: lessons from the field. In Proceedings of the 2020 conference on fairness, accountability, and transparency . 45-55.
- [69] Os Keyes. 2018. The misgendering machines: Trans/HCI implications of automatic gender recognition. Proceedings of the ACM on human-computer interaction 2, CSCW (2018), 1-22. https://doi.org/10.1145/3274357
- [70] Os Keyes. 2019. Counting the Countless: Why data science is a profound threat for queer people. Real Life 2 (2019).
- [71] Os Keyes, Zo√´ Hitzig, and Mwenza Blell. 2021. Truth from the machine: artificial intelligence and the materialization of identity. Interdisciplinary Science Reviews 46 (2021), 158 - 175.
- [72] Khipu. (n.d.). https://khipu.ai/committee-2023/
- [73] Andrey Kormilitzin, Nenad Tomasev, Kevin R McKee, and Dan W Joyce. 2023. A participatory initiative to include LGBT+ voices in AI for mental health. Nature Medicine (2023), 1-2.
- [74] Gary A Kreps and Susan Lovegren Bosworth. 1994. Organizing, role enactment, and disaster: A structural theory . University of Delaware Press.
- [75] Katie Langin. 2023. NSF still won't track sexual orientation among scientific workforce, prompting frustration. https://www.science.org/content/article/nsfstill-won-t-track-sexual-orientation-among-scientific-workforce-prompting
- [76] LatinX in AI (n.d.). https://www.latinxinai.org
- [77] Neil Lawrence. 2021. Comment on pull request: Fix author name. https: //github.com/mlresearch/v119/pull/4#issuecomment-760081621
- [78] Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman, Ashley Cordes, Joel Davison, et al. 2020. Indigenous protocol and artificial intelligence position paper. (2020).
- [79] Yanan Long. 2021. Automatic Gender Recognition: Perspectives from Phenomenological Hermeneutics. Queer in AI Workshop at International Conference on Machine Learning 2021 (2021). https://sites.google.com/view/queer-inai/icml-2021#h.lx7wo16mt2ax
- [80] Christina Lu, Jackie Kay, and Kevin McKee. 2022. Subverting machines, fluctuating identities: Re-learning human categorization. In 2022 ACM Conference on Fairness, Accountability, and Transparency . 1005-1015.
- [81] Sarah Maiter, Laura Simich, Nora Jacobson, and Julie Wise. 2008. Reciprocity: An ethic for community-based participatory action research. Action research 6, 3 (2008), 305-325.
- [82] Miranda Marquit. 2018. Survey: 60% of LGBTQ Student Borrowers Regret Taking Out Student Loans. (2018). https://www.lendingtree.com/student/lgbtqstudent-borrowers-regret-loans-survey/
- [83] Masakhane (n.d.). https://www.masakhane.io
- [84] Lyndsey McMillon-Brown. 2021. Implementing diversity, equity and inclusion efforts at conferences. Nature Energy 6, 11 (2021), 1000-1002.
- [85] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. A Survey on Bias and Fairness in Machine Learning. ACM Comput. Surv. 54, 6, Article 115 (jul 2021), 35 pages. https://doi.org/10.1145/ 3457607
- [86] Doug Meyer. 2015. Violence against queer people: Race, class, gender, and the persistence of anti-LGBT discrimination . Rutgers University Press.
- [87] Muslims in ML. (n.d.). http://www.musiml.org/
- [88] Name Change Policy Working Group (n.d.). Name Change Policy Working Group. https://ncpwg.org/
- [89] NeurIPS. (n.d.). NeurIPS Proceedings: Name Change Policy. https://papers.nips. cc/, 'Name Change Policy' link in footer [Accessed Feb 2023].
- [90] North Africans in ML. (n.d.). https://sites.google.com/view/northafricansinml
- [91] Molly Olmstead. 2021. A Prominent Priest Was Outed for Using Grindr. Experts Say It's a Warning Sign. Slate (2021). https://slate.com/technology/2021/07/ catholic-priest-grindr-data-privacy.html
- [92] ORCID (n.d.). Open Researcher and Contributor ID (ORCID). https://orcid.org/
- [93] Matt Payton. 2021. Egyptian police 'are using Grindr to find and arrest LGBT people'. The Independent (2021). https://www.independent.co.uk/news/world/ africa/egyptian-police-grindr-dating-app-arrest-lgbt-gay-antigay-lesbianhomophobia-a7211881.html
- [94] Billy Perrigo. 2023. OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic. Time (2023). https://time.com/6247678/openaichatgpt-kenya-workers/
- [95] Anthony T Pinter, Morgan Klaus Scheuerman, and Jed R Brubaker. 2021. Entering Doors, Evading Traps: Benefits and Risks of Visibility During Transgender Coming Outs. Proceedings of the ACM on Human-Computer Interaction 4, CSCW3 (2021), 1-27.
- [96] Anastasia Powell, Adrian J Scott, and Nicola Henry. 2020. Digital harassment and abuse: Experiences of sexuality and gender minority adults. European journal of criminology 17, 2 (2020), 199-223.
- [97] ACL Pubcheck. (n.d.). https://github.com/acl-org/aclpubcheck [Accessed Feb 2023].
- [98] Queer in AI at NeurIPS 2021. http://queerinai.org/neurips-2021
- [99] Queer in AI Organizers. 2019. Code of Conduct. https://sites.google.com/view/ queer-in-ai/code-of-conduct.
- [100] Organizers of QueerInAI, A Pranav, MaryLena Bleile, Arjun Subramonian, Luca Soldaini, Danica J. Sutherland, Sabine Weber, and Pan Xu. 2021. How to Make Virtual Conferences Queer-Friendly: A Guide. In Proceedings of the 2021 Workshop on Widening NLP . Conference on Empirical Methods in Natural Language Processing, Punta Cana, Dominican Republic. queerinai.org/diversity-guide
- [101] Suman Ravuri, Karel Lenc, Matthew Willson, Dmitry Kangin, Remi Lam, Piotr Mirowski, Megan Fitzsimons, Maria Athanassiadou, Sheleem Kashem, Sam Madge, et al. 2021. Skilful precipitation nowcasting using deep generative models of radar. Nature 597, 7878 (2021), 672-677.
- [102] Eva Reid. 2021. How To Make Conference Speaker Fees More Inclusive And Equitable. hhttps://technical.ly/2021/07/22/conferences-pay-speakers//. https: //technical.ly/2021/07/22/conferences-pay-speakers/
- [103] Christina R. Richey, Katharine M N Lee, Erica M. Rodgers, and Kathryn B. H. Clancy. 2019. Gender and sexual minorities in astronomy and planetary science face increased risks of harassment and assault. Bulletin of the American Astronomical Society 51 (2019), 0206.
- [104] Nancy Russell, Susan Igras, Nalin Johri, Henrietta Kuoh, Melinda Pavin, and Jane Wickstrom. 2008. ACQUIRE Project Working Paper. https://pdf.usaid. gov/pdf\_docs/Pnadm497.pdf
- [105] Morgan Klaus Scheuerman, Aaron Jiang, Katta Spiel, and Jed R. Brubaker. 2021. Revisiting Gendered Web Forms: An Evaluation of Gender Inputs with (Non)Binary People. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama, Japan) (CHI '21) . Association for Computing Machinery, New York, NY, USA, Article 400, 18 pages. https://doi.org/10.1145/ 3411764.3445742
- [106] Morgan Klaus Scheuerman, Madeleine Pape, and Alex Hanna. 2021. Autoessentialization: Gender in automated facial analysis as extended colonial project. Big Data &amp; Society 8, 2 (2021), 20539517211053712.
- [107] Morgan Klaus Scheuerman, Jacob M Paul, and Jed R Brubaker. 2019. How computers see gender: An evaluation of gender classification in commercial facial analysis services. Proceedings of the ACM on Human-Computer Interaction

- 3, CSCW (2019), 1-33.
- [108] Natalie Schluter. 2018. The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing . 2793-2798.
- [109] Sarah Schulman. 2021. Let the Record Show: A Political History of ACT UP New York, 1987-1993 . Farrar, Straus and Giroux.
- [110] Tom Simonite. 2021. AI and the List of Dirty, Naughty, Obscene, and Otherwise Bad Words. Wired (2021). https://www.wired.com/story/ai-list-dirty-naughtyobscene-bad-words/
- [111] Mona Sloane, Emanuel Moss, Olaitan Awomolo, and Laura Forlano. 2022. Participation Is Not a Design Fix for Machine Learning. In Equity and Access in Algorithms, Mechanisms, and Optimization (Arlington, VA, USA) (EAAMO '22) . Association for Computing Machinery, New York, NY, USA, Article 1, 6 pages. https://doi.org/10.1145/3551624.3555285
- [112] Shakira Smith, Oliver L Haimson, Claire Fitzsimmons, and Nikki Echarte Brown. 2021. Censorship of Marginalized Communities on Instagram. Salty (2021). https://saltyworld.net/exclusive-report-censorship-of-marginalizedcommunities-on-instagram-2021-pdf-download/
- [113] Dean Spade. 2020. Mutual aid: Building solidarity during this crisis (and the next) . Verso Books.
- [114] Robyn Speer. 2021. Google Scholar deadnames trans authors and obstructs their name change. Link. https://docs.google.com/document/d/ 1st05rXL1wcBBdgcMVqgN0X3L-6HGqORGfgnHMfXHKvE
- [115] Robyn Speer. 2021. Google Scholar has failed us. (2021). https://scholar.hasfailed. us/
- [116] Kate Starbird and Leysia Palen. 2011. "Voluntweeters" self-organizing by digital volunteers in times of crisis. In Proceedings of the SIGCHI conference on human factors in computing systems . 1071-1080.
- [117] Luke Stark and Jevan Hutson. 2021. Physiognomic Artificial Intelligence. Available at SSRN 3927300 32, 4 (2021), 922.
- [118] Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen, Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, and Catherine D'Ignazio. 2022. Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection. In 2022 ACM Conference on Fairness, Accountability, and Transparency (Seoul, Republic of Korea) (FAccT '22) . Association for Computing Machinery, New York, NY, USA, 667-678. https: //doi.org/10.1145/3531146.3533132
- [119] Danica J. Sutherland. 2022. Name Change Policies: A Brief (Personal) Tour. Queer in AI workshop, NeurIPS 2022; https://djsutherland.ml/slides/qai-namechange.
- [120] Rajesh Tandon. 1988. Social transformation and participatory research. Convergence 21, 2 (1988), 5.
- [121] Theresa Jean Tanenbaum, Irving Rettig, H Michael Schwartz, BM Watson, Teddy G Goetz, Katta Spiel, and Mike Hill. 2021. A vision for a more transinclusive publishing world: guest article. Committee on Publication Ethics. https: //publicationethics.org/news/vision-more-trans-inclusive-publishing-world.
- [122] NAACL DEI Team. (n.d.). NAACL Citation Name Change Procedure. https: //2021.naacl.org/blog/name-change-procedure/ [Accessed Feb 2023].
- [123] Nenad Tomasev, Kevin R McKee, Jackie Kay, and Shakir Mohamed. 2021. Fairness for Unobserved Characteristics: Insights from Technological Impacts on Queer Communities. arXiv preprint arXiv:2102.04257 (2021). https://doi.org/10.1145/ 3461702.3462540
- [124] Paige Yes Treebridge. 2021. Crowdsourcing a Corpus of Dogwhistle Transphobia. Queer in AI Workshop at International Conference on Machine Learning 2021 (2021). https://sites.google.com/view/queer-in-ai/icml-2021#h.lx7wo16mt2ax
- [125] Fangjing Tu. 2022. What can we learn from longitudinal studies on the impacts of college internships? https://ccwt.wisc.edu/wpcontent/uploads/2022/04/Final\_CCWT\_report\_LR-What-can-we-learnfrom-longitudinal-studies-on-the-impacts-of-college-internships.pdf
- [126] Ayesha IT Tulloch. 2020. Improving sex and gender identity equity and inclusion at conservation and ecology conferences. Nature Ecology &amp; Evolution 4, 10 (2020), 1311-1320.
- [127] Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran, George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer, et al. 2019. Applications of machine learning in drug discovery and development. Nature Reviews Drug discovery 18, 6 (2019), 463-477.
- [128] Lindsay Weinberg. 2022. Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches. Journal of Artificial Intelligence Research 74 (2022), 75-109.
- [129] Widening NLP (n.d.). http://www.winlp.org
- [130] Bianca DM Wilson, Soon Kyu Choi, Gary W Harper, Marguerita Lightfoot, Stephen Russell, and Ilan H Meyer. 2020. Homelessness among LGBT adults in the US. https://williamsinstitute.law.ucla.edu/publications/lgbt-homelessnessus/
- [131] Women in Machine Learning. 2021. Code of Conduct. https://wimlworkshop. org/conduct/.
- [132] Women in Machine Learning (n.d.). https://wimlworkshop.org
- [133] Aman Yadav, Christopher D Seals, Cristina M Soto Sullivan, Michael Lachney, Quintana Clark, Kathy G Dixon, and Mark JT Smith. 2020. The forgotten scholar:

underrepresented minority postdoc experiences in STEM fields. Educational Studies 56, 2 (2020), 160-185.