---
title: "Singh 2025 reparative"
original_document: Singh_2025_reparative.md
document_type: Conference Paper
research_domain: AI Ethics
methodology: Mixed Methods
keywords: AI harm reparation, justice frameworks, accountability, responsible AI, stakeholder analysis
mini_abstract: "This paper develops a taxonomy of reparative actions following AI-caused harm by analyzing 1,060 incidents through justice frameworks. Findings reveal that current responses concentrate on symbolic acknowledgment rather than meaningful accountability or systemic reform."
target_audience: Researchers, Policymakers, Industry
key_contributions: "Framework for evaluating AI harm reparation adequacy"
geographic_focus: Global
publication_year: 2025
related_fields: AI Governance, Social Justice, Organizational Accountability
summary_date: 2025-11-07
language: English
ai_model: claude-haiku-4-5
---

# Summary: Singh 2025 reparative

## Overview

This paper addresses a fundamental blind spot in Responsible AI research: what happens after AI systems cause documented harm. While the RAI community has invested considerable effort in identifying, characterizing, and auditing AI harms, remarkably little scholarly attention has focused on the subsequent phase—reparative action. The authors argue that this oversight has allowed a troubling pattern to emerge: organizations frequently engage in symbolic compliance (disclosure, acknowledgment) while avoiding substantive accountability or systemic reform. Using the NYC hiring algorithm disclosure law as a cautionary example, they demonstrate how formal regulatory compliance can mask the absence of meaningful redress for affected parties. This paper systematically maps reparative actions across 1,060 documented AI incidents using a four-stage taxonomy grounded in justice theory.

## Main Findings

The analysis reveals a stark asymmetry in reparative efforts distributed across four sequential stages: (1) acknowledging harm, (2) attributing responsibility, (3) providing remedies, and (4) enabling systemic change. Most responses concentrate in stage one (acknowledgment)—the earliest and least demanding stage—with severely limited progression through subsequent stages. The research demonstrates that reparation efforts rarely advance beyond symbolic recognition toward accountability or structural reform. Stakeholder involvement is unequally distributed across stages, with affected parties having minimal agency in later, more consequential stages. Critically, the findings show that existing approaches fall short of delivering justice according to punitive, restorative, and transformative justice standards. This pattern indicates that without deliberate intervention, AI governance mechanisms may perpetuate cycles of harm acknowledgment without genuine accountability or systemic change.

## Methodology/Approach

The authors employ a mixed-methods approach grounded in justice theory. They develop a comprehensive taxonomy organizing reparative actions into four overarching goals: acknowledging harm, attributing responsibility, providing remedies, and enabling systemic change. This taxonomy serves as an analytical framework for categorizing observed responses. The theoretical foundation draws from three justice frameworks—punitive justice (accountability/consequences), restorative justice (victim restoration/relationship repair), and transformative justice (systemic structural change)—borrowed from criminology and social justice scholarship. These frameworks provide normative standards against which to evaluate reparative adequacy. The quantitative component analyzes 1,060 AI-related incidents, examining the prevalence of each reparative action type, stage progression patterns, and stakeholder involvement distribution across different reparative stages.

## Relevant Concepts

**Reparative Action:** The process of remedying harm caused by AI systems and restoring justice for affected parties, grounded in normative justice theory rather than pragmatic problem-solving.

**Four-Stage Reparative Taxonomy:** (1) Acknowledging harm—recognizing that damage occurred; (2) Attributing responsibility—identifying accountable parties; (3) Providing remedies—delivering concrete redress to victims; (4) Enabling systemic change—implementing structural reforms preventing recurrence.

**Symbolic Compliance:** Formal adherence to regulatory requirements that creates appearance of accountability without substantive reform or meaningful redress.

**Accountability Gap:** The disconnect between recognizing harm and implementing genuine accountability mechanisms, allowing organizations to maintain legitimacy while avoiding structural change.

**Justice Frameworks:** Punitive justice emphasizes consequences and accountability; restorative justice prioritizes victim restoration and relationship repair; transformative justice seeks systemic structural change addressing root causes.

## Significance

This work represents a critical intervention in RAI discourse by reorienting attention from harm identification toward post-harm response and reparative adequacy. By importing justice frameworks from criminology into AI ethics, the paper establishes normative standards for evaluating whether reparative actions constitute meaningful justice. The empirical evidence of concentrated symbolic compliance in early stages provides crucial documentation of the accountability gap in AI governance. The four-stage taxonomy offers a diagnostic tool for assessing reparative completeness. Most significantly, this research establishes foundations for advancing prescriptive frameworks—moving RAI beyond descriptive analysis toward actionable standards for meaningful reparation. For policymakers, technologists, and affected communities, this work provides both diagnostic clarity about current inadequacies and theoretical grounding for demanding substantive justice across all reparative stages.
