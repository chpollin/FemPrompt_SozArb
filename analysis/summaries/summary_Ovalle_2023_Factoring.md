---
title: "Ovalle 2023 Factoring"
original_document: Ovalle_2023_Factoring.md
document_type: Literature Review
research_domain: AI Ethics, AI Bias & Fairness
methodology: Literature Review, Comparative Analysis, Theoretical
keywords: intersectionality, AI fairness, structural oppression, epistemology, critical framework
mini_abstract: "This paper critiques AI fairness research for narrowly operationalizing intersectionality as technical subgroup metrics rather than engaging it as a critical framework for examining structural oppression. The authors argue that adopting intersectionality's praxis-oriented approach is essential for just AI development."
target_audience: Researchers, Policymakers, Practitioners
key_contributions: "Bridging critical theory with AI fairness through epistemological analysis"
geographic_focus: North America
publication_year: Unknown
related_fields: Critical Theory, Feminist Studies, Decolonial Studies
summary_date: 2025-11-07
language: English
ai_model: claude-haiku-4-5
---

# Summary: Ovalle 2023 Factoring

## Overview

This paper by Ovalle, Subramonian, Gee, Gautam, and Chang presents a critical examination of how intersectionality—a foundational framework from critical scholarship—is adopted and operationalized within AI fairness research. The authors argue that contemporary AI fairness literature fundamentally misappropriates intersectionality by reducing it to a technical problem of protecting intersectional demographic subgroups, rather than engaging with it as a critical analytical framework designed to expose and challenge structural oppression. The paper challenges the epistemological foundations of AI fairness research itself, contending that the field's positivist orientation—inherited from colonial scientific traditions—is fundamentally incompatible with intersectionality's praxis-oriented, power-conscious methodology. This incompatibility produces fairness interventions that fail to address systemic inequalities at their root, particularly regarding how multiple, interlocking systems of oppression operate simultaneously.

## Main Findings

The critical literature review of 30 AI fairness papers reveals significant gaps between intersectionality's theoretical origins and its practical implementation in AI contexts. First, researchers consistently interpret intersectionality narrowly as a technical challenge: ensuring that AI systems perform equitably across intersectional demographic categories (e.g., Black women, disabled Latinx individuals) through various operationalization methods (pre/in/post-processing). However, this operationalization strips intersectionality of its critical dimension—the examination of how multiple, interlocking systems of oppression (racism, sexism, ableism, colonialism) produce and perpetuate structural inequality, distinct from mere demographic intersection. Second, AI fairness literature conflates intersectional subgroup fairness with intersectionality itself, following Kong's observation that this myopic conceptualization has non-trivial consequences for just AI design. Third, the papers analyzed demonstrate that fairness research overlooks intersectionality's praxis component: the commitment to generating knowledge that directly informs strategies for dismantling oppressive systems and reclaiming power. Instead, the field maintains a positivist distance between knowledge production and power transformation, treating fairness as a neutral technical optimization problem rather than a justice-oriented political project rooted in affected communities' knowledge systems.

## Methodology/Approach

The authors employ a critical literature review methodology, analyzing 30 papers from AI fairness discourse through both deductive and inductive analysis. Deductively, they map how intersectionality tenets theoretically operate within AI fairness paradigms, examining various fairness conceptualizations (group, individual) and operationalizations (pre/in/post-processing). Inductively, they uncover emergent gaps between intersectionality's conceptualization in critical scholarship and its operationalization in technical AI contexts. This dual analytical approach is grounded in critical theory frameworks—particularly feminist, antiracist, and decolonial scholarship—that examine how knowledge systems reflect and reproduce power relations. The theoretical framework explicitly critiques colonial epistemology, distinguishing between positivist approaches (claiming neutral, quantifiable observation with "unlimited rights of access" to data) and critical approaches (acknowledging knowledge production as inherently political, power-laden, and requiring community participation).

## Relevant Concepts

**Intersectionality:** A traveling framework of critical inquiry and praxis examining interlocking mechanisms of structural oppression that produce inequality across multiple social domains; originates from feminist, antiracist, and decolonial scholarship.

**Praxis:** The unity of critical reflection and practical action aimed at transforming oppressive systems; knowledge generation inseparable from power reclamation and community participation.

**Colonial Epistemology:** Knowledge systems rooted in colonialism that impose positivist paradigms on oppressed populations, erasing Indigenous knowledge while establishing dominant systems as universal truth, preventing marginalized groups from creating and sharing their own knowledge.

**Matrix of Domination:** Multiple, interconnected systems of oppression (racism, sexism, ableism, colonialism) operating simultaneously across structures and disciplines, producing inequality through interlocking mechanisms.

**Intersectional Subgroup Fairness:** Technical operationalization ensuring AI system performance equity across demographic intersections; distinct from intersectionality as critical framework.

**Positivist Paradigm:** Approach treating knowledge as result of neutral, quantifiable observation relying strictly on measurement and reason, claiming researcher objectivity and unlimited data access.

## Significance

This paper's significance lies in its epistemological intervention within computer science. By demonstrating that AI fairness research operates within colonial epistemological frameworks fundamentally misaligned with intersectionality's critical praxis, the authors argue for comprehensive reorientation of the field. The work bridges computer science with critical theory, establishing that technical AI research requires accountability to marginalized communities' intellectual traditions and power-conscious knowledge production. Critically, the paper identifies that current fairness operationalizations—regardless of conceptualization type or processing stage—fail to interrogate structural mechanisms producing inequality because they operate within positivist frameworks that decouple knowledge from power. This challenges the field to move beyond narrow fairness metrics toward justice-oriented approaches that center affected communities' knowledge, participation, and liberation, fundamentally reconceptualizing what "fairness" means in AI development.
