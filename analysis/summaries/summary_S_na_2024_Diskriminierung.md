---
title: "S na 2024 Diskriminierung"
original_document: S_na_2024_Diskriminierung.md
document_type: Literature Review
research_domain: AI Bias & Fairness
methodology: Literature Review
keywords: algorithmic discrimination, intersectionality, media pedagogy, digital inequality, AI literacy
mini_abstract: "This chapter examines how algorithmic systems perpetuate discrimination against vulnerable populations and proposes media pedagogical interventions to empower users with critical AI competence for equitable digital participation."
target_audience: Researchers, Practitioners, Policymakers
key_contributions: "Integrating intersectionality framework with algorithmic literacy pedagogy"
geographic_focus: Europe
publication_year: 2024
related_fields: Media Education, Digital Justice, Critical Algorithm Studies
summary_date: 2025-11-07
language: English
ai_model: claude-haiku-4-5
---

# Summary: S na 2024 Diskriminierung

## Overview

This chapter from "Un|Sichtbarkeiten? Medienpädagogik, Intersektionalität und Teilhabe" (Schriften zur Medienpädagogik 60), authored by Süna, Hoffmann, and Mollen, addresses algorithmic discrimination as a critical media pedagogical challenge. Funded by Germany's Federal Ministry for Family, Seniors, Women and Youth, the work examines how AI systems and algorithmic curation—operating across search engines, social media platforms, healthcare diagnostics, and refugee labor market assessments—systematically disadvantage vulnerable populations. The chapter's central intervention framework proposes that media pedagogical competence development can enable marginalized groups to engage critically with algorithms, achieving everyday objectives without experiencing discrimination-based disadvantage.

## Main Findings

Research reveals a critical awareness-competence gap: while algorithmic systems make consequential decisions affecting vulnerable populations daily, users demonstrate limited awareness of discriminatory potential and lack competence to recognize or resist algorithmic bias. The authors document three specific mechanisms of algorithmic discrimination: (1) racial bias rendering groups invisible, hypervisible, or distorted; (2) amplification of existing structural inequalities through algorithmic reproduction; (3) compounded risks including data-driven manipulation, misinformation dissemination, and stereotype reinforcement. Empirical studies (MeMo:Ki 2021; Overdiek/Petersen 2022; Cousseran et al. 2023) demonstrate that users evaluate algorithms ambivalently, often failing to recognize curation as problematic. Vulnerable populations—specifically migrants, women, elderly persons, and those with limited educational attainment—face disproportionate exposure to these risks. The authors conclude that self-determined digital participation requires three-stage intervention: sensitization to algorithmic discrimination, development of critical competence, and enablement of instrumental algorithm use for achieving personal objectives without disadvantage.

## Methodology/Approach

The chapter employs systematic literature synthesis integrating empirical findings with theoretical frameworks addressing digital inequality and intersectionality. The analysis bridges algorithmic accountability scholarship with intersectional media education, positioning pedagogical intervention as central to addressing algorithmic discrimination. The methodology distinguishes between awareness (recognizing algorithmic curation exists) and competence (critically evaluating and resisting discriminatory outcomes), enabling differentiated intervention design.

## Relevant Concepts

**Algorithmic Bias/Racial Bias**: Systematic patterns rendering demographic groups invisible, hypervisible, or distorted in algorithmic outputs, amplifying structural inequalities.

**In/Visibilities (Un|Sichtbarkeiten)**: Core organizing principle examining how algorithms selectively render populations visible or invisible, structuring social participation.

**Digital Inequality**: Differential access, competence, and vulnerability to algorithmic discrimination affecting marginalized populations disproportionately.

**Data-Driven Manipulation**: Targeted misinformation and stereotype reinforcement enabled by algorithmic curation systems.

**Media Pedagogical Competence**: Informed, reflective, critical engagement enabling instrumental algorithm use—achieving objectives without experiencing disadvantage.

**Intersectionality**: Framework recognizing how multiple identity dimensions (migration status, gender, age, education) compound algorithmic vulnerability.

## Significance

This work advances critical media pedagogy by proposing actionable interventions addressing algorithmic discrimination's structural dimensions. Rather than documenting problems, it develops a three-stage pedagogical framework (sensitization-competence-instrumental use) applicable to vulnerable populations. By positioning media literacy as infrastructure for digital justice, the chapter contributes to contemporary discourse recognizing algorithmic literacy as prerequisite for meaningful social participation. The intersectional framework acknowledges differential vulnerability while proposing universal pedagogical principles, distinguishing this contribution through its emphasis on empowerment and participatory justice rather than technological determinism or fatalistic acceptance.
