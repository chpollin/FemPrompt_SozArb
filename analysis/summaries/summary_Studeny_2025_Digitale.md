---
title: "Studeny 2025 Digitale"
original_document: Studeny_2025_Digitale.md
document_type: Conference Paper
research_domain: AI Ethics
methodology: Theoretical
keywords: digital power asymmetries, social work, algorithmic discrimination, data sovereignty, digital autonomy
mini_abstract: "Critical examination of how digital tools and AI systems reinforce power imbalances in social work practice, arguing for client-centered approaches prioritizing autonomy and data justice over technological efficiency."
target_audience: Practitioners, Policymakers, Researchers
key_contributions: "Framework for analyzing digital power dynamics in welfare systems"
geographic_focus: Europe
publication_year: 2025
related_fields: Critical Digital Sociology, Social Work Ethics, Algorithm Studies
summary_date: 2025-11-07
language: English
ai_model: claude-haiku-4-5
---

# Summary: Studeny 2025 Digitale

## Overview

This academic document presents a critical examination of digital tools within social work practice, specifically addressing how technology mediates power relationships between practitioners and clients. Prepared for the OGSA conference in Graz (March 2025), the work challenges the prevailing assumption that digitalization inherently improves social services. Instead, it argues that digital systems often reproduce and amplify existing institutional power asymmetries while creating novel forms of control and dependency. The document's central concern is whether technology serves emancipatory or oppressive functions within welfare systems, with particular attention to how digital infrastructure shapes client autonomy, data rights, and access to services. It contextualizes "Projekt Konrad" as a case study examining these dynamics in practice.

## Main Findings

The analysis reveals several critical tensions in digital social work implementation. First, digital tools function as mechanisms of power amplification rather than neutral instruments—they embed institutional interests and structural inequalities into their design and deployment. Second, algorithmic decision-making systems perpetuate discrimination by encoding historical biases into automated processes, creating ostensibly objective yet fundamentally unjust outcomes. Third, surveillance technologies marketed as care mechanisms paradoxically undermine the trust essential to effective social work relationships. Fourth, digital exclusion creates stratified access to services, with vulnerable populations experiencing compounded marginalization. Fifth, **digital steering (Steuerung)** operates invisibly to constrain client autonomy without explicit coercion, representing subtle but pervasive threats to self-determination. Sixth, institutional dependencies on proprietary Big Tech systems create structural vulnerabilities requiring alternative models. Finally, **human decision-making authority must be preserved** as a non-negotiable ethical requirement, with transparency mechanisms embedded as accountability safeguards rather than afterthoughts.

## Methodology/Approach

The document employs critical social theory as its analytical foundation, integrating Foucauldian power analysis with institutional critique and rights-based frameworks. This approach examines how surveillance, data control, and algorithmic governance function within welfare bureaucracies. The methodology is explicitly reflexive, requiring social workers to examine their complicity in digital power structures rather than positioning themselves as neutral implementers. The framework combines structural inequality analysis—particularly regarding algorithmic bias—with participatory action research traditions emphasizing co-determination. Critically, the approach identifies **practitioner reflexivity itself as an essential finding**, not merely a methodological tool. This interdisciplinary approach bridges critical digital sociology, social work ethics, and data justice scholarship, creating a comprehensive critique that moves beyond technical solutions toward systemic transformation.

## Relevant Concepts

**Data Sovereignty**: Client control over personal information and decision-making authority regarding data usage; fundamental to dignity and autonomy.

**Algorithmic Discrimination**: Systematic bias embedded in AI systems that reproduces social inequalities through ostensibly objective automated decisions.

**Surveillance Paradox**: The contradiction between surveillance framed as protective care and its actual function as control mechanism undermining trust.

**Digital Steuerung (Steering)**: Invisible algorithmic governance that constrains autonomy through subtle nudging rather than explicit coercion; distinct from overt surveillance.

**Digital Exclusion**: Stratified access to digital services creating new forms of social marginalization alongside traditional inequalities.

**Transparenz (Transparency)**: Requirement for explicability of algorithmic decisions and data usage as justice imperative, not merely technical documentation.

**Mitbestimmung (Co-determination)**: Genuine client participation in technology governance decisions rather than passive service consumption.

**Digital Sovereignty**: Institutional and individual independence from proprietary systems, enabling autonomous decision-making and reducing Big Tech dependency.

**Vertrauen (Trust)**: Central relational element of social work undermined by surveillance systems; prerequisite for effective practice.

## Significance

This work holds substantial significance for social work practice, policy, and ethics. It provides practitioners with critical frameworks for evaluating technology adoption rather than uncritically accepting digitalization narratives. For policymakers, it demonstrates that efficiency gains cannot justify autonomy erosion or rights violations. Theoretically, it advances critical digital sociology by specifically contextualizing algorithm studies within social work's ethical obligations to vulnerable populations. The emphasis on co-determination, digital literacy, and digital sovereignty as justice imperatives reframes digitalization as fundamentally a question of power distribution rather than technical progress. Critically, the document identifies **digital education as a key to social justice**, positioning literacy not as individual skill-building but as structural empowerment. By challenging techno-optimism while avoiding technological determinism, the document enables more nuanced, ethically grounded approaches to digital transformation in welfare systems that prioritize human decision-making authority and institutional independence from proprietary systems.
