---
title: "West 2023 Discriminating"
original_document: West_2023_Discriminating.md
document_type: Research Paper
research_domain: AI Ethics
methodology: Comparative Analysis
keywords: AI diversity, algorithmic bias, workforce demographics, intersectionality, systemic discrimination
mini_abstract: "This paper documents severe underrepresentation of women and people of color in AI development and argues that workforce homogeneity directly perpetuates discriminatory outcomes in AI systems. The authors demonstrate that pipeline-focused interventions have failed and call for structural reforms addressing power asymmetries and workplace culture."
target_audience: Researchers, Policymakers, Industry, Practitioners
key_contributions: "Linking workforce diversity to algorithmic bias through intersectional analysis"
geographic_focus: North America
publication_year: 2019
related_fields: Critical theory, organizational sociology, science and technology studies
summary_date: 2025-11-07
language: English
ai_model: claude-haiku-4-5
---

# Summary: West 2023 Discriminating

## Overview

"Discriminating Systems: Gender, Race, and Power in AI" is a 2019 report by West, Whittaker, and Crawford from the AI Now Institute that investigates systemic discrimination within artificial intelligence development and deployment. The document establishes a critical causal relationship between workforce underrepresentation and algorithmic bias, arguing that the homogeneous demographics of AI creators directly produce discriminatory AI systems that reflect and amplify historical discrimination patterns. Rather than treating diversity and algorithmic fairness as separate concerns, the authors position them as interconnected manifestations of structural inequality requiring simultaneous institutional transformation. The report fundamentally challenges technocratic approaches to bias mitigation, asserting that technical solutions alone cannot address problems rooted in power asymmetries, workplace cultures, and systemic exclusion.

## Main Findings

The research reveals an acute diversity crisis across the AI sector with extreme underrepresentation. Women constitute only 18% of authors at leading AI conferences and represent merely 10-15% of AI research staff at major technology companies (Google and Facebook respectively). The situation is dramatically worse for Black workers, comprising only 2.5-4% of workforces at major tech firms, while no public data exists regarding trans or non-binary workers. The document demonstrates that decades of "pipeline problem" research and intervention have failed to produce meaningful progress, indicating that recruitment-focused solutions are fundamentally inadequate. Instead, the authors identify workplace culture, power asymmetries, harassment, exclusionary hiring practices, unfair compensation, and tokenization as primary drivers of attrition and exclusion. Critically, the research highlights how AI systems are actively deployed for "classification, detection, and prediction of race and gender," practices requiring urgent re-evaluation given their discriminatory potential. Additionally, narrow "women in tech" frameworks inadvertently privilege white women while marginalizing other intersecting identities, and binary gender assumptions in AI research systematically erase non-binary and transgender experiences.

## Methodology/Approach

The document employs mixed analytical methods combining empirical data aggregation with critical institutional analysis. Authors compile diversity statistics from leading AI conferences and major technology companies, providing quantitative evidence of disparity. Simultaneously, they employ intersectional feminist theory to examine how race, gender, and power dynamics intersect within institutional contexts. The framework incorporates historical contextualization, connecting contemporary algorithmic bias to historical patterns of discrimination and "race science." Critically, the methodology rejects technocratic problem-framing, instead emphasizing structural power dynamics, institutional barriers, and the interconnection between workforce composition and system outputs as primary analytical lenses.

## Relevant Concepts

**Intersectionality**: The analytical framework recognizing how multiple marginalized identities (race, gender, sexuality, etc.) interact and compound discrimination experiences, rather than existing independently.

**Pipeline Problem**: The conventional framing attributing diversity gaps to insufficient recruitment of underrepresented groups from educational pipelines, which the authors critique as inadequate and masking deeper structural issues.

**Discrimination Feedback Loop**: The bidirectional mechanism whereby homogeneous AI development teams create systems reflecting their biases and historical discrimination patterns, which subsequently reinforce and amplify inequality in broader society through algorithmic deployment.

**Tokenization**: The practice of including minimal representation of marginalized individuals without addressing systemic barriers, power structures, or workplace culture.

**Algorithmic Bias as Social Justice Issue**: The conceptual reframing positioning AI discrimination not as technical problem requiring engineering solutions, but as structural inequality requiring institutional transformation.

## Significance

This report represents a paradigm shift in AI ethics discourse, establishing that algorithmic bias is fundamentally a social justice issue rather than merely a technical problem. By demonstrating the causal relationship between workforce demographics and system outputs, the authors provide empirical grounding for structural critiques of technology development. The work challenges industry narratives of meritocracy and incremental progress, instead advocating for profound institutional transformation addressing workplace power dynamics, hiring practices, and retention simultaneously with algorithmic fairness. The document's emphasis on intersectionality and rejection of narrow "women in tech" frameworks has substantially influenced subsequent policy discussions and corporate accountability frameworks. Published by influential scholars at a leading AI ethics institute, this work has become foundational to contemporary AI ethics scholarship and policy development.
