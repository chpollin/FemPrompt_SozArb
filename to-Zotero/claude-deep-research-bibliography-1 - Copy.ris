TY  - JOUR
AU  - Toupin, S.
PY  - 2024
TI  - Shaping feminist artificial intelligence
JO  - New Media & Society
VL  - 26
IS  - 4
SP  - 1875
EP  - 1894
DO  - 10.1177/14614448221150776
UR  - https://journals.sagepub.com/doi/full/10.1177/14614448221150776
AB  - Comprehensive examination of feminist artificial intelligence through historical analysis and contemporary typology development. Provides detailed framework categorizing FAI as: model, design, policy, culture, discourse, and science. Traces FAI's evolution from foundational work to contemporary initiatives, analyzing tensions between commercialized approaches and community-oriented methods.
N1  - Quality: High - Published in New Media & Society (Impact Factor: 5.9), demonstrates rigorous theoretical framework combining historical analysis with contemporary case studies, establishes clear typology with significant pedagogical implications for feminist AI literacy education.
ER  -

TY  - JOUR
AU  - Small, S. F.
PY  - 2023
TI  - Generative AI and opportunities for feminist classroom assignments
JO  - Feminist Pedagogy
VL  - 3
IS  - 5
SP  - Article 10
DO  - 
UR  - https://digitalcommons.calpoly.edu/feministpedagogy/vol3/iss5/10/
AB  - Addresses integration of generative AI into feminist classroom assignments to develop reflexivity and feminist epistemology. Proposes intentional feminist approaches where students collaborate with AI to develop understanding of feminist knowledge production, transforming AI from educational threat into tool for critical learning about power and epistemology.
N1  - Quality: High - Published in peer-reviewed Feminist Pedagogy journal, grounded in feminist pedagogical theory with practical classroom applications, directly addresses feminist AI literacy pedagogy implementation.
ER  -

TY  - RPRT
AU  - Derechos Digitales
PY  - 2023
TI  - Feminist reflections for the development of Artificial Intelligence
JO  - Latin America and Caribbean Hub, f<A+I>er project Report
DO  - 
UR  - https://www.derechosdigitales.org/fair-2023-en/
AB  - Synthesizes conversations among Latin American women developing AI systems, providing methodological frameworks for feminist AI development based on four real-world projects. Emphasizes co-design methodologies, digital autonomy, data sovereignty, and intersectional approaches through community agreements and power-balancing strategies.
N1  - Quality: High - Organizational publication with academic rigor supported by IDRC funding, based on systematic practitioner conversations with clear methodological frameworks, provides practical pedagogical applications for feminist AI literacy.
ER  -

TY  - JOUR
AU  - Gallegos, I. O.
AU  - Rossi, R. A.
AU  - Barrow, J.
AU  - Tanjim, M. M.
AU  - Kim, S.
AU  - Dernoncourt, F.
AU  - Yu, T.
AU  - Zhang, R.
AU  - Ahmed, N. K.
PY  - 2024
TI  - Bias and fairness in large language models: A survey
JO  - Computational Linguistics
VL  - 50
IS  - 3
SP  - 1097
EP  - 1179
DO  - 10.1162/coli_a_00524
UR  - https://doi.org/10.1162/coli_a_00524
AB  - Comprehensive survey consolidating notions of social bias and fairness in NLP, defining distinct facets of harm and introducing desiderata to operationalize fairness for LLMs. Proposes three taxonomies: metrics for bias evaluation, datasets for bias evaluation, and techniques for bias mitigation classified by intervention timing.
N1  - Quality: High - Published in top-tier Computational Linguistics (MIT Press), represents most comprehensive survey with rigorous methodology, extensive peer review, and significant research community impact.
ER  -

TY  - CONF
AU  - Sant, A.
AU  - Escolano, C.
AU  - Mash, A.
AU  - De Luca Fornaciari, F.
AU  - Melero, M.
PY  - 2024
TI  - The power of prompts: Evaluating and mitigating gender bias in MT with LLMs
JO  - Proceedings of the 5th Workshop on Gender Bias in Natural Language Processing (GeBNLP)
SP  - 94
EP  - 139
DO  - 10.18653/v1/2024.gebnlp-1.7
UR  - https://doi.org/10.18653/v1/2024.gebnlp-1.7
AB  - Examines gender bias in machine translation through LLMs using four widely-used test sets. Develops specific prompting engineering techniques that reduce gender bias by up to 12% on WinoMT evaluation dataset. Identifies optimal prompt structures incorporating explicit fairness instructions and context-aware guidelines.
N1  - Quality: High - Published at ACL's premier gender bias workshop, provides concrete empirical validation of prompting techniques with quantitative bias reduction results, reproducible experimental design with practical applications.
ER  -

TY  - CONF
AU  - Chisca, A.-V.
AU  - Rad, A.-C.
AU  - Lemnaru, C.
PY  - 2024
TI  - Prompting fairness: Learning prompts for debiasing large language models
JO  - Proceedings of the Fourth Workshop on Language Technology for Equality, Diversity, Inclusion
SP  - 52
EP  - 62
DO  - 
UR  - https://aclanthology.org/2024.ltedi-1.6/
AB  - Introduces novel prompt-tuning method for reducing biases in encoder models like BERT and RoBERTa through training small sets of additional reusable token embeddings. Demonstrates state-of-the-art performance while maintaining minimal impact on language modeling capabilities through parameter-efficient approach applicable across different models and tasks.
N1  - Quality: High - Peer-reviewed at specialized ACL workshop focusing on equality and inclusion, provides innovative technical contributions with empirical validation, demonstrates clear technical advancement over existing methods.
ER  -

TY  - CONF
AU  - Wilson, K.
AU  - Caliskan, A.
PY  - 2024
TI  - Gender, race, and intersectional bias in AI resume screening via language model retrieval
JO  - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society
VL  - 7
IS  - 1
SP  - 1578
EP  - 1590
DO  - 10.1609/aies.v7i1.31748
UR  - https://doi.org/10.1609/aies.v7i1.31748
AB  - Analyzes bias in large language models used for resume screening, examining over 550 job descriptions and 550 resumes across multiple demographic combinations. Reveals significant intersectional discrimination with Black male candidates facing most severe disadvantages, validating three key hypotheses of intersectionality theory through over 40,000 comparisons.
N1  - Quality: High - Strong intersectionality theoretical framework drawing from Crenshaw's foundational work, robust empirical methodology with large-scale data analysis, direct policy relevance for employment discrimination, published in premier AI ethics venue.
ER  -

TY  - CONF
AU  - Ovalle, A.
AU  - Subramonian, A.
AU  - Gautam, V.
AU  - Gee, G.
AU  - Chang, K. W.
PY  - 2023
TI  - Factoring the matrix of domination: A critical review and reimagination of intersectionality in AI fairness
JO  - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society
SP  - 704
EP  - 716
DO  - 10.1145/3600211.3604705
UR  - https://dl.acm.org/doi/abs/10.1145/3600211.3604705
AB  - Critical review examining how intersectionality is conceptualized and operationalized within AI fairness research, analyzing 30 papers from the field. Identifies significant gaps between intersectionality theory and technical applications, proposing six key tenets for properly applying intersectionality in AI research drawn from Patricia Hill Collins and Sirma Bilge's framework.
N1  - Quality: High - Rigorous theoretical grounding in critical intersectionality literature, systematic review methodology examining gaps in current practice, provides actionable recommendations addressing fundamental theoretical issues in the field.
ER  -

TY  - JOUR
AU  - An, J.
AU  - Huang, D.
AU  - Lin, C.
AU  - Tai, M.
PY  - 2025
TI  - Measuring gender and racial biases in large language models: Intersectional evidence from automated resume evaluation
JO  - PNAS Nexus
VL  - 4
IS  - 3
SP  - pgaf089
DO  - 10.1093/pnasnexus/pgaf089
UR  - https://doi.org/10.1093/pnasnexus/pgaf089
AB  - Large-scale experimental study examining bias across five major LLMs using over 361,000 randomized resumes. Reveals complex intersectional patterns where LLMs favor female candidates but discriminate against Black male candidates, with bias effects translating to 1-3 percentage point differences in hiring probabilities, validating intersectionality theory through three key findings.
N1  - Quality: High - Massive scale empirical study with cutting-edge LLMs, strong intersectionality theoretical framework, direct economic impact quantification, comprehensive methodological rigor, published in prestigious multidisciplinary venue.
ER  -

TY  - BOOK
AU  - Browne, J.
AU  - Cave, S.
AU  - Drage, E.
AU  - McInerney, K.
PY  - 2023
TI  - Feminist AI: Critical Perspectives on Algorithms, Data, and Intelligent Machines
JO  - Oxford University Press
DO  - 10.1093/oso/9780192889898.001.0001
UR  - https://doi.org/10.1093/oso/9780192889898.001.0001
AB  - First comprehensive collection bringing together leading feminist thinkers across disciplines to examine AI's societal impact. Features 21 chapters covering topics from techno-racial capitalism to AI's military applications, examining how feminist scholarship can hold the AI sector accountable for designing systems that further social justice through diverse feminist approaches.
N1  - Quality: High - Published by prestigious Oxford University Press as open access, featuring preeminent scholars in feminist STS and AI ethics, demonstrates exceptional theoretical rigor through interdisciplinary feminist frameworks, represents most comprehensive feminist AI scholarship to date.
ER  -

TY  - CONF
AU  - Klein, L.
AU  - D'Ignazio, C.
PY  - 2024
TI  - Data feminism for AI
JO  - Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency
SP  - 540
EP  - 551
DO  - 10.1145/3630106.3658543
UR  - https://doi.org/10.1145/3630106.3658543
AB  - Extends the influential "Data Feminism" framework to AI research, presenting intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. Rearticulates original seven data feminism principles specifically for AI contexts and introduces two new principles addressing environmental impact and consent, providing concrete methodological guidance.
N1  - Quality: High - Published at premier FAccT venue by leading scholars Catherine D'Ignazio and Lauren Klein, builds on influential "Data Feminism" work with rigorous theoretical foundations and practical applications, high policy relevance.
ER  -

TY  - JOUR
AU  - Browne, J.
AU  - Drage, E.
AU  - McInerney, K.
PY  - 2024
TI  - Tech workers' perspectives on ethical issues in AI development: Foregrounding feminist approaches
JO  - Big Data & Society
VL  - 11
IS  - 1
DO  - 10.1177/20539517231221780
UR  - https://doi.org/10.1177/20539517231221780
AB  - Empirical study examining tech workers' understanding of ethical AI development through feminist lens, revealing critical gaps in current AI ethics approaches. Finds that the term "bias" creates confusion among tech workers, undermining AI ethics initiatives, and argues for moving beyond diversity narratives toward "design justice" that centers marginalized voices.
N1  - Quality: High - Published in Big Data & Society, prestigious peer-reviewed journal, empirical study with clear feminist methodological framework, directly relevant to feminist AI literacy education and workplace implementation.
ER  -

TY  - RPRT
AU  - UNESCO
PY  - 2021
TI  - Recommendation on the Ethics of Artificial Intelligence
JO  - UNESCO Publishing
DO  - 
UR  - https://unesdoc.unesco.org/ark:/48223/pf0000380455
AB  - First global standard on AI ethics adopted by 193 member states, establishing comprehensive policy frameworks addressing gender equality in AI development and deployment. Explicitly addresses gender stereotyping, discriminatory biases, and need for equitable participation across the AI lifecycle, with recent implementation including Women4Ethical AI platform and systematic bias studies.
N1  - Quality: High - Global policy standard adopted by 193 countries, comprehensive implementation framework, significant real-world policy impact, ongoing research and monitoring programs.
ER  -

TY  - RPRT
AU  - UN Women
PY  - 2024
TI  - Artificial Intelligence and gender equality
JO  - UN Women Policy Brief Series
DO  - 
UR  - https://www.unwomen.org/en/articles/explainer/artificial-intelligence-and-gender-equality
AB  - Comprehensive policy brief series analyzing how AI systems perpetuate gender inequalities while highlighting pathways for more equitable development. Documents that 44% of AI systems show gender bias, with 25% exhibiting both gender and racial bias, and provides evidence-based policy recommendations for addressing systematic underrepresentation and discriminatory outcomes.
N1  - Quality: High - Authoritative UN agency source, comprehensive policy analysis with evidence-based recommendations, significant influence on international AI governance discussions.
ER  -

TY  - RPRT
AU  - A+ Alliance
PY  - 2024
TI  - Incubating Feminist AI: Executive Summary 2021-2024
JO  - A+ Alliance Report
DO  - 
UR  - https://aplusalliance.org/incubatingfeministai2024/
AB  - Documents outcomes from $2 million CAD Feminist AI Research Network project across Latin America, Middle East, and Asia. Developed 12 feminist AI prototypes addressing gender-based violence, transit safety, bias detection in NLP systems, and judicial transparency, demonstrating practical applications of feminist AI principles through community-centered design and intersectional analysis capabilities.
N1  - Quality: High - Significant funding and scope, documented real-world implementations with measurable impact outcomes, innovative technical solutions, policy influence through UNESCO integration.
ER  -