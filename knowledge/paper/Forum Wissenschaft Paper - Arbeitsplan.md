---
type: knowledge
created: 2026-02-02
tags: [workflow, research, original]
status: draft
---

# Forum Wissenschaft Paper - Arbeitsplan

## Summary

Arbeitsplan f√ºr das Paper "Deep-Research-gest√ºtzte Literature Reviews im Praxistest" f√ºr Forum Wissenschaft (Ausgabe 2/2026). Das Paper dokumentiert den Vergleich zwischen LLM-gest√ºtzter und menschlicher Literature Review am Beispiel feministischer AI Literacies in der Sozialen Arbeit.

## Rahmenbedingungen

| Parameter | Wert |
|-----------|------|
| Deadline | 4. Mai 2026 |
| Umfang | 18.000 Zeichen |
| Format | Wissenschaftlich-journalistisch |
| Zitierweise | Fu√ünoten (kein Literaturverzeichnis) |
| Zielgruppe | Wenig KI-Vorwissen |
| Autor:innen | Christopher Pollin, Susanne Sackl-Sharif, Sabine Klinger, Christian Steiner |

## Aktueller Stand (2. Februar 2026)

### FemPrompt Literature Review

| Phase | Status | Details |
|-------|--------|---------|
| Deep Research | ‚úÖ Abgeschlossen | 303 Papers identifiziert (4 LLM-Modelle) |
| Thematisches Assessment | üîÑ L√§uft | Susi & Sabine via Google Sheets |
| Kategoriendefinition | ‚ö†Ô∏è Abstimmung n√∂tig | Meeting mit Susi diese Woche |
| PDF-Akquise | ‚è∏Ô∏è Wartet | Blockiert durch Assessment |
| Markdown-Konversion | ‚è∏Ô∏è Wartet | Pipeline bereit |
| LLM-Summarisierung | ‚è∏Ô∏è Wartet | Pipeline bereit |
| Obsidian Vault | ‚è∏Ô∏è Wartet | Pipeline bereit |

### Repository-Status

GitHub: `chpollin/FemPrompt_SozArb`

- 33 Python-Scripts im `analysis/` Ordner
- 5-Stage Pipeline implementiert und getestet
- SozArb-Vault operativ (266 Papers, 144 Konzepte) ‚Äî als Referenz verf√ºgbar

### Benchmark-Komponente (geplant)

Das Repository enth√§lt einen eingebauten Benchmark f√ºr den Human-LLM-Vergleich:

```
benchmark/
‚îú‚îÄ‚îÄ README.md                    # Methodenbeschreibung
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ human_assessment.csv     # Export Google Sheets
‚îÇ   ‚îú‚îÄ‚îÄ llm_assessment.csv       # Export assessment-llm/
‚îÇ   ‚îî‚îÄ‚îÄ merged_comparison.csv    # Vereinigt (Paper-ID als Key)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ merge_assessments.py     # Zusammenf√ºhrung
‚îÇ   ‚îú‚îÄ‚îÄ calculate_agreement.py   # Kappa, √úbereinstimmung
‚îÇ   ‚îî‚îÄ‚îÄ analyze_disagreements.py # Qualitative Divergenzanalyse
‚îî‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ agreement_metrics.json   # Quantitative Ergebnisse
    ‚îî‚îÄ‚îÄ disagreement_cases.csv   # F√§lle f√ºr Paper
```

**Erwartete Metriken:**
- Gesamt√ºbereinstimmung und Cohen's Kappa
- √úbereinstimmung nach Kategorie (explizit feminist, intersektional, deutschsprachig)
- Konfusionsmatrix (Human Include/Exclude √ó LLM Include/Exclude)
- Qualitative Analyse der Disagreement-F√§lle

## Offene Aufgaben

### Blocker (vor Pipeline-Ausf√ºhrung)

> [!warning] BLOCKER: Thematisches Assessment
> Das menschliche Assessment durch Susi und Sabine muss abgeschlossen sein, bevor die Pipeline f√ºr FemPrompt ausgef√ºhrt werden kann. Die Kategoriendefinitionen wurden √ºberarbeitet und m√ºssen im Meeting abgestimmt werden.

1. **Meeting mit Susi** (diese Woche)
   - √úberarbeitete Kategoriendefinitionen besprechen
   - Bewertungskriterien finalisieren
   - Timeline f√ºr Assessment-Abschluss kl√§ren

2. **Assessment abschlie√üen** (Susi & Sabine)
   - 303 Papers bewerten
   - Include/Exclude-Entscheidungen dokumentieren
   - Inter-Rater-Diskussion bei Uneinigkeit

### Nach Assessment-Abschluss

3. **Metadata in Zotero erg√§nzen**
   - PDF-Links hinzuf√ºgen
   - Fehlende Metadaten vervollst√§ndigen

4. **Pipeline ausf√ºhren**
   ```
   PDF-Akquise ‚Üí Markdown-Konversion ‚Üí Summarisierung ‚Üí Vault-Generierung
   ```

5. **Benchmark ausf√ºhren** (Human-LLM Assessment Comparison)
   - Human-Assessment aus Google Sheets exportieren
   - LLM-Assessment aus `assessment-llm/` exportieren
   - Merge-Skript ausf√ºhren ‚Üí `merged_comparison.csv`
   - √úbereinstimmungsmetriken berechnen (Cohen's Kappa)
   - Disagreement-Analyse f√ºr qualitative Auswertung

### Paper-Entwicklung

6. **Textbausteine entwickeln** (parallel m√∂glich)
   - Methodenbeschreibung (bereits im Abstract)
   - Theoretischer Rahmen (Co-Intelligence, PRISMA)
   - Reflexion √ºber epistemische Grenzen

7. **Ergebnisse einarbeiten**
   - Nach Pipeline-Abschluss
   - Quantitative Vergleichsdaten
   - Qualitative Beobachtungen

8. **Finalisierung**
   - Auf 18.000 Zeichen k√ºrzen
   - Fu√ünoten formatieren
   - Co-Autor:innen-Review

## Paper-Gliederung (Entwurf)

```
1. Einleitung (~2.500 Zeichen)
   - KI ver√§ndert wissenschaftliche Wissensproduktion
   - Deep Research als neues Werkzeug
   - Forschungsfrage: Wo Co-Intelligence, wo Grenzen?

2. Kontext: Feministische AI Literacies (~2.000 Zeichen)
   - Arbeitsdefinition
   - Elisabeth-List-Fellowship Projekt
   - Soziale Arbeit als Anwendungsfeld

3. Methodik (~4.000 Zeichen)
   - 3-Phasen-Workflow
   - Phase 1: Deep Research (4 LLMs)
   - Phase 2: Parallele Bewertung (LLM vs. Expert:innen)
   - Phase 3: Synthese und Knowledge Graph

4. Ergebnisse (~5.000 Zeichen)
   - Quantitativer Vergleich
   - Wo √úbereinstimmung, wo Divergenz
   - Epistemische Asymmetrien

5. Diskussion (~3.000 Zeichen)
   - Co-Intelligence: St√§rken und Grenzen
   - Verantwortungsfrage
   - Abh√§ngigkeit von propriet√§ren Systemen

6. Fazit (~1.500 Zeichen)
   - Praktische Empfehlungen
   - Offene Fragen
```

## Kernbotschaft des Papers

Die Frage ist nicht, *ob* KI bei Literature Reviews eingesetzt wird, sondern *wie*. Der Praxistest zeigt:

1. **Deep Research funktioniert** f√ºr breite Literaturidentifikation
2. **Expert:innenwissen bleibt unverzichtbar** f√ºr Qualit√§tsurteil und Kontextualisierung
3. **Transparenz** √ºber den Prozess ist wissenschaftliche Pflicht
4. **Abh√§ngigkeit** von propriet√§ren Systemen ist ein Grundproblem

## Verbindung zu anderen Dokumenten

- [[Abstract - Deep-Research-gest√ºtzte Literature Reviews]]: Eingereicher Abstract
- [[Literature Review Pipeline - Technische Dokumentation]]: Technische Details
- [[Human-LLM Assessment Benchmark]]: Benchmark-Spezifikation und Workflow
- [[FemPrompt-SozArb MOC]]: Projekt-Navigation
- [[Workflow f√ºr eine Deep-Research-gest√ºtzte Literaturanalyse am Beispiel von feministischem AI-Literacy]]: Methodendokument

## Related

- [[SocialAI MOC]]
- [[Promptotyping MOC]]
- [[Critical-Expert-in-the-Loop]]
