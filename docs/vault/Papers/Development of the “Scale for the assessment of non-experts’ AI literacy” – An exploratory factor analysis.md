---
title: Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis
authors:
  - Matthias Carl Laupichler
  - Alexandra Aster
  - Nicolas Haverkamp
  - Tobias Raupach
year: 12/2023
type: journalArticle
url: https://linkinghub.elsevier.com/retrieve/pii/S2451958823000714
doi: 10.1016/j.chbr.2023.100338
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
---

# Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis

## Key Concepts

## Full Text

---
title: "Development of the 'Scale for the assessment of non-experts' AI literacy' - An exploratory factor analysis"
authors: ["Matthias Carl Laupichler", "Alexandra Aster", "Nicolas Haverkamp", "Tobias Raupach"]
year: 2023
type: journalArticle
language: en
processed: 2026-02-05
source_file: Laupichler_2023_Development_of_the_“Scale_for_the_assessment_of.md
confidence: 91
---

# Development of the 'Scale for the assessment of non-experts' AI literacy' - An exploratory factor analysis

## Kernbefund

Ein Drei-Faktoren-Modell (TUCAPA: Technical Understanding, Critical Appraisal, Practical Application) erklärt die AI-Literacy-Struktur bei Laien am besten. Die finale SNAIL-Skala mit 31 Items zeigt exzellente interne Konsistenz (α=0.93-0.94).

## Forschungsfrage

Wie viele latente Faktoren konstituieren AI Literacy bei Laien, und welche Items laden auf welche Faktoren, um ein valides und reliables Messinstrument zu entwickeln?

## Methodik

Empirisch - Exploratory Factor Analysis (EFA) mit 479 online-Befragten nicht-Experten, die 39 AI-Literacyitems auf einer 7-Punkt-Likert-Skala bewerteten.
**Datenbasis:** n=479 Teilnehmende (50% männlich, 50% weiblich), rekrutiert über Prolific-Plattform, English-sprachig, über 18 Jahre, heterogene Zusammensetzung

## Hauptargumente

- AI-Literacy ist ein kritisches Konstrukt für Laien im Zeitalter von ChatGPT und alltäglichen KI-Anwendungen, erfordert aber bisher keine psychometrisch validierten Messinstrumente - diese Studie füllt diese Lücke durch induktiven Bottom-Up-Ansatz.
- Die identifizierten drei Faktoren (technisches Verständnis, kritische Bewertung, praktische Anwendung) sind inhaltlich kohärent und unterscheiden sich von bisherigen deduktiven Modellen (z.B. Wang et al. 2022: awareness, usage, evaluation, ethics) durch fokussierten Laien-Zuschnitt.
- Das SNAIL-Instrument ermöglicht sowohl Individual-Assessment als auch Evaluation von AI-Literacy-Kursen und kann zur Vergleichbarkeit zwischen Populationen genutzt werden, adressiert aber Limitation durch Englisch-Monolingualität und Selection-Bias bei interessierten Prolific-Nutzern.

## Kategorie-Evidenz

### Evidenz 1

Gesamtes Paper widmet sich AI Literacy Definition und Assessment: 'The term AI literacy describes competencies that include basic knowledge and analytical evaluation of AI, as well as critical use of AI applications by non-experts.' Entwicklung und Validierung der SNAIL-Skala mit 31 Items zur Messung dieser Kompetenzen.

### Evidenz 2

Breite Behandlung von KI-Konzepten: Machine Learning, Deep Learning, Rule-based Systems, Reinforcement Learning, Data Privacy, Data Security, Algorithmic Decision-Making, Black Box-Problematik, explainable AI, Biases in AI systems.

### Evidenz 3

Explizit werden unterschiedliche AI-Literacy-Niveaus in Populationen thematisiert und die Identifikation von 'strengths and weaknesses' verschiedener Subgruppen als Ziel genannt. Begründung für heterogene Stichprobenziehung zur Vermeidung von Selection-Bias.

### Evidenz 4

Bewusste Kontrolle für Geschlecht in der Stichprobenziehung: 'exactly 50% of the participants (n = 240) should identify as male and 50% (n = 240) as female.' Ermöglicht potenzielle Geschlechterdifferenz-Analysen.

### Evidenz 5

Heterogene Stichprobenzusammensetzung beabsichtigt: 'we did not survey a specific (sub-) population but rather attempted to obtain a sample that is as heterogenous as possible.' Diskussion von Unterschieden nach Bildungsniveau, Herkunftsland und potenziell fachspezifischen Domänen.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist für KI-Literacies und Diversity-Perspektiven hochrelevant, aber ohne direkten Bezug zu Sozialer Arbeit. Die Bedeutung von AI Literacy für Laien und nicht-spezialisierte Nutzer ist transferierbar auf sozialarbeiterische Kontexte (Fachkräfte und Klient:innen), wird aber nicht explizit diskutiert.

**Unique Contribution:** Erstes psychometrisch validiertes Messinstrument (SNAIL) für AI Literacy bei Laien mit explorativem, induktivem Zugang statt deduktiv-theoretisch, plus bewusste Kontrolle für Geschlechtergerechtigkeit in der Stichprobe.

**Limitations:** Englisch-Monolingualität, Selection-Bias durch Prolific-Nutzer (möglicherweise höhere baseline AI-Interest), keine konfirmatorische Faktorenanalyse zur Validierung, kleine Stichprobenumfänge pro Subgruppe zur Geschlechter- oder Subpopulationsanalyse, kein Test gegen verwandte Konstrukte wie Digital Literacy oder AI Attitudes.

**Target Group:** KI-Bildungsforscher:innen, Curriculum-Entwickler:innen von AI Literacy Kursen (Hochschulen, Erwachsenenbildung, K-16), Evaluator:innen von AI Education Interventionen, Forschende zu Human-AI Interaction, potentiell Sozialarbeiter:innen und Policy-Maker zur Kompetenzentwicklung in breiten Populationen

## Schlüsselreferenzen

- [[Long_Magerko_2020]] - What is AI literacy? Competencies and design considerations
- [[Ng_et_al_2021]] - Conceptualizing AI literacy: An exploratory review
- [[Wang_et_al_2022]] - Measuring user competence in using artificial intelligence: Validity and reliability of artificial intelligence literacy scale
- [[Pinski_Benlian_2023]] - AI literacy - towards measuring human competency in artificial intelligence
- [[Carolus_et_al_2023]] - MAILS - meta AI literacy scale
- [[Laupichler_et_al_2023]] - Delphi study for the development and preliminary validation of an item set for the assessment of non-experts' AI literacy
- [[Cattell_1978]] - Use of factor analysis in behavioral and life sciences
- [[Field_Miles_Field_2012]] - Discovering statistics using R
