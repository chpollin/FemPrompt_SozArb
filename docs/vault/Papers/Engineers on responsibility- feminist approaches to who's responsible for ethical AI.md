---
title: Engineers on responsibility: feminist approaches to who's responsible for ethical AI
authors:
  - J. Browne
  - E. Drage
  - K. McInerney
year: 2024
type: journalArticle
doi: 10.1007/s10676-023-09739-1
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Discrimination
---

# Engineers on responsibility: feminist approaches to who's responsible for ethical AI

## Abstract

Through interviews with AI practitioners interpreted via feminist political thought, reimagines responsibility in AI development beyond individualized approaches. Critiques current AI responsibility frameworks focused on individual competency and technical solutions, proposing instead "responsibility as the product of work cultures that enable tech workers to be responsive and answerable for their products." Moves beyond "individual competency approaches" toward understanding responsibility as embedded in structural power relations and organizational cultures.

## Key Concepts

### Bias Types
- [[Discrimination]]

## Full Text

---
title: "Engineers on responsibility: feminist approaches to who's responsible for ethical AI"
authors: ["Eleanor Drage", "Kerry McInerney", "Jude Browne"]
year: 2024
type: journalArticle
language: en
processed: 2026-02-05
source_file: Browne_2024_Engineers_on_responsibility_feminist_approaches.md
confidence: 95
---

# Engineers on responsibility: feminist approaches to who's responsible for ethical AI

## Kernbefund

Verantwortung sollte nicht als statisches individuelles Merkmal verstanden werden, sondern als 'response-ability' – eine dynamische, kollektive Fähigkeit zur Rechenschaft, die durch organisationale Kulturen ermöglicht wird, die Care- und Wartungsarbeit wertschätzen und strukturelle Barrieren abbaut.

## Forschungsfrage

Wie verstehen KI-Praktiker Verantwortung im Kontext von KI-Entwicklung und -Einsatz, und wer sollte verantwortlich sein, wenn etwas schiefgeht?

## Methodik

Empirisch-qualitativ: 50 leitfadengestützte Interviews mit KI-Praktikern und Tech-Arbeitern in einem multinationalen Technologieunternehmen (2020-2021), interpretiert durch feministische politische Theorie
**Datenbasis:** n=ca. 50+ Interviews mit KI-Praktikern und Tech-Arbeitern an einem multinationalen Technologieunternehmen über 12 Monate (2020-2021)

## Hauptargumente

- Traditionelle, statische Modelle von individueller Verantwortung können nicht mit den dynamischen, fluiden Ökosystemen von KI-Entwicklung umgehen, in denen Systeme die Besitzer wechseln, Arbeitskräfte das Unternehmen verlassen und Produkte orphan werden.
- KI-Ingenieure werden durch Druck und 'Tunnel-Vision'-Fokus auf unmittelbare technische Leistung daran gehindert, holistische Verantwortung für Langzeiteffekte zu übernehmen; dies erfordert Umgestaltung von Arbeitskultur und Bewertung von Wartungsarbeit.
- Feministische Theorie (Haraway, Puig de la Bellacasa, Young, Butler) bietet einen konzeptionellen Rahmen, der Verantwortung als relationales, gegenseitig abhängiges Phänomen rekonzeptualisiert und die unsichtbaren Care- und Wartungsarbeiten – historisch feminisiert und marginalisiert – als zentral für ethische KI-Entwicklung anerkennt.

## Kategorie-Evidenz

### Evidenz 1

Paper untersucht 'practitioners' personal understandings of responsibility' und wie KI-Praktiker Kompetenz und Wissen über KI-Systeme entwickeln und anwenden: 'we are unable to access the bigger picture' & interviews with 'AI practitioners and tech workers'

### Evidenz 2

Fokus auf 'algorithmic tools which are often, but not always, created through the use of machine learning techniques', black box problem, unexplainability, AI lifecycle management, algorithmic drift

### Evidenz 3

Thematisiert Care-Arbeit als zentral: 'caring responsibilities are distinctly gendered and racialized forms of work' und verbindet dies mit Care-ethischen Konzepten, die für Soziale Arbeit relevant sind; Fokus auf Beziehungen, Abhängigkeit, Verantwortung für vulnerable Populationen

### Evidenz 4

Analysiert wie 'AI replicates, perpetuates, or exacerbates existing patterns of discrimination and injustice' (Amazon hiring tool, UK A-level algorithm); erwähnt 'gendered and racialized workers' und 'Global South', Gefängnisarbeit, strukturelle Benachteiligung

### Evidenz 5

Expliziter Gender-Fokus: 'Amazon's gender discriminatory AI-powered hiring tool', 'caring responsibilities are distinctly gendered and racialized forms of work', Analyse von Frauen in Tech, Geschlechtsdimension von invisibilisierter Arbeit

### Evidenz 6

Untersucht Repräsentation und Marginalisierung: 'communities and individuals who are most likely to be harmed', intersektionale Perspektive auf Arbeit ('gendered and racialized workers'), Global South und Gefängnissysteme

### Evidenz 7

EXPLIZIT feministische Theorie als Kern: 'use feminist theory and methodological approaches', 'feminist perspectives on responsibility' (Maria Puig de la Bellacasa, Donna Haraway, Iris Marion Young, Judith Butler), 'feminist organizational studies', 'feminist STS', 'feminist political economy', 'Data Feminism' (D'Ignazio & Klein)

### Evidenz 8

Adressiert Fairness in KI-Systemen und algorithmische Gerechtigkeit durch feministische Linse: 'what does ethical, fair, and responsible AI look like?' Kritik an oberflächlichen Fairness-Checks ('box-ticking ethics frameworks')

## Assessment-Relevanz

**Domain Fit:** Sehr hohe Relevanz für die Schnittstelle AI/Soziale Arbeit/Gender. Das Paper kombiniert explizit feministische Theorie mit KI-Ethik und adressiert strukturelle Verantwortung, Care-Arbeit und Marginalisierung – Kernthemen der Sozialen Arbeit. Es zeigt, wie invisibilisierte, gendered Arbeit (Datenbereinigung, Labeling, Wartung) die gesamte KI-Wirtschaft trägt.

**Unique Contribution:** Bringt feministische politische Philosophie und organisationale Studien in Konversation über KI-Ethik; rekonzeptualisiert Verantwortung von individueller Zurechnung zu relationaler 'response-ability' und wertet Care/Maintenance-Arbeit auf – eine bislang marginalisierte Perspektive in KI-Ethik-Literatur.

**Limitations:** Studie begrenzt auf einen multinationalen Tech-Konzern, Generalisierbakeit auf andere Industrien unklar; Abhängigkeit von Unternehmens-Wohlwollen zur Umsetzung von Empfehlungen; begrenzte Analyse von Power-Differentialen zwischen Interviews-Durchführenden und befragten Arbeitern.

**Target Group:** KI-Ethiker:innen, Organisationsentwickler:innen in Tech-Unternehmen, Sozialarbeiter:innen in Policy/Tech-Governance, Genderstudies-Forschende, Arbeitnehmer:innen-Vertreter:innen in Tech, CSR/Sustainability-Manager:innen, Hochschullehrende in KI-Ethik und Feminist STS

## Schlüsselreferenzen

- [[Haraway_Donna_2016]] - Staying with the Trouble: Making Kin in the Chthulucene
- [[Puig_de_la_Bellacasa_Maria_2012]] - Nothing comes without its World: Thinking with Care
- [[Young_Iris_Marion_2011]] - Responsibility for Justice
- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[Butler_Judith_2003]] - Violence, Mourning, Politics
- [[Braidotti_Rosi_2021]] - Posthuman Feminism and Gender Methodology
- [[Coeckelbergh_Mark_2020]] - Artificial Intelligence, Responsibility Attribution, and Relational Justification of Explainability
- [[Fraser_Nancy_2016]] - Contradictions of Capital and Care
- [[Anzaldúa_Gloria_1999]] - La Frontera/Borderlands
- [[Chen_Aileen_2019]] - Inmates in Finland are Training AI as Part of Prison Labor
