---
title: Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit
authors:
  - Gesa Alena Linnemann
  - Julian Löhe
  - Beate Rottkemper
year: 2023
type: journalArticle
url: https://doi.org/10.1007/s12592-023-00455-7
doi: 10.1007/s12592-023-00455-7
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Stereotypen
  - Stereotype
---

# Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit

## Abstract

Die Bedeutung des Einsatzes von Verfahren, die unter dem Begriff der Künstlichen Intelligenz (KI) zusammenzufassen sind, wird sowohl für gesellschaftliche Prozesse als auch den Auftrag an die Soziale Arbeit zunehmend erkannt und diskutiert. Mit diesem Artikel wird ein Beitrag zum Diskurs geleistet, indem vertieft der Bereich der Sprachverarbeitung durch KI, das Natural Language Processing (NLP), in den Blick genommen wird. Verarbeitung natürlicher Sprache ist aufgrund der hohen Bedeutung kommunikativer Prozesse für die Praxis der Sozialen Arbeit von besonderer Relevanz, zugleich wird die Profession der Sozialen Arbeit tangiert. Bezugnehmend auf Staub-Bernasconis Handlungstheorie werden Implikationen und Diskussionspunkte von NLP identifiziert und diskutiert. Zudem werden mögliche Gratifikationen für Klient*innen herausgearbeitet, die sich u. a. aus der Wirkung und sozialen Interaktion ergeben. Hier wird die Media-Equation-Theorie von Nass und Reeves als Erkenntnisfolie herangezogen. Vor diesen Perspektiven ergeben sich sowohl Risiken (u. a. die Gefahr einer modularisierten Herauslösung genuin sozialarbeiterischer Tätigkeit) als auch Chancen (u. a. Teilhabe, niederschwelliger Zugang, Zugriff auf breitere Datenbasis).

## Key Concepts

### Bias Types
- [[Stereotype]]
- [[Stereotypen]]

## Full Text

---
title: "Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)"
authors: ["Gesa Alena Linnemann", "Julian Löhe", "Beate Rottkemper"]
year: 2023
type: journalArticle
language: de
processed: 2026-02-05
source_file: Linnemann_2023_Bedeutung_von_Künstlicher_Intelligenz_in_der.md
confidence: 91
---

# Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)

## Kernbefund

NLP bietet sowohl Chancen (niederschwelliger Zugang, Teilhabe, erweiterte Wissensbasis) als auch erhebliche Risiken (Modularisierung der Profession, Reproduktion von Stereotypen und Diskriminierung, ethische Probleme) für die Soziale Arbeit; ein kritisch begleiteter Einsatz unter Wahrung von Menschenrechten und Transparenz ist erforderlich.

## Forschungsfrage

Welche Implikationen und Chancen sowie Risiken ergeben sich aus dem Einsatz von Natural Language Processing (NLP) für die Praxis und Profession der Sozialen Arbeit in verschiedenen Handlungsfeldern?

## Methodik

Theoretisch-konzeptionell: Systematische Analyse unter Anwendung von Staub-Bernasconis Handlungstheorie, Uses-and-Gratification-Ansatz und Media Equation Theory; exemplarische Betrachtung verschiedener Handlungsfelder (Beratung, Kinder- und Jugendhilfe, Altenhilfe); Analyse von Praxisprojekten.
**Datenbasis:** Keine empirischen Daten; Analyse von bestehenden Projekten (Caritas 'Lernende Systeme in der Beratung', MAEWIN, CASoTex, KiJuAssistenz) und theoretischer Literatur

## Hauptargumente

- NLP ist für die Soziale Arbeit von besonderer Relevanz, da kommunikative Prozesse fundamental für die Praxis sind; zugleich berührt der Einsatz von KI alle drei Mandate der Profession (Gesellschaft, Klient*innen, Profession selbst) nach Staub-Bernasconi.
- Chatbots und Sprachassistenten können niederschwellige Erstkontakte ermöglichen und Gratifikationen wie Verfügbarkeit, Interaktivität und Autonomie bieten, müssen aber transparent gemacht werden und dürfen persönliche Beratung nicht ersetzen.
- Algorithmische Entscheidungssysteme (Predictive Analytics, Entscheidungsunterstützung) können Wissensbasis erweitern und Effizienz erhöhen, erfordern aber kritische Kompetenz von Fachkräften und bergen Risiken der Diskriminierung, Bias-Reproduktion und Modularisierung genuiner Sozialarbeitsleistungen.

## Kategorie-Evidenz

### Evidenz 1

Ausdrückliche Betonung der Notwendigkeit von Fachkompetenz: 'Fachkräfte müssen dazu befähigt werden, diese Wahrscheinlichkeiten zu interpretieren' und 'Es ist essenziell für den Einsatz von Entscheidungsunterstützungssystemen in der Praxis, dass transparent gemacht wird, mit welcher Wahrscheinlichkeit ein Ergebnis passend ist.'

### Evidenz 2

Explizite Diskussion von GPT-3 und ChatGPT: 'Das im Jahr 2020 veröffentlichte OpenAI GPT-3 nutzt DeepLearning-Applikationen und ist in der Lage, anhand von wenigen Input-Parametern qualitativ hochwertige Texte zu generieren' sowie 'ChatGPT' mit Verweis auf dessen Bestehen einer Jura-Prüfung 2023.

### Evidenz 3

Umfassende Behandlung von Natural Language Processing, Machine Learning, Deep Learning, Künstlichen Neuronalen Netzwerken und Predictive Analytics als zentrale Technologien.

### Evidenz 4

Expliziter Fokus auf alle Handlungsfelder: 'In verschiedenen Handlungsfeldern der Sozialen Arbeit wird der Einfluss von NLP exemplarisch dargestellt'; Analyse von Kinder- und Jugendhilfe, Altenhilfe, Beratung; Referenz zu Staub-Bernasconis Konzept der Menschenrechtsprofession.

### Evidenz 5

Warnung vor Reproduktion von Diskriminierung: 'stereotype Rollenbilder wiederholt werden' und 'Ohne interdisziplinäre Teams in der Entwicklung von Werkzeugen, die NLP nutzen, besteht die Gefahr der Reproduktion von Diskriminierung und sogar weiterer Radikalisierung'.

### Evidenz 6

Thematisierung marginalisierter Gruppen durch NLP und Sprachassistenz: besondere Betrachtung älterer Menschen, von Einsamkeit betroffener Menschen, weniger digital affiner Hilfesuchender: 'grundsätzlich darf die digitale Kontaktaufnahme nicht die ausschließliche Form des Erstkontakts sein, da sonst weniger digital affine Hilfesuchende nicht mehr erreicht werden.'

### Evidenz 7

Explizite Forderung nach Fairness im Sinne der Menschenrechte: 'Im Bereich NLP sind insbesondere das Verbot von Diskriminierung, der Schutz der Freiheitssphäre des Einzelnen und die Meinungs- und Informationsfreiheit zu beachten.'

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI und Soziale Arbeit: Das Paper bietet eine systematische, theoretisch fundierte Analyse des Einsatzes von NLP in verschiedenen sozialarbeiterischen Handlungsfeldern und diskutiert explizit die Spannung zwischen technologischen Chancen und professionalen sowie ethischen Standards der Menschenrechtsprofession.

**Unique Contribution:** Das Paper leistet einen seltenen deutschsprachigen, systématischen Beitrag zur KI-Ethik in der Sozialen Arbeit, indem es NLP-Technologien nicht abstrakt, sondern feldspezifisch (Beratung, Altenhilfe, Kinder- und Jugendhilfe) durch die Linse von Staub-Bernasconis Tripelmandat analysiert und sowohl Chancen als auch strukturelle Risiken der Professionalisierung adressiert.

**Limitations:** Das Paper ist rein konzeptionell-theoretisch ohne empirische Validierung der postulierten Chancen und Risiken in der Praxis; die Analyse von Gender-Bias bleibt oberflächlich und nutzt nicht explicitly feministische Theorien, obwohl Geschlechterdimensionen (insbesondere bei GPT-3 Bias) vorhanden sind.

**Target Group:** Primär: Sozialarbeiter*innen, Lehrende in Sozialer Arbeit, Fachkräfte in Beratung, Kinder- und Jugendhilfe sowie Altenhilfe; Sekundär: KI-Ethiker*innen, Policymaker im Sozialwesen, Studierende der Sozialen Arbeit und angrenzender Disziplinen

## Schlüsselreferenzen

- [[StaubBernasconi_2018]] - Soziale Arbeit als Handlungswissenschaft
- [[StaubBernasconi_2007]] - Soziale Arbeit: Dienstleistung oder Menschenrechtsprofession
- [[Nass_Brave_2005]] - Media Equation Theory
- [[Russell_Norvig_2021]] - Artificial Intelligence: A Modern Approach
- [[OpenAI_2020]] - GPT-3 Language Model
- [[Beranek_Hill_Sagebiel_2019]] - Digitalisierung und Soziale Arbeit - Diskursüberblick
- [[Schneider_Seelmeyer_2019]] - Challenges in Using Big Data for Decision Support Systems in Social Work
- [[Lucy_Bamman_2021]] - Gender and Representation Bias in GPT-3 Generated Stories
- [[McGuffie_Newhouse_2020]] - Radicalization Risks of GPT-3
- [[Fellmann_et_al_2020]] - Digitalisierung personennaher Dienstleistungen in der Kinder- und Jugendhilfe
