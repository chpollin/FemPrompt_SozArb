---
title: Trustworthy AI and the Logics of Intersectional Resistance
authors:
  - B. Knowles
  - J. Fledderjohann
  - J. T. Richards
  - K. R. Varshney
year: 2023
type: conferencePaper
url: https://doi.org/10.1145/3593013.3593986
doi: 10.1145/3593013.3593986
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Intersectionality
mitigation_strategies:
  - Intersectionality
---

# Trustworthy AI and the Logics of Intersectional Resistance

## Abstract

Critically examines mainstream "Trustworthy AI" frameworks from an intersectional feminist perspective, arguing that traditional AI ethics often privilege dominant groups and fail marginalized communities. Suggests reframing trustworthy AI principles to incorporate stewardship, care, humility, and empowerment, addressing intersectional injustices through power-sharing and structural change.

## Key Concepts

### Bias Types
- [[Intersectionality]]

### Mitigation Strategies
- [[Intersectionality]]

## Full Text

---
title: "Trustworthy AI and the Logics of Intersectional Resistance"
authors: ["Bran Knowles", "Jasmine Fledderjohann", "John T. Richards", "Kush R. Varshney"]
year: 2023
type: conferencePaper
language: en
processed: 2026-02-05
source_file: Knowles_2023_Trustworthy_AI_and_the_Logics_of_Intersectional.md
confidence: 75
---

# Trustworthy AI and the Logics of Intersectional Resistance

## Kernbefund

Distrust von KI durch marginalisierte Gruppen ist rational und gerechtfertigt, nicht irrational. Aktuelle Trustworthy AI Ansätze ignorieren die strukturellen Gründe für dieses Misstrauen und können dadurch öffentliches Misstrauen sogar verstärken.

## Forschungsfrage

Wie können wir die legitimen Gründe für Misstrauen gegenüber KI bei marginalisierten Menschen verstehen und in die Konzeptualisierung von 'vertrauenswürdiger KI' integrieren?

## Methodik

Theoretisch-konzeptuell. Kritische Analyse von Trustworthy AI Literatur kombiniert mit sozialwissenschaftlichen Perspektiven auf Vertrauen, intersektionale Theorie und Machtkritik.
**Datenbasis:** nicht empirisch; theoretisch-konzeptuelle Analyse mit Literaturbasierung

## Hauptargumente

- Distrust gegenüber KI bei marginalisierten Menschen ist nicht einfach cognitive Voreingenommenheit, sondern rationales, wohlbegründetes Misstrauen basierend auf historischen und gegenwärtigen Erfahrungen struktureller Gewalt durch Institutionen und Technologien.
- KI wird verwendet um eine 'digitale Underclass' zu konstruieren, die als 'undeserving' (unverdient) dargestellt wird, um strukturelle Gewalt moralisch zu rechtfertigen und der privilegierten Bevölkerung zu ermöglichen, ihre eigene Unbewusstheit zu bewahren.
- Vertrauen ist nicht objektiv; es ist teilweise subjektiv und durch Machtverhältnisse strukturiert. Menschen mit weniger Ressourcen können sich rationales Misstrauen eher leisten als marginalisierte Menschen, deren Risiko bei Vertrauen höher ist.

## Kategorie-Evidenz

### Evidenz 1

Fokus auf algorithmic decision-making systems, predictive analytics im Kontext von Ressourcenallokation, Risikobewertung und sozialen Kontrollmechanismen.

### Evidenz 2

Explizite Bezüge zu Vulnerability, Care-Arbeit, Sozialschutz, marginalisierte Bevölkerungsgruppen als Zielgruppen von KI-Systemen. Beispiele: Sozialhilfesysteme, Jugendhilfe, Risikoeinschätzung.

### Evidenz 3

Zentrale These: 'AI is being used to construct a digital underclass that is rhetorically labelled as undeserving' [Abstrakt]. Analyse struktureller Gewalt ('structural violence') durch KI, Reproduktion von Ungleichheit, Digital Divide.

### Evidenz 4

Multiply marginalized people und intersektionale Perspektive durchziehen das gesamte Paper. Spezifische Analyse unterschiedlicher Marginalisierungsformen (Race, Class, Disability etc.) und deren Kumulation.

### Evidenz 5

Explizite Verwendung von intersectionality (Crenshaw), Referenzen auf D'Ignazio & Klein 'Data Feminism', care ethics und Jean Watson's theory of human caring. Feminist ML approaches zitiert. Intersektionale und Care-theoretische Rahmung.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für Schnittstelle KI/Soziale Arbeit/Gender. Das Paper adressiert zentral, wie KI in Systemen sozialer Kontrolle und Ressourcenallokation Marginalisierte schadet und warum Sozialarbeiter:innen kritische Perspektiven auf KI brauchen.

**Unique Contribution:** Das Paper rekonzeptualisiert Distrust als rationale, intersektionale Widersetzung statt als kognitiver Fehler und schlägt grundsätzliche Reformulierungen von Fairness, Accountability und Transparency vor, die auf Care und Stewardship basieren.

**Limitations:** Nicht empirisch; Aussagen zur Prävalenz von Distrust-Einstellungen sind ankündigt ('future work'). Konzeptionelle und literaturbasierte Analyse ohne empirische Verifikation der theoretischen Modelle.

**Target Group:** KI-Ethiker:innen, Policymaker, Sozialarbeiter:innen, marginalisierte Communities, kritische Tech-Researcher:innen, Aktivist:innen, Fairness-ML Praktiker:innen, Care workers, Organisationen im Sozialsektor

## Schlüsselreferenzen

- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[Benjamin_Ruha_2019]] - Race After Technology / Racial logics of trust
- [[Eubanks_Virginia_2018]] - Automating Inequality
- [[Noble_Safiya_Umoja_2018]] - Algorithms of Oppression
- [[Crenshaw_Kimberlé_1989]] - Intersectionality concept
- [[Baier_Annette_2020]] - Trust and Trustworthiness
- [[Green_Ben_2020]] - The False Promise of Risk Assessments
- [[McQuillan_Dan_2022]] - Resisting AI: An Anti-fascist Approach
- [[Fricker_Miranda_2007]] - Epistemic Injustice
- [[Roberts_Dorothy_2014]] - Complicating the triangle of race, class and state
