---
title: "Training in Co-Creation as a Methodological Approach to Improve AI Fairness"
zotero_key: FL9N6Q3E
author_year: "Slesinger (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: journalArticle
language: nan
doi: "nan"
url: "https://cris.unibo.it/retrieve/707c849f-3aeb-4ca3-8d1f-2817960064bd/societies-14-00259%20(1).pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 2
rel_vulnerable: 3
rel_bias: 3
rel_praxis: 3
rel_prof: 1
total_relevance: 12

# Categorization
relevance_category: high
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "high-relevance", "dim-ai-komp-medium", "dim-vulnerable-high", "dim-bias-high", "dim-praxis-high", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Slesinger_2024_Training.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Training in Co-Creation as a Methodological Approach to Improve AI Fairness

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **12/15** (high) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 2/3 | ⭐⭐ Medium |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 3/3 | ⭐⭐⭐ High |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

This study examines the integration of training components in co-creation processes with vulnerable and marginalized stakeholder groups as part of developing AI bias detection and mitigation tools. The research shows that training on AI definitions, terminology, and socio-technical impacts is necessary to enable non-technical stakeholders to clearly articulate their insights on AI fairness. The authors emphasize the importance of critical reflection on appropriate use of training in co-creation approaches and their design and implementation for a truly more inclusive approach to AI system design.


## AI Summary

## Overview

This academic paper addresses a critical gap in AI fairness governance by examining how training components integrated into co-creation (Co-C) processes can enable meaningful participation of vulnerable and marginalized groups in AI system design. Grounded in practical experience developing an AI bias mitigation developer toolkit, the research confronts a fundamental challenge: those most adversely affected by biased AI systems are typically excluded from design processes due to technical complexity barriers. The paper's central contribution is demonstrating that structured training on AI bias, when thoughtfully incorporated into participatory design frameworks, can democratize technical expertise and enable substantive stakeholder engagement. However, the authors critically caution that such approaches risk becoming performative compliance mechanisms—particularly within the EU AI Act's regulatory landscape—where powerful institutions may instrumentalize Co-C exercises to demonstrate ethical credentials without achieving genuine fairness improvements or addressing underlying power asymmetries.

## Main Findings

The analysis reveals several critical insights. First, an "accessibility paradox" exists: while participatory design theoretically promotes fairness and social inclusion, AI's technical complexity creates insurmountable barriers for non-expert stakeholders, particularly vulnerable populations. Second, training serves as a viable methodological bridge for expertise democratization, but only when carefully designed with critical reflection on deployment timing, content, and pedagogical approach. Third, vulnerable groups' meaningful participation cannot be assumed automatic; it requires deliberate integration mechanisms, sustained engagement, and genuine decision-making power—not tokenistic inclusion. Fourth, the regulatory environment creates perverse incentives: institutions conduct superficial Co-C exercises primarily for EU AI Act compliance demonstration rather than substantive fairness advancement. Fifth, the paper identifies a critical distinction between procedural inclusion (having a seat at the table) and substantive equity (influencing outcomes), warning that training without power redistribution risks reinforcing existing hierarchies. Finally, the authors emphasize that Co-C's increasing instrumentalization by powerful actors threatens to co-opt participatory processes while maintaining structural inequalities.

## Methodology/Approach

The research employs a **socio-technical analytical framework** combining participatory design theory, co-creation methodology, and critical science and technology studies perspectives. Socio-technical researchers—positioned at the intersection of technical and social analysis—ground their investigation in practical experience developing an AI bias mitigation developer toolkit. This case study approach enables examination of real-world implementation challenges, power dynamics, regulatory pressures, and the gap between participatory design ideals and actual practice. The methodology integrates critical reflection on how training functions within Co-C processes, examining both enabling and constraining factors for genuine stakeholder participation.

## Relevant Concepts

**Co-creation (Co-C)**: Collaborative processes where diverse stakeholders, including those typically excluded from design, actively participate in developing technological solutions with genuine decision-making influence.

**Participatory Design (PD)**: Methodological approach ensuring marginalized stakeholder voices substantively shape technological development, not merely provide input.

**AI Bias/Fairness**: Technical and social challenge of preventing AI systems from reproducing or amplifying discrimination against vulnerable groups; requires both technical mitigation and social justice perspectives.

**Accessibility Paradox**: The contradiction between participatory design's inclusionary goals and technical barriers preventing meaningful participation by non-expert stakeholders.

**Expertise Democratization**: Process of making specialized technical knowledge accessible to non-experts, enabling informed participation in technical decision-making.

**Performative Compliance**: Superficial adherence to regulatory or ethical requirements (e.g., EU AI Act) without substantive commitment to underlying principles or outcomes.

**Power Asymmetries**: Structural inequalities in decision-making authority, resource access, and outcome influence between dominant institutions and marginalized stakeholders.

**Tokenistic Participation**: Inclusion of marginalized voices without genuine integration into decision-making processes or meaningful influence on outcomes.

## Significance

This paper makes crucial contributions to AI ethics and governance scholarship by challenging techno-optimistic assumptions about participatory approaches. It bridges applied AI fairness research with critical STS perspectives, questioning whether procedural inclusion automatically guarantees substantive equity. The work is particularly timely given regulatory developments like the EU AI Act, where Co-C exercises increasingly serve compliance functions. By highlighting risks of instrumentalization while proposing training as a methodological solution, the paper provides practical guidance for researchers and practitioners seeking genuinely inclusive AI development while maintaining critical awareness of power dynamics and regulatory capture risks. The research reveals that training alone is insufficient; meaningful participation requires redistributing decision-making power and ensuring vulnerable groups' perspectives substantively influence outcomes. This positions the work at the intersection of technical AI development, social justice concerns, and governance critique, with implications for policy frameworks, institutional practices, and future participatory AI research.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://cris.unibo.it/retrieve/707c849f-3aeb-4ca3-8d1f-2817960064bd/societies-14-00259%20(1).pdf
- **Zotero:** [Open in Zotero](zotero://select/items/FL9N6Q3E)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

