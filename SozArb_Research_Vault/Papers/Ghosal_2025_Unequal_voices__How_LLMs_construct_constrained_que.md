---
title: "Unequal voices: How LLMs construct constrained queer narratives"
zotero_key: RSMUFA95
author_year: "Ghosal (2025)"
authors: []

# Publication
publication_year: 2025.0
item_type: report
language: nan
doi: "nan"
url: "https://arxiv.org/abs/2507.15585"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 3
rel_praxis: 1
rel_prof: 1
total_relevance: 9

# Categorization
relevance_category: medium
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-high", "dim-bias-high", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Ghosal_2025_Unequal.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Unequal voices: How LLMs construct constrained queer narratives

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2025.0 |
| **Decision** | **Include** |
| **Total Relevance** | **9/15** (medium) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

Investigates how large language models represent queer individuals in generated narratives, uncovering tendencies toward stereotyped and narrow portrayals. Identifies phenomena including narrow topic range, discursive othering, and identity foregrounding. Shows LLMs unconsciously reinforce divide where marginalized groups are not afforded same breadth of narrative roles as others.


## AI Summary

## Overview

This paper investigates how Large Language Models systematically construct narrower, more identity-constrained narratives about LGBTQ+ individuals compared to non-queer personas in neutral contexts. The research addresses a critical gap in AI ethics by moving beyond traditional toxicity auditing to examine subtle representational biases embedded in LLM outputs. The authors argue that even when responses appear neutral or positive, they reflect and amplify real-world media disparities that marginalize LGBTQ+ people by reducing their complexity to identity-focused characteristics. The motivation is urgent: LLMs increasingly function in creative, educational, and therapeutic roles (including therapist chatbots), making their representational patterns consequential for cultural narrative formation. The paper demonstrates that problematic outputs operate through subtle prevalence patterns rather than overt toxicity, rendering them invisible to conventional bias auditing methods.

## Main Findings

The study demonstrates statistically significant differences in LLM portrayals of queer versus non-queer personas. When assuming LGBTQ+ identities, models disproportionately center responses on sexual orientation or gender identity, even when contextually irrelevant. For example, queried about employment, a queer male persona emphasizes identity-related job aspects, while a non-queer male persona focuses on career aspirations and community contributions. This reveals that LLMs default to identity-focused narratives for marginalized groups while affording non-marginalized groups full human complexity. The authors identify three distinct textual phenomena operating simultaneously: (1) **explicitly harmful representations** (overtly negative content), (2) **overly narrow representations** (identity-constrained scope), and (3) **discursive othering** (systematic marking of difference). Crucially, findings show that problematic outputs operate through cumulative prevalence patterns—the sheer frequency of identity-focus—rather than individual toxic instances, making detection difficult through standard bias audits.

## Methodology/Approach

The research employs comparative persona-based prompting experiments using Llama-3.1-8B-Instruct. Researchers instruct the model to assume specific identities (queer and non-queer pairs) and respond to identical neutral queries without additional contextual cues. This methodology operationalizes "constrained narratives" through systematic textual comparison. The theoretical framework integrates media studies (examining how narratives shape cultural consciousness and societal perception of marginalized groups) with disability justice scholarship (particularly the "inspiration porn" concept). Replication code is forthcoming, supporting methodological transparency and reproducibility.

## Relevant Concepts

**Constrained Narratives**: Narrow, stereotyped topic ranges assigned to marginalized groups, contrasting with full complexity afforded to default groups.

**Explicitly Harmful Representations**: Overtly negative or toxic content about marginalized individuals.

**Overly Narrow Representations**: Identity-constrained portrayals that reduce individuals to single characteristics.

**Discursive Othering**: Textual practices systematically marking marginalized individuals as fundamentally different through representational choices.

**Inspiration Porn**: Problematic portrayals reducing marginalized people (especially disabled individuals) to motivational examples, denying full humanity.

**Representational Bias**: Subtle associative patterns in AI outputs mirroring real-world media biases without explicit toxicity.

## Significance

This work advances AI ethics by establishing analytical frameworks for detecting structural representational constraints beyond explicit bias. It demonstrates how neutral prompts reveal embedded biases and connects LLM outputs to real-world narrative marginalization patterns. The research has immediate implications for applications where LLMs function as creative or therapeutic agents, suggesting current bias auditing practices inadequately address how AI systems reproduce social inequalities through representation. By bridging computational linguistics with critical media studies and disability justice frameworks, the paper opens new methodological pathways for understanding AI's role in cultural narrative formation and provides evidence-based grounds for demanding more equitable LLM development practices. The distinction between explicit bias and structural representational constraints represents a significant conceptual advance in the field.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://arxiv.org/abs/2507.15585
- **Zotero:** [Open in Zotero](zotero://select/items/RSMUFA95)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

