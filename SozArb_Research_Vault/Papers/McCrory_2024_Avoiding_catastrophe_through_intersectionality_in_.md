---
title: "Avoiding catastrophe through intersectionality in global AI governance"
zotero_key: NMD5P5LN
author_year: "McCrory (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: report
language: nan
doi: "nan"
url: "https://www.cigionline.org/documents/3375/DPH-paper-Laine_McCrory.pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 2
rel_praxis: 1
rel_prof: 1
total_relevance: 8

# Categorization
relevance_category: medium
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-high", "dim-bias-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_McCrory_2024_Avoiding.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Avoiding catastrophe through intersectionality in global AI governance

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **8/15** (medium) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 2/3 | ⭐⭐ Medium |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

In this working paper, McCrory argues that prevailing global AI governance efforts (especially those focused on “AI safety” and existential risks) lack an adequate intersectional, feminist perspective, which is needed to avert not just hypothetical future catastrophes but ongoing injustices. The paper analyzes seven prominent international AI policy initiatives (e.g. global AI accords and principles) against criteria derived from feminist theory, such as intersectionality, context, and power dynamics. McCrory finds that these high-level policies often remain techno-centric: they invoke abstract risks or neutrality, but fail to engage with how AI harms are unevenly distributed along lines of gender, race, and class. For example, current AI “safety” pledges seldom consider the lived experiences of marginalized communities or the way existing structural inequalities are mirrored in AI systems. The author contends that treating AI governance as a purely technical, top-down process is misguided; instead, governance should include meaningful participation from under-represented groups and incorporate feminist insights about power and oppression. The paper’s recommendations call for centering intersectionality in AI policy: explicitly addressing how AI-related risks and harms intersect with social identity and historical injustices, and ensuring that any frameworks for AI risk management or ethics actively involve those who have been marginalized by past technological developments.


## AI Summary

![[summary_McCrory_2024_Avoiding.md]]


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://www.cigionline.org/documents/3375/DPH-paper-Laine_McCrory.pdf
- **Zotero:** [Open in Zotero](zotero://select/items/NMD5P5LN)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

