---
title: "AI gender bias, disparities, and fairness: Does training data matter?"
zotero_key: 5KXKHIKC
author_year: "Latif (2023)"
authors: []

# Publication
publication_year: 2023.0
item_type: report
language: nan
doi: "nan"
url: "https://arxiv.org/html/2312.10833v2"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 0
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 1
rel_prof: 1
total_relevance: 7

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Vulnerable Groups"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-medium", "dim-bias-high"]

# Summary
has_summary: false
summary_file: ""

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# AI gender bias, disparities, and fairness: Does training data matter?

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2023.0 |
| **Decision** | **Include** |
| **Total Relevance** | **7/15** (medium) |
| **Top Dimensions** | Bias Analysis, Vulnerable Groups |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 0/3 | — None |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

Empirische Analyse von Geschlechterbias in Bewertungssystemen mit BERT und GPT-3.5. Mixed-gender Trainingsdaten reduzierten Bias, aber verstärkten Unterschiede. Drei Bias-Metriken angewendet.


## AI Summary

*No AI summary available. This paper was assessed but not yet processed through the summarization pipeline.*


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://arxiv.org/html/2312.10833v2
- **Zotero:** [Open in Zotero](zotero://select/items/5KXKHIKC)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

