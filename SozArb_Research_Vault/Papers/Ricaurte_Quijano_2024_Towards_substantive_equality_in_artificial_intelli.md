---
title: "Towards substantive equality in artificial intelligence: Transformative AI policy for gender equality and diversity"
zotero_key: SXXJ9Y7C
author_year: "Ricaurte Quijano (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: report
language: nan
doi: "nan"
url: "https://wp.oecd.ai/app/uploads/2025/05/towards-substantive-equality-in-artificial-intelligence_Transformative-AI-policy-for-gender-equality-and-diversity.pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 3
rel_praxis: 2
rel_prof: 1
total_relevance: 10

# Categorization
relevance_category: high
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "high-relevance", "dim-vulnerable-high", "dim-bias-high", "dim-praxis-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Ricaurte_Quijano_2024_Towards.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Towards substantive equality in artificial intelligence: Transformative AI policy for gender equality and diversity

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **10/15** (high) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

This extensive report – developed through the Global Partnership on AI (GPAI) with contributors from academia and policy – sets out a vision for “substantive equality” in AI as opposed to mere formal equality. It recognizes that AI systems can replicate and even amplify societal power imbalances (“algorithmic discrimination”), thus requiring proactive governance to ensure historically marginalized groups are not left behind in the AI era. The report argues that purely technical bias mitigation is insufficient; instead, transformative policies should intervene at multiple points in the AI lifecycle to address structural inequities. Key principles advocated include: anchoring AI development in human rights and intersectional gender analysis, improving inclusive representation in data and AI design, and imposing stronger transparency and accountability obligations on AI systems to prevent harm. It provides practical policy recommendations (e.g., mandating diverse datasets and impact assessments, establishing a “right to information” about AI algorithms, and supporting community-led AI initiatives) to achieve de facto equality of outcomes – meaning AI should actively help reduce societal inequalities rather than reinforce them. Overall, the report positions digital equity as an extension of social justice: ensuring not only fairness within AI outputs but also equitable access, participation, and empowerment in shaping AI technology.


## AI Summary

![[summary_Ricaurte_Quijano_2024_Towards.md]]


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://wp.oecd.ai/app/uploads/2025/05/towards-substantive-equality-in-artificial-intelligence_Transformative-AI-policy-for-gender-equality-and-diversity.pdf
- **Zotero:** [Open in Zotero](zotero://select/items/SXXJ9Y7C)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

