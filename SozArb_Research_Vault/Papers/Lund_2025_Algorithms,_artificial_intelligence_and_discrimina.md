---
title: "Algorithms, artificial intelligence and discrimination"
zotero_key: GN5D9A7D
author_year: "Lund (2025)"
authors: []

# Publication
publication_year: 2025.0
item_type: report
language: nan
doi: "nan"
url: "https://ldo.no/content/uploads/2025/05/Algorithms-artificial-intelligence-and-discrimination-report.pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 0
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 2
rel_prof: 1
total_relevance: 8

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Vulnerable Groups"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-medium", "dim-bias-high", "dim-praxis-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Lund_2025_Algorithms.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Algorithms, artificial intelligence and discrimination

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2025.0 |
| **Decision** | **Include** |
| **Total Relevance** | **8/15** (medium) |
| **Top Dimensions** | Bias Analysis, Vulnerable Groups |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 0/3 | — None |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

Dieser norwegische Regierungsbericht überprüft Schlüsselelemente des norwegischen Gleichstellungs- und Antidiskriminierungsgesetzes mit primärem Fokus auf algorithmische Diskriminierung. Der Bericht diskutiert die mögliche Einführung spezifischer Definitionen direkter und indirekter algorithmischer Diskriminierung und schlägt die Schaffung einer spezifischen Bestimmung zu rechtmäßiger algorithmischer Differenzialbehandlung vor. Die Komplexität algorithmischer Systeme erschwert die Unterscheidung zwischen direkter und indirekter Diskriminierung, was neue rechtliche Ansätze erfordert.


## AI Summary

## Overview

This Norwegian legal report, authored by Professor Vibeke Blaker Strand (University of Oslo) and published by the Equality and Anti-Discrimination Ombud (LDO) in 2024, examines whether existing equality and anti-discrimination legislation adequately protects individuals from discriminatory outcomes produced by algorithmic systems and artificial intelligence. The document addresses a critical gap in contemporary legal scholarship by integrating three distinct regulatory domains: Norwegian equality law, the EU's General Data Protection Regulation (GDPR), and the emerging EU AI Act. Originally published in Norwegian, the English translation reflects the author's active involvement in ensuring accuracy and currency. The report's central premise is that algorithmic discrimination cannot be adequately addressed through isolated legal frameworks, requiring instead coordinated analysis across multiple regulatory instruments.

## Main Findings

The analysis reveals that traditional anti-discrimination frameworks possess significant but incomplete capacity to regulate algorithmic systems. Specifically: (1) Norwegian equality and anti-discrimination laws offer partial protection against algorithmic harm but contain substantial gaps in detecting, proving, and remedying algorithmic discrimination; (2) The AI Act, GDPR, and equality law create both regulatory opportunities and dangerous lacunae when applied to algorithmic decision-making; (3) These frameworks were designed for human decision-making contexts, creating interpretive challenges when applied to algorithmic systems characterized by opacity, complexity, and scale; (4) Informational privacy protection and anti-discrimination objectives are deeply interconnected, requiring integrated legal analysis; (5) Current legal instruments lack adequate mechanisms for addressing causation difficulties inherent in algorithmic discrimination cases. The report concludes that existing legal frameworks require substantial adaptation to address the unique challenges posed by AI-driven discrimination, particularly regarding burden of proof and remedial mechanisms.

## Methodology/Approach

The author employs rigorous doctrinal legal methodology, systematically examining statutory provisions and their interpretive scope across multiple jurisdictions and regulatory instruments. The approach combines comparative legal analysis, evaluating Norwegian equality law against EU regulatory frameworks (AI Act, GDPR) to identify convergences, divergences, and complementarities. The institutional perspective of the Equality and Anti-Discrimination Ombud provides authoritative grounding and practical enforcement context. Rather than treating discrimination law, data protection, and AI regulation as separate domains, the methodology integrates these fields, examining their interconnections and mutual implications. This integrated theoretical framework represents a sophisticated departure from siloed legal analysis, recognizing that algorithmic discrimination requires multidimensional legal understanding and coordinated regulatory application.

## Relevant Concepts

**Algorithmic Discrimination**: Discriminatory outcomes produced by automated decision-making systems, distinct from intentional human discrimination and presenting novel evidentiary challenges regarding causation and intent.

**Algorithmic Opacity**: The technical and interpretive difficulty in understanding how algorithmic systems reach specific decisions, creating barriers to legal proof of discrimination.

**Informational Privacy**: Protection of personal data and information autonomy, increasingly critical as AI systems process vast datasets to generate predictions and decisions affecting fundamental rights.

**Regulatory Gap**: Spaces where existing legal frameworks fail to address emerging technological harms, particularly regarding algorithmic opacity, causation difficulties, and burden of proof.

**Integrated Regulation**: Coordinated application of multiple legal instruments (equality law, GDPR, AI Act) to comprehensively address algorithmic discrimination rather than siloed regulatory approaches.

**Doctrinal Legal Methodology**: Systematic examination of statutory provisions, case law, and legal principles to determine their scope, application, and interpretive possibilities.

## Significance

This report holds substantial significance for multiple audiences. For legal scholars, it contributes to emerging discourse on law and AI governance, specifically discrimination-focused analysis within European regulatory contexts. For policymakers and enforcement bodies, it provides institutional authority and practical guidance on regulatory adequacy and necessary legal reforms. The transnational relevance—addressing EU-level regulations (GDPR, AI Act) applicable across member states—extends its impact beyond Norway, informing broader European legal development. The work identifies critical gaps between technological reality and legal capacity, establishing that algorithmic discrimination represents a qualitatively different challenge requiring adaptive legal frameworks, enhanced evidentiary mechanisms, and coordinated regulatory approaches. By bridging legal scholarship with practical regulatory concerns, the report advances understanding of how contemporary legal systems must evolve to protect fundamental equality rights in algorithmic societies, particularly regarding burden of proof, causation standards, and remedial mechanisms.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://ldo.no/content/uploads/2025/05/Algorithms-artificial-intelligence-and-discrimination-report.pdf
- **Zotero:** [Open in Zotero](zotero://select/items/GN5D9A7D)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

