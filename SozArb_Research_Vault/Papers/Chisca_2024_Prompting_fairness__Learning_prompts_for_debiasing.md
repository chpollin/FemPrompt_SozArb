---
title: "Prompting fairness: Learning prompts for debiasing large language models"
zotero_key: MHZTET9D
author_year: "Chisca (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: conferencePaper
language: nan
doi: "nan"
url: "https://aclanthology.org/2024.ltedi-1.6/"

# Assessment
decision: Exclude
exclusion_reason: "Not relevant topic"

# Relevance Scores (0-3)
rel_ai_komp: 0
rel_vulnerable: 0
rel_bias: 0
rel_praxis: 0
rel_prof: 0
total_relevance: 0

# Categorization
relevance_category: low
top_dimensions: []

# Tags
tags: ["paper", "exclude", "low-relevance"]

# Summary
has_summary: false
summary_file: ""

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Prompting fairness: Learning prompts for debiasing large language models

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Exclude** |
| **Total Relevance** | **0/15** (low) |
| **Top Dimensions** | None |


## Exclusion Reason

Not relevant topic


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 0/3 | — None |
| Vulnerable Groups & Digital Equity | 0/3 | — None |
| Bias & Discrimination Analysis | 0/3 | — None |
| Practical Implementation | 0/3 | — None |
| Professional/Social Work Context | 0/3 | — None |


## Abstract

Introduces novel prompt-tuning method for reducing biases in encoder models like BERT and RoBERTa through training small sets of additional reusable token embeddings. Demonstrates state-of-the-art performance while maintaining minimal impact on language modeling capabilities through parameter-efficient approach applicable across different models and tasks.


## AI Summary

*No AI summary available. This paper was assessed but not yet processed through the summarization pipeline.*


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://aclanthology.org/2024.ltedi-1.6/
- **Zotero:** [Open in Zotero](zotero://select/items/MHZTET9D)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

