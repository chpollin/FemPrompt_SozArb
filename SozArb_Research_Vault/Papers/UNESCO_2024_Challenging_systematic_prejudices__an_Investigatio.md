---
title: "Challenging systematic prejudices: an Investigation into Gender Bias in Large Language Models"
zotero_key: WD9KQG9J
author_year: "UNESCO (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: journalArticle
language: nan
doi: "nan"
url: "https://discovery.ucl.ac.uk/id/eprint/10188772/1/Unesco_results.pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 0
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 1
rel_prof: 1
total_relevance: 7

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Vulnerable Groups"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-medium", "dim-bias-high", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_UNESCO_2024_Challenging.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Challenging systematic prejudices: an Investigation into Gender Bias in Large Language Models

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **7/15** (medium) |
| **Top Dimensions** | Bias Analysis, Vulnerable Groups |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 0/3 | — None |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

This study explores biases in three significant large language models (LLMs): OpenAI’s GPT-2 and ChatGPT, along with Meta’s Llama 2, highlighting their role in both advanced decision-making systems and as user-facing conversational agents. Across multiple studies, the brief reveals how biases emerge in the text generated by LLMs, through gendered word associations, positive or negative regard for gendered subjects, or diversity in text generated by gender and culture. The research uncovers persistent social biases within these state-of-the-art language models, despite ongoing efforts to mitigate such issues. The findings underscore the critical need for continuous research and policy intervention to address the biases that exacerbate as these technologies are integrated across diverse societal and cultural landscapes. The emphasis on GPT-2 and Llama 2 being open-source foundational models is particularly noteworthy, as their widespread adoption underlines the urgent need for scalable, objective methods to assess and correct biases, ensuring fairness in AI systems globally.


## AI Summary

![[summary_UNESCO_2024_Bias.md]]


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://discovery.ucl.ac.uk/id/eprint/10188772/1/Unesco_results.pdf
- **Zotero:** [Open in Zotero](zotero://select/items/WD9KQG9J)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

