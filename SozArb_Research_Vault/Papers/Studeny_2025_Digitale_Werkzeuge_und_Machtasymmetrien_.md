---
title: "Digitale Werkzeuge und Machtasymmetrien?"
zotero_key: JIQLZ5E6
author_year: "Studeny (2025)"
authors: []

# Publication
publication_year: 2025.0
item_type: conferencePaper
language: nan
doi: "nan"
url: "https://www.ogsa.at/wp-content/uploads/2025/03/ogsaTAGUNG2025_AG-Digitalisierung_Handout-Machtasymmetrien-Susanne-Studeny.pdf"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 1
rel_prof: 3
total_relevance: 10

# Categorization
relevance_category: high
top_dimensions: ["Bias Analysis", "Professional Context"]

# Tags
tags: ["paper", "include", "high-relevance", "dim-vulnerable-medium", "dim-bias-high", "dim-prof-high", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Studeny_2025_Digitale.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Digitale Werkzeuge und Machtasymmetrien?

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2025.0 |
| **Decision** | **Include** |
| **Total Relevance** | **10/15** (high) |
| **Top Dimensions** | Bias Analysis, Professional Context |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 3/3 | ⭐⭐⭐ High |


## Abstract

Studeny analyzes power asymmetries in digital social work, emphasizing that digital tools and algorithms create new, often invisible forms of power and control. AI decisions remove influence from both professionals and clients while responsibility remains unclear. Algorithms reinforce discrimination as they work with biased data. The author demands that social work critically reflects on digital technologies, demands transparency, and ensures that technology serves people.


## AI Summary

## Overview

This academic document presents a critical examination of digital tools within social work practice, specifically addressing how technology mediates power relationships between practitioners and clients. Prepared for the OGSA conference in Graz (March 2025), the work challenges the prevailing assumption that digitalization inherently improves social services. Instead, it argues that digital systems often reproduce and amplify existing institutional power asymmetries while creating novel forms of control and dependency. The document's central concern is whether technology serves emancipatory or oppressive functions within welfare systems, with particular attention to how digital infrastructure shapes client autonomy, data rights, and access to services. It contextualizes "Projekt Konrad" as a case study examining these dynamics in practice.

## Main Findings

The analysis reveals several critical tensions in digital social work implementation. First, digital tools function as mechanisms of power amplification rather than neutral instruments—they embed institutional interests and structural inequalities into their design and deployment. Second, algorithmic decision-making systems perpetuate discrimination by encoding historical biases into automated processes, creating ostensibly objective yet fundamentally unjust outcomes. Third, surveillance technologies marketed as care mechanisms paradoxically undermine the trust essential to effective social work relationships. Fourth, digital exclusion creates stratified access to services, with vulnerable populations experiencing compounded marginalization. Fifth, **digital steering (Steuerung)** operates invisibly to constrain client autonomy without explicit coercion, representing subtle but pervasive threats to self-determination. Sixth, institutional dependencies on proprietary Big Tech systems create structural vulnerabilities requiring alternative models. Finally, **human decision-making authority must be preserved** as a non-negotiable ethical requirement, with transparency mechanisms embedded as accountability safeguards rather than afterthoughts.

## Methodology/Approach

The document employs critical social theory as its analytical foundation, integrating Foucauldian power analysis with institutional critique and rights-based frameworks. This approach examines how surveillance, data control, and algorithmic governance function within welfare bureaucracies. The methodology is explicitly reflexive, requiring social workers to examine their complicity in digital power structures rather than positioning themselves as neutral implementers. The framework combines structural inequality analysis—particularly regarding algorithmic bias—with participatory action research traditions emphasizing co-determination. Critically, the approach identifies **practitioner reflexivity itself as an essential finding**, not merely a methodological tool. This interdisciplinary approach bridges critical digital sociology, social work ethics, and data justice scholarship, creating a comprehensive critique that moves beyond technical solutions toward systemic transformation.

## Relevant Concepts

**Data Sovereignty**: Client control over personal information and decision-making authority regarding data usage; fundamental to dignity and autonomy.

**Algorithmic Discrimination**: Systematic bias embedded in AI systems that reproduces social inequalities through ostensibly objective automated decisions.

**Surveillance Paradox**: The contradiction between surveillance framed as protective care and its actual function as control mechanism undermining trust.

**Digital Steuerung (Steering)**: Invisible algorithmic governance that constrains autonomy through subtle nudging rather than explicit coercion; distinct from overt surveillance.

**Digital Exclusion**: Stratified access to digital services creating new forms of social marginalization alongside traditional inequalities.

**Transparenz (Transparency)**: Requirement for explicability of algorithmic decisions and data usage as justice imperative, not merely technical documentation.

**Mitbestimmung (Co-determination)**: Genuine client participation in technology governance decisions rather than passive service consumption.

**Digital Sovereignty**: Institutional and individual independence from proprietary systems, enabling autonomous decision-making and reducing Big Tech dependency.

**Vertrauen (Trust)**: Central relational element of social work undermined by surveillance systems; prerequisite for effective practice.

## Significance

This work holds substantial significance for social work practice, policy, and ethics. It provides practitioners with critical frameworks for evaluating technology adoption rather than uncritically accepting digitalization narratives. For policymakers, it demonstrates that efficiency gains cannot justify autonomy erosion or rights violations. Theoretically, it advances critical digital sociology by specifically contextualizing algorithm studies within social work's ethical obligations to vulnerable populations. The emphasis on co-determination, digital literacy, and digital sovereignty as justice imperatives reframes digitalization as fundamentally a question of power distribution rather than technical progress. Critically, the document identifies **digital education as a key to social justice**, positioning literacy not as individual skill-building but as structural empowerment. By challenging techno-optimism while avoiding technological determinism, the document enables more nuanced, ethically grounded approaches to digital transformation in welfare systems that prioritize human decision-making authority and institutional independence from proprietary systems.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://www.ogsa.at/wp-content/uploads/2025/03/ogsaTAGUNG2025_AG-Digitalisierung_Handout-Machtasymmetrien-Susanne-Studeny.pdf
- **Zotero:** [Open in Zotero](zotero://select/items/JIQLZ5E6)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

