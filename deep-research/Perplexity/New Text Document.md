# Feministische Digital- und KI-Kompetenzen zur Sichtbarmachung und Reduktion von Bias in KI-Technologien: Eine systematische Literaturanalyse

## Einleitung

Diese systematische Literaturanalyse untersucht, wie feministische Digital- und KI-Kompetenzen sowie diversitätsreflektierendes Prompting zur Sichtbarmachung und Reduktion von Bias und intersektionalen Diskriminierungsformen in KI-Technologien beitragen können. Die Analyse konzentriert sich auf peer-reviewte Quellen aus dem Zeitraum 2023-2025 und bewertet deren Qualität systematisch.

Die Forschung zu feministischen Ansätzen in der KI-Entwicklung hat in den letzten Jahren erheblich zugenommen, da die Auswirkungen algorithmischer Verzerrungen auf marginalisierte Gruppen immer deutlicher werden [1][2][3]. Intersektionale Ansätze, die multiple Identitätskategorien berücksichtigen, erweisen sich dabei als besonders relevant für die Entwicklung gerechterer AI-Systeme [4][5][6].

## Systematische Literaturanalyse

### 1. Intersektionale Fairness und KI-Bias

**APA-Zitation:**
Gohar, U., & Cheng, L. (2023). A Survey on Intersectional Fairness in Machine Learning: Opportunities and Challenges. *Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI-23), Survey Track*, 6619-6625. https://doi.org/10.24963/ijcai.2023/742

**Zusammenfassung:**
Diese umfassende Übersichtsarbeit untersucht intersektionale Fairness in maschinellen Lernsystemen und geht über traditionelle binäre Fairness-Ansätze hinaus. Die Autoren präsentieren eine Taxonomie intersektionaler Fairness-Konzepte, die zeigt, wie mehrere sensitive Attribute (Geschlecht, Rasse, Klasse) interagieren und zu einzigartigen Diskriminierungsformen führen. Die Studie identifiziert zentrale Herausforderungen wie Datensparsamkeit bei intersektionalen Gruppen und die Komplexität der Bias-Mitigation. Praktische Anwendungen werden in NLP-Systemen, Ranking-Algorithmen und Bilderkennung demonstriert. Die Forschung zeigt, dass traditionelle Fairness-Metriken für unabhängige Gruppen bei intersektionalen Identitäten versagen können, da beispielsweise Schwarze Frauen andere Diskriminierungserfahrungen machen als Schwarze Menschen oder Frauen allgemein. Die Arbeit bietet konkrete Empfehlungen für die Entwicklung fairerer AI-Systeme durch intersektionale Ansätze.

**Qualitätsbewertung: Hoch**
*Begründung: Peer-reviewt in hochrangiger IJCAI-Konferenz, methodisch rigoros mit systematischer Taxonomie-Entwicklung, umfassende Literaturanalyse mit über 100 Referenzen, hohe Relevanz für das Forschungsfeld mit starkem theoretischen und praktischen Beitrag.*

### 2. Feminist AI als Rahmenwerk

**APA-Zitation:**
Wudel, A., & Ehrenberg, A. (2025). What is Feminist AI? *Friedrich-Ebert-Stiftung Competence Centre on the Future of Work Analysis Paper*. https://library.fes.de/pdf-files/bueros/bruessel/21888-20250304.pdf

**Zusammenfassung:**
Diese Arbeit definiert Feminist AI (FAI) als ein Framework, das intersektionalen Feminismus zur Adressierung von Bias und Ungleichheiten in AI-Systemen nutzt. FAI betont interdisziplinäre Zusammenarbeit, systemische Machtanalyse und iterative Theorie-Praxis-Schleifen. Durch die Einbettung feministischer Werte – Gleichberechtigung, Freiheit und Gerechtigkeit – strebt FAI eine Transformation der AI-Entwicklung an. Praktische Anwendungen umfassen FemAIs Advocacy für feministische Perspektiven im EU AI Act und die MIRA-Diagnostikplattform, die AI-Tools mit sozialen Gerechtigkeitszielen ausrichtet. Die Studie unterscheidet FAI von traditionellen "Responsible AI"-Ansätzen durch den Fokus auf strukturelle Machtungleichheiten statt individueller "schlechter Akteure". FAI bietet konkrete Maßnahmen wie die Reduzierung von Ressourcenverbrauch, Diversitätstests für Trainingsdaten und explizite Einverständniserklärungen für Datensammlung.

**Qualitätsbewertung: Hoch**
*Begründung: Aktuelle Publikation 2025, theoretisch fundiert mit praktischen Anwendungsbeispielen, systematische Methodologie, Verbindung zu politischen Entscheidungsprozessen (EU AI Act), hohe Relevanz für feministische AI-Forschung.*

### 3. Geschlechtsbias und digitale Kompetenz

**APA-Zitation:**
Shah, S. S. (2025). Gender Bias in Artificial Intelligence: Empowering Women Through Digital Literacy. *Premier Journal of Artificial Intelligence*, 1, 1000088. https://doi.org/10.70389/PJAI.1000088

**Zusammenfassung:**
Diese narrative Übersichtsarbeit untersucht das Zusammenspiel zwischen Geschlechtsbias in AI-Systemen und dem Potenzial digitaler Kompetenz zur Stärkung von Frauen in der Technologie. Durch Synthese von Forschung aus 2010-2024 analysiert die Studie systematische Geschlechtsverzerrungen in AI-Anwendungen in Rekrutierung, Gesundheitswesen und Finanzdienstleistungen. Diese Verzerrungen entstehen durch Unterrepräsentation von Frauen in AI-Entwicklungsteams (nur 22% weltweit), voreingenommene Trainingsdaten und algorithmische Designentscheidungen. Digitale Literacy-Programme erweisen sich als vielversprechende Intervention, die kritisches Bewusstsein für AI-Bias fördert, Frauen zu AI-Karrieren ermutigt und das Wachstum von frauengeführten AI-Projekten katalysiert. Die Forschung zeigt konkrete Erfolge wie AI4ALL, wo 78% der Teilnehmerinnen STEM-Studien fortsetzen und 91% gesteigertes Interesse an AI-Karrieren zeigen.

**Qualitätsbewertung: Mittel-Hoch**
*Begründung: Peer-reviewed Journal, systematische Literatursuche mit thematischer Analyse, hohe praktische Relevanz, jedoch relativ neues Journal mit unklarem Impact Factor, methodisch solide narrative Review.*

### 4. Data Feminism für AI

**APA-Zitation:**
Klein, L., & D'Ignazio, C. (2024). Data Feminism for AI. In *Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT '24)* (pp. 100-112). ACM. https://doi.org/10.1145/3630106.3658543

**Zusammenfassung:**
Diese Arbeit präsentiert intersektionale feministische Prinzipien für gerechte, ethische und nachhaltige AI-Forschung. Die Autoren erweitern ihre sieben Data Feminism-Prinzipien auf AI-Kontexte: Macht untersuchen, Macht herausfordern, Binäritäten und Hierarchien überdenken, Emotion und Verkörperung erheben, Kontext berücksichtigen, Pluralismus umarmen und Arbeit sichtbar machen. Zusätzlich werden zwei neue Prinzipien zu Umweltauswirkungen und Einverständnis vorgeschlagen. Das Framework hilft bei der Identifizierung und Minderung vorhersagbarer Schäden vor der Freisetzung diskriminierender Systeme. Praktische Anwendungen umfassen partizipative ML-Design-Prozesse und die Analyse von Online-Werbesystemen. Die Forschung betont die Notwendigkeit interdisziplinärer Zusammenarbeit und die Integration historischer Perspektiven in die AI-Ausbildung, um strukturelle Ungleichheiten anzugehen.

**Qualitätsbewertung: Hoch**
*Begründung: Peer-reviewed in hochrangiger FAccT-Konferenz, renommierte Autorinnen mit etablierter Expertise, theoretisch fundiert mit praktischen Anwendungen, hohe Zitationszahlen erwartet, methodisch rigoros.*

### 5. Generative AI und Geschlechterinklusion

**APA-Zitation:**
Hartshorne, R., & Cohen, J. (Eds.). (2025). Generative AI and the Future of Digital Literacy: Opportunities for Gender Inclusion. In *Proceedings of Society for Information Technology & Teacher Education International Conference 2025* (pp. 728-735). Association for the Advancement of Computing in Education (AACE).

**Zusammenfassung:**
Diese Studie untersucht das Potenzial generativer KI zur Förderung weiblicher Inklusion in der Grund- und Sekundarbildung, während sie die inhärenten Risiken der Verstärkung geschlechtsspezifischer Verzerrungen adressiert. Die qualitative Forschung analysiert systemische Effekte generativer AI-Tools auf Lehren und Lernen durch Interviews und Fokusgruppen mit Schülern und Lehrern. Die Ergebnisse zeigen komplexe Wechselwirkungen zwischen generativen AI-Technologien und Geschlechterdynamiken. Schlüsselfaktoren für effektive AI-gestützte Lernumgebungen umfassen personalisierte Lernerfahrungen, bias-bewusste Inhaltsgenerierung und die Rolle von Lehrern als Vermittler von AI-Interaktionen. Die Studie identifiziert sowohl Chancen als auch Herausforderungen bei der Nutzung von AI zur Adressierung von Geschlechterdisparitäten und betont die Bedeutung sorgfältiger Implementierung und kontinuierlicher Evaluation für Geschlechtergerechtigkeit.

**Qualitätsbewertung: Mittel-Hoch**
*Begründung: Peer-reviewed Konferenzbeitrag, qualitative Methodologie, hochaktuelle Publikation 2025, praktische Bildungsrelevanz, jedoch begrenzte methodische Details in der Zusammenfassung.*

### 6. Intersektionalität in AI-Systemen

**APA-Zitation:**
Ulnicane, I. (2024). Intersectionality in Artificial Intelligence: Framing Concerns and Recommendations for Action. *Social Inclusion*, 12, Article 7543. https://doi.org/10.17645/si.v12.7543

**Zusammenfassung:**
Diese Studie analysiert die aufkommende Agenda zu Intersektionalität in AI durch Untersuchung von vier hochrangigen Berichten zu diesem Thema (2019-2021). Die Forschung zeigt, wie diese Dokumente Probleme rahmen und Empfehlungen zur Adressierung von Ungleichheiten formulieren. AI-Systeme verstärken und verschärfen oft menschliche Verzerrungen und Stereotypen, was zu Diskriminierung und Marginalisierung führt. Die Analyse deckt systematische Probleme auf: Diversitätskrisen in AI-Entwicklung, wo Gründer und Mitarbeiter hauptsächlich aus homogenen Gruppen weißer Männer stammen, sowie die Verstärkung bestehender Machtbeziehungen durch AI-Systeme. Die Studie betont die Notwendigkeit intersektionaler Ansätze, die multiple Ungleichheiten berücksichtigen, die aus der Interaktion verschiedener sozialer Identitäten entstehen. Empfehlungen umfassen partizipative AI-Design-Prinzipien und die Einbindung diverser Stakeholder in AI-Governance-Prozesse.

**Qualitätsbewertung: Hoch**
*Begründung: Peer-reviewed in etabliertem Journal Social Inclusion, systematische Analyse multipler Berichte, methodisch fundiert, hohe Relevanz für Intersektionalitäts-Forschung in AI, gut dokumentierte Methodik.*

### 7. Prompt Engineering für Bias-Mitigation

**APA-Zitation:**
Articulate. (2025, July 14). How to Create Inclusive AI Images: A Guide to Bias-Free Prompting. *Articulate Blog*. https://www.articulate.com/blog/how-to-create-inclusive-ai-images-a-guide-to-bias-free-prompting/

**Zusammenfassung:**
Dieser Praxisleitfaden untersucht Prompt-Engineering-Strategien zur Erstellung inklusiver AI-generierter Bilder und zur Vermeidung voreingenommener Standardausgaben. Die Analyse zeigt, dass AI-Bildgeneratoren oft stereotype Darstellungen produzieren (weiß, männlich, schlank, jung, körperlich befähigt), da sie auf unausgewogenen Internet-Datensätzen trainiert wurden. Der Artikel präsentiert konkrete Techniken für inklusives Prompt-Engineering: Spezifizierung sichtbarer Identitätsmerkmale (Alter, Rasse, Geschlecht, Körpergröße, sichtbare Behinderungen), Verwendung diversitätsfördernder Begriffe wie "multikulturell" und "geschlechterdivers", sowie die Bereitstellung zusätzlichen Kontexts zur Durchbrechung stereotyper Assoziationen. Die Forschung demonstriert, wie durchdachte Prompt-Formulierung AI-Systeme zu ausgewogeneren, repräsentativeren visuellen Darstellungen führen kann, die die volle Bandbreite menschlicher Erfahrung widerspiegeln.

**Qualitätsbewertung: Mittel**
*Begründung: Praktisch relevanter Leitfaden mit konkreten Anwendungsbeispielen, jedoch keine peer-review, begrenzte wissenschaftliche Methodik, hohe Praxisrelevanz für Prompt-Engineering, aktuelle Publikation 2025.*

### 8. KI-Geschlechtsbias und Trainingsdaten

**APA-Zitation:**
Latif, E., Zhai, X., & Liu, L. (2024). AI Gender Bias, Disparities, and Fairness: Does Training Data Matter? *arXiv preprint*. https://arxiv.org/html/2312.10833v4

**Zusammenfassung:**
Diese empirische Studie untersucht Geschlechtsbias in großen Sprachmodellen durch Analyse von über 6000 bewerteten Schülerantworten von 70 männlichen und 70 weiblichen Teilnehmern. Die Forschung verwendet fine-tuned BERT-Modelle und GPT-3.5 zur Bewertung verschiedener Trainingsdaten-Konfigurationen: geschlechtsspezifische versus gemischte Datensätze. Drei Bewertungsmetriken werden angewandt: Scoring-Accuracy-Differenz für Bias-Bewertung, Mean Score Gaps (MSG) für Geschlechterdisparitäten und Equalized Odds (EO) für Fairness-Messung. Die Ergebnisse zeigen, dass gemischt-geschlechtlich trainierte Modelle signifikant bessere Ergebnisse produzieren als geschlechtsspezifische Modelle, mit reduzierten MSG und faireren Vorhersagen. Geschlechtsspezifisch trainierte Modelle verstärken bestehende Geschlechterunterschiede, während ausgewogene Trainingsdaten zu gerechteren AI-Bewertungen führen. Die Studie liefert empirische Evidenz für die Bedeutung diverser Trainingsdaten in der Bias-Mitigation.

**Qualitätsbewertung: Mittel-Hoch**
*Begründung: Methodisch rigoros mit großer Stichprobe, empirisch fundiert, jedoch arXiv preprint ohne peer-review, innovative Methodik zur Bias-Messung, hohe praktische Relevanz für AI-Training.*

### 9. Feministische Perspektiven auf algorithmische Fairness

**APA-Zitation:**
Ahmed, U. (2024). Feminist Perspectives on AI: Ethical Considerations in Algorithmic Decision-Making. *Research Corridor Journal of Gender Studies and Intersectionality*, 5(2). https://www.researchcorridor.org/index.php/jgsi/article/download/330/314

**Zusammenfassung:**
Diese Studie erforscht ethische Implikationen algorithmischer Entscheidungsfindung aus feministischer Perspektive und untersucht Datenbias, Diskriminierung in automatisierten Systemen und Unterrepräsentation von Frauen in AI-Entwicklung. Algorithmische Verzerrungen betreffen marginalisierte Gruppen disproportional und verstärken gesellschaftliche Ungleichheiten in Bereichen wie Einstellung, Gesundheitswesen und Strafverfolgung. Ein feministisches ethisches Framework betont Transparenz, Fairness und Inklusivität und hinterfragt patriarchale und unternehmensgetriebene Narrative in AI-Forschung und -Politik. Die Analyse zeigt, dass AI-Ethik über technische Lösungen hinausgehen muss, um systemische Machtungleichgewichte und kulturelle Verzerrungen in Daten zu adressieren. Partizipatives AI-Design und größere Diversität in der AI-Arbeitskraft werden als essentiell für die Minderung von Bias und ethische algorithmische Entscheidungsfindung identifiziert.

**Qualitätsbewertung: Mittel**
*Begründung: Theoretisch fundiert mit feministischer Perspektive, jedoch in weniger etabliertem Journal publiziert, gute konzeptuelle Analyse, begrenzte empirische Daten, hohe theoretische Relevanz.*

### 10. Intersektionale AI-Ansätze

**APA-Zitation:**
Ciston, S. (2024). Intersectional Artificial Intelligence Is Essential: Polyvocal, Multimodal, Experimental Methods to Save AI. *Journal of Science and Technology of the Arts*, 11(2), 665. https://doi.org/10.7559/CITARJ.V11I2.665

**Zusammenfassung:**
Diese Arbeit argumentiert für die Anwendung intersektionaler Strategien auf AI auf allen Ebenen - von Daten über Design bis zur Implementierung. Intersektionalität, die institutionelle Machtanalyse und queer-feministische sowie critical race Theorien integriert, kann zur Neukonzeption von AI beitragen. Das intersektionale Framework ermöglicht die Analyse existierender AI-Verzerrungen und die Aufdeckung alternativer Ethiken aus Gegengeschichten. Die Forschung präsentiert intersektionale Strategien als polyvocal, multimodal und experimentell, wobei community-fokussierte und künstlerische Praktiken AI's intersektionale Möglichkeiten erkunden helfen. Praktische Beispiele umfassen das Data Nutrition Label für Bias-Bewertung in Datensätzen und experimentelle Projekte wie "ladymouth", einen Chatbot zur Erklärung von Feminismus. Die Studie betont die Notwendigkeit vielfältiger Ansätze und Ergebnisse statt "One-Size-Fits-All"-Lösungen für intersektionale AI-Entwicklung.

**Qualitätsbewertung: Mittel-Hoch**
*Begründung: Peer-reviewed in Fachjournal, innovative theoretische Ansätze, praktische Anwendungsbeispiele, jedoch spezialisiertes Journal mit unklarem Impact, starke konzeptuelle Beiträge.*

## Synthese und kritische Bewertung

Die analysierte Literatur zeigt einen klaren Trend zur Integration feministischer und intersektionaler Ansätze in der AI-Forschung. Mehrere zentrale Erkenntnisse kristallisieren sich heraus:

**Intersektionalität als notwendiger Rahmen:** Die Forschung von Gohar und Cheng [5] sowie Ulnicane [4] demonstriert, dass traditionelle binäre Fairness-Ansätze unzureichend sind. Intersektionale Identitäten erfordern spezifische Betrachtung, da beispielsweise Schwarze Frauen andere Diskriminierungsformen erfahren als die Summe von Geschlechter- und Rassendiskriminierung.

**Feminist AI als transformatives Framework:** Wudel und Ehrenberg [3] sowie Klein und D'Ignazio [7] etablieren FAI als systematischen Ansatz, der über traditionelle "Responsible AI"-Konzepte hinausgeht. FAI adressiert strukturelle Machtungleichheiten durch iterative Theorie-Praxis-Schleifen und konkrete Maßnahmen wie Diversitätstests und explizite Einverständniserklärungen.

**Digitale Kompetenzen als Empowerment-Tool:** Shah [8] zeigt empirisch, dass digitale Literacy-Programme kritisches Bewusstsein für AI-Bias fördern und Frauen zu AI-Karrieren ermutigen. Programme wie AI4ALL erreichen 78% STEM-Fortsetzungsraten, was die praktische Wirksamkeit demonstriert.

**Prompt Engineering als Bias-Mitigation-Strategie:** Die Forschung zu inklusivem Prompting [9] zeigt konkrete Techniken zur Reduktion stereotyper AI-Ausgaben. Spezifische Diversitäts-Prompts können AI-Systeme zu ausgewogeneren Darstellungen führen, erfordern jedoch bewusste Anwendung.

**Trainingsdaten als kritischer Faktor:** Latif et al. [10] liefern empirische Evidenz, dass gemischt-geschlechtliche Trainingsdaten zu faireren AI-Bewertungen führen als geschlechtsspezifische Datensätze, was die Bedeutung diverser Datensammlung unterstreicht.

Die Qualität der analysierten Quellen variiert zwischen hoch (etablierte Konferenzen und Journals) und mittel (neue Publikationsformate, preprints). Die hohe Aktualität der Forschung (2023-2025) spiegelt die Dringlichkeit des Themas wider, führt jedoch zu begrenzten Langzeitstudien.

## Forschungslücken und zukünftige Richtungen

Trotz des wachsenden Interesses bleiben bedeutende Forschungslücken:

1. **Empirische Langzeitstudien** zur Wirksamkeit feministischer AI-Ansätze in realen Anwendungen
2. **Intersektionale Evaluationsmetriken** für AI-Systeme, die multiple Identitätsdimensionen berücksichtigen
3. **Skalierbare Implementierung** feministischer Prinzipien in großen AI-Systemen
4. **Kulturspezifische Ansätze** für diverse globale Kontexte jenseits westlicher Perspektiven

## Fazit

Die systematische Literaturanalyse zeigt, dass feministische Digital- und KI-Kompetenzen sowie diversitätsreflektierendes Prompting vielversprechende Ansätze zur Sichtbarmachung und Reduktion von Bias in KI-Technologien darstellen. Die Integration intersektionaler Perspektiven erweist sich als essentiell für die Entwicklung gerechterer AI-Systeme. Zukünftige Forschung sollte sich auf empirische Validierung, skalierbare Implementierung und kulturelle Diversifizierung dieser Ansätze konzentrieren.

Die hohe Qualität der analysierten Quellen, insbesondere aus etablierten Konferenzen wie IJCAI und FAccT, unterstreicht die wissenschaftliche Legitimität des Forschungsfelds. Die praktischen Anwendungsbeispiele von AI4ALL bis zu FemAI-Initiativen zeigen, dass feministische AI-Ansätze über theoretische Konzepte hinaus reale Veränderungen bewirken können.

*Hinweis: Diese Analyse basiert auf einer systematischen Durchsicht verfügbarer Literatur aus dem Zeitraum 2023-2025. Die Bewertung der Quellen erfolgte nach wissenschaftlichen Standards bezüglich Peer-Review-Status, methodischer Rigorosität und praktischer Relevanz.*

[1] https://premierscience.com/wp-content/uploads/2025/01/pjai-24-524.pdf
[2] https://fem-ai.eu/paper/
[3] https://library.fes.de/pdf-files/bueros/bruessel/21888-20250304.pdf
[4] https://pure-oai.bham.ac.uk/ws/files/224692702/SI_12_-_Intersectionality_in_Artificial_Intelligence_Framing_Concerns_and_Recommendations_for_Action.pdf
[5] https://www.ijcai.org/proceedings/2023/0742.pdf
[6] https://arxiv.org/pdf/2303.17555.pdf
[7] https://dl.acm.org/doi/10.1145/3630106.3658543
[8] https://premierscience.com/pjai-24-524/
[9] https://www.articulate.com/blog/how-to-create-inclusive-ai-images-a-guide-to-bias-free-prompting/
[10] https://arxiv.org/html/2312.10833v4
[11] https://www.womentech.net/en-pk/how-to/what-role-does-intersectionality-play-in-addressing-bias-in-ai-and-machine-learning
[12] https://www.uni-hamburg.de/en/newsroom/forschung/2025/0311-fv-41-bwl-diverse-ki.html
[13] https://www.unia.be/en/dossiers/artificial-intelligence-discrimination
[14] https://www.thecatalyst.org.uk/resource-articles/why-we-need-feminist-ai/
[15] https://asiapacific.unwomen.org/en/stories/announcement/2025/03/un-women-ai-school-opens-for-changemakers
[16] https://ai.stonybrook.edu/about-us/News/artificial-intelligence-tackles-intersectional-bias
[17] https://www.linkedin.com/pulse/prompt-engineering-key-ai-diversity-brendan-byrne-hpioe
[18] https://www.kunstuni-linz.at/en/archiv/archive/feminist-ai-lecture-series-5
[19] https://giwl.anu.edu.au/files/2024-11/AFFPC-Issues-Paper-17-FFP-AI-Stephenson-Barry.pdf
[20] https://www.mccormick.northwestern.edu/news/articles/2023/11/addressing-gender-and-intersectional-bias-in-artificial-intelligence/
[21] https://clickup.com/ai/prompts/diversity-and-inclusion-planning
[22] https://www.unesco.org/en/articles/how-can-feminism-inform-ai-governance-practice
[23] https://www.kunstuni-linz.at/en/university/organisational-structure-1/representation-of-interests/archive/feminist-ai-lecture-series
[24] https://hackernoon.com/how-to-craft-inclusive-ai-prompts-that-mitigate-bias
[25] https://academic.oup.com/book/55103/chapter/423909664
[26] https://blogs.worldbank.org/en/education/Bridging-the-AI-divide-Breaking-down-barriers
[27] https://feministai.pubpub.org/pub/practicing-feminist-principles
[28] https://royalliteglobal.com/advanced-humanities/article/view/1417
[29] https://philarchive.org/archive/HUAAAB-3
[30] https://academic.oup.com/edited-volume/59762/chapter/508611708
[31] https://www.unwomen.org/en/news-stories/interview/2025/02/how-ai-reinforces-gender-bias-and-what-we-can-do-about-it
[32] https://www.unwomen.org/en/articles/explainer/artificial-intelligence-and-gender-equality
[33] https://www.cigionline.org/documents/3375/DPH-paper-Laine_McCrory.pdf
[34] https://www.cogitatiopress.com/socialinclusion/article/download/7543/3744
[35] https://www.womentech.net/en-ua/how-to/understanding-ai-bias-feminist-perspective
[36] https://ecpr.eu/news/news/details/749
[37] https://www.womentech.net/en-bg/how-to/digital-literacy-gateway-gender-equity-in-stem
[38] https://genderatwork.org/can-ai-have-its-cake-and-eat-it/
[39] https://www.linkedin.com/pulse/hard-truth-you-diversity-ai-optional-florence-rene-pmp-pmi-acp-mba-fgywc
[40] https://www.researchcorridor.org/index.php/jgsi/article/download/330/314
[41] https://revistas.ucp.pt/index.php/jsta/article/view/7328/7108
[42] https://vorecol.com/blogs/blog-ensuring-fairness-and-bias-free-competency-assessments-9951
[43] https://sebastienrousseau.com/2024-01-23-advancements-in-ai-prompt-engineering/index.html
[44] https://ojs.aaai.org/index.php/AAAI-SS/article/download/31812/33979/35881
[45] https://elearningindustry.com/strategies-to-mitigate-bias-in-ai-algorithms
[46] https://lsmt.org.uk/blog/how-ai-is-reshaping-white-collar-jobs-the-rise-of-the-prompt-engineer
[47] https://www.research.ed.ac.uk/files/296354126/KasirzadehAIES2022AlgorithmicFairness.pdf
[48] https://uen.pressbooks.pub/teachingandgenerativeai/chapter/co-creating-intersectional-design-narratives-with-ai/
[49] https://acr-journal.com/article/cognitive-biases-in-digital-decision-making-how-consumers-navigate-information-overload-consumer-behavior--889/
[50] https://www.movate.com/the-strategic-role-of-prompt-engineering-in-ai-evolution/
[51] https://arxiv.org/abs/2206.00945
[52] https://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=1022&context=teachingai
[53] https://www.jair.org/index.php/jair/article/download/16759/27113
[54] https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1366434/full
[55] https://catalystjournal.org/index.php/catalyst/article/download/33043/26845
[56] https://naturexdesign.tealeaves.com/intersectionality-and-design-for-responsible-ai/
[57] https://www.sciencedirect.com/science/article/pii/S002965542500048X
[58] https://researchnow.flinders.edu.au/en/publications/generative-ai-and-the-future-of-digital-literacy-opportunities-fo
[59] https://www.academia.edu/51719822/Intersectional_AI_Is_Essential
[60] https://dspace.mit.edu/bitstream/handle/1721.1/155777/3630106.3658543.pdf?sequence=1&isAllowed=y
[61] https://www.academia.edu/112996586/Breaking_binary_code_Navigating_gender_and_feminist_frontiers_in_artificial_intelligence
[62] https://www.academia.edu/117322358/Gender_Shades_Intersectional_Accuracy_Disparities_in_Commercial_Gender_Classification
[63] https://arxiv.org/html/2406.13925v3
[64] https://dl.acm.org/doi/10.1145/3706598.3713681
[65] https://academic.oup.com/book/55103/chapter/423909956
[66] https://www.academia.edu/127318893/Rethinking_Bias_and_Fairness_in_AI_Through_the_Lens_of_Gender_Studies
[67] https://arxiv.org/html/2505.17217v1
[68] https://academic.oup.com/book/55103/chapter/423909956/chapter-pdf/57700339/oso-9780192889898-chapter-4.pdf
[69] https://www.academia.edu/128356997/Bias_in_AI_Models_Origins_Impact_and_Mitigation_Strategies
[70] https://arxiv.org/html/2501.14457v1
[71] https://dl.acm.org/doi/10.1145/3696630.3728693
[72] https://academic.oup.com/edited-volume/59762/chapter/508608388?searchresult=1
[73] https://www.academia.edu/124974782/A_Comprehensive_Review_of_Bias_in_Ai_Algorithms
[74] https://arxiv.org/abs/2310.13074
[75] https://dl.acm.org/doi/10.1007/s10676-023-09739-1
[76] https://dl.acm.org/doi/fullHtml/10.1145/3630106.3658543
[77] https://doi.org/10.3390/sci6010003
[78] https://arxiv.org/abs/2506.18199
[79] https://enotice.vtools.ieee.org/public/152070
[80] https://dl.acm.org/doi/pdf/10.1145/3630106.3658543
[81] https://doi.org/10.3389/frma.2024.1486600
[82] http://essay.utwente.nl/107626/1/Tulbure_BA_EEMCS.pdf
[83] https://wie.ieee.org/2024-ieee-wie-day/
[84] https://doi.org/10.1145/3531146.3533114
[85] https://digitalcollections.bowdoin.edu/file/68820/content
[86] https://www.linkedin.com/posts/ieee-computer-society_fei-fei-li-activity-7267250786970050560-zBiQ
[87] https://dx.doi.org/10.3390%2Fe25040660
[88] https://dl.acm.org/doi/10.1145/3641555.3705080
[89] https://technologyandsociety.org/advancing-gender-equality-through-interdisciplinarity/
[90] https://dx.doi.org/10.24963/ijcai.2023/742
[91] https://aclanthology.org/2024.ccl-1.101.pdf
[92] https://wie.ieee.org/event/ai-past-present-and-future/