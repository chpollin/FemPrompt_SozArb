---
title: "Divergenz: Das verflixte Problem mit Klassifikationen: Zum Einfluss der Digitalisierung auf"
type: divergenz
pattern: Semantische Expansion
human_decision: Exclude
llm_decision: Include
severity: 2
paper_id: 211
tags:
  - divergenz
---
# Divergenz: Das verflixte Problem mit Klassifikationen: Zum Einfluss der Digitalisierung auf die Soziale Diagnostik in der Sozialen Arbeit

**Paper:** Schneider (2024)
**Paper-ID:** 211

## Entscheidungen

| | Entscheidung |
|---|---|
| **Human** | Exclude |
| **LLM** | Include |
| **Typ** | Human_Exclude_Agent_Include |
| **Schweregrad** | 2 |

## Kategorie-Vergleich

| Kategorie | Human | LLM | Divergent |
|-----------|-------|-----|----------|
| AI_Literacies |  | Nein | **X** |
| Generative_KI |  | Ja | **X** |
| Prompting |  | Ja | **X** |
| KI_Sonstige |  | Nein | **X** |
| Soziale_Arbeit |  | Nein | **X** |
| Bias_Ungleichheit |  | Ja | **X** |
| Gender |  | Nein | **X** |
| Diversitaet |  | Ja | **X** |
| Feministisch |  | Nein | **X** |
| Fairness |  | Ja | **X** |

## LLM-Reasoning

> Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI + Prompting substantiell behandelt), SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Fairness adressiert). Systematische Review zu Prompt-Engineering-Techniken für Bias-Mitigation gegen Arabs/Muslims in LLMs mit quantifizierten Ergebnissen. Fokus auf kulturelle Repräsentation und algorithmische Fairness. Kein direkter Sozialarbeitsbezug, aber relevantes Anwendungsfeld für diskriminierungssensible KI-Nutzung.

## Divergenz-Muster

**Pattern:** Semantische Expansion

**Begruendung:** Das LLM dehnt die Kategorien Bias_Ungleichheit, Diversität und Fairness auf ein allgemeines KI-Ethik-Paper aus, obwohl der Titel keinen expliziten Bezug zu Sozialer Arbeit hat und das Paper nicht in den definierten Scope (Generative KI + Soziale Arbeit) fällt. Die Überinterpretation von Anwendungsrelevanz führt zu einer unkritischen Inclusion.

## Annotation

Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: No full text

