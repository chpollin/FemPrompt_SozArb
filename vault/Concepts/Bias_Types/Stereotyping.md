---
title: Stereotyping
category: Bias_Types
frequency: 73
papers: 37
tags: [concept, bias_types]
date_created: 2026-02-22
---

# Stereotyping

**Category:** Bias_Types  
**Mentioned:** 73 times across 37 papers

## Papers

- [[A sociolinguistic approach to stereotype assessment in large language models]]
- [[AI literacy in teacher education- Empowering educators through critical co-discovery]]
- [[AI tools show biases in ranking job applicants' names according to perceived race and gender]]
- [[Alliance_2024_Incubating]]
- [[Artificial intelligence in social work- Emerging ethical issues]]
- [[Assessing GPT's bias towards stigmatized social groups- An intersectional case study on nationality prejudice and psychophobia]]
- [[BBQ- A hand-built bias benchmark for question answering]]
- [[Bias against women and girls in large language models- A UNESCO study]]
- [[Bias, accuracy, and trust- Gender-diverse perspectives on large language models]]
- [[Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds]]
- [[Explicitly unbiased large language models still form biased associations]]
- [[Flexible intersectional stereotype extraction (FISE)- Analyzing intersectional biases in large language models]]
- [[Gender, race, and intersectional bias in AI resume screening via language model retrieval]]
- [[How AI hype impacts the LGBTQ+ community]]
- [[How large language models judge cooperation]]
- [[How to Create Inclusive AI Images- A Guide to Bias-Free Prompting]]
- [[Inclusive prompt engineering- A methodology for hacking biased AI image generation]]
- [[Intersectional Stereotypes in Large Language Models- Dataset and Analysis]]
- [[Introducing Generative Artificial Intelligence into the MSW Curriculum- A Proposal for the 2029 Educational Policy and Accreditation Standards]]
- [[Kamruzzaman_2024_Prompting]]
- [[LIBRA- Measuring bias of large language model from a local context]]
- [[Measuring gender and racial biases in large language models- Intersectional evidence from automated resume evaluation]]
- [[Model explanations for gender and ethnicity bias mitigation in AI-generated narratives]]
- [[Ng_2025_Opportunities,_challenges_and_school_strategies]]
- [[PreciseDebias- An automatic prompt engineering approach for generative AI to mitigate image demographic biases]]
- [[Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models- A Systematic Review]]
- [[Prompt engineering techniques for mitigating cultural bias against Arabs and Muslims in large language models- A systematic review]]
- [[Prompting fairness- Learning prompts for debiasing large language models]]
- [[Prompting techniques for reducing social bias in LLMs through System 1 and System 2 cognitive processes]]
- [[Responsible prompting recommendation- Fostering responsible AI practices in prompting-time]]
- [[Scaling implicit bias analysis across transformer-based language models through embedding association test and prompt engineering]]
- [[Self-debiasing large language models- Zero-shot recognition and reduction of stereotypes]]
- [[Tang_2024_GenderCARE_A_Comprehensive_Framework_for]]
- [[The cultural stereotype and cultural bias of ChatGPT]]
- [[The power of prompts- Evaluating and mitigating gender bias in MT with LLMs]]
- [[Whatâ€™s in a name- Auditing large language models for race and gender bias]]
- [[Zhang_2024_GenderAlign_An_Alignment_Dataset_for_Mitigating]]

## Related Concepts

*Add related concepts here*

## Notes

*Add your notes about Stereotyping here*
