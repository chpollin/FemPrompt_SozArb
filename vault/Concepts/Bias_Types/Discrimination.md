---
title: Discrimination
category: Bias_Types
frequency: 126
papers: 57
tags: [concept, bias_types]
date_created: 2026-02-22
---

# Discrimination

**Category:** Bias_Types  
**Mentioned:** 126 times across 57 papers

## Papers

- [[AI Creates the Message- Integrating AI Language Learning Models into Social Work Education and Practice]]
- [[AI Gender Bias, Disparities, and Fairness- Does Training Data Matter-]]
- [[AI for decision support- What are possible futures, social impacts, regulatory options, ethical conundrums and agency constellations-]]
- [[AI implementation science for social issues- Pitfalls and tips]]
- [[AI tools show biases in ranking job applicants' names according to perceived race and gender]]
- [[Advancing Accountability in AI]]
- [[Algorithmic decision-making in social work practice and pedagogy- confronting the competency-critique dilemma]]
- [[Algorithmic discrimination- examining its types and regulatory measures with emphasis on US legal practices]]
- [[Algorithms, artificial intelligence and discrimination]]
- [[Alliance_2024_Incubating]]
- [[Artificial Intelligence Competence Needs for Youth Workers]]
- [[Artificial intelligence in social work- Emerging ethical issues]]
- [[Assessing trustworthy AI- Technical and legal perspectives of fairness in AI]]
- [[Attard-Frost_2025_Countergovernance]]
- [[Barman_2024_Beyond]]
- [[Biases in large language models- Origins, inventory and discussion]]
- [[Coded injustice- Surveillance and discrimination in Denmark's automated welfare state]]
- [[Decision support and algorithmic support- The construction of algorithms and professional discretion in social work]]
- [[Diskriminierung durch Algorithmen – Überlegungen zur Stärkung KI-bezogener Kompetenzen]]
- [[Engineers on responsibility- feminist approaches to who's responsible for ethical AI]]
- [[Explicitly unbiased large language models still form biased associations]]
- [[Exploring opportunities and risks in decision support technologies for social workers- An empirical study in the field of disabled people's services]]
- [[Factoring the Matrix of Domination- A Critical Review and Reimagination of Intersectionality in AI Fairness]]
- [[Failing our youngest- On the biases, pitfalls, and risks in a decision support algorithm used for child protection]]
- [[Female perspectives on algorithmic bias- Implications for AI researchers and practitioners]]
- [[Flexible intersectional stereotype extraction (FISE)- Analyzing intersectional biases in large language models]]
- [[Friedrich-Ebert-Stiftung_2025_artificial]]
- [[Gender, race, and intersectional bias in AI resume screening via language model retrieval]]
- [[Gohar_2023_Survey]]
- [[Incubating Feminist AI- Executive Summary 2021-2024]]
- [[Intersectional Fairness- A Fractal Approach]]
- [[Intersectional Stereotypes in Large Language Models- Dataset and Analysis]]
- [[Introduction to the digital welfare state- Contestations, considerations and entanglements]]
- [[Learning About AI- A Systematic Review of Reviews on AI Literacy]]
- [[Measuring gender and racial biases in large language models- Intersectional evidence from automated resume evaluation]]
- [[Ovalle_2023_Factoring]]
- [[Policy advice and best practices on bias and fairness in AI]]
- [[Positionings, challenges, and ambivalences in children's and parents' perspectives in digitalized familial contexts]]
- [[Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models- A Systematic Review]]
- [[Prompt engineering techniques for mitigating cultural bias against Arabs and Muslims in large language models- A systematic review]]
- [[Prompting fairness- Learning prompts for debiasing large language models]]
- [[RETHINKING SOCIAL SERVICES WITH ARTIFICIAL INTELLIGENCE- OPPORTUNITIES, RISKS, AND FUTURE PERSPECTIVES]]
- [[Recommendation on the Ethics of Artificial Intelligence]]
- [[Reflexive prompt engineering- A framework for responsible prompt engineering and AI interaction design]]
- [[Shaping feminist artificial intelligence]]
- [[Sharma_2024_Intersectional]]
- [[Social work and artificial intelligence- Collaboration and challenges]]
- [[Social work in the age of artificial intelligence- A rights-based framework for evidence-based practice through social psychology, group dynamics, and institutional analysis]]
- [[Tang_2024_GenderCARE_A_Comprehensive_Framework_for]]
- [[Tensions in digital welfare states- Three perspectives on care and control]]
- [[The AI Act, gender equality and non-discrimination- what role for the AI Office-]]
- [[The EU artificial intelligence act through a gender lens]]
- [[The End of the World as We Know It- ChatGPT and Social Work]]
- [[The end of the world as we know it- ChatGPT and social work]]
- [[Training in Co-Creation as a Methodological Approach to Improve AI Fairness]]
- [[What is Feminist AI-]]
- [[Wudel_2025_What]]

## Related Concepts

*Add related concepts here*

## Notes

*Add your notes about Discrimination here*
