---
title: Algorithmic Bias in Language Models
type: concept
frequency: 4
papers_count: 4
related_concepts:
  - Gender Bias in NLP
  - Intersectional Fairness
  - Prompt Engineering
tags:
  - concept
---
# Algorithmic Bias in Language Models

## Definition

Systematische Verzerrungen in großen Sprachmodellen, die Stereotypen, Missrepräsentationen und ausgrenzende Sprache aus Trainingsdaten erben und reproduzieren, mit überproportionalen Schäden für marginalisierte Gemeinschaften.

## Co-occurrence

| Konzept | Gemeinsame Papers |
|---------|------------------|
| [[Gender Bias in NLP]] | 2 |
| [[Intersectional Fairness]] | 1 |
| [[Prompt Engineering]] | 1 |

## Papers

- [[Prompting fairness- Learning prompts for debiasing large language models]]
- [[Bias and fairness in large language models- A survey]]
- [[Responsible prompting recommendation- Fostering responsible AI practices in prompting-time]]
- [[Guardrails, not guidance- Understanding responses to LGBTQ+ language in large language models]]

## Assessment-Divergenz

Von 1 bewerteten Papers: 0 Divergenzen (0%)

