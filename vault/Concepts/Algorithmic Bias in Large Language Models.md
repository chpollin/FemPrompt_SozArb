---
title: Algorithmic Bias in Large Language Models
type: concept
frequency: 5
papers_count: 5
related_concepts:
  - AI Literacy
  - Explainable Artificial Intelligence (XAI)
  - Prompt Engineering
  - Responsible AI Use
  - AI Literacy in Professional Practice
tags:
  - concept
---
# Algorithmic Bias in Large Language Models

## Definition

Systematische Verzerrungen in LLMs, die durch Training auf nicht-verifizierten Internet-Daten entstehen und eurozentristische sowie weiße Perspektiven überrepräsentieren, während Arbeiten von BIPOC-Autoren und marginalisierten Gruppen marginalisiert werden.

## Co-occurrence

| Konzept | Gemeinsame Papers |
|---------|------------------|
| [[AI Literacy]] | 1 |
| [[Explainable Artificial Intelligence (XAI)]] | 1 |
| [[Prompt Engineering]] | 1 |
| [[Responsible AI Use]] | 1 |
| [[AI Literacy in Professional Practice]] | 1 |
| [[Disparate Impact Assessment]] | 1 |
| [[Intersectional Bias]] | 1 |
| [[Algorithmic Fairness]] | 1 |

## Papers

- [[Beyond transparency and explainability- On the need for adequate and contextualized user guidelines (Barman_2024_Beyond_transparency_and_expl)]]
- [[LIBRA- Measuring bias of large language model from a local context (Pan_2025_LIBRA_Measuring_bias_of_large_l)]]
- [[ChatGPT for Social Work Science- Ethical Challenges and Opportunities]]
- [[What’s in a name- Auditing large language models for race and gender bias]]
- [[Bias in decision-making for AI's ethical dilemmas- A comparative study of ChatGPT and Claude]]

## Assessment-Divergenz

Von 4 bewerteten Papers: 2 Divergenzen (50%)

