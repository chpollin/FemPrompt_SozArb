---
title: Gender Bias in Language Models
type: concept
frequency: 2
papers_count: 2
related_concepts:
  - Intersectional Bias
  - Algorithmic Fairness
tags:
  - concept
---
# Gender Bias in Language Models

## Definition

Systematische Verzerrung in Sprachmodellen, die Geschlechter ungleich behandelt und stereotype Zuordnungen verstärkt, messbar durch differentielle Modellverhalten bei männlichen vs. weiblichen Attributen und Kontexten.

## Co-occurrence

| Konzept | Gemeinsame Papers |
|---------|------------------|
| [[Intersectional Bias]] | 1 |
| [[Algorithmic Fairness]] | 1 |

## Papers

- [[Biases in large language models- Origins, inventory and discussion]]
- [[DR.GAP- Mitigating bias in large language models using gender-aware prompting with demonstration and (Qiu_2025_Mitigating)]]

## Assessment-Divergenz

Von 2 bewerteten Papers: 1 Divergenzen (50%)

