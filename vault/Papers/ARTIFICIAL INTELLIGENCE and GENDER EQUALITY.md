---
title: ARTIFICIAL INTELLIGENCE and GENDER EQUALITY
authors:
  - UNESCO
year: 2020
type: report
doi: 
url: unesdoc.unesco.org/in/rest/annotationSVC/DownloadWatermarkedAttachment/attach_import_ab07646d-c784-4a4e-96a1-3be7855b6f76?_=374174eng.pdf&to=54&from=1
tags:
  - paper
llm_decision: Include
llm_confidence: 0.85
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
---

# ARTIFICIAL INTELLIGENCE and GENDER EQUALITY

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.85)

## Key Concepts

- [[Gender Bias in AI Systems]]

## Wissensdokument

# Artificial Intelligence and gender equality

## Kernbefund

Etwa 44% der analysierten AI-Systeme zeigen Geschlechterbias, und nur 30% der AI-Fachkräfte sind Frauen. Diese Unterrepräsentation von Frauen in der AI-Entwicklung perpetuiert vorhandene gesellschaftliche Stereotypen in Trainingsdaten und führt zu diskriminierenden Konsequenzen in kritischen Bereichen wie Gesundheit, Kredite und Beschäftigung.

## Forschungsfrage

Wie spiegelt künstliche Intelligenz Geschlechterbias in der Gesellschaft wider und wie können diese Verzerrungen durch gendersensible Governance und diverse Entwicklungsteams reduziert werden?

## Methodik

Review/Explainer - Kombination von Sekundärliteratur-Analyse (Berkeley Haas Center Studie), Fallbeispielen und Expert:innen-Interviews mit Praktiker:innen und Forschenden
**Datenbasis:** Sekundärdatenanalyse (Berkeley Haas Center: 133 AI-Systeme analysiert); Expert:innen-Interviews (Beyza Doğuç, Sola Mahfouz, Natacha Sangwa, Helene Molinier); Global Gender Gap Report 2023; World Economic Forum STEM-Daten 2023

## Hauptargumente

- Geschlechterbias in AI ist direkt auf die Unterrepräsentation von Frauen in der AI-Entwicklung und geschlechterstereotypische Trainingsdaten zurückzuführen. Wenn AI-Systeme auf Daten trainiert werden, die Frauen und Männer mit unterschiedlichen Fähigkeiten assoziieren, reproduzieren und verstärken diese Systeme diese Verzerrungen systematisch.
- Der globale digitale Geschlechterdivide verstärkt AI-Bias: In Ländern mit niedrigem Einkommen haben nur 20% der Frauen Internetzugang, was zu Datenlücken und einer Unterrepräsentation von Frauen in Trainingsdatensätzen führt. Dies hat konkrete negative Konsequenzen für Frauen bei der Nutzung von AI-gesteuerten Diagnosesystemen und anderen kritischen Anwendungen.
- Ohne gendersensible globale AI-Governance-Mechanismen werden bestehende Geschlechterungleichheiten durch AI-Systeme perpetuiert und verstärkt. Eine robuste multistakeholder-Governance, die Gender-Perspektiven bei der AI-Entwicklung verankert, ist notwendig, um AI zum Instrument der Geschlechtergleichstellung zu machen statt zu ihrer Verschärfung.

## Kategorie-Evidenz

### Evidenz 1

The AI field needs more women, and that requires enabling and increasing girls' and women's access to and leadership in STEM and ICT education and careers. African Girls Can Code Initiative als Beispiel für Bildungsinitiativen.

### Evidenz 2

Beyza Doğuç encountered gender bias in Generative AI when researching for a novel and prompted it to write a story about a doctor and a nurse. Generative AI creates new content (text, images, video, etc.) inspired by similar content and data that it was trained on.

### Evidenz 3

AI-powered solutions used for health diagnosis, job decisions, credit assessments. Berkeley Haas Center analysed 133 AI systems across different industries for gender bias.

### Evidenz 4

A study by the Berkeley Haas Center for Equity, Gender and Leadership analysed 133 AI systems across different industries and found that about 44 per cent of them showed gender bias, and 25 per cent exhibited both gender and racial bias. The gender digital divide creates a data gap that is reflected in the gender bias in AI.

### Evidenz 5

The world has a gender equality problem, and Artificial Intelligence (AI) mirrors the gender bias in our society. According to the Global Gender Gap Report of 2023, there are only 30 per cent women currently working in AI.

### Evidenz 6

There is a critical need for drawing upon diverse fields of expertise when developing AI, including gender expertise, so that machine learning systems can serve us better. More women researchers are needed in the field. The unique lived experiences of women can profoundly shape the theoretical foundations of technology.

### Evidenz 7

Right now, there is no mechanism to constrain developers from releasing AI systems before they are ready and safe. There's a need for a global multistakeholder governance model that prevents and redresses when AI systems exhibit gender or racial bias, reinforce harmful stereotypes, or does not meet privacy and security standards.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochrelevant für die Schnittstelle AI und Gender Studies. Es problematisiert systematisch, wie AI-Systeme Geschlechterbias reproduzieren und verstärken, und argumentiert für gendersensible Governance. Der Bezug zu Sozialer Arbeit ist jedoch indirekt, da der Fokus auf AI-Entwicklung und Policy liegt, nicht auf sozialarbeiterische Praxis selbst.

**Unique Contribution:** Das Paper leistet einen wichtigen Beitrag durch die Verbindung von technischen Bias-Analysen mit strukturellen Diversity-Problemen in der AI-Industrie und fordert explizit gendersensible globale Governance als Lösungsansatz auf Policy-Ebene.

**Limitations:** Das Paper ist ein Explainer ohne primäre Forschung; es basiert auf Sekundärquellen und Experteninterviews, fehlt eine detaillierte methodische Darstellung, und adressiert sozialarbeiterische Anwendungskontexte nicht explizit.

**Target Group:** Policymaker und globale Governance-Akteure, AI-Entwickler und Tech-Unternehmen, Gender-Expert:innen und Gender-Equality-Advocate:innen, Bildungsverantwortliche im STEM-Bereich, internationale Organisationen (UN Women Hauptadressat)

## Schlüsselreferenzen

- [[Berkeley_Haas_Center_for_Equity_Gender_and_Leadership_2024]] - Analysis of 133 AI systems for gender and racial bias
- [[World_Economic_Forum_2023]] - Women in STEM: 29% of STEM workers
- [[Global_Gender_Gap_Report_2023]] - 30% women in AI field
- [[Epoch_2024]] - AI training data scarcity by 2026
