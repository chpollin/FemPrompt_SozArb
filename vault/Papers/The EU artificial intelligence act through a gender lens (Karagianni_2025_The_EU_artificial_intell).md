---
title: The EU artificial intelligence act through a gender lens
authors:
  - Unknown Author
year: 2025
type: report
doi: 
url: "https://library.fes.de/pdf-files/bueros/bruessel/21887-20250304.pdf"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.75
llm_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Fairness
---

# The EU artificial intelligence act through a gender lens

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 96 |
| Category Validation | 98 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.75)

## Key Concepts

- [[Algorithmic Fairness Auditing]]
- [[Gender Bias in AI Systems]]

## Wissensdokument

# The EU Artificial Intelligence Act through a Gender Lens

## Kernbefund

Das EU-AI-Gesetz enthält zwar Verweise auf Nicht-Diskriminierung, verfügt aber über kritische Lücken bei der expliziten Behandlung von Geschlechtergerechtigkeit und feministischen Perspektiven. Eine intersektionale, geschlechtersensible Überarbeitung ist notwendig, um marginalisierte Gruppen effektiv zu schützen.

## Forschungsfrage

Wie adressiert das EU-Gesetz über künstliche Intelligenz Geschlechtergerechtigkeit und strukturelle Machtungleichgewichte in KI-Systemen, und welche Lücken bestehen bei der Bekämpfung von Geschlechterbias?

## Methodik

Theoretisch: Feministische Textanalyse des AI Act mit artikel-für-artikel-Analyse; Fallstudienanalyse zur Illustration von KI-bedingten Geschlechterungerechtigkeit
**Datenbasis:** nicht angegeben (theoretisches und dokumentenanalytisches Papier)

## Hauptargumente

- KI-Systeme können bestehende gesellschaftliche Geschlechterverzerrungen perpetuieren (Amazon-Rekrutierungstool, Deliveroo-Algorithmus, iBorderCtrl, VioGen), was die Notwendigkeit geschlechtssensitiver Regulation unterstreicht.
- Das EU-AI-Gesetz verwendet überwiegend geschlechtsneutrale Sprache und vermeidet explizite geschlechtsspezifische Begriffe, wodurch die Herausforderungen marginalisierter Gruppen einschließlich Frauen of Colour, LGBTQIA+ und nicht-binärer Personen übersehen werden.
- Eine intersektionale, feministische Approach ist notwendig, um zu verstehen, wie Geschlecht mit Rasse, Klasse, Behinderung und anderen Identitätsfaktoren interagiert und wie KI-Systeme diese multiplen Diskriminierungen verstärken können.

## Kategorie-Evidenz

### Evidenz 1

Das Paper analysiert verschiedene AI-Systeme und deren Regulierung durch das EU-AI-Gesetz, einschließlich hochriskanter KI-Systeme in Rekrutierung, Gesundheitswesen, Grenzmanagement und prädiktiver Polizei.

### Evidenz 2

The paper provides extensive case studies showing how AI systems perpetuate discrimination: 'AI technologies, if not designed with comprehensive oversight, can inadvertently perpetuate existing societal biases, leading to discriminatory impacts against women and marginalised communities.'

### Evidenz 3

Explicit gender focus throughout: 'This paper examines the need for feminist-informed AI frameworks to address diverse socio-technical impacts and counter the risk of AI reflecting biases favouring white, cisgender, able-bodied men.'

### Evidenz 4

The paper emphasizes intersectionality: 'Feminist scholars contend that existing laws must incorporate stronger protections for individuals, especially women, facing vulnerabilities related to privacy breaches and surveillance' and explicitly discusses marginalized communities including women of color, LGBTQIA+, disabled individuals.

### Evidenz 5

Explicit feminist theoretical framework: 'Drawing on feminist theories, the paper evaluates the AI Act's limitations in mitigating gender biases.' Uses feminist scholars like Crenshaw (intersectionality), MacKinnon, objectification theory, and feminist legal analysis throughout.

### Evidenz 6

Addresses algorithmic fairness in context of gender: 'Conformity assessments should require comprehensive bias audits that extend beyond identifying overt discrimination' and discusses fairness in recruitment, healthcare, and border control contexts.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittmenge von KI-Regulierung, Geschlechterforschung und sozialer Gerechtigkeit. Das Paper bietet eine einzigartige feministische Analyse von EU-KI-Politik und deren Auswirkungen auf marginalisierte Gruppen.

**Unique Contribution:** Das Paper leistet einen originären Beitrag durch die systematische, intersektionale feministische Analyse des EU-AI-Gesetzes und identifiziert spezifische textuelle Lücken sowie praktische Handlungsempfehlungen für geschlechtersensible KI-Governance.

**Limitations:** Das Paper ist primär dokumenten- und theoriebasiert; es fehlen empirische Daten zur realen Auswirkung des AI Act auf Geschlechtergerechtigkeit oder qualitative Forschung mit betroffenen marginalisierten Gruppen.

**Target Group:** Policymakers und EU-Institutionen, Geschlechterstudien und Gender-Forscher:innen, KI-Ethiker:innen und Regulierungsspezialisten:innen, Menschenrechtsorganisationen und feministische Aktivist:innen, Juristen:innen im Bereich Technologierecht

## Schlüsselreferenzen

- [[Crenshaw_K_2019]] - 'Difference' through intersectionality
- [[Fredrickson_B_L_Roberts_T_A_1997]] - Objectification Theory: Toward Understanding Women's Lived Experiences and Mental Health Risks
- [[Dastin_J_2018]] - Amazon scraps secret AI recruiting tool that showed bias against women
- [[Zuiderveen_Borgesius_F_2018]] - Discrimination, Artificial Intelligence and Algorithmic Decision-Making
- [[Theilen_J_T_et_al_2021]] - Feminist data protection: an introduction
- [[Leavy_S_2018]] - Gender bias in artificial intelligence: The need for diversity and gender theory in machine learning
- [[Karagianni_A_Doh_M_2024]] - A feminist legal analysis of non-consensual sexualized deepfakes
- [[Sovacool_B_et_al_2021]] - Can prosuming become perilous? Exploring systems of control and domestic abuse in the smart homes of the future
