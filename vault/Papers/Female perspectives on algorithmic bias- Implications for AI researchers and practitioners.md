---
title: Female perspectives on algorithmic bias: Implications for AI researchers and practitioners
authors:
  - B. Fraile-Rojas
  - C. De-Pablos-Heredero
  - M. Méndez-Suárez
year: 2025
type: journalArticle
url: https://colab.ws/articles/10.1108%2Fmd-04-2024-0884
doi: 10.1108/MD-04-2024-0884
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Discrimination
  - Algorithmic Bias
  - Intersectionality
mitigation_strategies: []
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
---

# Female perspectives on algorithmic bias: Implications for AI researchers and practitioners

## Abstract

This study uses NLP and machine learning to analyze 172,041 tweets from female users discussing gender inequality in AI. It identifies prominent themes including the future of AI technologies and women's active role in ensuring gender-balanced systems. Findings show that algorithmic bias directly affects women's experiences, prompting engagement in online discourse about injustices. Women lead constructive conversations and create entrepreneurial solutions when faced with bias, demonstrating how feminist digital literacies can make AI biases visible and push for their reduction.

## Assessment

**LLM Decision:** Include (Confidence: 0.92)
**LLM Categories:** AI_Literacies, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness

## Key Concepts

### Bias Types
- [[Algorithmic Bias]]
- [[Discrimination]]
- [[Intersectionality]]

## Full Text

---
title: "Female perspectives on algorithmic bias: implications for AI researchers and practitioners"
authors: ["Belen Fraile-Rojas", "Carmen De-Pablos-Heredero", "Mariano Mendez-Suarez"]
year: 2025
type: journalArticle
language: en
processed: 2026-02-05
source_file: Fraile-Rojas_2025_Female_perspectives_on_algorithmic_bias.md
confidence: 95
---

# Female perspectives on algorithmic bias: implications for AI researchers and practitioners

## Kernbefund

Weibliche Nutzer konzentrieren sich primär auf die Zukunft von KI-Technologien und die aktive Rolle von Frauen zur Gewährleistung geschlechtergerechter Systeme; algorithmischer Bias beeinflusst weibliches Verhalten als Reaktion auf Ungerechtigkeit, wobei Frauen verstärkt unternehmerische Lösungen vorantreiben.

## Forschungsfrage

Welche Perspektiven teilen weibliche Nutzer in sozialen Medien zum Thema algorithmischer Bias und Geschlechtergerechtigkeit in KI-Systemen?

## Methodik

Empirisch, Mixed Methods: Social Opinion Mining mit Natural Language Processing (NLP) und Machine Learning (ML), angewandt auf Twitter-Daten; Wort-Wolken-Analyse, Sentimentanalyse, Clustering und Chi-Quadrat-Tests
**Datenbasis:** 172.041 Tweets weltweit über einen Zeitraum von 359 Tagen; Analyse von 100 einflussreichsten weiblichen Nutzern; 88% der Beiträge von englischsprachigen Nutzern aus USA, UK, Australien und Kanada

## Hauptargumente

- Algorithmischer Bias ist nicht nur ein technisches Problem, sondern ein sozio-technisches Problem, das strukturelle Ungleichheiten widerspiegelt und verstärkt. Weibliche Nutzer fordern intersektionale, kollaborative Ansätze zur Adressierung dieser Ungleichheiten.
- Weibliche Gründerinnen und Aktivistinnen nutzen soziale Medien proaktiv, um auf Geschlechter- und Rassengerechtigkeit hinzuweisen und lösungsorientierte Conversations zu führen. Die Mehrheit der einflussreichsten weiblichen Nutzer sind Unternehmerinnen, die prosoziale Lösungen entwickeln.
- Geschlecht und Rasse konvergieren in kollektiven digitalen Gesprächen (Chi-Quadrat-Test: p=0,0). Dies bestätigt die intersektionale Matrix-of-Domination-Theorie von Patricia Hill Collins und zeigt, dass weibliche Nutzer bewusst intersektionale Perspektiven in Diskussionen um KI-Gerechtigkeit einbringen.

## Kategorie-Evidenz

### Evidenz 1

Fokus auf Natural Language Processing (NLP), Machine Learning (ML) Modelle und algorithmische Entscheidungssysteme: 'explores the use of natural language processing (NLP) techniques and machine learning (ML) models to discover underlying concepts of gender inequality applied to artificial intelligence (AI) technologies'

### Evidenz 2

Bezug zu Gerechtigkeit, sozialen Auswirkungen und Interventionen in vulnerable Gruppen: 'highlighting the need for critical analysis to ensure social justice', 'endure the consequences of stigmatized products and services'

### Evidenz 3

Expliziter Fokus auf algorithmischen Bias und strukturelle Ungleichheit: 'algorithmic bias impacts female user behaviours in response to injustice and inequality in algorithmic outcomes', 'gender bias in state-of-the-art AI models'

### Evidenz 4

Umfassender Gender-Fokus durchgehend: 'Female perspectives on algorithmic bias', 'gender bias in AI-based decision-making systems', 'gender inequality concepts applied to AI technologies'

### Evidenz 5

Intersektionale Perspektive und Fokus auf marginalisierte Gruppen: 'They request an intersectional, collaborative and pluralistic understanding of gender and race in AI', 'affirms that women challenged by cultural bias and social discrimination are more likely to fund entrepreneurial solutions'

### Evidenz 6

Explizite Verwendung feministischer Theorie und Methodologie: 'Haraway's manifesto', 'feminist critical thought is indispensable', 'feminist socio-technical approaches', 'Black feminist scholar Patricia Hill Collins' matrix of domination', 'Crenshaw (2017) developed the concept of intersectionality', 'Data feminists contend that feminism inherently involves activist efforts'

### Evidenz 7

Fokus auf faire und ausgewogene KI-Systeme: 'gender balanced systems', 'responsible, impartial technologies', 'balanced and inclusive' technologies, Analyse zwischen fairen und diskriminierenden Begriffen in 172.041 Tweets

## Assessment-Relevanz

**Domain Fit:** Hochrelevant für die Schnittstelle KI/Soziale Arbeit/Gender. Das Paper zeigt empirisch, wie weibliche Stimmen algorithmische Ungerechtigkeit kritisieren und Lösungen fordern. Es verbindet feministische Theorie mit KI-Kritik und liefert Evidenz für die Notwendigkeit intersektionaler Perspektiven in der KI-Entwicklung.

**Unique Contribution:** Das Paper kombiniert Social Opinion Mining mit feministischer Theorie und bietet eine empirisch fundierte Analyse der weiblichen Perspektiven auf AI-Bias, die zeigt, dass Frauen nicht passive Leidtragende sind, sondern aktive Agentinnen für Wandel.

**Limitations:** Starke geografische und sprachliche Verzerrung: 88% der Beiträge stammen aus USA, UK, Australien und Kanada (englischsprachig), was westliche, kulturell spezifische Perspektiven auf Geschlechtergerechtigkeit überrepräsentiert; die Wahl bestimmter Keywords könnte andere relevante Diskurse ausschließen.

**Target Group:** KI-Forscher und Praktiker, die Gender-Gerechtigkeit in KI-Systemen adressieren; feministische Technologiekritiker; Policy-Maker und Entscheidungsträger in Tech-Industrie und Akademia; Sozialarbeiter, die mit technologieinduzierten Diskriminierungen umgehen; Unternehmer und Unternehmerinnen in der KI-Ethik

## Schlüsselreferenzen

- [[Haraway_1987]] - A Cyborg Manifesto (Feminist Socio-Technical Approach)
- [[Harding_1991]] - Whose Science? Whose Knowledge? (Feminist Epistemology)
- [[Cockburn_Ormrod_1993]] - Gender and Technology: The Curious Relationship
- [[Collins_1990]] - Black Feminist Thought (Matrix of Domination)
- [[Wajcman_2010]] - Feminist Theories of Technology
- [[Crawford_2016]] - Gender and Technology (Masculine Values in Design)
- [[Buolamwini_Gebru_2018]] - Gender Shades (Facial Recognition Bias)
- [[DIgnazio_Klein_2023]] - Data Feminism (Critical AI and Feminist Methods)
- [[Crenshaw_2017]] - Intersectionality (Interlocking Systems of Oppression)
- [[West_Whittaker_Crawford_2019]] - Discriminating Systems: Gender, Race, and Power in AI
