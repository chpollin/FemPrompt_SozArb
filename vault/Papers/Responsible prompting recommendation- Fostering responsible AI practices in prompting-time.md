---
title: "Responsible prompting recommendation: Fostering responsible AI practices in prompting-time"
authors:
  - P. James
  - M. Meeussen
  - I. Matthes
  - D. Siemon
year: 2025
type: conferencePaper
doi: 10.1145/3706598.3713365
url: 
tags:
  - paper
llm_decision: Include
llm_confidence: 0.87
llm_categories:
  - AI_Literacies
  - Generative_KI
  - Prompting
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Fairness
---

# Responsible prompting recommendation: Fostering responsible AI practices in prompting-time

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, Prompting, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 88 |
| Correctness | 92 |
| Category Validation | 85 |
| **Overall Confidence** | **88** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.87)

## Key Concepts

- [[Algorithmic Bias in Language Models]]
- [[Prompt Engineering]]

## Wissensdokument

# Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time

## Kernbefund

Responsible Prompting Recommendations haben das Potenzial, anfängliche Prompt-Engineers zu unterstützen und Bewusstsein für Responsible AI zu schärfen, sollten aber gleichzeitig Prompt-Ähnlichkeit und Diversität sozialer Werte maximieren.

## Forschungsfrage

Wie können Recommender-Systeme IT-Professionelle dabei unterstützen, verantwortungsvoll mit Generative-AI-Systemen zu interagieren und dabei RAI-Praktiken zu fördern?

## Methodik

Mixed Methods: 10 qualitative Interviews mit IT-Professionellen, Entwicklung eines open-source Recommender-Systems, 20 Usability-Sessions mit Think-Aloud-Protokoll und retrospektivem End-User Walkthrough
**Datenbasis:** 10 Interviews mit IT-Professionellen, 20 User Sessions mit IT-Professionellen

## Hauptargumente

- Generative AI erfordert zusätzliche Designüberlegungen für User Interfaces und benötigt Nutzerleitfaden zu Affordanzen, Inputs und Outputs; ein Recommender-System kann Responsible AI Praktiken beim Prompting fördern.
- IT-Professionelle unterscheiden sich in ihren Prompting-Praktiken nach Rolle (Client-facing vs. Research): Client-facing Teams betonen Iterativität und Laboriösität, Research-Teams fokussieren auf Spezifizität und Nuancen bei komplexen Problemen.
- Benutzerempfehlungen sollten Additions- und Removal-Empfehlungen bieten, um sowohl positive Werte zu verstärken als auch potentiell schädliche Inhalte zu flaggen; Human-in-the-Loop ist essentiell zur Vermeidung von False Positives.

## Kategorie-Evidenz

### Evidenz 1

Responsible Prompting als Prozess wird definiert als Kommunikation mit KI-Systemen unter Vermeidung von Schäden und Förderung verantwortungsvoller Praktiken. Das Paper bietet praktische Leitfäden für Nutzer zum kompetenten Umgang mit GenAI.

### Evidenz 2

Focus auf Large Language Models (LLMs) und generative AI (GenAI), einschließlich Stochastizität, Variabilität und Halluzination von generativen Systemen.

### Evidenz 3

Zentral sind Prompt Engineering, Prompt-Strategien, Template-Empfehlungen und Best Practices beim Strukturieren von Eingaben für Text-Generierung und Bild-Generierung.

### Evidenz 4

GenAI kann zu 'erasing or obfuscating social terms or issues, stereotyping or misrepresenting people' führen. Adversarial prompting und Jailbreaks werden als Sicherheitsrisiken thematisiert. Concerns um fairness, bias, und marginalisierte Communities werden erwähnt.

### Evidenz 5

Mehrere Teilnehmer aus Brasilien äußern Bedenken bezüglich Priorisierung des Englischen gegenüber anderen Sprachen. Research-Teams arbeiten mit spezifischen Populationen (z.B. ALS-Patienten) und betonen Notwendigkeit, Nuancen und Variationen in Sprachverwendung zu erfassen.

### Evidenz 6

Responsible AI als umbrella term für faire, ethische und verantwortungsvolle KI-Entwicklung. Fairness-Überlegungen in Bias-Mitigation, Systembewertung und Value Alignment werden integriert.

## Assessment-Relevanz

**Domain Fit:** Das Paper trägt zu Responsible AI und HCI bei, hat aber keinen direkten Bezug zu Sozialer Arbeit oder Gender Studies. Die Relevanz liegt in der Schnittstelle von KI-Kompetenzen, Fairness und inklusiver Gestaltung von KI-Systemen.

**Unique Contribution:** Erstmaliges open-source Recommender-System, das RAI-Praktiken direkt in den Prompting-Prozess integriert und empirisch validiert, mit Differenzierung zwischen verschiedenen beruflichen Rollen und Praktiken.

**Limitations:** Begrenzte Sample-Größe (20 Usability-Sessions), Fokus auf IT-Professionelle (keine Diversity in Benutzerprofilen), fehlende Analyse langfristiger Auswirkungen auf Prompting-Verhalten und Responsible AI Kultur.

**Target Group:** KI-Entwickler, Prompt-Engineers, UX-Designer von GenAI-Systemen, Verantwortliche für Responsible AI in Technologieunternehmen, HCI-Forscher, Policy-Maker für AI Governance

## Schlüsselreferenzen

- [[Sunrise_Mark_2020]] - Responsible Innovation
- [[Zwitter_Andrej_2014]] - Responsible Innovation Framework
- [[Floridi_Luciano_Cowley_Josh_2019]] - AI Ethics Framework
- [[Greshake_Kai_et_al_2023]] - Prompt Injection Attacks
- [[Sap_Maarten_et_al_2019]] - Social Bias in AI
- [[OpenAI_2023]] - Prompt Engineering Guide
- [[Vallada_AnnaMaria_et_al_2023]] - Red Teaming Dataset
- [[Braun_Virginia_Clarke_Victoria_2006]] - Thematic Analysis Methods
