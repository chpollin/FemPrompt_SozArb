---
title: Algorithmic Governance and the International Politics of Big Tech
authors:
  - S. Srivastava
year: 2024
type: journalArticle
doi: 
url: "https://www.cambridge.org/core/journals/perspectives-on-politics/article/algorithmic-governance-and-the-international-politics-of-big-tech/3C04908735A5F2EE8A70AFED647741FB"
tags:
  - paper
llm_decision: Exclude
llm_confidence: 0.85
llm_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
human_decision: Unclear
human_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
agreement: disagree
---

# Algorithmic Governance and the International Politics of Big Tech

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** KI_Sonstige, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 4: Assessment

**LLM:** Exclude (Confidence: 0.85)
**Human:** Unclear

**Kategorie-Vergleich (bei Divergenz):**

| Kategorie | Human | LLM | Divergent |
|-----------|-------|-----|----------|
| AI_Literacies | Nein | Nein |  |
| Generative_KI | Nein | Nein |  |
| Prompting | Nein | Nein |  |
| KI_Sonstige | Ja | Ja |  |
| Soziale_Arbeit | Nein | Nein |  |
| Bias_Ungleichheit | Ja | Ja |  |
| Gender | Nein | Nein |  |
| Diversitaet | Ja | Nein | X |
| Feministisch | Nein | Nein |  |
| Fairness | Ja | Nein | X |

> Siehe [[Divergenz Srivastava_2024_Algorithmic_Governance_and_the_International]] fuer detaillierte Analyse


## Key Concepts

- [[Algorithmic Discrimination]]
- [[Algorithmic Governance]]
- [[Algorithmic Opacity]]

## Wissensdokument

# Algorithmic Governance and the International Politics of Big Tech

## Kernbefund

Algorithmic governance by Big Tech creates unprecedented forms of private authority that challenge existing IR frameworks of legitimacy, and requires new conceptualizations of corporate international responsibility that account for opacity, scale, and the complex oscillation between state-corporate collaboration and contestation.

## Forschungsfrage

How should International Relations scholarship engage with algorithmic governance by Big Tech companies, and what are the implications for private authority and state-corporate relations?

## Methodik

Theoretisch/Konzeptionell: Integrative Literaturanalyse und IR-theoretische Neukonzeptualisierung, teilweise qualitative Fallstudien (Facebook Content Oversight Board, Trending Topics)
**Datenbasis:** Nicht primär empirisch; hauptsächlich theoretische und dokumentarische Analyse mit illustrativen Beispielen aus Unternehmenshandlungen und Policies

## Hauptargumente

- Big Tech companies exercise algorithmic governance that functions as private authority comparable to state governance, creating 'arbiters of knowledge, connection, and desire' through classification algorithms that make automated decisions affecting billions of users without meaningful consent or representation.
- Algorithmic opacity in machine-learning systems creates a fundamental legitimation crisis: algorithms are black boxes both to users and often to their designers, making it impossible for surveillance subjects to internalize governance norms, which IR legitimacy theory defines as essential for non-coercive authority.
- State-corporate relations around algorithmic governance involve complex dynamics of interdependence (state delegation), circumvention (Big Tech resistance to state overreach), and curtailment (state regulation), requiring IR scholars to move beyond simplistic 'states versus markets' frameworks toward understanding simultaneous collaboration and contestation.

## Kategorie-Evidenz

### Evidenz 1

Classification algorithms using unsupervised and semi-supervised machine learning for object detection, text processing, and predictive modeling; algorithmic governance defined as 'deference to automated decision-making makes algorithms a source and factor of social order'; focus on algorithmic systems in surveillance, content moderation, risk assessment, and recommendation systems.

### Evidenz 2

Risk-assessment algorithms 'construct people's identities and reputations by classifying them as risky, associating them with undesirable traits'; examples of algorithmic discrimination including Facebook's differential treatment of content moderation for Black activists versus white users; mass surveillance generating behavioral data extraction; algorithmic systems perpetuating structural inequalities in credit, terrorism, and crime assessment.

### Evidenz 3

Discussion of marginalized communities affected by algorithmic governance; reference to Rohingya genocide facilitated by Facebook's algorithmic amplification; mention of diverse global operating contexts and multilingual oversight challenges; intersectional harms affecting different user populations differently through algorithmic systems.

### Evidenz 4

Emphasis on due process, transparency, and fair procedures in algorithmic governance; discussion of 'obligations of transparency, notice, and fair procedures' for tech platforms; evaluation of Facebook's Content Oversight Board as attempt at fairness and accountability mechanisms; concerns about algorithmic discrimination and need for nondiscrimination standards.

## Assessment-Relevanz

**Domain Fit:** Das Paper hat moderate Relevanz für die KI-Soziale-Arbeit-Schnittstelle: Es adressiert algorithmische Diskriminierung und Bias in klassischen ML-Systemen, aber nicht explizit Anwendungen in der Sozialen Arbeit (Jugendhilfe, Casework). Die Analyse von Fairness, Bias und privater Autorität ist jedoch hochrelevant für die ethische Gestaltung von KI-Systemen in sozialen Diensten.

**Unique Contribution:** Der Paper leistet einen innovativen IR-theoretischen Beitrag durch Rekonseptualisierung von Big Tech als private Autorität und durch Analyse der komplexen state-corporate relations, die Algorithmic Governance umgeben—ein bislang unterbeleuchtetes Thema in der internationalen Politikwissenschaft.

**Limitations:** Keine empirische Primärdatenerhebung; konzeptionell-theoretischer Fokus auf Global Governance eher als auf konkrete Auswirkungen in spezifischen Sektoren wie Soziale Arbeit; begrenzte Behandlung nicht-westlicher Perspektiven auf algorithmische Governance trotz Erwähnung chinesischer Tech-Unternehmen.

**Target Group:** Internationale Politikwissenschaftler:innen, Global-Governance-Forscher:innen, Tech-Regulator:innen und Policymaker, Vertreter:innen von Menschenrechtsorganisationen, Tech Ethics und Corporate Responsibility Spezialist:innen; sekundär relevant für Sozialarbeiter:innen, die mit algorithmischen Systemen in ihrer Praxis konfrontiert sind

## Schlüsselreferenzen

- [[Benjamin_Ruha_2019]] - Race after Technology: Abolitionist Tools for the New Jim Code
- [[Crawford_Kate_2021]] - Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence
- [[Noble_Safiya_2018]] - Algorithms of Oppression: How Search Engines Reinforce Racism
- [[Pasquale_Frank_2015]] - The Black Box Society: The Secret Algorithms that Control Money and Information
- [[Yeung_Karen_2018]] - Algorithmic Regulation: A Critical Interrogation
- [[Zuboff_Shoshana_2019]] - The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power
- [[Amoore_Louise_2020]] - Cloud Ethics: Algorithms and the Attributes of Ourselves and Others
- [[Citron_Danielle_Pasquale_Frank_2014]] - The Scored Society: Due Process for Automated Predictions
- [[Hall_Rodney_Biersteker_Thomas_2002]] - The Emergence of Private Authority in Global Governance
- [[Balkin_Jack_2018]] - Free Speech in an Algorithmic Society: Big Data, Private Governance, and New School Speech Regulation
