---
title: Digitale Werkzeuge und Machtasymmetrien?
authors:
  - S. Studeny
year: 2025
type: conferencePaper
doi: 
url: "https://www.ogsa.at/wp-content/uploads/2025/03/ogsaTAGUNG2025_AG-Digitalisierung_Handout-Machtasymmetrien-Susanne-Studeny.pdf"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Fairness
human_decision: Include
human_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
agreement: agree
---

# Digitale Werkzeuge und Machtasymmetrien?

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 5 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 88 |
| Correctness | 92 |
| Category Validation | 85 |
| **Overall Confidence** | **88** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.92)
**Human:** Include

## Key Concepts

- [[Algorithmic Discrimination]]
- [[Algorithmic Transparency]]
- [[Digital Divide]]
- [[Digital Sovereignty]]

## Wissensdokument

# Digitale Werkzeuge und Machtasymmetrien? Eine kritische Betrachtung von Technologie und Abhängigkeiten in der Sozialen Arbeit

## Kernbefund

Digitale Systeme sind nicht neutral und verstärken bestehende Machvasymmetrien durch unsichtbare Kontrolle, algorithmische Diskriminierung und Ausgrenzung, während sie gleichzeitig professionelle Autonomie und Klient:innen-Selbstbestimmung untergraben. Soziale Arbeit muss diese Dynamiken kritisch reflektieren und sich politisch für digitale Gerechtigkeit einsetzen.

## Forschungsfrage

Wie verändern digitale Werkzeuge und Algorithmen Machtverhältnisse in der Sozialen Arbeit und welche Konsequenzen hat dies für Gerechtigkeit, Selbstbestimmung und die Rechte von Klient:innen?

## Methodik

Theoretisch-kritische Analyse mit praxisorientierten Fallbeispielen und Reflexionsfragen; interdisziplinäre Perspektive (Macht-Theorien, Digitalisierungskritik, Soziale Arbeit)

## Hauptargumente

- Macht in der Sozialen Arbeit wird durch digitale Tools verstärkt und verändert: Digitale Systeme sind nie neutral, sondern tragen gesellschaftliche Normen und Machtstrukturen in sich (Foucault'sche Perspektive) und können Kontrolle unsichtbarer und massiver machen, besonders durch Algorithmen bei automatisierten Entscheidungen.
- Digitale Steuerung und unsichtbare Lenkung (Digital Nudging, algorithmische Risikobewertungen) reduzieren Selbstbestimmung von Klient:innen und professionelle Autonomie von Fachkräften, indem sie Entscheidungen vorgeben, ohne dass Alternativen sichtbar sind oder echte Mitbestimmung möglich wird.
- Algorithmen und KI-Systeme verstärken Diskriminierung durch historisch verzerrte Trainingsdaten und reproduzieren systematisch Benachteiligungen gegen Menschen mit Migrationsgeschichte, People of Color, Frauen, Menschen mit Behinderungen und sozial Benachteiligte, während sie als 'objektiv' und 'neutral' erscheinen.
- Digitale Teilhabe und digitale Souveränität sind zentrale Gerechtigkeitsfragen: Der Digital Divide auf drei Ebenen (Zugang, Kompetenzen, Mitbestimmung) verstärkt soziale Ungleichheit, und die Abhängigkeit von Big-Tech-Infrastruktur widerspricht dem ethischen Auftrag Sozialer Arbeit.
- Soziale Arbeit muss sich als politische Kraft verstehen, die aktiv für digitale Gerechtigkeit, Transparenz, Datenschutz und Mitbestimmung eintritt und gegen diskriminierende Technologien kämpft, statt diese passiv zu übernehmen.

## Kategorie-Evidenz

### Evidenz 1

Digitale Bildung wird als 'Schlüssel für soziale Gerechtigkeit' behandelt; Reflexionsfragen zu Verständnis und kritischer Nutzung von Technologie; Forderung nach Kompetenzentwicklung für Fachkräfte und Klient:innen im Umgang mit digitalen Systemen.

### Evidenz 2

Fokus auf Algorithmen, Scoring-Modelle, automatisierte Risikobewertungen, KI-gestützte Entscheidungssysteme in Fallmanagement, Chatbots und prädiktive Analytik in der Sozialverwaltung; 'Künstliche Intelligenz - Transparenz, Gerechtigkeit und menschliche Entscheidungsmacht' als eigenständiges Kapitel.

### Evidenz 3

Durchgehender Fokus auf Fachkräfte und Klient:innen in Sozialer Arbeit; konkrete Praxisbereiche wie Schuldnerberatung, Kindeswohl, Jugendhilfe, Jobcenter, Beratungssettings; Machtkritik mit Bezug zu professioneller Ethik und Werteorientierung Sozialer Arbeit.

### Evidenz 4

Kapitel 'Diskriminierung durch Algorithmen'; Beispiele wie rassistische Algorithmen bei Bewerbungsportalen, Kindeswohlalgorithmen mit Bias gegen Migrant:innen, Jobcenter-Systeme die nach Merkmalen wie 'Alter, Schulbildung, Stadtteil' diskriminieren; Digital Divide als strukturelle Ungleichheit.

### Evidenz 5

Explizite Nennung betroffener Gruppen: 'Menschen mit Migrationsgeschichte, People of Color, Frauen, Menschen mit Behinderungen, Arme', 'ältere Menschen, Personen mit geringer Bildung oder Migrationserfahrung'; Intersektionalität implizit durch Mehrfachnennungen; marginalisierte Communities im Fokus der Kritik.

### Evidenz 6

Kapitel 'Gerechtigkeit, Transparenz und Verantwortung gestalten'; Forderungen nach fairen Algorithmen ('Algorithmen dürfen keine Menschen benachteiligen'), Transparenz in algorithmischen Entscheidungen, Fairness-Überprüfung ('Fairness: Algorithmen dürfen keine Menschen benachteiligen'), Equitable Access zu Ressourcen.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit: Das Paper adressiert zentrale Fragen von algorithmischer Diskriminierung, Machtasymmetrien und digitaler Gerechtigkeit in einem sozialarbeiterischen Kontext und verbindet klassische Machttheorien mit aktuellen Digitalisierungskritik. Besonders wertvoll für sozialarbeiterische Fachkräfte und Policy-Maker.

**Unique Contribution:** Die systematische Verknüpfung von Macht-Theorien (Weber, Arendt, Foucault, Hobbes) mit konkreten Problemen digitaler Technologien in der Sozialen Arbeit bietet ein innovatives kritisches Analyserahmenwerk, das über technische Debatten hinausgeht und politische Forderungen mit praxisrelevanten Beispielen verbindet.

**Limitations:** Empirische Daten fehlen; keine eigenen Fallstudien oder Befragungen von Fachkräften/Klient:innen; primär theoretisch-analytisch ohne quantitative oder qualitative Validierung der kritisierten Probleme; Konrad als digitaler Avatar selbst exemplifiziert die technologischen Fragen, die das Paper kritisiert, ohne dies zu reflektieren.

**Target Group:** Primär: Sozialarbeiter:innen, Fachkräfte in Sozialen Diensten, Soziale-Arbeit-Studierende, Verbände und Träger der Sozialen Arbeit. Sekundär: KI-Entwickler:innen in Verwaltungskontexten, Policy-Maker im Sozialbereich, Aktivist:innen für digitale Gerechtigkeit, Hochschuldozent:innen in Sozialer Arbeit und kritischer Medienpädagogik.

## Schlüsselreferenzen

- [[Weber_Max_nicht spezifiziert]] - Macht als Durchsetzungsvermögen in sozialen Beziehungen
- [[Arendt_Hannah_nicht spezifiziert]] - Macht als kollektive Handlungskraft
- [[Foucault_Michel_nicht spezifiziert]] - Macht durch Diskurse und Strukturen / Mikrophysik der Macht
- [[Hobbes_Thomas_nicht spezifiziert]] - Macht als permanentes Streben nach Kontrolle
- [[HerwigLempp_Johannes_nicht spezifiziert]] - Sozialarbeiter:innen und Macht
- [[Distelmeyer_Jan_2021]] - Kritik der Digitalität
- [[Kutscher_Nadia_et_al_2020]] - Handbuch Soziale Arbeit und Digitalisierung
- [[Kettemann_Matthias_C_et_al_2022]] - Menschenrechte im Digitalen
- [[Kaminsky_Carmen_et_al_2020]] - Digitale Technologien zwischen Lenkung und Selbstermächtigung
- [[Martinsen_Franziska_2018]] - Wissen - Macht - Meinung. Demokratie und Digitalisierung
