---
title: Exploring opportunities and risks in decision support technologies for social workers: An empirical study in the field of disabled people's services
authors:
  - D. Schneider
  - A. Maier
  - P. Cimiano
  - U. Seelmeyer
year: 2022
type: journalArticle
doi: 10.1093/bjsw/bcab262
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Discrimination
mitigation_strategies: []
llm_decision: Include
llm_confidence: 0.95
llm_categories:
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Fairness
human_decision: Exclude
human_categories:
  - KI_Sonstige
  - Soziale_Arbeit
agreement: disagree
---

# Exploring opportunities and risks in decision support technologies for social workers: An empirical study in the field of disabled people's services

## Abstract

Empirical study investigating German social workers' perspectives on decision support systems in disability services through practitioner interviews. Identifies both opportunities (consistency across cases, evidence-based practice, administrative time-saving) and significant risks (deprofessionalization, data protection concerns, reduced professional autonomy, loss of holistic assessment capabilities). Social workers express ambivalence: recognizing potential for reducing subjective bias and improving resource allocation transparency while worrying about losing relational aspects of assessment and client trust.

## Assessment

**LLM Decision:** Include (Confidence: 0.95)
**LLM Categories:** KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Fairness
**Human Decision:** Exclude
**Human Categories:** KI_Sonstige, Soziale_Arbeit
**Agreement:** Disagree

## Key Concepts

### Bias Types
- [[Discrimination]]

## Full Text

---
title: "Exploring Opportunities and Risks in Decision Support Technologies for Social Workers: An Empirical Study in the Field of Disabled People's Services"
authors: ["Diana Schneider", "Angelika Maier", "Philipp Cimiano", "Udo Seelmeyer"]
year: 2022
type: journalArticle
language: en
processed: 2026-02-05
source_file: Schneider_2022_Exploring_opportunities_and_risks_in_decision.md
confidence: 89
---

# Exploring Opportunities and Risks in Decision Support Technologies for Social Workers: An Empirical Study in the Field of Disabled People's Services

## Kernbefund

DSSs mit Visualisierungen der Klient*innen-Entwicklung werden als unterstützend wahrgenommen; es besteht Bedarf für partizipative Entscheidungsfindung; technische und professionelle Zuverlässigkeit dürfen nicht verwechselt werden.

## Forschungsfrage

Wie können Fachkräfte der Sozialen Arbeit in der Teilhabeplanung für Menschen mit Behinderung durch Entscheidungsunterstützungssysteme (DSSs) unterstützt werden, und welche Erwartungen, Befürchtungen und ethischen Implikationen sind damit verbunden?

## Methodik

Mixed Methods: Empirisch qualitativ mit zwei Teilen - ESI Study (Interviews zu Erwartungen und Befürchtungen, n nicht spezifiziert) und User Study (Prototyp-Testing mit 5 Fachkräften). Prospektive Technologiebewertung mit Antizipationsmethoden.
**Datenbasis:** 22 Klient*innen-Dateien mit 295.812 Datensätzen von 2 Wohneinrichtungen; Interviews mit Fachkräften von Leistungserbringern und Teilhabebehörden; Prototyp-Teststudie mit 5 Sozialarbeiter*innen

## Hauptargumente

- Visuelle Darstellungen von Klient*innen-Entwicklungen durch KI-basierte DSSs können berufliche Reflexion fördern und einen Mehrwert bieten, insofern sie subjektive Perspektiven transparenter machen und die professionelle Urteilsbildung unterstützen.
- Gegenwärtige Vorstellungen von DSSs fokussieren primär auf Professional-Algorithmus-Interaktion und ignorieren die Notwendigkeit partizipativer Entscheidungsfindung mit Service-Nutzer*innen, was ein kritisches Defizit in der Konzeptentwicklung darstellt.
- Die in professionelle Dokumentation eingeflossenen Biases, Subjektivitäten und Datenqualitätsprobleme stellen grundsätzliche Herausforderungen dar und erfordern Datenkompetenz und kritisches Verständnis der Unterschiede zwischen technischer und professioneller Zuverlässigkeit.

## Kategorie-Evidenz

### Evidenz 1

Data literacy und Verständnis technischer Prozesse werden als erforderlich benannt: 'Keeping this crucial distinction in mind and accounting for it in daily work with algorithms requires data literacy and an understanding of the technical processes'

### Evidenz 2

Fokus auf AI-basierte Vorhersagesysteme (LONA-Scoring), algorithmische Entscheidungssysteme und natürliche Sprachverarbeitung: 'The system relies on an artificial intelligence (AI) based system trained to predict levels of need for assistance (LONA) from textual documentations'

### Evidenz 3

Expliziter Fokus auf Soziale Arbeit in Teilhabeplanung für Menschen mit Behinderung, professionelle Urteilsbildung und Fachkräfte-Kompetenzen: 'MAEWIN project, therefore, addresses the question of how professionals of social care providers could be supported in the context of SSP by DSSs'

### Evidenz 4

Kritische Analyse von Biases in Dokumentation und Datenbasis: 'documentation may contain hidden biases, biased perspectives, or prejudices' und Diskriminierungsrisiken von Algorithmen: 'systemic discrimination'

### Evidenz 5

Fokus auf Menschen mit Behinderung als marginalisierte Gruppe und deren Partizipation in Entscheidungsprozessen: 'shared decision-making processes with the persons entitled to benefits'

### Evidenz 6

Fairness-Konzepte in algorithmischen Entscheidungssystemen und Anforderung fairer Darstellung: 'data basis used by algorithms is quality controlled and free of biases caused by data reflecting the perceptions of specific stakeholders'

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit. Das Paper adressiert zentrale Fragen der Implementierung von KI-Systemen in einer kritischen Profession und untersucht Auswirkungen auf vulnerable Zielgruppen (Menschen mit Behinderung) und professionelle Praxis mit Fokus auf Partizipation.

**Unique Contribution:** Einzigartig ist die Beteiligung von Sozialarbeiter*innen als Antizipant*innen in frühen Entwicklungsphasen von DSSs kombiniert mit kritischer Analyse von Subjektivität und Bias in professioneller Dokumentation sowie die Forderung nach partizipativen (statt nur technokratischen) Entscheidungsmodellen.

**Limitations:** Kleine Stichprobe in User Study (n=5); fehlende explizite Perspektive von Service-Nutzer*innen (Menschen mit Behinderung) selbst; Geschlechter- und intersektionale Dimensionen werden nicht systematisch analysiert; Fokus auf Deutschland begrenzt Generalisierbarkeit.

**Target Group:** Sozialarbeiter*innen, Fachkräfte der Behindertenhilfe, KI-Entwickler*innen mit Anwendungsfokus Soziale Arbeit, Policymaker im Sozialsektor, Forscher*innen zu Technology Assessment und Verantwortungsvoller Innovation, Vertreter*innen von Behindertenorganisationen

## Schlüsselreferenzen

- [[Gillingham_2019]] - Decision support systems, social justice and algorithmic accountability in social work
- [[Crawford_2013]] - The hidden biases in big data
- [[Raji_2020]] - How our data encodes systematic racism
- [[Wachter_Mittelstadt_Floridi_2017]] - Transparent, explainable, and accountable AI
- [[Collingridge_1980]] - The social control of technology
- [[Braun_et_al_2020]] - Primer on an ethics of AI-based decision support systems in the clinic
- [[Schneider_Seelmeyer_2019]] - Challenges in using big data to develop decision support systems for social work in Germany
- [[Chiusi_et_al_2020]] - Automating society report 2020
