---
title: "Social work in the age of artificial intelligence: A rights-based framework for evidence-based practice through social psychology, group dynamics, and institutional analysis"
authors:
  - N. Alam
year: 2025
type: journalArticle
doi: 10.1080/26408066.2025.2547219
url: "https://doi.org/10.1080/26408066.2025.2547219"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
---

# Social work in the age of artificial intelligence: A rights-based framework for evidence-based practice through social psychology, group dynamics, and institutional analysis

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **91** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.92)

## Key Concepts

- [[Ethical AI Literacy]]

## Wissensdokument

# Social Work in the Age of Artificial Intelligence: A rights-Based Framework for evidence-Based Practice Through Social Psychology, Group Dynamics, and Institutional Analysis

## Kernbefund

Ein umfassendes rechtsbasiertes Framework wurde entwickelt, das vier Komponenten integriert (Ethical AI Literacy, Participatory Governance, Continuous Impact Assessment, Community-Centered Advocacy) und AI-Integration in der sozialen Arbeit mit sozialen Psychologie-, Gruppendynamik- und institutionellen Erkenntnissen verbindet.

## Forschungsfrage

Wie können Sozialarbeiter:innen AI-Integration in der sozialen Arbeit navigieren und dabei ethische Implikationen berücksichtigen sowie die Kernwerte der Profession bewahren?

## Methodik

Theoretisch: Systematische Literaturanalyse (Narrative Review) mit Synthesierung interdisziplinärer Forschung aus Sozialpsychologie, Gruppendynamik und institutioneller Analyse; Analyse existierender Fachliteratur und dokumentierter Fallbeispiele
**Datenbasis:** Sekundärforschung: Literaturrecherche in Social Work Abstracts, PsycINFO, JSTOR, ACM Digital Library (2015-2025); dokumentierte Fallbeispiele aus Kinderschutz, psychische Gesundheit und Sozialdiensten

## Hauptargumente

- AI-Systeme beeinflussen Vulnerable Populationen tiefgreifend durch Mediierung von zwischenmenschlichen Beziehungen und Sinnkonstruktion; ohne proaktives Engagement der Sozialen Arbeit riskiert AI bestehende Ungleichheiten zu verstärken, während diese hinter technologischer Neutralität verborgen bleiben.
- Bestehende ethische Rahmenbedingungen der Sozialen Arbeit (NASW Code of Ethics) bieten Grundlagen, erfordern aber sorgfältige Interpretation und Expansion für technologische Kontexte, insbesondere bezüglich menschlicher Würde, Selbstbestimmung und Gerechtigkeit.
- Kognitives Bias (Automation Bias, Algorithm Aversion) und Epistemic Injustice in AI-Systemen gefährden sozialpädagogische Praxis; ein rechtsbasiertes Framework mit vier Komponenten kann diese Risiken adressieren und democratic governance in sozialen Diensten etablieren.

## Kategorie-Evidenz

### Evidenz 1

Ethical AI literacy wird als zentrale Komponente definiert: 'the ability to understand, evaluate, and ethically use AI technologies' einschließlich technischen Verständnisses, kritischem Bewusstsein für soziale Implikationen und 'algorithmic translation' für Klienten.

### Evidenz 2

Fokus auf Predictive Analytics, Algorithmic Decision Systems und Risk Assessment Tools in Kinderschutz, psychische Gesundheit und Wohnunterstützung; Analyse von Automation Bias und Algorithm Aversion.

### Evidenz 3

Explizit für Soziale Arbeit entwickelt; bezieht sich auf NASW Code of Ethics, sozialpädagogische Kernwerte (Menschenwürde, Selbstbestimmung, Gerechtigkeit), Micro-, Meso- und Makro-Ebenen der Praxis, sowie Ausbildung und Forschungsmethodologie.

### Evidenz 4

Detaillierte Analyse wie AI-Systeme Marginalisierte Populationen unverhältnismäßig stark beeinträchtigen: Allegheny County-Fallbeispiel zeigt wie Armutsfaktoren als Missbrauchsindikatoren gekennzeichnet wurden; Thematisierung von Epistemic Injustice und Algorithmic Discrimination.

### Evidenz 5

Fokus auf vulnerable Populationen, marginalisierte Communities, differenzielle Auswirkungen über sozialen Gruppen hinweg; Betonung von Community-zentrierter Partizipation, intersektionaler Berücksichtigung in Impact Assessments.

### Evidenz 6

Entwicklung sozialpädagogik-informierter Fairness-Metriken; kontinuierliche Impact-Analysen mit Attention auf Differential Impacts; Algorithmic Auditing über technische Metriken hinaus; Stop LAPD Spying Coalition als Beispiel für Accountability.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant: Das Paper adressiert direkt die Schnittstelle AI-Integration/Soziale Arbeit mit Fokus auf ethische, professionelle und justice-orientierte Implikationen; kritisiert AI-bedingte Verstärkung bestehender Ungleichheiten in sozialen Diensten.

**Unique Contribution:** Entwicklung eines umfassenden, rechtsbasierten Frameworks speziell für Soziale Arbeit, das Sozialpsychologie, Gruppendynamik und institutionelle Analyse integriert und konkrete, evidenzbasierte Handlungsempfehlungen für Praxis, Ausbildung, Forschung und Policy bietet.

**Limitations:** Primär theoretische Analyse ohne empirische Testung des Frameworks in realen Implementierungskontexten; Forschung basiert überwiegend auf westlichen Kontexten, limitiert Anwendbarkeit in diversen globalen Settings; rasche AI-Entwicklung könnte Framework schneller überholen als Theoriebildung.

**Target Group:** Sozialarbeiter:innen (Praktiker, Educators, Researchers), Social Work Policy Advocate:innen, Organisationen in sozialen Diensten, Kinderschutzbehörden, Computer Scientists/AI Developer:innen in Social Services, Policymaker im Bereich Soziale Dienste und Digital Governance

## Schlüsselreferenzen

- [[Eubanks_2018]] - Automating Inequality: How high-tech tools profile, police, and punish the poor
- [[Noble_2018]] - Algorithms of Oppression: How search engines reinforce racism
- [[Fricker_2007]] - Epistemic Injustice: Power and the ethics of knowing
- [[CostanzaChock_2020]] - Design Justice: Community-led practices to build the worlds we need
- [[Barocas_Hardt_Narayanan_2020]] - Fairness and Machine Learning
- [[Reamer_2018]] - Social Work Values and Ethics
- [[Berzin_Singer_Chan_2015]] - Practice innovation through technology in the digital age: A grand challenge for social work
- [[Abrams_der_Pütten_2020]] - I-C-E framework: Concepts for group dynamics research in human-robot interaction
- [[Vaithianathan_et_al_2019]] - Allegheny Family Screening Tool: Methodology
- [[Birhane_2021]] - Algorithmic Injustice: A relational ethics approach
