---
title: Algorithmic decision-making in social work practice and pedagogy: confronting the competency/critique dilemma
authors:
  - P. James
  - J. Lal
  - A. Liao
  - L. Magee
  - K. Soldatic
year: 2023
type: journalArticle
url: https://www.tandfonline.com/doi/full/10.1080/02615479.2023.2195425
doi: 10.1080/02615479.2023.2195425
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Discrimination
  - Intersectionality
mitigation_strategies:
  - Equitable Resource
  - Intersectionality
llm_decision: Include
llm_confidence: 0.85
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Fairness
---

# Algorithmic decision-making in social work practice and pedagogy: confronting the competency/critique dilemma

## Abstract

The world is experiencing an accelerating digital transformation. One aspect of this is the implementation of...[source](https://www.google.com/search?q=https://www.aminer.cn/pub/645d0410d68f896efa94d024/algorithmic-decision-making-in-social-work-practice-and-pedagogy-confronting-the-competency)

## Assessment

**LLM Decision:** Include (Confidence: 0.85)
**LLM Categories:** AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Fairness

## Key Concepts

### Bias Types
- [[Discrimination]]
- [[Intersectionality]]

### Mitigation Strategies
- [[Equitable Resource]]
- [[Intersectionality]]

## Full Text

---
title: "Algorithmic decision-making in social work practice and pedagogy: confronting the competency/critique dilemma"
authors: ["Paul James", "Jason Lal", "Ashley Liao", "Liam Magee", "Karen Soldatic"]
year: 2024
type: journalArticle
language: en
processed: 2026-02-05
source_file: James_2023_Algorithmic_decision-making_in_social_work.md
confidence: 91
---

# Algorithmic decision-making in social work practice and pedagogy: confronting the competency/critique dilemma

## Kernbefund

Sozialarbeitseducation muss ein Spannungsverhältnis zwischen technischer Kompetenz und kritischer Analyse auflösen, indem sie theoriegeleitet und praxisorientiert ADM-Systeme als Werkzeuge (nicht als Rahmen) behandelt, um sowohl ihre positiven als auch ihre diskriminierenden Potenziale zu adressieren.

## Forschungsfrage

Wie kann Sozialarbeitspädagogik Studierende sowohl auf die technische Kompetenz im Umgang mit algorithmischen Entscheidungssystemen als auch auf deren kritische Reflexion vorbereiten?

## Methodik

Theoretisch und konzeptionell; Case-Study-Analyse von drei Fallbeispielen (AFST, COMPAS, NDIS) plus zwei zusätzliche Fälle (Heat List, HEALER); Curriculumentwicklung basierend auf Fallstudien
**Datenbasis:** Keine primären empirischen Daten; qualitative Analyse von vier dokumentierten Algorithmen-Fallstudien in Sozialarbeit, Justizvollzug und Wohlfahrt

## Hauptargumente

- Algorithmische Entscheidungssysteme werden zunehmend in Sozialarbeit implementiert, ohne dass Sozialarbeiter angemessen geschult werden; dies erzeugt ein Dilemma zwischen technischer Kompetenz und kritischer Reflexion.
- Die bisherige Pädagogik 'normalisiert' Technologieeinsatz kritiklos oder lehrt Kritik getrennt von Technik-Verständnis; stattdessen braucht es eine integrierte, theorieinformierte Pädagogik, die ADM-Systeme als Werkzeuge innerhalb sozialer Machtstrukturen versteht.
- Case-Studies zeigen, dass ADM-Systeme zwar Bias reduzieren können (z.B. AFST), aber oft neue Verzerrungen einführen, Transparenzmangel ('Black Box') schaffen und die Advocacy-Fähigkeit von Sozialarbeitern unterminieren; Studierende müssen lernen, solche Systeme kritisch zu hinterfragen.

## Kategorie-Evidenz

### Evidenz 1

Digital literacy needs to include 'technical competency and critical understanding of the technical implications and social form of such digital tools'; 'algorithmic literacy that centers on understanding the often-critical limitations of such technologies and systems'

### Evidenz 2

Algorithmic decision-making (ADM) systems, predictive risk-assessment techniques, machine learning models trained on large datasets; 'black-box AI' systems; simple rule-based systems and complex AI systems

### Evidenz 3

Fokus auf Sozialarbeitspraxis, -pädagogik und -theorie; Case-Studies in Kinderschutz (AFST), Strafvollzug (COMPAS), Behindertenhilfe (NDIS); Curricula-Entwicklung für Sozialarbeitsstudierende

### Evidenz 4

Even AFST 'threatens the human right of nondiscrimination' when it creates 'imprecise risk-predictions based on invalid correlations'; COMPAS shows 'African-American populations had a higher false-negative rate compared to white populations'; disadvantages are 'amplified by automated processes, especially for the already most precarious'

### Evidenz 5

Children with disabilities in child-protection settings; African-American populations in justice systems; disabled people in NDIS scheme; marginalized and precarious populations systematically affected by ADM; intersectional contexts emphasized

### Evidenz 6

Algorithmic fairness concerns: systems designed to 'reduce bias in decision-making' have instead 'accentuated or introduce new biases'; discussion of equitable resource allocation, non-discrimination rights, and 'moral crumple zones'

## Assessment-Relevanz

**Domain Fit:** Sehr hohes Fit: Das Paper adressiert direkt die Schnittstelle von KI-Literacies und Sozialer Arbeit und thematisiert sowohl technische als auch kritische Aspekte algorithmischer Systeme in wohlfahrtsstaatlichen Kontexten, wo vulnerable Gruppen betroffen sind.

**Unique Contribution:** Der besondere Beitrag liegt in der Operationalisierung der 'competency/critique dilemma' für die Sozialarbeitspädagogik und der Entwicklung eines theoriegeleiten, praxisorientierten Curriculumrahmens, der fünf reflexive Leitfragen vorschlägt (Grounding assumptions, Contextualizing complexities, Intended/Unintended consequences, Application tensions).

**Limitations:** Rein konzeptionell ohne empirische Evaluation der vorgeschlagenen Curricula; keine quantitativen Daten zu Effektivität von ADM-Systemen; Gender-Perspektive ist unterrepräsentiert troitz Intersektionalitätsfokus; keine Detailanalyse der technischen Funktionsweise von Algorithmen

**Target Group:** Primär: Sozialarbeitsdozenten, Curriculum-Entwickler, Pädagogen im Hochschulbereich; Sekundär: Praktikierende Sozialarbeiter, Policy-Maker in Wohlfahrtsagenturen, kritische Tech-Forscher, Organisationen der Behindertenbewegung und Bürgerrechte

## Schlüsselreferenzen

- [[Eubanks_2018]] - Automating inequality: How high-tech tools profile, police, and punish the poor
- [[Keddell_2019]] - Algorithmic justice in child protection: Statistical fairness, social justice and the implications for practice
- [[Gillingham_2019]] - Decision support systems, social justice and algorithmic accountability in social work
- [[Pasquale_2017]] - Toward a fourth law of robotics: Preserving attribution, responsibility, and explainability in an algorithmic society
- [[Bennett_Moses_2019]] - Helping future citizens navigate an automated, datafied world
- [[Angwin_et_al_2016]] - Machine bias: There's software used across the country to predict future criminals. And it's biased against blacks
- [[La_Mendola_2010]] - Social work and social presence in an online world
- [[CuccaroAlamin_et_al_2017]] - Risk assessment and decision making in child protective services: Predictive risk modeling in context
- [[Lipsky_2010]] - Street-level bureaucracy: Dilemmas of the individual in public services
