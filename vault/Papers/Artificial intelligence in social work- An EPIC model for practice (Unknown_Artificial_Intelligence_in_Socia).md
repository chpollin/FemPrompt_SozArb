---
title: "Artificial intelligence in social work: An EPIC model for practice"
authors:
  - L. Goldkind
  - Y. Hamama-Raz
  - Z. Levitats
  - L. Levin
  - M. Ben-Ezra
year: 2024
type: journalArticle
doi: 10.1080/0312407X.2025.2488345
url: "https://doi.org/10.1080/0312407X.2025.2488345"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Fairness
human_decision: Exclude
human_categories: []
agreement: disagree
---

# Artificial intelligence in social work: An EPIC model for practice

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.92)
**Human:** Exclude

**Kategorie-Vergleich (bei Divergenz):**

| Kategorie | Human | LLM | Divergent |
|-----------|-------|-----|----------|
| AI_Literacies | Nein | Ja | X |
| Generative_KI | Nein | Nein |  |
| Prompting | Nein | Nein |  |
| KI_Sonstige | Nein | Ja | X |
| Soziale_Arbeit | Nein | Ja | X |
| Bias_Ungleichheit | Nein | Ja | X |
| Gender | Nein | Nein |  |
| Diversitaet | Nein | Nein |  |
| Feministisch | Nein | Nein |  |
| Fairness | Nein | Ja | X |

> Siehe [[Divergenz Unknown_Artificial_Intelligence_in_Social_Work_An_EPIC]] fuer detaillierte Analyse


## Key Concepts

- [[Algorithmic Bias in Social Work]]
- [[Algorithmic Fairness in Social Services]]
- [[EPIC Model for AI Integration]]
- [[Intersectional AI Governance]]

## Wissensdokument

# Artificial Intelligence in Social Work: An EPIC Model for Practice

## Kernbefund

Ein vierpeiliges EPIC-Modell (Ethics and Justice, Policy Development and Advocacy, Intersectoral Collaboration, Community Engagement and Empowerment) wird als strukturierter Ansatz zur ethischen Integration von KI in der Sozialen Arbeit präsentiert, um Chancen zu nutzen und Risiken wie algorithmische Verzerrungen und Desinformation zu mitigieren.

## Forschungsfrage

Wie kann künstliche Intelligenz in der Sozialen Arbeit ethisch und gerecht integriert werden, um die beruflichen Werte und die Unterstützung marginalisierter Gruppen zu wahren?

## Methodik

Theoretisch: Umfassende Literaturrevision zur Schnittstelle KI und Soziale Arbeit; Entwicklung eines konzeptuellen Rahmens (EPIC-Modell)
**Datenbasis:** Sekundäranalyse: Literaturrevision (keine primären Daten)

## Hauptargumente

- KI-Systeme reproduzieren historische Diskriminierungen und koloniale Wissensbestände durch ihre Abhängigkeit von großen historischen Datensätzen, was besonders für First Nations Peoples und marginalisierte Gruppen problematisch ist.
- Eine duale Mensch-Technologie-Ansatz ist erforderlich, bei dem KI als Entscheidungsunterstützung fungiert, nicht als Ersatz für professionelle Urteilskraft und empathische Beziehungen zwischen Fachkräften und Nutzer:innen.
- Intersektorale Zusammenarbeit zwischen Sozialarbeiter:innen, Informatiker:innen, Regierungen und Privatsektor sowie Gemeinschaftsbeteiligung sind zentral, um KI-Systeme gerecht und transparent zu gestalten und marginalisierte Perspektiven einzubeziehen.

## Kategorie-Evidenz

### Evidenz 1

Inclusion of AI content in professional social work policy documents and practice standards; development of education opportunities for increasing community AI knowledge and skills; staff training in organisations implementing AI.

### Evidenz 2

ChatGPT is discussed as problematic case study that has yielded inaccurate output data and breached privacy principles in child protection settings; generative AI's capacity to autonomously augment, synthesise, and innovate new data; concerns about 'black box' problem especially with generative AI.

### Evidenz 3

AI applications in predictive risk modelling for suicide, domestic violence, and child protection; AI-powered chatbots in mental health settings; machine learning algorithms and deep neural networks; decision support systems in social work.

### Evidenz 4

The article directly examines AI's influence on social work profession, including risks to professional ethics, mission and values; dual human-technology approach supporting social work methods; service user-practitioner relationship; social workers' roles and responsibilities being reshaped by AI.

### Evidenz 5

Algorithmic bias in AI systems due to reliance on historical datasets that are not representative of marginalised groups; gender classification systems producing error rates up to 34.7% for darker-skinned females; digital divide and 'information poverty' for marginalised groups; discrimination and exclusion risks; colonial knowledges reinforced in algorithms.

### Evidenz 6

Emphasis on inclusion of First Nations' perspectives and data sovereignty; ethnic data governance; representation of marginalised groups and underrepresented communities in AI design and development; intersectional perspectives; diverse reference groups in organisations.

### Evidenz 7

Addressing racial justice and health equity in AI development; non-discriminatory outcomes; algorithmic fairness concerns; legal protection for marginalised groups; transparent and regulated use of AI systems; equitable access to AI.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochgradig relevant für die Schnittstelle KI und Soziale Arbeit. Es adressiert kritische ethische, justice-orientierte und praktische Fragen, die für Sozialarbeiter:innen zentral sind, und verbindet technische KI-Fragen mit sozialpolitischen Werten der Profession.

**Unique Contribution:** Die Entwicklung des EPIC-Modells bietet einen strukturierten, professionsspezifischen Rahmen zur ethischen KI-Integration in der Sozialen Arbeit, der explizit Dekolonisierung, Gemeinschaftsbeteiligung und intersektorale Zusammenarbeit priorisiert.

**Limitations:** Das Paper ist theoretisch orientiert und präsentiert kein empirisches Validierungsdesign für das EPIC-Modell; es wird anerkannt, dass marginalisierte Gruppen möglicherweise nicht über ausreichende Ressourcen für aktive AI-Partizipation verfügen, aber wenig konkrete Lösungsansätze dafür geboten.

**Target Group:** Primär: Sozialarbeiter:innen, Sozialarbeits-Praktiker:innen und -Fachkräfte, Sozialarbeits-Ausbildende und -Verbände. Sekundär: KI-Entwickler:innen und Informatiker:innen, die mit Sozialsektor arbeiten; Policymaker:innen und Regierungsverantwortliche; Organisationen im Bereich Health und Social Services; Gemeinschaftsorganisationen und First Nations-Organisationen.

## Schlüsselreferenzen

- [[Buolamwini_Gebru_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Gough_Spencer_2019]] - Ethical social work practice in the technological era
- [[DankwaMullan_et_al_2021]] - Framework on integrating health equity and racial justice into the AI development lifecycle
- [[Reamer_2023]] - Artificial intelligence in social work: Emerging ethical issues
- [[Rice_Tambe_2018]] - Merging social work science and computer science for social good
- [[Meilvang_Dahler_2024]] - Decision support and algorithmic support: The construction of algorithms and professional discretion in social work
- [[Khawaja_BélislePipon_2023]] - Your robot therapist is not your therapist: Understanding the role of AI-powered mental health chatbots
- [[Cave_Dihal_2020]] - The whiteness of AI
- [[World_Economic_Forum_2024]] - The Global Risks Report
- [[Jacobi_Christensen_2023]] - Functions, utilities and limitations: A scoping study of decision support algorithms in social work
