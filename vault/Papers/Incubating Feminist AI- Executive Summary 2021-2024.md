---
title: Incubating Feminist AI: Executive Summary 2021-2024
authors:
  - Unknown Author
year: 2024
type: report
url: https://aplusalliance.org/incubatingfeministai2024/
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Stereotypen
  - Discrimination
mitigation_strategies:
  - Feminist AI
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
human_decision: Exclude
human_categories:
  - Generative_KI
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
agreement: disagree
---

# Incubating Feminist AI: Executive Summary 2021-2024

## Abstract

Documents outcomes from $2 million CAD Feminist AI Research Network project across Latin America, Middle East, and Asia. Developed 12 feminist AI prototypes addressing gender-based violence, transit safety, bias detection in NLP systems, and judicial transparency, demonstrating practical applications of feminist AI principles through community-centered design and intersectional analysis capabilities.

## Assessment

**LLM Decision:** Include (Confidence: 0.92)
**LLM Categories:** KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Human Decision:** Exclude
**Human Categories:** Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Agreement:** Disagree

## Key Concepts

### Bias Types
- [[Discrimination]]
- [[Stereotypen]]

### Mitigation Strategies
- [[Feminist AI]]

## Full Text

---
title: "Incubating Feminist AI: Executive Summary 2021-2024"
authors: ["A+ Alliance", "f<a+i>r Feminist AI Research Network"]
year: 2024
type: report
language: en
processed: 2026-02-04
source_file: A+ Alliance_2024_Incubating_Feminist_AI_Executive_Summary_2021-2024.md
confidence: 93
---

# Incubating Feminist AI: Executive Summary 2021-2024

## Kernbefund

Das f<a+i>r Netzwerk hat über 2021-2024 nachgewiesen, dass eine kombinierte Strategie aus Forschung, Prototyping und Pilotierung mit echter Community-Beteiligung zu transformativen KI-Anwendungen führt, die Geschlechtergerechtigkeit, Sicherheit und Zugang zu Justiz für marginalisierte Gruppen verbessern.

## Forschungsfrage

Wie können feministische KI-Ansätze und automatisierte Entscheidungssysteme konkret und positiv auf soziale/Geschlechtergerechtigkeit wirken, die Lebensqualität verbessern und historische Ausschlüsse korrigieren?

## Methodik

Mixed-Methoden: Multidisziplinäre Teams, Design Justice Prinzipien, Community Engagement, Paper-Prototype-Pilot Methodik, partizipative Technologiegestaltung, regionale Hubs in Lateinamerika, Südostasien und MENA
**Datenbasis:** 9 Stand-Alone Papers, 4 Paper-zu-Prototype Projekte, 5 vollständige Paper-Prototype-Pilot Projekte aus 10 Ländern (Argentinien, Brasilien, Chile, Ekuador, Ägypten, Indien, Indonesien, Mexiko, Philippinen, Thailand)

## Hauptargumente

- Feministische KI muss von Grund auf mit Inklusion als Kernprinzip gestaltet werden und sollte nicht nur Gewalt bekämpfen, sondern neue Chancen für marginalisierte Communities schaffen, insbesondere Frauen und Mädchen als gleichberechtigte Partner in Entscheidungsfindung und Werkzeugentwicklung.
- Echte Community-Beteiligung ist unverzichtbar für die Entwicklung wirksamer KI-Systeme; multidisziplinäre Teams von Technolog:innen, Sozialwissenschaftler:innen und Community-Vertreter:innen können transformative Lösungen co-kreieren, die tatsächliche Bedürfnisse marginalisierter Gruppen erfüllen.
- Regionale Hubs in der Globalen Süd sind entscheidend für die Vertiefung von feministischem KI-Denken und -Praxis und für die Schaffung vernetzter Lösungen, die lokale Kontexte und unterschiedliche epistemologische Traditionen berücksichtigen.

## Kategorie-Evidenz

### Evidenz 1

Workshops für neue Grantees zu intersektionalen, feministischen Themen; Training von KI-Entwickler:innen in feministischen Prinzipien; AI & Equality Human Rights Toolbox, Course & Community als Bildungsangebot.

### Evidenz 2

SOF+IA: GenAI chatbot zur Dialogue und Bewältigung von Gewalt und digitaler Belästigung gegen Frauen auf Social-Media-Plattformen.

### Evidenz 3

Natural Language Processing für Bias-Erkennung (E.D.I.A.); Annotierte Korpora (Work Related Diseases); automatisierte Datenextraktion (AymurAI); AI-gesteuerte Mobilitäts-Apps (SafeHER); Machine Learning für Tutoring-Systeme.

### Evidenz 4

Projekte zu Gewaltprävention (SafeHER Transit Safety, SOF+IA gegen digitale Gewalt), Kinderehen-Prävention (Indonesien), Menschenhandel (ASEAN), Integration mit sozialen Diensten und Justizinstitutionen, Unterstützung für Gewaltüberlebende durch technische Lösungen.

### Evidenz 5

E.D.I.A. zur Identifikation von Bias und Stereotypen in NLP; Analyse von Geschlechterperspektiven in öffentlicher Beschaffung; Auseinandersetzung mit algorithmischem Bias durch intersektionale Analyse; Fokus auf historische Ausschlüsse marginalisierter Gruppen.

### Evidenz 6

Gesamtnetzwerk fokussiert auf Geschlechtergerechtigkeit; spezifische Projekte zu Frauensicherheit im Transit, geschlechtsspezifischer Gewalt, geschlechtsspezifischen Stereotypen in Sprachtechnologie, Arbeitskrankheiten und Geschlechtsdifferenzen.

### Evidenz 7

Explizite Fokussierung auf Frauen, Mädchen und marginalisierte Gemeinschaften; intersektionale Analysen (E.D.I.A. berücksichtigt mehrere binäre Dimensionen); regionale Hubs in Global South; Community-zentrierte Methoden; Einbeziehung der am stärksten Benachteiligten.

### Evidenz 8

Netzwerk ist explizit als 'Feminist AI Research Network' strukturiert; verwendet feministische Prinzipien (Gender Justice, JEDI - Justice, Equity, Diversity, Inclusion); Design Justice Prinzipien; Referenzen zu Gender-transformativen Ansätzen; feministische Epistemologien und intersektionale feministische Theorien als Grundlage.

### Evidenz 9

Ziel ist es, Gleichheitsergebnisse (equality outcomes) zu liefern; Fokus auf Fairness in automatisierten Entscheidungssystemen (ADM); Transparenz in der Justiz (AymurAI); Equity-zentierte Designs; Korrekturen für historische Ungleichheiten und Ausschlüsse.

## Assessment-Relevanz

**Domain Fit:** Außergewöhnlich relevant für die Schnittstelle von KI, Sozialer Arbeit und Gender Studies. Das Paper dokumentiert konkrete, implementierte Projekte, die KI-Systeme zu sozialer und Geschlechtergerechtigkeit einsetzen und verbindet technische Innovation mit sozialarbeiterischen Praxisfeldern und feministischen Ansätzen.

**Unique Contribution:** Der einzigartige Beitrag liegt in der systematischen, multi-regionalen Dokumentation des Paper-Prototype-Pilot-Ansatzes zur Entwicklung von feministischer KI mit echter Community-Partizipation, die nachweist, dass regionale, dezentralisierte Ansätze in der Globalen Süd transformative Lösungen für strukturelle Ungleichheiten schaffen können.

**Limitations:** Das Dokument ist ein Executive Summary, das eher einen Überblick über Prozesse und Outcomes bietet als detaillierte methodische Validierung oder kritische Analyse von Fehlern und Grenzen der Projekte; quantitative Evaluationsergebnisse und vergleichbare Metriken zur Wirksamkeit fehlen.

**Target Group:** Multidisziplinär adressiert: KI-Entwickler:innen und Informatiker:innen (zur Schulung in feministischen Prinzipien), Sozialarbeiter:innen und Sozialwissenschaftler:innen (zur Integration von KI in Praxis), Feminist:innen und Gender-Forscher:innen (zur Anwendung feministischer Theorie in Tech), Policymaker:innen und Justizinstitutionen (zur Implementierung von Systemen), Aktivist:innen und civil society Organisationen (zur Community-Partizipation), Geldgeber:innen und Philanthropien (zur Finanzierung transformativer Ansätze)

## Schlüsselreferenzen

- [[Biana_HT_Jabar_M_Yabut_H_and_Domingo_R_2023]] - Modified feminist self-defense: violence against women in transit in Metro Manila
- [[Alemany_LA_Benotti_L_Maina_H_Gonzalez_L_Martinez_L_Busaniche_B_Halvorsen_A_Rojo_A_and_Rajngewerc_M_2023]] - Bias assessment for experts in discrimination, not in computer science
- [[Soudi_M_Ali_E_Bali_M_and_Mabrouk_N_2023]] - Generative AI-Based Tutoring System for Upper Egypt Community Schools
- [[UNESCO_2024]] - Global toolkit on AI and the rule of law for the judiciary
- [[A_Alliance_2019]] - Declaration for Affirmative Action for Algorithms
- [[Women_at_the_Table_Ciudadania_Inteligente_2019]] - Co-founding of A+ Alliance
