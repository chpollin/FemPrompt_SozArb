---
title: Messung von AI Literacy – Empirische Evidenz und Implikationen
authors:
  - Patrick Weber
  - Lorenz Baum
  - Marc Pinski
year: 2023
type: journalArticle
doi: 
url: "https://aisel.aisnet.org/wi2023/3"
tags:
  - paper
llm_decision: Exclude
llm_confidence: 0.65
llm_categories:
  - AI_Literacies
human_decision: Exclude
human_categories:
  - AI_Literacies
  - KI_Sonstige
agreement: agree
---

# Messung von AI Literacy – Empirische Evidenz und Implikationen

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 88 |
| Category Validation | 78 |
| **Overall Confidence** | **86** |

### Stufe 4: Assessment

**LLM:** Exclude (Confidence: 0.65)
**Human:** Exclude

## Key Concepts

- [[AI Literacy]]
- [[Digital Divide]]
- [[Measurement Instrument Development]]

## Wissensdokument

# Messung von AI Literacy - Empirische Evidenz und Implikationen

## Kernbefund

Es besteht keine eindeutige Korrelation zwischen subjektiver und objektiver AI Literacy, was die Notwendigkeit objektiver Messinstrumente unterstreicht. Das entwickelte 25-Item-Messinstrument diskriminiert erfolgreich zwischen verschiedenen Populationen mit unterschiedlicher AI Literacy.

## Forschungsfrage

Wie kann objektive AI Literacy gemessen werden und welche Unterschiede bestehen zwischen subjektiver und objektiver Messung?

## Methodik

Empirisch/Mixed Methods: Literaturrecherche, Experteninterviews (n=10), Card-Sorting (n=12 Forschende), drei Studien mit insgesamt n=134 Teilnehmenden (Online-Survey, Zentralbank-Manager, Universitätskurs), etablierter Skalenentwicklungsprozess nach MacKenzie et al. (2011)
**Datenbasis:** n=134 Teilnehmende in drei Studien: Onlinestichprobe (n=88, zwei Gruppen: mit/ohne IT-Hintergrund), Zentralbank (n=17 Manager), Universitätskurs (n=29 nicht-technische Studierende); geplante Fortsetzung mit n~450

## Hauptargumente

- Während KI alle Bereiche der modernen Lebens- und Arbeitswelt durchdringt, existierte bisher kein objektives Messinstrument für AI Literacy, sondern nur subjektive Selbsteinschätzungen, die systematische Fehler aufweisen.
- AI Literacy wird als Menge sozio-technischer Kompetenzen konzeptualisiert, die relevante Typen von Mensch-KI-Interaktion beeinflussen, kombiniert mit dem sozio-technischen Kontinuum und Blooms Taxonomie.
- Die fehlende Korrelation zwischen subjektiver und objektiver AI Literacy (Abbildung 1) zeigt, dass Menschen ihre Kompetenzen im KI-Umgang systematisch falsch einschätzen, was ein bekanntes Phänomen aus der Literacy-Forschung ist.

## Kategorie-Evidenz

### Evidenz 1

Kernfokus des Papers: 'AI literacy is a set of socio-technical competencies of humans that shape relevant types of human-AI interaction'. Entwicklung eines objektiven 25-Item-Messinstruments mit vier Dimensionen (Socio User, Socio Creator/Evaluator, Technical User, Technical Creator/Evaluator).

### Evidenz 2

Fokus auf Mensch-KI-Interaktion, KI-Systeme in Bildung und Arbeitsmarkt, algorithmische Entscheidungsfindung: 'ihre Nutzenden und Erschaffenden sowie diejenigen, die mit Hilfe von KI Entscheidungen treffen, werden in der Lage sein müssen, KI effizient zur Problemlösung einsetzen zu können'.

### Evidenz 3

Analyse von unterschiedlichen AI Literacy Levels zwischen Gruppen mit/ohne IT-Hintergrund (31,3% vs. 27,5%), unterschiedliche Literacy zwischen technischen und nicht-technischen Studierenden (Socio 63% vs. Technical 51%), Digital Divide implizit thematisiert.

### Evidenz 4

Geschlechterverteilung in den Stichproben erfasst (46-52% weiblich, 41-52% männlich, bis zu 7% andere Geschlechter), aber keine explizite geschlechterspezifische Analyse oder Diskussion von Gender-Unterschieden in AI Literacy durchgeführt.

### Evidenz 5

Erfassung diverser Populationen: verschiedene Bildungshintergründe, mit/ohne IT-Hintergrund, verschiedene Beschäftigungsstatus (Studierende, berufstätig, arbeitslos), unterschiedliche Altersgruppen (24-25 Jahre Durchschnitt), Manager vs. Studierende.

## Assessment-Relevanz

**Domain Fit:** Das Paper hat begrenzte direkte Relevanz für Soziale Arbeit, ist aber relevant für die Frage, wie KI-Kompetenzen in verschiedenen Bevölkerungsgruppen gemessen und entwickelt werden können. Die Fokussierung auf diverse Populationen (mit/ohne IT-Hintergrund, verschiedene Bildungshintergründe) berührt indirekt Fragen von digitaler Ungleichheit, die für Soziale Arbeit relevant sind.

**Unique Contribution:** Erste empirisch validierte objektive Messskala für AI Literacy, die zwischen subjektiver Selbsteinschätzung und tatsächlichen Kompetenzen unterscheidet und ein konzeptuelles 2x2-Modell (sozio-technisch × Nutzer-Gestalter) anwendet.

**Limitations:** Kleine Stichproben in zwei von drei Studien (n=17, n=29), begrenzte demographische Erfassung (Zentralbank-Studie: keine Demografien), bisherige Studien noch nicht abgeschlossen (Research in Progress), keine explizite Analyse von Gender- oder intersektionalen Unterschieden trotz Erfassung dieser Daten, begrenzte Validierung gegen externe Kriterien.

**Target Group:** KI-Forschende und -Entwickler, Bildungsinstitutionen (Curriculum-Designer, Lehrende), HR und Organisationsentwicklung, Policymaker im Bereich digitale Kompetenzen und Arbeitsfähigkeit, mittelbar relevant für Sozialarbeiter und Beratungseinrichtungen, die mit digitalen Transformationen und Ungleichheiten konfrontiert sind

## Schlüsselreferenzen

- [[MacKenzie_et_al_2011]] - Construct measurement and validation procedures in MIS and behavioral research
- [[Pinski_Benlian_2023]] - AI Literacy—Towards Measuring Human Competency in Artificial Intelligence
- [[Ng_et_al_2021]] - Conceptualizing AI literacy: An exploratory review
- [[Long_Magerko_2020]] - What is AI literacy? Competencies and design considerations
- [[Dunning_2011]] - The Dunning-Kruger effect: On being ignorant of one's own ignorance
- [[Sarker_et_al_2019]] - The Sociotechnical Axis of Cohesion for the IS Discipline
- [[Krathwohl_2002]] - A Revision of Bloom's Taxonomy: An Overview
- [[Laupichler_et_al_2022]] - Artificial intelligence literacy in higher and adult education: A scoping literature review
