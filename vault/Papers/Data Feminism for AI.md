---
title: Data feminism for AI
authors:
  - L. Klein
  - C. D'Ignazio
year: 2024
type: conferencePaper
doi: 10.1145/3630106.3658543
url: "https://doi.org/10.1145/3630106.3658543"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.95
llm_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
human_decision: Exclude
human_categories:
  - AI_Literacies
  - Generative_KI
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
agreement: disagree
---

# Data feminism for AI

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.95)
**Human:** Exclude

**Kategorie-Vergleich (bei Divergenz):**

| Kategorie | Human | LLM | Divergent |
|-----------|-------|-----|----------|
| AI_Literacies | Ja | Nein | X |
| Generative_KI | Ja | Nein | X |
| Prompting | Nein | Nein |  |
| KI_Sonstige | Ja | Ja |  |
| Soziale_Arbeit | Nein | Nein |  |
| Bias_Ungleichheit | Ja | Ja |  |
| Gender | Ja | Ja |  |
| Diversitaet | Ja | Ja |  |
| Feministisch | Ja | Ja |  |
| Fairness | Ja | Ja |  |

> Siehe [[Divergenz D'Ignazio_2024_Data_Feminism_for_AI]] fuer detaillierte Analyse


## Key Concepts

- [[Algorithmic Fairness]]
- [[Data Feminism]]
- [[Gender Bias in NLP]]
- [[Intersectional Feminism]]

## Wissensdokument

# Data Feminism for AI

## Kernbefund

Feministische Prinzipien - insbesondere die Fokussierung auf Machtverhältnisse, Pluralismus, Sichtbarmachung von Arbeit und Kontext - sind essentiell zur Entwicklung gerechter, ethischer und nachhaltiger KI-Systeme. Die Autor:innen schlagen zudem zwei neue Prinzipien vor: Berücksichtigung von Umweltauswirkungen und intersektionales Verständnis von Konsens.

## Forschungsfrage

Wie können intersektional-feministische Prinzipien dazu beitragen, ungleiche Machtverhältnisse in der KI-Forschung, -Entwicklung und -Bereitstellung zu identifizieren und zu verändern?

## Methodik

Theoretisch/Literature Review: Reartikulierung und Erweiterung der sieben Data-Feminism-Prinzipien auf AI sowie Entwicklung zweier neuer Prinzipien zu Umweltauswirkungen und Consent; basierend auf intersektionaler feministischer Theorie und bestehender Literatur zu Feminismus, AI und Data Justice.
**Datenbasis:** Keine empirische Datenerhebung; Literaturanalyse und theoretische Reflexion auf Basis von akademischen und aktivistischen Arbeiten zu Feminismus, KI-Ethik, Data Justice und strukturellen Machtasymmetrien.

## Hauptargumente

- Intersektionaler Feminismus bietet analytische Werkzeuge zur Offenlegung von Machtverhältnissen in KI-Systemen: Die Fokussierung auf Intersektionalität (Crenshaw) und 'interlocking systems of oppression' (Combahee River Collective) ermöglicht es, komplexe Ungleichheiten zu verstehen, die über Gender hinausgehen und Race, Klasse, Kolonialismus einschließen.
- Die sieben Data-Feminism-Prinzipien sind auf AI übertragbar und adressieren zentrale ethische Probleme: 'Examine Power' offenbart, wie Großkonzerne und Regierungen Daten zur Machtausübung nutzen; 'Challenge Power', 'Consider Context' und 'Make Labor Visible' zeigen auf, wie Trainings-Daten, Design-Prozesse und globale Arbeitsteilung strukturelle Ausbeutung reproduzieren.
- Umweltgerechtigkeit und Konsens sind notwendige neue Prinzipien für eine feministische KI: Ökofeministische und Indigenous-feministische Perspektiven verbinden Umweltzerstörung mit globaler Ungleichheit (Nord/Süd-Divide, Wasserbedarf von Data Centers); erweitertes Verständnis von Konsens (jenseits binär, individualistischer Modelle) adressiert Nicht-Konsent in Datenbeschaffung und Deepfakes.

## Kategorie-Evidenz

### Evidenz 1

Explizite Analysen von LLMs und deren Trainings-Praktiken: 'the work of data science replicated professional hierarchies, with credentialed data scientists at the top' und Beispiel von ChatGPT mit Arbeitern in Kenia, die 'screening potentially offensive responses in real-time' durchführten.

### Evidenz 2

Breite KI-Fokussierung auf Computer Vision (Buolamwini & Gebru), NLP, Algorithmen, algorithmische Entscheidungssysteme, ML-Trainings-Praktiken.

### Evidenz 3

Zentrales Thema durchgehend: 'unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment'; Analyse von Datenbias, Geschlechterbias in Sprachmodellen, reproduktion von sexistischen, rassistischen und kolonialen Vorurteilen in Text-to-Image-Modellen.

### Evidenz 4

Explizite Behandlung von Geschlechterperspektiven: Deepfakes von Frauen, Nicht-Konsent bei Audio/visueller Generierung, Geschlechterbias in NLP und Autocomplete-Systemen, Frauenrepräsentation in Tech/AI-Feldern.

### Evidenz 5

Intersektionale Perspektive auf marginalisierte Communities: Indigenous feminists, Black feminists, Latin American feminists, Global South vs. North Asymmetrien, Analysen von Repräsentation und Exklusion in AI-Forschung und -Entwicklung.

### Evidenz 6

Explizit feministische Theorie durchgehend: Intersektionaliät (Crenshaw, Combahee River Collective, Patricia Hill Collins 'matrix of domination'), feministische Epistemologie, Black Feminism, Ökofeminismus, Indigenous Feminism, reproductive justice, trans justice.

### Evidenz 7

Direkte Behandlung algorithmischer Fairness: 'fairness research', Fairness-Aspekte in ML-Entwicklung, Kritik an unzureichender Operationalisierung von Intersektionalität in AI-Fairness-Forschung.

## Assessment-Relevanz

**Domain Fit:** Hohes Potenzial für die Schnittstelle AI/Soziale Arbeit/Gender Studies: Das Paper bietet einen umfassenden feministischen Rahmen zur Kritik struktureller Ungleichheiten in KI-Systemen und adressiert besonders auch Fragen von Datenjustice, Arbeitsbedingungen und Körperautonomie, die für Soziale Arbeit und intersektionale Praxis zentral sind.

**Unique Contribution:** Die Reartikulierung der sieben Data-Feminism-Prinzipien speziell für AI sowie die Vorschläge für zwei neue Prinzipien (Umweltgerechtigkeit, erweitertes Konsens-Verständnis) bieten einen kohärenten, intersektional-feministischen Kritikrahmen, der über Gender-Bias hinausgeht und strukturelle, koloniale und kapitalistische Machtdynamiken explizit adressiert.

**Limitations:** Das Paper ist primär literaturbasiert und theoretisch; es fehlen empirische Validierungen oder Fallstudien zur praktischen Implementierung der Prinzipien in konkreten AI-Entwicklungs- oder Einsatzszenarien. Die Autor:innen sind weiße, überwiegend heterosexuelle, nicht-behinderte Frauen, was die eigenen positionalen Grenzen widerspiegelt.

**Target Group:** AI-Forschende und -Entwickler:innen (besonders in FAccT-Community), Policymaker:innen und Regulatoren, Sozialarbeiter:innen und Care-Professionals, Feminist Scholar:innen und Gender Studies Akademiker:innen, Aktivist:innen im Bereich Data Justice und Digital Rights, Lehrende in Computer Science und Digital Humanities, Civil-Society-Organisationen zur Algorithmic Justice.

## Schlüsselreferenzen

- [[DIgnazio_Catherine_Klein_Lauren_2020]] - Data Feminism
- [[Crenshaw_Kimberlé_1989]] - Intersectionality
- [[Combahee_River_Collective_1977]] - A Black Feminist Statement
- [[Buolamwini_Joy_Gebru_Timnit_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Collins_Patricia_Hill_2000]] - Black Feminist Thought: Knowledge, Consciousness, and the Politics of Empowerment
- [[Hampton_Leila_Marie_2021]] - Black Feminism and Algorithmic Oppression
- [[Birhane_Abeba_et_al_2022]] - Meta-analysis of AI Ethics Research at FAccT
- [[Jo_Eun_Seo_Gebru_Timnit_2020]] - Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning
- [[Mitchell_Margaret_et_al_2019]] - Model Cards for Model Reporting
- [[Zuboff_Shoshana_2019]] - The Age of Surveillance Capitalism
