---
title: "Indecision on the use of artificial intelligence in healthcare: A qualitative study of patient perspectives on trust, responsibility and self-determination using AI-CDSS"
authors:
  - D. Schneider
  - W. Liedtke
  - A. D. Klausen
  - M. Lipprandt
  - F. Funer
  - M. Langanke
  - N. B. Heyen
  - H. Aichinger
  - T. Bratan
year: 2025
type: journalArticle
doi: 10.1186/s12910-024-01143-5
url: 
tags:
  - paper
llm_decision: Exclude
llm_confidence: 0.85
llm_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
  - Fairness
human_decision: Exclude
human_categories:
  - KI_Sonstige
  - Soziale_Arbeit
agreement: agree
---

# Indecision on the use of artificial intelligence in healthcare: A qualitative study of patient perspectives on trust, responsibility and self-determination using AI-CDSS

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 88 |
| **Overall Confidence** | **92** |

### Stufe 4: Assessment

**LLM:** Exclude (Confidence: 0.85)
**Human:** Exclude

## Wissensdokument

# Indecision on the use of artificial intelligence in healthcare - A qualitative study of patient perspectives on trust, responsibility and self-determination using AI-CDSS

## Kernbefund

Patienten zeigen erhebliche Unsicherheit gegenüber AI-CDSS-Implementierung. Die Wahrnehmung oszilliert zwischen supportivem Werkzeug und Zweitmeinung, wobei enge Verflechtungen zwischen Vertrauen, Verantwortung und Selbstbestimmung bestehen, die durch unzureichendes Verständnis der KI-Funktionalität gefährdet sind.

## Forschungsfrage

Wie nehmen Patienten die Implementierung von KI-gestützten klinischen Entscheidungsunterstützungssystemen wahr, insbesondere bezüglich Vertrauen, Verantwortung und Selbstbestimmung?

## Methodik

Empirisch: Qualitativ. Drei Fokusgruppen mit insgesamt 18 Patienten (n=18, 5-7 pro Gruppe, April 2021-April 2022). Strukturierte qualitative Inhaltsanalyse nach Kuckartz und Rädiker (2022). Präsentation von AI-CDSS-Fallvignetten (Chirurgie, Nephrologie, Home-Care) als Stimuli.
**Datenbasis:** n=18 Patienten in 3 Fokusgruppen (Zeitraum April 2021-April 2022), Rekrutierung via Selbsthilfegruppen in Deutschland

## Hauptargumente

- Vertrauen und Verantwortung in der Arzt-Patient-Beziehung basieren auf gemeinsamen Voraussetzungen: technische Expertise der Fachleute, empirisches Wissen und die Fähigkeit, Standards mit individuellen Patientensituationen zu verbinden.
- Patienten befürchten einen Verlust von Selbstbestimmung durch AI-CDSS, insbesondere hinsichtlich informationeller Selbstbestimmung, des Rechts nicht-zu-wissen, und der Gefahr der Entmenschlichung und Objektivierung in der Pflege.
- Die Implementierung von AI-CDSS erfordert neue Formen von AI-Literalität bei Fachkräften und verbesserte Kommunikation/Transparenz, um Patienten als aktive Partner in geteilten Entscheidungsfindungsprozessen einzubeziehen.

## Kategorie-Evidenz

### Evidenz 1

Patienten und Fachleute müssen 'AI literacy in ongoing work processes' entwickeln. 'It is therefore of importance to provide patients and healthcare professionals with information to prevent indecision.' Die Studie zeigt, dass 'the patients' perspective is profoundly influenced by the individuals' comprehension of the functionality of AI-CDSS.'

### Evidenz 2

Fokus auf AI-CDSS (Clinical Decision Support Systems) mit Machine Learning in Radiologie, Chirurgie, Nephrologie und Home-Ventilation. Explizit: 'AI-based clinical decision support systems (AI-CDSS) aim to assist healthcare professionals and patients in making decisions.'

### Evidenz 3

Studie analysiert Patientenperspektiven in Gesundheitsversorgung, Care-Kontexten (Home-Ventilation), und die professionelle Beziehung zwischen Patientinnen und Fachkräften. Fokus auf Selbstbestimmung und Partizipation vulnerable Gruppen (chronisch erkrankte, home-ventilierte Patienten). Ein Autor arbeitet am 'Department of Social Work' der Protestant University of Applied Sciences.

### Evidenz 4

Patienten befürchten Diskriminierungsmöglichkeiten durch Algorithmen: 'the reliability of technology and possible risks of discriminating algorithms.' Besorgnis um marginalisierte Gruppen und ungleiche Auswirkungen: 'possible loss of human interaction in the entire care process' führt zu unterschiedlichen Zugängen je nach Patientenlage.

### Evidenz 5

Studie rekrutiert verschiedene Patientengruppen über Selbsthilfegruppen in unterschiedlichen medizinischen Domänen (Nephrologie, Chirurgie, Home-Care), um unterschiedliche Perspektiven zu erfassen. Fokus auf Inklusion von Patientenperspektiven: 'Special consideration must be given to the AI-CDSS implementation from all users' perspectives.' Heterogene Fokusgruppen als 'homogeneous groups.'

### Evidenz 6

Studie thematisiert algorithmische Fairness durch Patientenperspektive: 'concerns like data security, responsibility, fairness and autonomy are being discussed, yet remain unsolved.' Forderung nach fairem Design: 'algorithms should thus be developed with a wider spectrum of stakeholders than just the doctor to ensure that the people affected by the system's analysis can also understand the system's results.' Verteilungsgerechtigkeit bei Ressourcen und Verantwortung.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit: Die Studie thematisiert ethische Implikationen von AI-Systemen aus Patientenperspektive, fokussiert auf Selbstbestimmung, Partizipation und professionelle Beziehungen - zentrale Anliegen Sozialer Arbeit. Die explorative Methode und der Fokus auf vulnerable Gruppen (chronisch Kranke, Home-Care-Patienten) sind für sozialarbeiterische Kontexte hochrelevant.

**Unique Contribution:** Die Studie füllt eine Forschungslücke, indem sie (anders als bisherige Akzeptanzstudien) tiefergehend die ethischen Implikationen von AI-CDSS aus Patientenperspektive untersucht, insbesondere die Verflechtung von Vertrauen, Verantwortung und Selbstbestimmung als dynamische relationale Konzepte im Kontext der Arzt-Patient-Beziehung.

**Limitations:** Kleine Stichprobe (n=18), Convenience-Sampling via Selbsthilfegruppen (Selection-Bias), Fokusgruppen nur online durchgeführt, theoretisches Konzeptverständnis von 'Responsibility', 'Trust', 'Self-Determination' nicht vorab definiert sondern exploratif erhoben, kultureller Kontext Deutschland (begrenzte Generalisierbarkeit), hypothetische Vignetten statt reale Erfahrungen.

**Target Group:** Sozialarbeiter und Care-Professionelle in Gesundheitsversorgung, KI-Entwickler und Medical Informatics-Fachleute, Policymaker im Gesundheitswesen, Ethiker und Bioethiker, Patientenvertreter und Selbsthilfegruppen, Forschende im Bereich Mensch-Maschine-Interaktion und digitaler Transformation in der Medizin

## Schlüsselreferenzen

- [[Rajpurkar_et_al_2022]] - AI In health and medicine
- [[Amann_et_al_2020]] - Explainability for artificial intelligence in healthcare: a multidisciplinary perspective
- [[Obermeyer_Topol_2021]] - Artificial intelligence, bias, and patients' perspectives
- [[Jeyakumar_et_al_2023]] - Preparing for an artificial intelligence-enabled future: patient perspectives on engagement
- [[VallèsPeris_et_al_2021]] - Robots in healthcare? What patients say
- [[Dlugatch_et_al_2023]] - Trustworthy artificial intelligence and ethical design: public perceptions
- [[Kerasidou_2020]] - Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare
- [[Sauerbrei_et_al_2023]] - The impact of artificial intelligence on the person-centred, doctor-patient relationship
- [[Topol_2019]] - High-performance medicine: the convergence of human and artificial intelligence
- [[Kuckartz_Rädiker_2022]] - Qualitative Inhaltsanalyse
