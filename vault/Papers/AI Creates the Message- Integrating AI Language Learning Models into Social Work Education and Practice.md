---
title: "AI Creates the Message: Integrating AI Language Learning Models into Social Work Education and Practice"
authors:
  - J. B. Singer
  - J. Creswell Báez
  - J. A. Rios
year: 2023
type: journalArticle
doi: 10.1080/10437797.2023.2189878
url: "https://doi.org/10.1080/10437797.2023.2189878"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.95
llm_categories:
  - AI_Literacies
  - Generative_KI
  - Soziale_Arbeit
  - Bias_Ungleichheit
human_decision: Exclude
human_categories:
  - Generative_KI
  - KI_Sonstige
  - Soziale_Arbeit
agreement: disagree
---

# AI Creates the Message: Integrating AI Language Learning Models into Social Work Education and Practice

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.95)
**Human:** Exclude

**Kategorie-Vergleich (bei Divergenz):**

| Kategorie | Human | LLM | Divergent |
|-----------|-------|-----|----------|
| AI_Literacies | Nein | Ja | X |
| Generative_KI | Ja | Ja |  |
| Prompting | Nein | Nein |  |
| KI_Sonstige | Ja | Nein | X |
| Soziale_Arbeit | Ja | Ja |  |
| Bias_Ungleichheit | Nein | Ja | X |
| Gender | Nein | Nein |  |
| Diversitaet | Nein | Nein |  |
| Feministisch | Nein | Nein |  |
| Fairness | Nein | Nein |  |

> Siehe [[Divergenz Singer_2023_AI_Creates_the_Message_Integrating_AI_Language]] fuer detaillierte Analyse


## Key Concepts

- [[AI Ethics Curriculum Integration]]
- [[Algorithmic Bias in Social Work]]
- [[Natural Language Processing (NLP)]]

## Wissensdokument

# AI Creates the Message: Integrating AI Language Learning Models into Social Work Education and Practice

## Kernbefund

Sozialarbeitende haben eine ethische Verantwortung, sich mit KI-Technologien auseinanderzusetzen und diese in Lehre und Praxis zu integrieren, während gleichzeitig Bias, Datenschutz und technologische Gerechtigkeit kritisch reflektiert werden müssen.

## Forschungsfrage

Wie können Sprachmodelle wie ChatGPT ethisch und gerecht in die Soziale Arbeit und ihre Ausbildung integriert werden?

## Methodik

Theoretisch/Editorial - Diskursive Analyse mit praktischen Anwendungsbeispielen und Best-Practice-Empfehlungen
**Datenbasis:** Keine empirischen Daten; basiert auf theoretischem Diskurs, bestehenden Initiativen an Universitäten und frühen Anwendungsbeispielen in der Praxis

## Hauptargumente

- Sozialarbeit muss sich aktiv mit KI-Technologien auseinandersetzen, um Studierende auf eine technologisch evolvierende Praxis vorzubereiten und die Profession aktiv in Tech-Design und -Regulierung einzubringen.
- ChatGPT und ähnliche Sprachmodelle bieten konkrete, praktische Werkzeuge für Lehrende (Syllabus-Entwicklung, Test-Erstellung, Manuskript-Bearbeitung) und Studierende (Lernunterstützung, Schreibfähigkeiten, Konzeptverständnis).
- Kritische Limitationen und Risiken (Bias, Halluzinationen, Datenschutz, mangelnde Empathie, Perpetuierung von Diskriminierung) müssen in Curricula und Syllabi transparent adressiert werden, um ethische Nutzung sicherzustellen.

## Kategorie-Evidenz

### Evidenz 1

Students need real-time experience and practice with the opportunities and challenges of AI. It is unethical for social workers not to learn and teach about technology-mediated social work.

### Evidenz 2

Focus on ChatGPT as a language model developed by OpenAI. ChatGPT is trained on a massive dataset of text to generate human-like responses to prompts.

### Evidenz 3

Examples throughout paper on prompt design: 'Write a 500-word editorial...', 'write an e-mail addressing the following topics...', 'Write a one paragraph story about a 13-year-old...'

### Evidenz 4

The field of AI encompasses machine learning, computer vision (facial recognition), and natural language processing (NLP).

### Evidenz 5

The editorial appears in the Journal of Social Work Education and addresses integration into social work education, practice with clients (case management, advocacy), and social work values throughout.

### Evidenz 6

ChatGPT could perpetuate bias and discrimination. ChatGPT is trained on a dataset that reflects the biases and limitations of the data on which it has been trained. Example: ChatGPT identified only White social workers when asked about founders of social work profession.

### Evidenz 7

We believe social workers have an ethical responsibility to provide education, support, and access to those who have historically been excluded from technological advances to bridge the gap in technological justice.

### Evidenz 8

Social workers must play a pivotal role in helping AI developers understand how these technologies can either exacerbate or alleviate existing social and structural inequities. Addresses technological justice and equitable access to AI capabilities.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle AI/Soziale Arbeit. Das Paper adressiert direkt die Integration generativer KI-Modelle in Sozialarbeit-Ausbildung und -Praxis mit kritischem Fokus auf Bias, Gerechtigkeit und ethische Verantwortung.

**Unique Contribution:** Erste umfassende, praktisch orientierte Editorial-Analyse, die konkrete Werkzeuge und Szenarien für ChatGPT-Integration in Sozialarbeit bietet, während gleichzeitig kritische Limitationen und technologische Gerechtigkeitsfragen foregrounded werden.

**Limitations:** Rein theoretisch-diskursiv ohne empirische Evaluation; begrenzte Behandlung intersektionaler Perspektiven und Gender-spezifischer Auswirkungen; keine tiefere kritische Analyse struktureller Macht in KI-Entwicklung.

**Target Group:** Sozialarbeiterlehrende und -ausbildende, Sozialarbeitende in der Praxis, Professorinnen und Professoren der Sozialen Arbeit, Policymaker in der Sozialarbeit, Technologiedesignerinnen und -designer mit Fokus auf Soziale Arbeit

## Schlüsselreferenzen

- [[Asakura_K_Occhiuto_K_Todd_S_Leithead_C_Clapperton_R_2020]] - A call to action on artificial intelligence and social work education: Lessons learned from a simulation project using natural language processing
- [[Goldkind_L_2021]] - Social work and artificial intelligence: Into the matrix
- [[Patton_D_U_2020]] - Social work thinking for UX and AI design
- [[Hodgson_D_Goldingay_S_Boddy_J_Nipperess_S_Watts_L_2022]] - Problematising artificial intelligence in social work education: Challenges, issues and possibilities
- [[Tambe_M_Rice_E_2018]] - Artificial intelligence and social work
- [[Leopold_D_2007]] - Socialism and (the rejection of) utopia
- [[Rittel_H_W_J_Webber_M_M_1973]] - Dilemmas in a general theory of planning
- [[Singer_J_B_Sage_M_Berzin_S_C_Coulton_C_J_2022]] - Harnessing technology for social good
