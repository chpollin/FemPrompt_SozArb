---
title: Gengler_2024_Faires_KI-Prompting_–_Ein_Leitfaden_für
authors:
  - Unknown Author
year: 2024
type: research-paper
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Stereotype
mitigation_strategies:
  - Feminist AI
  - Prompt Engineering
---

# Gengler_2024_Faires_KI-Prompting_–_Ein_Leitfaden_für

## Key Concepts

### Bias Types
- [[Stereotype]]

### Mitigation Strategies
- [[Feminist AI]]
- [[Prompt Engineering]]

## Full Text

---
title: "Faires KI-Prompting – Ein Leitfaden für Unternehmen"
authors: ["Eva Gengler", "Andreas Kraus", "Kristina Bodrožić-Brnić"]
year: 2024
type: report
language: de
processed: 2026-02-05
source_file: Gengler_2024_Faires_KI-Prompting_–_Ein_Leitfaden_für.md
confidence: 95
---

# Faires KI-Prompting – Ein Leitfaden für Unternehmen

## Kernbefund

Ein strukturiertes KI-FAIRNESS-Framework (Kontext, Input, Fokus, Ausschnitt, Iterationen, Repertoire, Nachbessern, Eignung, Sprache, Sinn) ermöglicht es Nutzer:innen, faire und diverse Ergebnisse aus Generativer KI zu gestalten. Organisationales Mindset, klare KI-Strategie und Werteorientierung sind grundlegend für fairen KI-Einsatz.

## Forschungsfrage

Wie können kleine und mittlere Unternehmen Generative KI-Systeme durch bewusstes und faires Prompting verantwortungsvoll einsetzen und dabei Diskriminierung vermeiden?

## Methodik

Theoretisch/Praktisch: Leitfaden basierend auf Literaturrecherche und Expertise im Bereich feministische KI, mit praktischen Beispielen und Fallstudien zur Bildgenerierung und Textgenerierung
**Datenbasis:** nicht angegeben (qualitatives Expertenleitfaden-Format, keine quantitativen Daten)

## Hauptargumente

- Generative KI reproduziert strukturelle Ungerechtigkeiten aus Trainingsdaten (Bias, Stereotype, Gender-Data-Gap), wenn nicht bewusst dagegen gesteuert wird. Der Zweck der KI-Entwicklung und -Nutzung – ob zur Reproduktion oder Transformation bestehender Prozesse – ist entscheidend.
- Faires KI-Prompting ist ein erlernbarer Skill: Durch systematische Prompt-Gestaltung (Kontext, Sprache, Diversitätsanforderungen, Iterationen) können Nutzer:innen faire und diverse Ergebnisse erzielen und damit gesellschaftliche Ungleichheiten abbauen.
- Organisationale Verankerung ist essentiell: KI-Strategie auf Führungsebene, Werteorientierung, diversitätsaffine Governance, Mindset-Entwicklung auf allen Ebenen und kontinuierliche Reflexion eigener Vorurteile ermöglichen verantwortungsvollen KI-Einsatz in KMU.

## Kategorie-Evidenz

### Evidenz 1

Gesamter Leitfaden vermittelt KI-Kompetenzen: 'Der Guide vermittelt Ihnen nicht nur das 'Was' und 'Wie', sondern auch das 'Warum' des Einsatzes Generativer KI.' Kapitel 1 behandelt 'Grundlagen: KI, Generative KI und KI-Prompting' und Best Practices beim Prompting.

### Evidenz 2

Fokus auf Generative KI-Systeme: 'Generative KI-Systeme - Programme, die selbstständig Texte, Bilder und vieles mehr erzeugen können'. Detaillierte Übersicht zu TextgeneratorenTools (ChatGPT 4, Claude 3, Gemini, DALL-E 2, Midjourney) in Kapitel 2.3.

### Evidenz 3

Zentral: Kapitel 5 'Promptingstrategien' mit KI-FAIRNESS-Framework (K-I-F-A-I-R-N-E-S-S). Punkt 'Sprache ist Macht' behandelt englisches Prompting, Neutralität vs. Diversität, Anonymisierung, Tonalität.

### Evidenz 4

Behandlung klassischer ML-Probleme wie Halluzinationen, Datenschutz, unzureichende Aktualität in Kapitel 2.2: 'Das sogenannte Halluzinieren, bei dem die Künstliche Intelligenz Informationen erfindet oder verfälscht.'

### Evidenz 5

Umfassende Behandlung: Kapitel 3 'Problemstellung: Warum Fair AI Prompting?' behandelt historische Daten, Gender-Data-Gap, Stereotype, Überrepräsentation weißer Männer: 'Viele Entscheidungsträger*innen und Entwickler*innen sind weiß, männlich* und privilegiert.' Praktische Beispiele zeigen Diskriminierung in KI-generierten Bildern (nur schlanke Menschen, lange Haare, priviligierte Kontexte).

### Evidenz 6

Explizit thematisiert: Gender-Data-Gap, genderstereotypische Beschreibungen, Repräsentation von Frauen in Berufsfeldern. Beispiel MissJourney: 'sich darauf spezialisiert hat, Bilder von Frauen in verschiedenen Berufsfeldern zu erstellen.' Hinweis auf Gefahr genderstereotypischer Formulierungen bei Empfehlungsschreiben.

### Evidenz 7

Kernthema: 'Ziel dieses Leitfadens ist es...diese mit Blick auf eine diverse Gesellschaft nutzen zu können.' KI-FAIRNESS-Framework fordert explizit diverse Darstellung. Beispiel: 'Es könnte z.B. explizit gefordert werden, dass Frauen und Männer, Menschen unterschiedlicher Hautfarbe und sozialer Schicht dargestellt werden sollen.'

### Evidenz 8

Leitfaden basiert auf feministischer KI-Perspektive: Co-Autorin Eva Gengler ist 'Expertin im Bereich feministischer KI' und Co-Founderin von 'feminist AI'. Referenzen auf D'Ignazio & Klein 'Data Feminism', Caroline Criado-Perez 'Unsichtbare Frauen' (Gender-Data-Gap). Konzept 'Feministische KI': 'Es gibt bereits einige Beispiele von KI mit feministischem Zweck und für die Stärkung der Rechte marginalisierter Gruppen.'

### Evidenz 9

Zentral: Kap. 4.5 'Werteorientierung bei Entwicklung und Einsatz von KI', Kap. 4.6 'KI-Governance: Prinzipien, Prozesse und Strukturen für KI' mit Fairness-Definition: 'Fairness im Kontext von KI bedeutet, dass alle Menschen gleichberechtigt und diskriminierungsfrei von KI-Systemen behandelt werden: Gleiche Chancen, Verbot der Diskriminierung, Transparenz und Nachvollziehbarkeit, Rechenschaftspflicht.' KI-FAIRNESS-Framework als systematischer Ansatz.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Fairness/Gender: Der Leitfaden verbindet technisches Wissen über Generative KI explizit mit feministischen und Diversity-Perspektiven und zielt auf praktische Anwendung in Unternehmen ab. Die Fokussierung auf KMU adressiert auch eine sozialpolitisch relevante Gruppe.

**Unique Contribution:** Systematisches KI-FAIRNESS-Framework, das Prompting-Praxis direkt mit organisationalen Strukturveränderungen (Governance, Mindset, Werteorientierung) verknüpft und konkrete Strategien zur Vermeidung von Diskriminierung in KI-generierten Inhalten bietet.

**Limitations:** Leitfaden basiert nicht auf empirischer Evaluation des KI-FAIRNESS-Frameworks; keine quantitative Überprüfung der Effektivität; Fokus auf deutschsprachige KMU, begrenzte Übertragbarkeit auf andere Kontexte.

**Target Group:** Primär: Führungskräfte und Mitarbeiter:innen in kleinen und mittleren Unternehmen (KMU). Sekundär: KI-Trainer:innen, Berater:innen, HR-Fachkräfte, Policymaker zu digitaler Gerechtigkeit, KI-Ethiker:innen. Interessant auch für: Sozialarbeitende, die KI in ihren Organisationen einführen oder kritisch hinterfragen.

## Schlüsselreferenzen

- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[CriadoPerez_Caroline_2019]] - Unsichtbare Frauen (Invisible Women: Data Bias in a World Designed for Men)
- [[Nuseir_et_al_nicht angegeben]] - Studie zu Diversity in KI-Entwicklungsteams
- [[OpenAI_2024]] - ChatGPT 4
- [[Midjourney_2024]] - Bildgenerierungs-Tool mit Fokus auf Diversität
- [[MissJourney_Project_nicht angegeben]] - Bilder von Frauen in Berufsfeldern generieren
- [[DAIRAI_nicht angegeben]] - Prompt Engineering Guide
- [[bitkom_2024]] - Leitfaden: Generative KI in Unternehmen
