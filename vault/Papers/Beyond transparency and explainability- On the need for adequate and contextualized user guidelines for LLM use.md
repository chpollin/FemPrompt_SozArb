---
title: "Beyond transparency and explainability: On the need for adequate and contextualized user guidelines for LLM use"
authors:
  - K. G. Barman
  - N. Wood
  - P. Pawlowski
year: 2024
type: journalArticle
doi: 10.1007/s10676-024-09778-2
url: "https://doi.org/10.1007/s10676-024-09778-2"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.85
llm_categories:
  - AI_Literacies
  - Generative_KI
  - Prompting
  - Bias_Ungleichheit
  - Diversitaet
---

# Beyond transparency and explainability: On the need for adequate and contextualized user guidelines for LLM use

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, Prompting, Bias_Ungleichheit, Diversitaet, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 88 |
| **Overall Confidence** | **92** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.85)

## Key Concepts

- [[AI Governance Frameworks]]

## Wissensdokument

# Guideline for the use of Generative Artificial Intelligence and Large Language Model Tools

## Kernbefund

Generative KI-Tools bieten erhebliche Produktivitätspotenziale für Regierungsbehörden, erfordern aber umfassende Governance-Frameworks, Datenschutzkontrollen und ethische Überlegungen, insbesondere bezüglich Verzerrungen, die marginalisierte Gruppen betreffen können.

## Forschungsfrage

Wie können Regierungsbehörden die sichere, ethisch verantwortungsvolle und risikominimierte Nutzung von generativen KI- und LLM-Tools gewährleisten?

## Methodik

Theoretisch/Policy-Analyse; Richtliniendokumentation mit Risikobewertung und Mitigationsmaßnahmen

## Hauptargumente

- Generative KI und LLMs können Routineaufgaben automatisieren und Mitarbeiter:innen für höherwertige Arbeit freisetzen, erfordern aber strikte Kontrollen zur Vermeidung von Datenverlust und unbefugter Weitergabe vertraulicher Regierungsinformationen.
- LLMs sind anfällig für 'Halluzinationen' – erfundene, aber selbstbewusst präsentierte Antworten – sowie für Bias und Diskriminierung aufgrund ihrer Trainings- und Entwicklungsdaten, was besonders für Aboriginal und Torres Strait Islander peoples und Minderheitsgruppen riskant ist.
- Behörden müssen umfassende Risk-Assessments durchführen, Privacy Impact Analyses durchlaufen, Governance-Frameworks etablieren und Mitarbeiter:innen kontinuierlich schulen, um ethische, rechtliche und sicherheitstechnische Standards einzuhalten.

## Kategorie-Evidenz

### Evidenz 1

Conduct awareness campaigns for the safe and ethical use of AI tools; Instruct employees via clearly understood and widely disseminated policies; Remind staff of their obligations under the Code of Ethics for the SA Public Sector

### Evidenz 2

This guideline covers the limitations and risks associated with the use of generative artificial intelligence (AI) and Large Language Model (LLM) tools; Generative AI and LLM tools, such as OpenAI's ChatGPT and Google Bard

### Evidenz 3

Employees can easily expose sensitive and proprietary government data in the questions and prompts they provide to generative AI and LLM tools; Disallow any cut-and-paste of enterprise content, such as emails, reports and chat logs into prompts

### Evidenz 4

Relying on vast amounts of algorithms and data carries the inherent risk of bias or discriminatory content in outputs; This can lead to inbuilt and amplified biases that could be particularly damaging for Aboriginal and Torres Strait Islander peoples and minority groups

### Evidenz 5

Where generative AI and LLM tools are used in circumstances that may impact Aboriginal and Torres Strait Islander peoples, agencies must consider the risk of negative bias in that instance and consult with Aboriginal and Torres Strait Islander peoples; Be wary of inherent biases that may be inbuilt and develop strategies to counter them

### Evidenz 6

Establish or update the agency's privacy policies to accommodate the use of AI tools to meet applicable obligations - including in relation to integrity, privacy, security, human rights, anti-discrimination, administrative and other laws; AI systems have the potential to be expressions of cultural and social frameworks, representing the socially dominant concepts and normative ideas of the system designers

## Assessment-Relevanz

**Domain Fit:** Das Dokument ist eine Governance- und Policy-Richtlinie für Behördeneinsatz von generativen KI-Tools und adressiert primär technische, rechtliche und ethische Risiken. Es hat begrenzte direkte Relevanz für Soziale Arbeit, bietet aber wichtige Erkenntnisse zu Bias-Risiken und Auswirkungen auf marginalisierte Gruppen.

**Unique Contribution:** Umfassende und praktisch anwendbare Governance-Richtlinie, die explizit die Risiken für Aboriginal und Torres Strait Islander peoples sowie marginalisierte Gruppen thematisiert und konkrete Mitigationsmaßnahmen fordert.

**Limitations:** Das Dokument ist eine Richtlinie ohne empirische Forschung oder theoretische Vertiefung; es bietet Überblicks-Level Orientierung statt detaillierter Analyse spezifischer Auswirkungen auf verschiedene gesellschaftliche Gruppen oder Soziale Arbeit.

**Target Group:** Regierungsbehörden, Public Sector Manager:innen, IT Security Officer:innen, Datenschutzverantwortliche, Policymaker:innen; potenziell relevant für Sozialarbeitende, die in behördlichen Kontexten tätig sind oder mit KI-gestützten Systemen interagieren

## Schlüsselreferenzen

- [[Forrester_None]] - Build your own business case for Microsoft 365 Copilot
- [[Australian_Government_None]] - Australia's AI Ethics Principles
- [[Australian_Government_None]] - National framework for the assurance of artificial intelligence in government
- [[ISOIEC_2023]] - ISO/IEC 42001:2023 Information Technology-Artificial Intelligence-Management Standard
- [[South_Australian_Government_None]] - SA Government Information Privacy Principles
- [[South_Australian_Government_None]] - Code of Ethics for the SA Public Sector
- [[Cybergovau_None]] - Deploying AI Systems Securely
