---
title: Governance of generative AI: A comprehensive framework for navigating challenges and opportunities
authors:
  - A. Taeihagh
year: 2025
type: journalArticle
url: https://academic.oup.com/policyandsociety/article/44/1/1/7997395
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types: []
mitigation_strategies: []
llm_decision: Include
llm_confidence: 0.85
llm_categories:
  - Generative_KI
  - Bias_Ungleichheit
  - Fairness
human_decision: Include
human_categories:
  - Generative_KI
  - Prompting
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Fairness
agreement: agree
---

# Governance of generative AI: A comprehensive framework for navigating challenges and opportunities

## Abstract

Provides comprehensive overview of governance challenges posed by generative AI, including bias amplification, privacy violations, misinformation, and exacerbation of power imbalances. Critiques inadequacy of voluntary self-regulation and proposes comprehensive governance framework that is proactive, adaptive, and participatory. Recommends improving data governance, mandating independent audits, enhancing public engagement, and fostering international cooperation.

## Assessment

**LLM Decision:** Include (Confidence: 0.85)
**LLM Categories:** Generative_KI, Bias_Ungleichheit, Fairness
**Human Decision:** Include
**Human Categories:** Generative_KI, Prompting, Bias_Ungleichheit, Gender, Diversitaet, Fairness
**Agreement:** Agree

## Key Concepts

## Full Text

---
title: "Governance of Generative AI: A Comprehensive Framework"
authors: ["A. Taeihagh"]
year: 2025
type: journalArticle
language: en
processed: 2026-02-05
source_file: Taeihagh_2025_Governance_of_generative_AI_A_comprehensive.md
confidence: 75
---

# Governance of Generative AI: A Comprehensive Framework

## Kernbefund

Traditionelle IT-Governance-Modelle und Regulierungsrahmen sind unzureichend für generative KI; es bedarf innovativer, inklusiver und komplexitätsbasierter Governance-Ansätze, die Stakeholder-Partizipation, Datenschutz, IPR, Bias-Reduktion und internationale Kooperation adressieren.

## Forschungsfrage

Wie können generative KI-Systeme durch adaptive, partizipative und proaktive Governance-Ansätze verantwortungsvoll reguliert werden, um gesellschaftliche Werte zu schützen und Risiken zu minimieren?

## Methodik

Theoretisch/Review – Systematische Analyse der Governance-Herausforderungen von generativer KI durch Literaturreview und Synthese von sieben Spezialartikeln einer Policy-Sonderausgabe
**Datenbasis:** Keine empirische Datenerhebung; konzeptionelle Synthese von sieben Peer-reviewed Artikeln und umfassender Literaturreview

## Hauptargumente

- Generative KI birgt einzigartige Risiken (Halluzination, Jailbreaking, Datenvergiftung, Bias-Verstärkung, Datenlecks, Desinformation), die nicht-entschärfbare Sicherheitsfragen für kritische Sektoren wie Gesundheit, Justiz und nationale Sicherheit aufwerfen.
- Die gegenwärtige Governance-Fragmentierung, Macht-Konzentration bei Big-Tech-Unternehmen und techokratische Ansätze ohne öffentliche Partizipation führen zu ungerechten Risiko-Allokationen, bei denen Profite privatisiert und Risiken externalisiert werden.
- Effektive Governance erfordert adaptive, partizipative Rahmenwerke mit Datenschutz-Reformen, IPR-Neugestaltung, Bias-Monitoring, öffentlicher Engagement, Capacity-Building in Behörden und bindende internationale Abkommen gegen autonome Waffensysteme und KI-induzierte Massenvernichtungswaffen.

## Kategorie-Evidenz

### Evidenz 1

Explizite Empfehlungen: 'Educate officials about AI benefits, challenges, and implications. Develop capacities to understand AI's impact on policymaking.' und 'Promote media literacy and educational campaigns about AI capabilities and risks.'

### Evidenz 2

Gesamter Fokus auf generative KI-Modelle: 'generative AI systems that create new content (text, images, audio, or video) based on inputs, leveraging ML, particularly generative adversarial networks (GANs), variational autoencoders (VAEs), large language models (LLMs), and diffusion models'

### Evidenz 3

Behandlung klassischer ML und algorithmischer Entscheidungssysteme: 'traditional rule-based AI' und 'algorithmic decision-making'

### Evidenz 4

Explizite Behandlung von Bias und Ungleichheit: 'if a model is trained on data that are not demographically representative, it might disproportionately underperform for those demographics' und 'bias amplification' sowie 'power imbalances' und 'Big Tech's influence exacerbated by generative AI developments'

### Evidenz 5

Mehrfache Forderungen nach Inklusion und diversen Stakeholdern: 'Assemble diverse teams and engage stakeholders to build trust' und 'Use participatory methods to involve the public in AI policy decisions' sowie 'increased inclusivity' und Berücksichtigung marginalisierter Gruppen durch 'impacts on low-skilled workers'

### Evidenz 6

Fairness-zentrale Governance-Empfehlungen: 'Develop tools and procedures to detect and address biases during training and deployment', 'Promote responsible innovation and ethical AI development', 'Institutionalize red teaming, impact assessments, and internal auditing' und 'Independent audits for models with high impact'

## Assessment-Relevanz

**Domain Fit:** Das Paper hat hohe Relevanz für die Schnittstelle AI/Soziale Arbeit durch seine Fokussierung auf gesellschaftliche Impacts, öffentliche Partizipation, Ungleichheit und vulnerable Gruppen. Es adressiert jedoch Soziale Arbeit nicht direkt, sondern aus einer Policy-Governance-Perspektive.

**Unique Contribution:** Komprehensive, integrierte Governance-Rahmenwerk für generative KI mit sieben Dimensionen (Datenschutz, IPR, Bias, Datenschutz, Desinformation, gesellschaftliche Impacts, Machtungleichgewichte, öffentliches Engagement, öffentlicher Sektor, internationale Kooperation), das technische, rechtliche, organisatorische, politische und soziale Aspekte vereint.

**Limitations:** Das Paper ist primär konzeptionell und synthesisch ohne empirische Validierung der vorgeschlagenen Governance-Ansätze; spezifische Implementierungsmechanismen und Messbarkeit von Erfolgskriterien sind unterentwickelt.

**Target Group:** Policymaker, Regierungsbeamte, AI-Governance-Experten, Regulatoren, Tech-Industrie-Führungskräfte, Civil-Society-Organisationen, Akademiker in Policy Studies und AI Ethics, internationale Organisationen; sekundär relevant für Sozialarbeiter im Kontext von AI-bedingten sozialen Impacts und vulnerable populations

## Schlüsselreferenzen

- [[Taeihagh_A_2021]] - Governance of artificial intelligence
- [[Chesterman_2025]] - Good models borrow, great models steal: Intellectual property rights and generative AI
- [[Janssen_M_2025]] - Responsible governance of generative AI: Complex adaptive systems perspective
- [[Khanal_S_Zhang_H_Taeihagh_A_2025]] - Why and how is the power of Big Tech increasing in the policy process?
- [[Ulnicane_I_2025]] - Governance fix? Power and politics in controversies about governing generative AI
- [[Judge_B_Nitzberg_M_Russell_S_2025]] - When code isn't law: rethinking regulation for artificial intelligence
- [[Cugurullo_Xu_2025]] - Social implications of generative AI and city brains
- [[Oder_N_Béland_D_2025]] - Artificial intelligence, emotional labor, and low-skilled workers
- [[Bender_E_Gebru_T_McMillanMajor_B_Mitchell_S_2021]] - On the Dangers of Stochastic Parrots (Training Data Issues)
- [[Abbas_A_Taeihagh_A_2024]] - Misinformation and synthetic media risks in generative AI
