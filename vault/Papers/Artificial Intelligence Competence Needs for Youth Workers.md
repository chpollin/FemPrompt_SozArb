---
title: Artificial Intelligence Competence Needs for Youth Workers
authors:
  - Miriam Lanzetta
  - Gianluca Abbruzzese
  - OVIDIU ACOMI
  - Nicoleta Acomi
  - Jorge Machado
  - Sonia Anastasia Maravelaki
  - Angela Mangiullo
  - Beatryz Schneider
  - Salomé Marques
year: 2024
type: journalArticle
url: https://zenodo.org/doi/10.5281/zenodo.11525357
doi: 10.5281/ZENODO.11525357
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types:
  - Discrimination
  - Intersectional Accuracy
  - Algorithmic Bias
  - Intersectional Perspectives
mitigation_strategies:
  - Intersectional Accuracy
  - Intersectional Perspectives
  - Equitable Access
llm_decision: Include
llm_confidence: 0.95
llm_categories:
  - AI_Literacies
  - Generative_KI
  - Soziale_Arbeit
human_decision: Include
human_categories:
  - AI_Literacies
  - Generative_KI
  - KI_Sonstige
  - Soziale_Arbeit
agreement: agree
---

# Artificial Intelligence Competence Needs for Youth Workers

## Abstract

The rapid developments in AI technology and the rise of accessible AI-powered tools are transforming the way we live, work and learn. While young people have already warmly embraced these solutions, with Gen Z being the most active users and experimenters of Generative AI (Microsoft, 2024), there is a sense of confusion and fear among youth workers about the future of how AI tools are going to be used in the youth sector, mixed with diverse emotions and viewpoints ranging from apprehension, scepticism, resistance to feelings of enthusiasm and recognition of the significance of AI's role in the field (Pawluczuk, 2023).

This study aims to advance knowledge on the specific competencies required by youth workers to effectively integrate AI into their professional activities, as well as picture the current and potential use of AI for youth professionals.  

The publication is part of the Artificial Intelligence for Youth Work (AI4YouthWork)project, a pioneering initiative under the Erasmus+ programme, co-funded by the European Union, dedicated to enhancing the youth sector across Europe through the integration of artificial intelligence (AI). The project unites four organisations - Lascò from Italy, TEAM4Excellence from Romania, Kyttaro Enallaktikon Anazitiseon Neon from Greece, and Contextos from Portugal -, aspiring to contribute to increasing youth professionals' capacity to harness AI's potential to enhance the quality, attractiveness and effectiveness of their work, and prepare young people to thrive in AI-powered environments. 





Chapter 1 introduces the project, highlighting the steps and methodological approaches to achieving the main objectives and the expected results.




Chapter 2, dedicated to the research methodology, outlines the approach and techniques used to conduct this study. It includes the research design, data collection methods through systematic review, focus groups and interviews, data analysis procedures, as well as limitations and criteria for ensuring the validity and reliability of the findings.




Chapter 3 presents the results of the desk research conducted by the consortium partners to explore the intersections of artificial intelligence, youth and youth work.  The chapter is divided into four main sections, addressing an introduction to AI, the impact of AI on youth, the role of youth workers in the AI revolution, and practical applications of AI in youth work settings.




Chapter 4 outlines the needs, challenges, and tasks involved in integrating AI into youth work, presenting the results of focus group discussions which have been conducted in each partner country.




Chapter 5 sets out the publication's conclusions, formulating recommendations for the development of an AI Competence Framework for Youth Workers, and enhancing the capacity of youth professionals to harness AI in their work.

## Assessment

**LLM Decision:** Include (Confidence: 0.95)
**LLM Categories:** AI_Literacies, Generative_KI, Soziale_Arbeit
**Human Decision:** Include
**Human Categories:** AI_Literacies, Generative_KI, KI_Sonstige, Soziale_Arbeit
**Agreement:** Agree

## Key Concepts

### Bias Types
- [[Algorithmic Bias]]
- [[Discrimination]]
- [[Intersectional Accuracy]]
- [[Intersectional Perspectives]]

### Mitigation Strategies
- [[Equitable Access]]
- [[Intersectional Accuracy]]
- [[Intersectional Perspectives]]

## Full Text

---
title: "Artificial Intelligence in Social Work: An EPIC Model for Practice"
authors: ["Heather Boetto"]
year: 2025
type: journalArticle
language: en
processed: 2026-02-05
source_file: Unknown_Artificial_Intelligence_in_Social_Work_An_EPIC.md
confidence: 95
---

# Artificial Intelligence in Social Work: An EPIC Model for Practice

## Kernbefund

Ein vierpeiliges EPIC-Modell (Ethics and Justice, Policy Development and Advocacy, Intersectoral Collaboration, Community Engagement and Empowerment) wird als strukturierter Ansatz zur ethischen Integration von KI in der Sozialen Arbeit präsentiert, um Chancen zu nutzen und Risiken wie algorithmische Verzerrungen und Desinformation zu mitigieren.

## Forschungsfrage

Wie kann künstliche Intelligenz in der Sozialen Arbeit ethisch und gerecht integriert werden, um die beruflichen Werte und die Unterstützung marginalisierter Gruppen zu wahren?

## Methodik

Theoretisch: Umfassende Literaturrevision zur Schnittstelle KI und Soziale Arbeit; Entwicklung eines konzeptuellen Rahmens (EPIC-Modell)
**Datenbasis:** Sekundäranalyse: Literaturrevision (keine primären Daten)

## Hauptargumente

- KI-Systeme reproduzieren historische Diskriminierungen und koloniale Wissensbestände durch ihre Abhängigkeit von großen historischen Datensätzen, was besonders für First Nations Peoples und marginalisierte Gruppen problematisch ist.
- Eine duale Mensch-Technologie-Ansatz ist erforderlich, bei dem KI als Entscheidungsunterstützung fungiert, nicht als Ersatz für professionelle Urteilskraft und empathische Beziehungen zwischen Fachkräften und Nutzer:innen.
- Intersektorale Zusammenarbeit zwischen Sozialarbeiter:innen, Informatiker:innen, Regierungen und Privatsektor sowie Gemeinschaftsbeteiligung sind zentral, um KI-Systeme gerecht und transparent zu gestalten und marginalisierte Perspektiven einzubeziehen.

## Kategorie-Evidenz

### Evidenz 1

Inclusion of AI content in professional social work policy documents and practice standards; development of education opportunities for increasing community AI knowledge and skills; staff training in organisations implementing AI.

### Evidenz 2

ChatGPT is discussed as problematic case study that has yielded inaccurate output data and breached privacy principles in child protection settings; generative AI's capacity to autonomously augment, synthesise, and innovate new data; concerns about 'black box' problem especially with generative AI.

### Evidenz 3

AI applications in predictive risk modelling for suicide, domestic violence, and child protection; AI-powered chatbots in mental health settings; machine learning algorithms and deep neural networks; decision support systems in social work.

### Evidenz 4

The article directly examines AI's influence on social work profession, including risks to professional ethics, mission and values; dual human-technology approach supporting social work methods; service user-practitioner relationship; social workers' roles and responsibilities being reshaped by AI.

### Evidenz 5

Algorithmic bias in AI systems due to reliance on historical datasets that are not representative of marginalised groups; gender classification systems producing error rates up to 34.7% for darker-skinned females; digital divide and 'information poverty' for marginalised groups; discrimination and exclusion risks; colonial knowledges reinforced in algorithms.

### Evidenz 6

Emphasis on inclusion of First Nations' perspectives and data sovereignty; ethnic data governance; representation of marginalised groups and underrepresented communities in AI design and development; intersectional perspectives; diverse reference groups in organisations.

### Evidenz 7

Addressing racial justice and health equity in AI development; non-discriminatory outcomes; algorithmic fairness concerns; legal protection for marginalised groups; transparent and regulated use of AI systems; equitable access to AI.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochgradig relevant für die Schnittstelle KI und Soziale Arbeit. Es adressiert kritische ethische, justice-orientierte und praktische Fragen, die für Sozialarbeiter:innen zentral sind, und verbindet technische KI-Fragen mit sozialpolitischen Werten der Profession.

**Unique Contribution:** Die Entwicklung des EPIC-Modells bietet einen strukturierten, professionsspezifischen Rahmen zur ethischen KI-Integration in der Sozialen Arbeit, der explizit Dekolonisierung, Gemeinschaftsbeteiligung und intersektorale Zusammenarbeit priorisiert.

**Limitations:** Das Paper ist theoretisch orientiert und präsentiert kein empirisches Validierungsdesign für das EPIC-Modell; es wird anerkannt, dass marginalisierte Gruppen möglicherweise nicht über ausreichende Ressourcen für aktive AI-Partizipation verfügen, aber wenig konkrete Lösungsansätze dafür geboten.

**Target Group:** Primär: Sozialarbeiter:innen, Sozialarbeits-Praktiker:innen und -Fachkräfte, Sozialarbeits-Ausbildende und -Verbände. Sekundär: KI-Entwickler:innen und Informatiker:innen, die mit Sozialsektor arbeiten; Policymaker:innen und Regierungsverantwortliche; Organisationen im Bereich Health und Social Services; Gemeinschaftsorganisationen und First Nations-Organisationen.

## Schlüsselreferenzen

- [[Buolamwini_Gebru_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Gough_Spencer_2019]] - Ethical social work practice in the technological era
- [[DankwaMullan_et_al_2021]] - Framework on integrating health equity and racial justice into the AI development lifecycle
- [[Reamer_2023]] - Artificial intelligence in social work: Emerging ethical issues
- [[Rice_Tambe_2018]] - Merging social work science and computer science for social good
- [[Meilvang_Dahler_2024]] - Decision support and algorithmic support: The construction of algorithms and professional discretion in social work
- [[Khawaja_BélislePipon_2023]] - Your robot therapist is not your therapist: Understanding the role of AI-powered mental health chatbots
- [[Cave_Dihal_2020]] - The whiteness of AI
- [[World_Economic_Forum_2024]] - The Global Risks Report
- [[Jacobi_Christensen_2023]] - Functions, utilities and limitations: A scoping study of decision support algorithms in social work
