---
title: Faires KI-Prompting – Ein Leitfaden für Unternehmen
authors:
  - E. Gengler
  - A. Kraus
  - K. Bodrožić-Brnić
year: 2024
type: report
doi: 
url: "https://www.digitalzentrum-zukunftskultur.de/wp-content/uploads/2024/05/Faires-KI-Prompting-Ein-Leitfaden-fuer-Unternehmen.pdf"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
  - Generative_KI
  - Prompting
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
---

# Faires KI-Prompting – Ein Leitfaden für Unternehmen

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 96 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.92)

## Key Concepts

- [[Algorithmic Fairness in Generative AI]]
- [[Feminist AI]]

## Wissensdokument

# Faires KI-Prompting – Ein Leitfaden für Unternehmen

## Kernbefund

Ein strukturiertes KI-FAIRNESS-Framework (Kontext, Input, Fokus, Ausschnitt, Iterationen, Repertoire, Nachbessern, Eignung, Sprache, Sinn) ermöglicht es Nutzer:innen, faire und diverse Ergebnisse aus Generativer KI zu gestalten. Organisationales Mindset, klare KI-Strategie und Werteorientierung sind grundlegend für fairen KI-Einsatz.

## Forschungsfrage

Wie können kleine und mittlere Unternehmen Generative KI-Systeme durch bewusstes und faires Prompting verantwortungsvoll einsetzen und dabei Diskriminierung vermeiden?

## Methodik

Theoretisch/Praktisch: Leitfaden basierend auf Literaturrecherche und Expertise im Bereich feministische KI, mit praktischen Beispielen und Fallstudien zur Bildgenerierung und Textgenerierung
**Datenbasis:** nicht angegeben (qualitatives Expertenleitfaden-Format, keine quantitativen Daten)

## Hauptargumente

- Generative KI reproduziert strukturelle Ungerechtigkeiten aus Trainingsdaten (Bias, Stereotype, Gender-Data-Gap), wenn nicht bewusst dagegen gesteuert wird. Der Zweck der KI-Entwicklung und -Nutzung – ob zur Reproduktion oder Transformation bestehender Prozesse – ist entscheidend.
- Faires KI-Prompting ist ein erlernbarer Skill: Durch systematische Prompt-Gestaltung (Kontext, Sprache, Diversitätsanforderungen, Iterationen) können Nutzer:innen faire und diverse Ergebnisse erzielen und damit gesellschaftliche Ungleichheiten abbauen.
- Organisationale Verankerung ist essentiell: KI-Strategie auf Führungsebene, Werteorientierung, diversitätsaffine Governance, Mindset-Entwicklung auf allen Ebenen und kontinuierliche Reflexion eigener Vorurteile ermöglichen verantwortungsvollen KI-Einsatz in KMU.

## Kategorie-Evidenz

### Evidenz 1

Gesamter Leitfaden vermittelt KI-Kompetenzen: 'Der Guide vermittelt Ihnen nicht nur das 'Was' und 'Wie', sondern auch das 'Warum' des Einsatzes Generativer KI.' Kapitel 1 behandelt 'Grundlagen: KI, Generative KI und KI-Prompting' und Best Practices beim Prompting.

### Evidenz 2

Fokus auf Generative KI-Systeme: 'Generative KI-Systeme - Programme, die selbstständig Texte, Bilder und vieles mehr erzeugen können'. Detaillierte Übersicht zu TextgeneratorenTools (ChatGPT 4, Claude 3, Gemini, DALL-E 2, Midjourney) in Kapitel 2.3.

### Evidenz 3

Zentral: Kapitel 5 'Promptingstrategien' mit KI-FAIRNESS-Framework (K-I-F-A-I-R-N-E-S-S). Punkt 'Sprache ist Macht' behandelt englisches Prompting, Neutralität vs. Diversität, Anonymisierung, Tonalität.

### Evidenz 4

Behandlung klassischer ML-Probleme wie Halluzinationen, Datenschutz, unzureichende Aktualität in Kapitel 2.2: 'Das sogenannte Halluzinieren, bei dem die Künstliche Intelligenz Informationen erfindet oder verfälscht.'

### Evidenz 5

Umfassende Behandlung: Kapitel 3 'Problemstellung: Warum Fair AI Prompting?' behandelt historische Daten, Gender-Data-Gap, Stereotype, Überrepräsentation weißer Männer: 'Viele Entscheidungsträger*innen und Entwickler*innen sind weiß, männlich* und privilegiert.' Praktische Beispiele zeigen Diskriminierung in KI-generierten Bildern (nur schlanke Menschen, lange Haare, priviligierte Kontexte).

### Evidenz 6

Explizit thematisiert: Gender-Data-Gap, genderstereotypische Beschreibungen, Repräsentation von Frauen in Berufsfeldern. Beispiel MissJourney: 'sich darauf spezialisiert hat, Bilder von Frauen in verschiedenen Berufsfeldern zu erstellen.' Hinweis auf Gefahr genderstereotypischer Formulierungen bei Empfehlungsschreiben.

### Evidenz 7

Kernthema: 'Ziel dieses Leitfadens ist es...diese mit Blick auf eine diverse Gesellschaft nutzen zu können.' KI-FAIRNESS-Framework fordert explizit diverse Darstellung. Beispiel: 'Es könnte z.B. explizit gefordert werden, dass Frauen und Männer, Menschen unterschiedlicher Hautfarbe und sozialer Schicht dargestellt werden sollen.'

### Evidenz 8

Leitfaden basiert auf feministischer KI-Perspektive: Co-Autorin Eva Gengler ist 'Expertin im Bereich feministischer KI' und Co-Founderin von 'feminist AI'. Referenzen auf D'Ignazio & Klein 'Data Feminism', Caroline Criado-Perez 'Unsichtbare Frauen' (Gender-Data-Gap). Konzept 'Feministische KI': 'Es gibt bereits einige Beispiele von KI mit feministischem Zweck und für die Stärkung der Rechte marginalisierter Gruppen.'

### Evidenz 9

Zentral: Kap. 4.5 'Werteorientierung bei Entwicklung und Einsatz von KI', Kap. 4.6 'KI-Governance: Prinzipien, Prozesse und Strukturen für KI' mit Fairness-Definition: 'Fairness im Kontext von KI bedeutet, dass alle Menschen gleichberechtigt und diskriminierungsfrei von KI-Systemen behandelt werden: Gleiche Chancen, Verbot der Diskriminierung, Transparenz und Nachvollziehbarkeit, Rechenschaftspflicht.' KI-FAIRNESS-Framework als systematischer Ansatz.

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Fairness/Gender: Der Leitfaden verbindet technisches Wissen über Generative KI explizit mit feministischen und Diversity-Perspektiven und zielt auf praktische Anwendung in Unternehmen ab. Die Fokussierung auf KMU adressiert auch eine sozialpolitisch relevante Gruppe.

**Unique Contribution:** Systematisches KI-FAIRNESS-Framework, das Prompting-Praxis direkt mit organisationalen Strukturveränderungen (Governance, Mindset, Werteorientierung) verknüpft und konkrete Strategien zur Vermeidung von Diskriminierung in KI-generierten Inhalten bietet.

**Limitations:** Leitfaden basiert nicht auf empirischer Evaluation des KI-FAIRNESS-Frameworks; keine quantitative Überprüfung der Effektivität; Fokus auf deutschsprachige KMU, begrenzte Übertragbarkeit auf andere Kontexte.

**Target Group:** Primär: Führungskräfte und Mitarbeiter:innen in kleinen und mittleren Unternehmen (KMU). Sekundär: KI-Trainer:innen, Berater:innen, HR-Fachkräfte, Policymaker zu digitaler Gerechtigkeit, KI-Ethiker:innen. Interessant auch für: Sozialarbeitende, die KI in ihren Organisationen einführen oder kritisch hinterfragen.

## Schlüsselreferenzen

- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[CriadoPerez_Caroline_2019]] - Unsichtbare Frauen (Invisible Women: Data Bias in a World Designed for Men)
- [[Nuseir_et_al_nicht angegeben]] - Studie zu Diversity in KI-Entwicklungsteams
- [[OpenAI_2024]] - ChatGPT 4
- [[Midjourney_2024]] - Bildgenerierungs-Tool mit Fokus auf Diversität
- [[MissJourney_Project_nicht angegeben]] - Bilder von Frauen in Berufsfeldern generieren
- [[DAIRAI_nicht angegeben]] - Prompt Engineering Guide
- [[bitkom_2024]] - Leitfaden: Generative KI in Unternehmen
