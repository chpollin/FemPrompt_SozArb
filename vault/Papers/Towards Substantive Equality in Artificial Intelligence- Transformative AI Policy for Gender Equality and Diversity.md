---
title: Towards Substantive Equality in Artificial Intelligence: Transformative AI Policy for Gender Equality and Diversity
authors:
  - A. Ovalle
year: 2024
type: report
url: https://datapopalliance.org/publications/towards-real-diversity-and-gender-equality-in-ai/
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types: []
mitigation_strategies:
  - Feminist AI
llm_decision: Include
llm_confidence: 0.92
llm_categories:
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
human_decision: Include
human_categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
agreement: agree
---

# Towards Substantive Equality in Artificial Intelligence: Transformative AI Policy for Gender Equality and Diversity

## Abstract

Dieser GPAI-Bericht, basierend auf Konsultationen mit über 200 Teilnehmern aus mehr als 50 Ländern, entwickelt einen menschenrechtsbasierten Rahmen für substantielle Gleichberechtigung in der KI. Der Bericht betont, dass KI ohne Intervention das Risiko birgt, gesellschaftliche Verzerrungen zu perpetuieren und zu verstärken, insbesondere gegen historisch marginalisierte Gruppen. Die Empfehlungen zielen darauf ab, die strukturellen Wurzeln der Ungleichheit zu bekämpfen und transformative Veränderungen zu fördern, die substantielle Gleichberechtigung in der KI erreichen. Solche Politiken verbessern die Effektivität, Fairness und Nutzbarkeit von KI-Systemen.

## Assessment

**LLM Decision:** Include (Confidence: 0.92)
**LLM Categories:** KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Human Decision:** Include
**Human Categories:** AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness
**Agreement:** Agree

## Key Concepts

### Mitigation Strategies
- [[Feminist AI]]

## Full Text

---
title: "Towards Substantive Equality in Artificial Intelligence: Transformative AI Policy for Gender Equality and Diversity"
authors: ["Paola Ricaurte Quijano", "Benjamin Prud'homme", "Isadora Hellegren Létourneau"]
year: 2024
type: report
language: en
processed: 2026-02-05
source_file: Ricaurte Quijano_2024_Towards_Substantive_Equality_in_Artificial.md
confidence: 93
---

# Towards Substantive Equality in Artificial Intelligence: Transformative AI Policy for Gender Equality and Diversity

## Kernbefund

KI-Systeme sind nicht neutral und reproduzieren strukturelle Ungleichheiten. Eine transformative Gleichstellungspolitik muss systembezogene Nachteile adressieren, demokratische Defizite überbrücken und Fehlrepräsentation umkehren durch inklusives Design, sinnvolle Partizipation und Accountability über den gesamten KI-Lebenszyklus.

## Forschungsfrage

Wie kann transformative KI-Politik Geschlechtergleichstellung und Vielfalt in KI-Ökosystemen fördern und strukturelle Ungleichheiten adressieren?

## Methodik

Mixed: Qualitativ - mehrsprachige regionale und gruppenspezifische Konsultationen mit multi-stakeholder Beteiligung in 5 Regionen (Asien, MENA, Nord-/Südamerika, Europa, Sub-Sahara-Afrika); Literaturanalyse; konzeptionelle Rahmenentwicklung
**Datenbasis:** Regionale und gruppenspezifische Konsultationen mit 100+ Teilnehmenden global; Projektberatungsgruppe mit 35+ Expert:innen; 8 Konsultationsexpert:innen; Analyse von Best Practices aus globalen Initiativen

## Hauptargumente

- KI-Systeme perpetuieren nicht nur durch technische Bias, sondern auch durch Ausschluss von marginalisierten Gruppen aus Designprozessen und Entscheidungsfindung - eine Form der algorithmischen Unterdrückung, die auf intersektionalen Machtverhältnissen basiert.
- Substantive Gleichstellung erfordert einen dreizeiligen Ansatz: Beseitigung systembezogener Nachteile durch faire Systeme, Überbrückung des demokratischen Defizits durch echte Partizipation, und Umkehrung von Fehlrepräsentation durch Würdeschutz und Anerkennung von marginalisierten Gruppen.
- Transformative KI-Politik muss Kapazitätsentwicklung, inklusives Design, Accountability-Mechanismen und sinnvolle Partizipation von Marginalisierten über den gesamten KI-Lebenszyklus integrieren - nicht nur einzelne technische Interventionen an einzelnen Phasen.

## Kategorie-Evidenz

### Evidenz 1

UNESCO Global Dialogue, Data Justice Policy Brief, AI & Equality Human Rights Toolbox, Indigenous Pathfinders in AI - alle fokussieren auf Kapazitätsentwicklung, öffentliche Bildung und AI-Literacies für diverse Gruppen.

### Evidenz 2

Umfassender Fokus auf KI-Lebenszyklen, algorithmische Entscheidungssysteme, KI-Governance, KI-Deployment und Auswirkungen auf verschiedene Bevölkerungsgruppen jenseits generativer KI.

### Evidenz 3

Explizite Fokussierung auf marginalisierte Communities, Junge, Frauen, Indigenous People, Personen mit Behinderungen, Migranten - zentrale Zielgruppen sozialer Arbeit. Integration von Menschenrechten und sozialer Gerechtigkeit als Kernrahmen.

### Evidenz 4

Zentral: 'AI systems reproduce the world models, cultural values, knowledge, and languages...thereby replicating or amplifying systemic inequalities based on gender, race, ethnicity, abilities, social class, and education.' Fokus auf algorithmic oppression und strukturelle Diskriminierung.

### Evidenz 5

Explizit im Titel und durchgehend: Geschlechtergerechtigkeit als Kernziel. UNESCO Global Dialogue on 'Artificial Intelligence and Gender Equality', Analyse von Gender-Bias in KI, sexualisierte Darstellungen racialiser Frauen durch AI image generators.

### Evidenz 6

Zentral: Inklusion von Indigenous Perspectives, Disability Justice, LGBTQI+ Perspektiven, mehrsprachige Global South Repräsentation. Indigenous Pathfinders in AI, RIADIS Workshop, intersektionale Perspektiven throughout.

### Evidenz 7

Explizite feministische Rahmengestaltung: Zitierung von 'feminist scholars (Benjamin, 2019; Eubanks, 2017; Noble and Roberts, 2019; West, 2020)' zu algorithmic oppression. Feminist AI Research Network als Co-Lead und Initiatoren. Data Feminism und intersektionale feministische Theorie strukturieren die Analyse.

### Evidenz 8

Behandlung von Fairness als Dimension von substantiver Gleichstellung, aber über technische Fairness-Metriken hinaus zu Würde, Anerkennung und Gerechtigkeit. 'Fairness' ist notwendig aber nicht hinreichend - erfordert demokratische Partizipation und Umkehrung von Fehlrepräsentation.

## Assessment-Relevanz

**Domain Fit:** Höchst relevant für die Schnittstelle KI/Soziale Arbeit/Gender: Das Report adressiert explizit die Auswirkungen von KI auf marginalisierte Gruppen (zentrale Zielgruppen sozialer Arbeit), integriert Gender-Perspektiven und feministische Theorie, und bietet policy-orientierte Empfehlungen für transformative Praxis.

**Unique Contribution:** Einzigartig ist die Integration eines transnationalen, partizipativen, mehrsprachigen Beratungsprozesses mit 100+ Stakeholdern aus dem Globalen Süden, kombiniert mit expliziter feministischer und intersektionaler Rahmengestaltung sowie einem sektoral-weiten Transformationsansatz, der über technische Lösungen zu Würde und Anerkennung führt.

**Limitations:** Report präsentiert best practices und policy-Empfehlungen, implementiert aber selbst keine empirischen Studien zur Wirksamkeit; Fokus auf Policy-Ebene mit weniger Granularität zu lokalen Kontexten; Messbarkeit von 'substantiver Gleichstellung' in der Praxis unklar.

**Target Group:** KI-Policymaker, Gouvernmentale und multilaterale AI-Governance-Akteure, KI-Entwickler und Deployer, Sozialarbeitende und NGOs mit Fokus auf marginalisierte Communities, Feminist AI Researchers, Global South Technologie-Aktivisten, Indigenous Leaders in Tech, Disability Rights Advocates

## Schlüsselreferenzen

- [[Benjamin_Ruha_2019]] - Race after Technology
- [[Eubanks_Virginia_2017]] - Automating Inequality
- [[Noble_Safiya_U_Roberts_Sarah_T_2019]] - Algorithms of Oppression/Critical Perspectives on Race and Technology
- [[West_Sarah_M_2020]] - Redistribution and Recognition: A Feminist Critique of Algorithmic Fairness
- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[Ricaurte_Paola_2019]] - Data Epistemologies, the Coloniality of Power, and Resistance
- [[UN_Women_2015]] - Progress of the World's Women 2015-2016: Substantive Equality for Women
- [[UNESCO_2022]] - Recommendation on the Ethics of Artificial Intelligence
