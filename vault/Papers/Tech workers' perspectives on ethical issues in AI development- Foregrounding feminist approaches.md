---
title: "Tech workers' perspectives on ethical issues in AI development: Foregrounding feminist approaches"
authors:
  - J. Browne
  - E. Drage
  - K. McInerney
year: 2024
type: journalArticle
doi: 10.1177/20539517231221780
url: "https://doi.org/10.1177/20539517231221780"
tags:
  - paper
llm_decision: Include
llm_confidence: 0.95
llm_categories:
  - AI_Literacies
  - KI_Sonstige
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
---

# Tech workers' perspectives on ethical issues in AI development: Foregrounding feminist approaches

## Transformation Trail

### Stufe 1: Extraktion & Klassifikation (LLM)

**Extrahierte Kategorien:** AI_Literacies, KI_Sonstige, Bias_Ungleichheit, Diversitaet, Feministisch, Fairness
**Argumente:** 3 extrahiert

### Stufe 3: Verifikation (LLM)

| Metrik | Score |
|--------|-------|
| Completeness | 92 |
| Correctness | 98 |
| Category Validation | 95 |
| **Overall Confidence** | **95** |

### Stufe 4: Assessment

**LLM:** Include (Confidence: 0.95)

## Wissensdokument

# Tech workers' perspectives on ethical issues in AI development: Foregrounding feminist approaches

## Kernbefund

Der Begriff 'Bias' verursacht Verwirrung unter Tech-Workern und kann seine beabsichtigte ethische Funktion nicht erfüllen; Tech-Worker sehen keinen direkten Zusammenhang zwischen DEI-Agenden und KI-Entwicklung; Legacy-Systeme stellen erhebliche Herausforderungen für ethische KI-Entwicklung dar.

## Forschungsfrage

Welche ethischen Fragen sehen Tech-Arbeiter bei der KI-Entwicklung als am dringendsten an, und wie können feministische Ansätze zur Analyse dieser Perspektiven beitragen?

## Methodik

Empirisch-qualitativ: In-depth interviews (n=63+) mit Tech-Mitarbeitern verschiedener Disziplinen (Engineering, Data Science, Legal, HR) in einem großen KI-Unternehmen (2020-2021); feministische Narrative-Analyse nach Sara Ahmed
**Datenbasis:** 63 qualitative Interviews mit Tech-Arbeitern in einem führenden KI-Unternehmen (Global North), verschiedene Funktionsbereiche

## Hauptargumente

- Der Begriff 'Bias' ist polysem und wird von Tech-Workern in verschiedenen Bedeutungen verwendet (mathematisch vs. ethisch), was zu Missverständnissen in der Implementierung von AI-Ethics-Frameworks führt. Der Vorschlag ist stattdessen, von 'AI-Partiality' zu sprechen, um die partiale Perspektive jeden ML-Modells zu betonen.
- DEI-Initiativen werden von Tech-Workern nicht mit AI-Entwicklung verbunden; nur 16% der Befragten sehen einen Zusammenhang zwischen DEI-Programmen und KI-Produktentwicklung, trotz der Betonung in unternehmensweiter Rhetorik. Wirtschaftlicher Druck (War for Talent) untergrätbt Integration von Diversität.
- Legacy-Systeme und fehlendes Lifecycle-Management von KI-Systemen stellen praktische Barrieren für ethische KI dar. Tech-Worker sind besorgt über unzureichende Monitoring- und Wartungsprotokolle für bestehende Systeme, die die Entwicklung neuer, ethischerer Produkte gefährden.

## Kategorie-Evidenz

### Evidenz 1

Fokus auf Verständnis und Kompetenzlücken von Tech-Workern: 'a 'lack of ethical knowledge' that made it difficult to expand and scale AI ethics principles in industry contexts' (Khan et al. 2023, zitiert im Paper)

### Evidenz 2

Umfassende Analyse von AI-Ethics-Frameworks, Bias-Mitigation-Strategien, ML-Modellen und algorithmischen Systemen in der KI-Produktentwicklung

### Evidenz 3

Zentrale Analyse von Bias-Konzepten und struktureller Ungleichheit: 'data should be understood as always laden with the uneven experiences of the unequal contexts in which it emerges'; Diskussion von Geschlecht und Rasse in Daten (Wikipedia-Beispiel)

### Evidenz 4

Explizit DEI-fokussiert mit Analyse marginalisierter Gruppen: 'marginalized users and consumers'; Untersuchung von Repräsentation in der Datenbeschaffung und unternehmensweiter Diversität

### Evidenz 5

Explizit feministische Methodik und Theorie durchgehend: 'we explicitly draw on feminist insights' und 'follow the methodological approach of feminist and critical race scholar Sara Ahmed (2012)'; Verwendung von Haraway's 'situated knowledges', D'Ignazio & Klein, Ahmed zur Analyse

### Evidenz 6

Diskussion von Fairness-Konzepten in AI: 'justice, fairness and equity' als zentrales AI-Ethics-Thema; kritische Analyse von Fairness-Mitigation-Ansätzen und Unmöglichkeit der Neutralität

## Assessment-Relevanz

**Domain Fit:** Hochrelevant für die Schnittstelle AI/Gender/Diversität. Das Paper kombiniert explizit feministische Theorie mit empirischer Forschung zu KI-Entwicklung und adressiert strukturelle Ungleichheiten. Die Perspektive marginalisierter Arbeitnehmer und systemische Barrieren haben große Relevanz für soziale Gerechtigkeit, lassen sich aber nur indirekt auf Soziale Arbeit anwenden.

**Unique Contribution:** Das Paper ist innovativ in seiner Kombination feministischer Methodologie mit empirischer Industrie-Feldforschung und gibt Tech-Workern explizit eine Stimme, die in AI-Ethics-Diskursen meist ausgeschlossen sind; es dekonstruiert zentrale Konzepte (Bias) und zeigt konzeptuelle Verwirrung in der Praxis auf.

**Limitations:** Fallstudie in einem einzigen Unternehmen (Tech Company X); begrenzte Generalisierbarkeit auf andere Organisationen; keine explizite Analyse von Geschlechts- oder Rasse-Positionen der Interviewten; keine longitudinalen Daten zur Veränderung über Zeit.

**Target Group:** AI-Praktiker und Entwickler, AI-Ethik-Forscher, Policymaker und AI-Governance-Experten, Tech-Unternehmen, feministische Technologiewissenschaftler:innen, Kritische Datenforschung und STS-Community; begrenzt relevant für Sozialarbeiter:innen (indirekt durch strukturelle Ungleichheitsanalyse)

## Schlüsselreferenzen

- [[Ahmed_S_2012]] - On Being Included: Racism and Diversity in Institutional Life
- [[Haraway_D_1988]] - Situated Knowledges: The Science Question in Feminism
- [[DIgnazio_C_Klein_L_2020]] - Data Feminism
- [[Benjamin_R_2019]] - Race after Technology: Abolitionist Tools for the New Jim Code
- [[Buolamwini_J_Gebru_T_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Amoore_L_2020]] - Cloud Ethics: Algorithms and the Attributes of Ourselves and Others
- [[Khan_A_et_al_2023]] - AI Ethics: An Empirical Study on the Views of Practitioners and Lawmakers
- [[Vakkuri_V_et_al_2020]] - AI Ethics in Industry: A Research Framework
- [[Munn_L_2022]] - The Usefulness of AI Ethics
- [[Whittaker_M_2021]] - The Steep Cost of Capture
