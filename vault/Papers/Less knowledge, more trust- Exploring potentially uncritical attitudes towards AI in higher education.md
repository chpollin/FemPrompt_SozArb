---
title: Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education
authors:
  - Gabriele Biagini
  - Stefano Cuomo
  - Maria Ranieri
year: Juli 24, 2024
type: journalArticle
url: https://doi.org/10.17471/2499-4324/1337
doi: 10.17471/2499-4324/1337
tags:
  - paper
  - feminist-ai
  - bias-research
date_added: 2026-02-22
date_modified: 2026-02-22
bias_types: []
mitigation_strategies: []
llm_decision: Exclude
llm_confidence: 0.92
llm_categories:
  - AI_Literacies
---

# Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education

## Abstract

L'intelligenza artificiale (IA) ha il potenziale per trasformare vari aspetti delle nostre vite, ma il suo sviluppo è stato accompagnato da numerose preoccupazioni sociali ed etiche. Per comprendere le implicazioni e i meccanismi sottostanti, è essenziale acquisire una comprensione ampia dei suoi benefici e svantaggi. A questo scopo, l'alfabetizzazione all'IA è un fattore fondamentale per promuovere atteggiamenti più consapevoli verso lo sviluppo dell'IA e delle sue implicazioni. Tuttavia, la ricerca sulla literacy all'IA è ancora agli esordi. Per contribuire ai progressi del settore, questo articolo presenta i risultati di uno studio volto a valutare l'alfabetizzazione all'IA degli studenti nel contesto dell'istruzione universitaria, concentrandosi su dei dottorandi. L’indagine sulla loro literacy all’IA è stata condotta su quattro dimensioni: cognitiva, operativa, critica ed etica. I risultati mostrano che, sebbene i partecipanti avessero poca conoscenza dell'IA, erano eccessivamente fiduciosi nelle capacità della tecnologia. Lo studio evidenzia la necessità di un approccio più completo all'alfabetizzazione all'IA, che includa una comprensione più profonda delle sue implicazioni etiche, sociali ed economiche.

## Assessment

**LLM Decision:** Exclude (Confidence: 0.92)
**LLM Categories:** AI_Literacies

## Key Concepts

## Full Text

---
title: "Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education"
authors: ["Gabriele Biagini", "Stefano Cuomo", "Maria Ranieri"]
year: 2024
type: journalArticle
language: en
processed: 2026-02-05
source_file: Biagini_2024_Less_knowledge,_more_trust_Exploring_potentially.md
confidence: 95
---

# Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education

## Kernbefund

Teilnehmende mit geringem KI-Wissen zeigen paradoxerweise höheres Vertrauen in KI-Fähigkeiten über alle getesteten Aufgaben hinweg, was auf den Dunning-Kruger-Effekt hindeutet und die Notwendigkeit umfassender KI-Literalität betont, die ethische und kritische Reflexion einschließt.

## Forschungsfrage

Wie ist das Niveau der KI-Literalität bei Doktorand:innen und gibt es einen Zusammenhang zwischen geringerem Wissen und höherer Vertrauensbereitschaft gegenüber KI-Technologien?

## Methodik

Empirisch: Quantitative Querschnittsstudie mit validiertem Fragebogen zur KI-Literalität (Critical AI Literacy Scale - CAILS) mit 66 italienischen Doktorand:innen aus verschiedenen Programmen, primär Erziehungswissenschaften. Vier Dimensionen gemessen: kognitiv, operativ, kritisch, ethisch.
**Datenbasis:** n=66 italienische Doktorand:innen; Survey-basierte Datenerhebung mit geschlossenen und offenen Fragen; Statistische Analyse mit Student's T-Test für Gruppenvergleiche (Group 1: hohe Literalität n=44; Group 2: geringe Literalität n=22)

## Hauptargumente

- KI-Literalität ist fundamental für kritische und informierte Einstellungen gegenüber KI, doch aktuelle Forschung ist noch in Anfangsstadien und konzeptionelle Definitionen bleiben unklar. Ein umfassendes Framework mit vier Dimensionen (kognitiv, operativ, kritisch, ethisch) ist notwendig.
- Das Phänomen der überoptimistischen KI-Vertrauensbereitschaft bei niedrigem Wissensniveau entspricht dem Dunning-Kruger-Effekt: Personen mit geringerer KI-Kompetenz schätzen ihre Fähigkeiten inkonsistent selbst ein und vertrauen KI unjustifiiert bei sensiblen Aufgaben (Chirurgie, emotionale Unterstützung).
- Doktorand:innen zeigen differenzierte, aber teilweise problematische Haltungen: Hohe Zustimmung zu KI in Bildung (72%) und Forschung (66%), aber kritische Bedenken bezüglich Datenschutz (60% Sorge), Gleichheit und Cybersicherheit (48% Besorgnis). Emotionale Unterstützung wird von 46% abgelehnt.

## Kategorie-Evidenz

### Evidenz 1

Die Studie entwickelt und wendet ein validiertes Framework zur Messung von KI-Literalität an, definiert als 'range of skills that enable critical evaluation and productive collaboration with AI technologies' über vier Dimensionen: 'a Knowledge-related Dimension', 'an Operational Dimension', 'a Critical Dimension' und 'an Ethical Dimension'. Das Paper adressiert 'the need for a more comprehensive approach to AI literacy that encompasses a deeper understanding of its ethical, social and economic implications'.

### Evidenz 2

Das Paper behandelt allgemeine KI-Systeme (nicht generativ), ihre Anwendungen in Notfalldiensten, Bildung, Chirurgie, Nachrichtenberichterstattung, medizinischer und wissenschaftlicher Forschung sowie emotionaler Unterstützung. Es diskutiert 'AI's potential benefits and drawbacks' sowie 'implications and underlying mechanisms' von KI-Entwicklung.

### Evidenz 3

Das Paper adressiert algorithmische Ungerechtigkeit und digitale Ungleichheit durch die Analyse von Bedenken hinsichtlich 'equity and fairness' (41.67% sehen unveränderte Situation), Arbeitsverdängung (62.5% Besorgnis) und Datenschutz als 'societal inequalities' und 'societal and ethical implications' von KI.

### Evidenz 4

Die Studie umfasst verschiedene Doktorandenprogramme mit unterschiedlichen Disziplinen ('mainly but not exclusively, in the field of educational sciences') und anerkennt kulturelle und subjektive Dimensionen von KI-Literalität: 'AI literacy is more than a set of technical abilities but also includes the ability to navigate and modify one's life amid AI's transformations'.

### Evidenz 5

Das Paper behandelt Fairness-Dimensionen durch die ethische Analyse und die Frage von Equity/Fairness in KI-Systemen ('Equity and fairness' als eine von fünf zukünftigen Auswirkungskategorien) und diskutiert die Notwendigkeit, KI-Bias und potenzielle Benachteiligungen zu verstehen: 'educational initiatives need to emphasise not only AI's capabilities but also their limitations and potential biases'.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochrelevant für die Schnittstelle KI und Bildung, insbesondere für die Entwicklung kritischer KI-Kompetenzen im Hochschulbereich. Es hat begrenzte direkte Relevanz für klassische Soziale Arbeit, bietet aber wichtige Erkenntnisse zur Vermittlung von KI-Verständnis in Fachkräfteausbildung und zur Vorbeugung von unkritischem Vertrauen in automatisierte Systeme, das auch Sozialarbeiter:innen gefährden könnte.

**Unique Contribution:** Die Studie identifiziert das Paradoxon des Dunning-Kruger-Effekts im KI-Kontext bei Doktorand:innen und dokumentiert empirisch, dass niedrigere KI-Literalität zu unjustifizierten höheren Vertrauenswerten in KI-Fähigkeiten führt - ein kritischer Befund für die Gestaltung von KI-Bildungsinterventionen.

**Limitations:** Die Studie hat begrenzte Verallgemeinerbarkeit durch kleine, nicht repräsentative Stichprobe (n=66 italienische Doktorand:innen), konzentriert sich auf spezifisches Bildungssetting, beruht auf Selbstangaben (Verzerrungspotenzial), und untersucht nicht die Exposition gegenüber alltäglichen KI-Systemen außerhalb der Akademie.

**Target Group:** Hochschuldozent:innen, Curriculum-Entwickler:innen, Bildungspolitiker:innen, KI-Ethiker:innen, Forscher:innen zur KI-Literalität, sowie indirekt relevante Praktiker:innen in Bereichen, die automatisierte Entscheidungen treffen (einschließlich Sozialarbeiter:innen, die KI-Systeme in ihrer Praxis begegnen)

## Schlüsselreferenzen

- [[Biagini_Cuomo_Ranieri_2023]] - Developing and validating a multidimensional AI literacy questionnaire (CAILS)
- [[Cuomo_Biagini_Ranieri_2022]] - AI Literacy Framework - four dimensions (cognitive, operational, critical, ethical)
- [[Kruger_Dunning_1999]] - Unskilled and unaware of it: Dunning-Kruger effect
- [[Long_Magerko_2020]] - What is AI literacy? Competencies and design considerations
- [[UNESCO_2021]] - AI and education: Guidance for policy makers
- [[Floridi_et_al_2021]] - AI4People - Ethical Framework for Good AI Society
- [[Yi_2021]] - Establishing the concept of AI literacy: cultural and subjective dimensions
- [[Selwyn_2022]] - The future of AI and education: cautionary notes
- [[Ng_Leung_Chu_Qiao_2021]] - Conceptualizing AI literacy: exploratory review
- [[Weber_Pinski_Baum_2023]] - Toward an objective measurement of AI literacy
