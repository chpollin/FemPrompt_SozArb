paper_id,title,author_year,human_decision,agent_decision,disagreement_type,severity,affected_categories,n_affected_categories,human_exclusion_reason,agent_exclusion_reason,agent_confidence,agent_reasoning,annotation_hint,manual_annotation,human_AI_Literacies,agent_AI_Literacies,human_Generative_KI,agent_Generative_KI,human_Prompting,agent_Prompting,human_KI_Sonstige,agent_KI_Sonstige,human_Soziale_Arbeit,agent_Soziale_Arbeit,human_Bias_Ungleichheit,agent_Bias_Ungleichheit,human_Gender,agent_Gender,human_Diversitaet,agent_Diversitaet,human_Feministisch,agent_Feministisch,human_Fairness,agent_Fairness
3,Feminist perspectives on AI: Ethical considerations in algorithmic decision-making,Ahmed (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",8,,"Nur TECHNIK-Kategorie erfüllt (AI_Literacies), aber keine SOZIAL-Kategorie. Paper behandelt KI-Kompetenzentwicklung in Organisationen allgemein, ohne Bezug zu Sozialer Arbeit, Bias, Ungleichheit, Gender oder Fairness.",0.85,"Titel deutet auf AI Literacy Framework hin - klare AI_Literacies-Kategorie. Kein Abstract vorhanden; basierend auf Titel keine Indikation für soziale Dimensionen (Bias, Ungleichheit, Gender, Fairness, Soziale Arbeit). Paper erfüllt nur Technik-Kriterium, nicht Sozial-Kriterium. EXCLUDE nach strikter Logik.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Titel deutet auf AI Literacy Framework hin - klare AI_Literacies-Kategorie. Kein Abstract vorhanden;... | Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein
156,Intersectional Stereotypes in Large Language Models: Dataset and Analysis,Ma (2023),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Fairness",7,,"SOZIAL_OK nicht erfüllt: Keine substantielle Verbindung zu Sozialer Arbeit, kein expliziter Fokus auf Diskriminierung/Ungleichheit, Gender oder Diversität",0.85,"Paper behandelt AI-Vertrauen, Transparenz und Accountability (AI_Literacies, KI_Sonstige, Fairness) sowie Prompting im Design-Kontext. Erfüllt TECHNIK_OK. Fehlt aber SOZIAL_OK: Kein direkter Bezug zu Sozialer Arbeit/Zielgruppen, keine Analyse von Bias/Ungleichheit oder struktureller Benachteiligung. Fairness bezieht sich auf Transparenz-Metriken, nicht auf systematische Diskriminierung.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt AI-Vertrauen, Transparenz und Accountability (AI_Literacies, KI_Sonstige, Fairness) ... | Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Fairness",,Nein,Ja,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Ja
177,LIBRA: Measuring bias of large language model from a local context,Pan (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet",7,,No_social_work_relevance,0.85,"Paper behandelt Trust-Management in AI-Systemen und Fairness durch adaptive Interventionen (TECHNIK: AI_Literacies, KI_Sonstige, Fairness erfüllt). Es befasst sich jedoch nicht mit sozialer Arbeit, Bias/Ungleichheit, Gender, Diversität oder feministischen Perspektiven (SOZIAL nicht erfüllt). Fokus liegt auf allgemeiner Human-AI Collaboration ohne direkten Bezug zu sozialarbeiterischen Kontexten.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt Trust-Management in AI-Systemen und Fairness durch adaptive Interventionen (TECHNIK:... | Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet",,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Ja
200,Introducing Generative Artificial Intelligence into the MSW Curriculum: A Proposal for the 2029 Educational Policy and Accreditation Standards,Rodriguez (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness",7,,Not_relevant_topic,0.6,"Paper behandelt Steerability von LLMs (Generative_KI: Ja, Prompting: Ja). Dies sind Technik-Kategorien. Jedoch fehlt jeglicher Bezug zu sozialen Aspekten (Bias, Fairness, Soziale Arbeit, etc.). Ohne Abstract kann keine substantielle Einschätzung des Inhalts erfolgen, aber auf Basis des Titels liegt ein rein technisches Paper zu LLM-Kontrollierbarkeit vor. TECHNIK_OK, aber SOZIAL nicht erfüllt → Exclude.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt Steerability von LLMs (Generative_KI: Ja, Prompting: Ja). Dies sind Technik-Kategori... | Technik-Differenz: AI_Literacies, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein
145,"AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",Latif (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Fairness",6,,SOZIAL-Kriterium nicht erfüllt,0.95,"Paper adressiert AI Literacy (kritisches Verständnis von KI-Limitations und vertrauensbasierter Reliance), KI_Sonstige (Decision-Support-Systeme), und Fairness (angemessenes Vertrauen, bias-freie Entscheidungen). ABER: Kein direkter Bezug zu Sozialer Arbeit, Bias/Ungleichheit, Gender, Diversität oder feministischer Theorie. Rein HCI-/Human-AI-Interaction-Forschung ohne sozialarbeiterischen oder kritischen Ungleichheits-Fokus. Sozialarbeitsbezug nicht substantiell gegeben.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper adressiert AI Literacy (kritisches Verständnis von KI-Limitations und vertrauensbasierter Reli... | Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Fairness",,Nein,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Ja
152,Künstliche Intelligenz in der Sozialen Arbeit: Grundlagen für Theorie und Praxis,Linnemann (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness",6,,"SOZIAL-Kriterium nicht erfüllt: Keine substantielle Behandlung von Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch oder Fairness",0.95,"Paper erfüllt TECHNIK-Kriterium mit 3 Ja-Kategorien (AI_Literacies: User-Trust-Kompetenz; Generative_KI: LLMs; Prompting: Prompt-Engineering-Vorschläge). Jedoch keine SOZIAL-Kategorien erfüllt: Kein direkter Sozialarbeitsbezug, keine Ungleichheits-, Gender-, Diversitäts-, feministischen oder Fairness-Analysen. Rein kognitive Vertrauensstudie ohne sozialgerechte Dimensionen.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper erfüllt TECHNIK-Kriterium mit 3 Ja-Kategorien (AI_Literacies: User-Trust-Kompetenz; Generative... | Technik-Differenz: KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein
171,Advancing Accountability in AI,OECD (2023),Include,Exclude,Human_Include_Agent_Exclude,3,"Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Diversitaet, Fairness",6,,Not_relevant_topic,0.85,"Das Paper behandelt substantiell AI_Literacies (Vertrauen, Kompetenzen im Umgang mit LLMs) und Generative_KI sowie Prompting-Strategien. Jedoch fehlt vollständig der zweite erforderliche Bereich (Sozial): keine direkte Soziale_Arbeit, keine Bias_Ungleichheit, kein Gender/Diversität/Feminismus/Fairness-Fokus. Es ist eine reine Nutzerpsychologie-Studie zu LLM-Vertrauen ohne sozialen Impact-Fokus. Die Prompt-Engineering-Erwähnung ist eher ein Implikation, nicht substantiell. TECHNIK_OK=Ja, SOZIAL_OK=Nein → Exclude.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Das Paper behandelt substantiell AI_Literacies (Vertrauen, Kompetenzen im Umgang mit LLMs) und Gener... | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Diversitaet, Fairness",,Ja,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein
175,Towards Substantive Equality in Artificial Intelligence: Transformative AI Policy for Gender Equality and Diversity,Ovalle (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch",6,,"TECHNIK erfüllt (AI_Literacies, Prompting, KI_Sonstige, Fairness), aber SOZIAL nicht erfüllt: Kein direkter Bezug zu Sozialer Arbeit, Bias/Ungleichheit, Gender, Diversität oder Feminismus. Paper behandelt algorithmische Transparenz und Vertrauen in allgemeinem organisatorischen Kontext, nicht in sozialarbeiterischer Praxis oder mit explizitem Fokus auf marginalisierte Gruppen/strukturelle Ungleichheit.",0.85,"Paper adressiert AI-Vertrauen, Transparenz und Fairness-Aspekte (TECHNIK-Seite erfüllt). Jedoch fehlt der Sozialarbeitsbezug und kein expliziter Fokus auf Ungleichheit oder Marginalisierung. Allgemeine organisationale Trust-Studie ohne Sozialbereich-Spezifika.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper adressiert AI-Vertrauen, Transparenz und Fairness-Aspekte (TECHNIK-Seite erfüllt). Jedoch fehl... | Technik-Differenz: Prompting | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Ja
180,BBQ: A hand-built bias benchmark for question answering,Parrish (2022),Include,Exclude,Human_Include_Agent_Exclude,3,"Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet, Fairness",6,,Not_relevant_topic,0.85,"Paper untersucht LLM-Fähigkeiten zur Vertrauensanalyse zwischen Individuen. Während Generative_KI (LLMs) relevant ist, fehlt jeglicher substantieller Bezug zu den sozialen Kategorien: kein direkter Sozialarbeitsbezug, keine Bias/Ungleichheit-Analyse, kein Gender-, Diversitäts- oder Fairness-Fokus. Die Vertrauensforschung ist allgemein sozialwissenschaftlich, nicht sozialarbeiterisch spezifisch. TECHNIK_OK, aber SOZIAL_NICHT_OK → Exclude.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper untersucht LLM-Fähigkeiten zur Vertrauensanalyse zwischen Individuen. Während Generative_KI (L... | Technik-Differenz: Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Fairness",,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein
153,More or less wrong: A benchmark for directional bias in LLM comparative reasoning,Liu (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Generative_KI, Prompting, Gender, Diversitaet",5,,Not_relevant_topic,0.85,"Paper erfüllt TECHNIK-Kriterium (AI_Literacies, KI_Sonstige) und SOZIAL-Kriterium (Bias_Ungleichheit, Fairness). JEDOCH: Thema ist klinische Entscheidungsunterstützung im Gesundheitswesen, NICHT Soziale Arbeit. Keine Verknüpfung zu sozialarbeiterischer Praxis, Theorie oder Zielgruppen. Bias/Fairness-Diskussion bezieht sich auf medizinische Kontexte, nicht auf Soziale Arbeit. Daher: außerhalb des Scope des Literaturreviews zu KI in Sozialer Arbeit.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper erfüllt TECHNIK-Kriterium (AI_Literacies, KI_Sonstige) und SOZIAL-Kriterium (Bias_Ungleichheit... | Technik-Differenz: AI_Literacies, Generative_KI, Prompting | Sozial-Differenz: Gender, Diversitaet",,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Ja
163,"Biases in large language models: Origins, inventory and discussion",Navigli (2023),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Bias_Ungleichheit, Gender, Diversitaet, Fairness",5,,Not_relevant_topic,0.85,"Das Paper behandelt LLMs (Generative_KI = Ja) und untersucht deren Fähigkeiten zur Analyse von Vertrauen. Es erfüllt aber KEINE der erforderlichen SOZIAL-Kategorien: Kein Bezug zu Sozialer Arbeit, keine Behandlung von Bias/Ungleichheit, Gender, Diversität, feministischen Perspektiven oder Fairness. Die Studie zu Trust-Reasoning ist rein technisch-kognitiv ausgerichtet, ohne sozialkritischen oder anwendungsbezogenen Fokus auf vulnerable Gruppen oder strukturelle Ungleichheiten.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Das Paper behandelt LLMs (Generative_KI = Ja) und untersucht deren Fähigkeiten zur Analyse von Vertr... | Technik-Differenz: Prompting | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Fairness",,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein
202,"AI Literacy: A Framework to Understand, Evaluate, and Use Emerging Technology",Ruiz (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Prompting, Bias_Ungleichheit, Gender, Diversitaet",5,,No_full_text; nur Titel verfügbar - Klassifikation unter Unsicherheit,0.35,"Der Titel deutet auf LLM-basierte Klassifikation von Mentalhygiene-Daten hin (Generative_KI + KI_Sonstige erfüllt, TECHNIK_OK). Jedoch: kein Abstract verfügbar, daher nicht erkennbar, ob ein substantieller Bezug zu sozialen/ethischen Dimensionen (SOZIAL_OK) besteht. Mental Health ist nicht automatisch Soziale Arbeit. Ohne Volltext: konservative Einstufung, da SOZIAL-Dimensionen nicht verifiable sind.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Der Titel deutet auf LLM-basierte Klassifikation von Mentalhygiene-Daten hin (Generative_KI + KI_Son... | Technik-Differenz: AI_Literacies, Prompting | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet",,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein
121,Evaluating gender bias in large language models via chain-of-thought prompting,Kaneko (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Bias_Ungleichheit, Gender, Fairness",4,,Not_relevant_topic,0.95,"Das Paper behandelt rein technische Aspekte von LLM-Inferenz (Nondeterminismus, Sampling, Reproducibility). Während es Generative KI erwähnt, fehlt jeder soziale Bezug: keine AI Literacies, keine Bias/Fairness-Analyse, keine Bezüge zu Soziale Arbeit, Diversität oder Ungleichheit. Es ist ein rein technisches Konzeptpaper ohne gesellschaftliche, ethische oder pädagogische Dimension.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Das Paper behandelt rein technische Aspekte von LLM-Inferenz (Nondeterminismus, Sampling, Reproducib... | Technik-Differenz: Prompting | Sozial-Differenz: Bias_Ungleichheit, Gender, Fairness",,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein
159,Assessing GPT's bias towards stigmatized social groups: An intersectional case study on nationality prejudice and psychophobia,Mei (2023),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Bias_Ungleichheit, Gender, Diversitaet",4,,Not_relevant_topic,0.85,"Paper behandelt Chatbot-Transparenz und Nutzerwahrnehmung mit Fokus auf AI Literacy (Effekt bei niedriger Vorkenntnis) und Prompting (Transparenz durch Prompt-Engineering). Technische Kriterien erfüllt. Es fehlt jedoch jeglicher Bezug zu sozialen Kategorien: Keine Soziale Arbeit, keine Analyse von Bias/Ungleichheit, kein Gender-, Diversitäts- oder Fairness-Fokus. Reine HCI-Studie ohne Bezug zu marginalizierten Gruppen, struktureller Benachteiligung oder Sozialarbeitspraxis.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt Chatbot-Transparenz und Nutzerwahrnehmung mit Fokus auf AI Literacy (Effekt bei nied... | Technik-Differenz: AI_Literacies | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet",,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein
189,DR.GAP: Mitigating bias in large language models using gender-aware prompting with demonstration and reasoning,Qiu (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Gender, Diversitaet, Fairness",4,,Not_relevant_topic,0.85,"Paper behandelt Fairness in Large Language Models (Generative_KI: Ja, Fairness: Ja, Bias_Ungleichheit: Ja). Jedoch fehlt der erforderliche SOZIAL-Kontext: Es gibt keinen direkten Bezug zu Sozialer Arbeit, Gender-Perspektive, Diversität oder feministischen Ansätzen. Allgemeine Fairness-Diskussionen in KI ohne Sozialarbeitsbezug sind nicht relevant für das Literature Review zu KI und Sozialer Arbeit. TECHNIK-Bedingung erfüllt, aber SOZIAL-Bedingung nicht erfüllt → Exclude.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt Fairness in Large Language Models (Generative_KI: Ja, Fairness: Ja, Bias_Ungleichhei... | Technik-Differenz: Prompting | Sozial-Differenz: Gender, Diversitaet, Fairness",,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Ja
254,Intersectionality in artificial intelligence: Framing concerns and recommendations for action,Ulnicane (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"Gender, Diversitaet, Feministisch, Fairness",4,,Not_relevant_topic,0.85,"Das Paper behandelt algorithmische Systeme (KI_Sonstige: Ja) und Machtungleichgewichte durch Big Tech (Bias_Ungleichheit: Ja). Allerdings fehlt ein direkter Bezug zu Sozialer Arbeit oder deren Praxis/Zielgruppen. Die Analyse fokussiert auf politische Wirtschaft und staatliche Souveränität, nicht auf Sozialbereich. SOZIAL-Bedingung ist nicht erfüllt.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Das Paper behandelt algorithmische Systeme (KI_Sonstige: Ja) und Machtungleichgewichte durch Big Tec... | Sozial-Differenz: Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein
262,Recommendation on the Ethics of Artificial Intelligence,UNESCO (2021),Include,Exclude,Human_Include_Agent_Exclude,3,"AI_Literacies, Soziale_Arbeit, Gender, Feministisch",4,,Not_relevant_topic,0.85,"Das Paper erfüllt die SOZIAL-Bedingung (Bias_Ungleichheit, Diversitaet, Feministisch, Fairness alle Ja) und auch die TECHNIK-Bedingung (KI_Sonstige Ja). Jedoch ist dies eine Keynote-Zusammenfassung von fundamentaler Kritischer Techniktheorie/Philosophie ohne direkten Bezug zu Sozialer Arbeit als Praxis oder Disziplin. Das Literature Review fokussiert auf KI-Anwendungen in der Sozialen Arbeit, nicht auf allgemeine KI-Ethik und Gesellschaftskritik. Benjamin's Werk ist relevant für theoretische Grundlagen, aber nicht spezifisch für das Scopus des Reviews.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Das Paper erfüllt die SOZIAL-Bedingung (Bias_Ungleichheit, Diversitaet, Feministisch, Fairness alle ... | Technik-Differenz: AI_Literacies | Sozial-Differenz: Soziale_Arbeit, Gender, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Nein,Ja,Ja,Ja
188,Prompt engineering techniques for mitigating cultural bias against Arabs and Muslims in large language models: A systematic review,Prakash (2023),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Gender, Diversitaet",3,,No_full_text,0.3,"Titel deutet auf Generative KI und Bias hin, aber ohne Abstract oder Volltext ist die Einordnung spekulativ. Sicher sind: Generative_KI=Ja (ChatGPT/Claude), Bias_Ungleichheit=Ja (Titel erwähnt 'Bias'). ABER: Kein Bezug zu Sozialer Arbeit erkennbar. Die Themen 'ethical dilemmas' sind philosophisch, nicht sozialarbeitsbezogen. Daher TECHNIK_OK (Generative_KI), aber SOZIAL nicht erfüllt (Bias allein ohne Sozialarbeitsbezug reicht nicht, und ohne Text kann nicht überprüft werden, ob tatsächlicher Fokus auf Ungleichheit besteht). Fehlende vollständige Information → Exclusion.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Titel deutet auf Generative KI und Bias hin, aber ohne Abstract oder Volltext ist die Einordnung spe... | Technik-Differenz: Prompting | Sozial-Differenz: Gender, Diversitaet",,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein
168,"Opportunities, challenges and school strategies for integrating generative AI in education",Ng (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"Prompting, Bias_Ungleichheit",2,,Not_relevant_topic,0.85,"Paper behandelt LLM-Vertrauen und individuelle Unterschiede (AI_Literacies, Generative_KI erfüllt). ABER: Kein Bezug zu sozialen Ungleichheiten, Bias, Gender, Diversität, Fairness oder Sozialer Arbeit. Prompting wird nur beiläufig erwähnt ('prompt-engineering'), nicht substantiell behandelt. Psychologische Vertrauensforschung ohne sozialen/kritischen Bezug. SOZIAL-Kriterien nicht erfüllt → Exclude.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt LLM-Vertrauen und individuelle Unterschiede (AI_Literacies, Generative_KI erfüllt). ... | Technik-Differenz: Prompting | Sozial-Differenz: Bias_Ungleichheit",,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Nein
169,The role of artificial intelligence (AI) and machine learning in social work practice,Nuwasiima (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"Soziale_Arbeit, Diversitaet",2,,Wrong_publication_type / Not_relevant_topic,0.85,"Paper behandelt AI-Kompetenzen (Vertrauen, Transparenzverstaendnis) und KI-Sonstige (klinische Entscheidungssysteme) sowie Bias/Fairness. ABER: Fokus liegt auf Healthcare/klinischem Kontext, nicht auf Soziale Arbeit. Keine direkter Bezug zu sozialarbeiterischer Praxis, Theorie oder Zielgruppen. SOZIAL-Kriterium nicht erfuellt: Bias_Ungleichheit und Fairness im Healthcare-Kontext sind nicht spezifisch fuer Soziale Arbeit. Paper adressiert Technik + allgemeine Ethik, aber nicht die sozialen Dimensionen des Literaturreviews (Soziale Arbeit, Gender, Diversitaet, Feministisch).","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt AI-Kompetenzen (Vertrauen, Transparenzverstaendnis) und KI-Sonstige (klinische Entsc... | Sozial-Differenz: Soziale_Arbeit, Diversitaet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Ja
176,AI literacy and trust: A multi-method study of Human-GAI team collaboration,Pan (2025),Include,Exclude,Human_Include_Agent_Exclude,3,"Bias_Ungleichheit, Fairness",2,,SOZIAL-Kriterium nicht erfüllt,0.92,"Paper erfüllt TECHNIK-Kriterium (AI_Literacies: Ja - Nutzer-Kompetenzen/Wissen über KI; Generative_KI: Ja - Chatbot-fokussiert; Prompting: Ja - Transparenz-Strategien für Prompt-Engineering erwähnt). Aber SOZIAL-Kriterium nicht erfüllt: Kein direkter Bezug zu Sozialer Arbeit, keine substantielle Behandlung von Bias, Gender, Diversität, Feminismus oder Fairness. Allgemeine Trust/UX-Studie ohne Fokus auf soziale Ungleichheit oder marginalisierte Gruppen.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper erfüllt TECHNIK-Kriterium (AI_Literacies: Ja - Nutzer-Kompetenzen/Wissen über KI; Generative_K... | Sozial-Differenz: Bias_Ungleichheit, Fairness",,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Nein
219,Can prompt modifiers control bias? A comparative analysis of text-to-image generative models,Shin (2024),Include,Exclude,Human_Include_Agent_Exclude,3,"Diversitaet, Fairness",2,,Not_relevant_topic,0.85,"Paper erfüllt TECHNIK-Bedingung (Generative_KI, Prompting). Jedoch fehlt SOZIAL-Bedingung für Anwendungsgebiet mit sozialem Fokus: Bias_Ungleichheit, Gender und Fairness behandeln allgemeine LLM-Bias, nicht spezifisch Soziale Arbeit, marginalisierte Communities oder sozialarbeiterische Kontexte. Reine KI-Ethik-Studie ohne Sozialarbeitsbezug → Exclude für dieses Review.","KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper erfüllt TECHNIK-Bedingung (Generative_KI, Prompting). Jedoch fehlt SOZIAL-Bedingung für Anwend... | Sozial-Differenz: Diversitaet, Fairness",,Nein,Nein,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja
204,What’s in a name? Auditing large language models for race and gender bias,Salinas (2025),Include,Exclude,Human_Include_Agent_Exclude,3,Diversitaet,1,,"SOZIAL-Bedingung nicht erfüllt: Paper adressiert Bias und Gender in generativen KI-Systemen, hat aber keinen Bezug zu Sozialer Arbeit, marginalisierten Communities oder strukturellen Ungleichheiten im sozialen Kontext. Es ist eine rein technische Studie zu Fairness in LLMs ohne sozialpolitische/sozialarbeiterische Dimension.",0.92,"Paper behandelt Prompting-Strategien zur Reduktion von Gender-Bias in LLMs—klare technische Komponente mit Fairness-Fokus. Allerdings fehlt jeder Bezug zu Sozialer Arbeit, Zielgruppen sozialer Dienste oder strukturellen sozialen Implikationen. Es ist eine Standard-Debiasing-Studie ohne sozialarbeitlichen Kontext.",KRITISCH: Agent übersieht Relevanz | Agent-Begründung: Paper behandelt Prompting-Strategien zur Reduktion von Gender-Bias in LLMs—klare technische Komponen... | Sozial-Differenz: Diversitaet,,Nein,Nein,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Ja,Ja
165,Conceptualizing AI literacy: An exploratory review,Ng (2021),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness",8,Duplicate,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI=Ja, Prompting=Ja, AI_Literacies=Ja durch Fokus auf Bildung und kritisches Verständnis von LLMs) und SOZIAL_OK (Soziale_Arbeit=Ja, direkter Bezug zu Forschung und Praxis in Social Work). Framework für verantwortungsvollen KI-Einsatz mit Dokumentations- und Transparenzanforderungen ist substantiell.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Ja,?,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein
225,AI Creates the Message: Integrating AI Language Learning Models into Social Work Education and Practice,Singer (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",8,Wrong publication type,,0.95,Paper behandelt generative KI (LLMs) mit substantiellem Fokus auf intersektionale Gender-Rassen-Biases. Explizite Bezüge zu Intersektionalitätstheorie (feministische Perspektive nach Crenshaw). Prompting wird als Interventionsstrategie adressiert. Erfüllt beide Bedingungen: TECHNIK (Generative_KI + Prompting) und SOZIAL (Bias_Ungleichheit + Gender + Diversitaet + Feministisch + Fairness).,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type | Technik-Differenz: Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
130,Trustworthy AI and the Logics of Intersectional Resistance,Knowles (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Gender, Feministisch, Fairness",7,Not relevant topic,,0.85,"Paper behandelt substantiell AI_Literacies (user guidelines und training für LLM-Nutzung), Generative_KI (LLM-fokussiert), Prompting (diversity-sensitive prompting techniques explizit genannt) und adressiert Bias_Ungleichheit sowie Diversität (diversity-sensitive approaches). Erfüllt TECHNIK (3 Kategorien) und SOZIAL (2 Kategorien). Kein direkter Sozialarbeitsbezug identifizierbar.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Gender, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Nein
147,Development of the “Scale for the assessment of non-experts’ AI literacy” – An exploratory factor analysis,Laupichler (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Diversitaet, Fairness",7,Not relevant topic,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI, Prompting substantiell behandelt), SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Fairness adressiert). Systematische Review zu Prompt-Engineering-Techniken für Bias-Mitigation gegen arabische/muslimische Minderheiten in LLMs. Direkter Fokus auf kulturelle Diskriminierung und Fairness-Optimierung.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Diversitaet, Fairness",,Ja,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja
210,Exploring opportunities and risks in decision support technologies for social workers: An empirical study in the field of disabled people's services,Schneider (2022),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness",7,Not relevant topic,,0.95,"Paper behandelt substantiell Generative KI (LLMs), Prompting (Chain-of-Thought als zentrale Intervention), Gender-Bias in LLM-Outputs und Fairness-Aspekte (Bias-Reduktion). Erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI + Prompting) und SOZIAL_OK (Bias_Ungleichheit + Gender + Fairness). Experimentelle Evaluationsstudie mit klarem Fokus auf Prompt-Strategien zur Bias-Mitigation.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja
243,AI implementation science for social issues: Pitfalls and tips,Takaoka (2022),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",7,No relevant topic,,0.95,"Das Paper erfüllt beide Bedingungen: TECHNIK: AI_Literacies (Policy-Rahmen für AI-Governance), KI_Sonstige (algorithmische Diskriminierung). SOZIAL: Bias_Ungleichheit (Fokus auf algorithmische Diskriminierung), Gender (explizite intersektionale Genderanalyse), Diversitaet (inklusive Repräsentation), Feministisch (intersektionale Analyse nach Crenshaw-Logik), Fairness (substantive equality vs. formale Fairness). Transformatives Policy-Framework mit starkem Fokus auf strukturelle Gerechtigkeit.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: No relevant topic | Technik-Differenz: AI_Literacies | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
258,Intersectionality in Artificial Intelligence: Framing Concerns and Recommendations for Action,Ulnicane (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, KI_Sonstige, Gender, Diversitaet, Feministisch, Fairness",7,Duplicate,,0.92,"Paper erfüllt TECHNIK-Kriterium durch AI_Literacies (Fokus auf kritische KI-Kompetenzentwicklung), Generative_KI (Erwähnung von Language Models) und SOZIAL-Kriterium durch Bias_Ungleichheit (expliziter Fokus auf Bias-Mechanismen) und Fairness (Verständnis von Fairness als zentrales Element). Empirische Studie mit großer Stichprobe (n=605). Kein Soziale_Arbeit-Bezug erkennbar.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Ja
267,"RETHINKING SOCIAL SERVICES WITH ARTIFICIAL INTELLIGENCE: OPPORTUNITIES, RISKS, AND FUTURE PERSPECTIVES",Unknown (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Diversitaet, Feministisch, Fairness",7,Not relevant topic,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI + Prompting), SOZIAL_OK (Bias_Ungleichheit + Gender + Feministisch + Fairness). Empirische Analyse von Gender-Bias in GPT-4/Copilot-generierten Policies mit intersektionalem Rahmen. Fokus auf Androzentrizität und strukturelle Biases entspricht feministischer Technikforschung. Keine direkte Soziale-Arbeit-Verbindung, aber Policymaking ist relevant für soziale Systeme.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Ja,Nein,Ja
276,Rationalisierung durch Digitalisierung?,Waag (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Feministisch, Fairness",7,Not relevant topic,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK (AI_Literacies: Training zu KI-Konzepten; KI_Sonstige: AI Bias Detection/Mitigation Tools; Fairness: Algorithmen-Fairness) + SOZIAL (Bias_Ungleichheit: Fokus auf Bias Detection; Diversitaet: vulnerable/marginalized stakeholder groups, inklusive AI-Entwicklung; Feministisch: Co-creation mit marginalisierten Gruppen, Machtstrukturen in AI-Design). Substantieller Fokus auf Training zur Befähigung von Non-Technical Stakeholders und kritische Reflexion von Inklusion in AI-Systemen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja
287,Broadening artificial intelligence education in K-12: where to start?,Wong (2020),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Diversitaet, Fairness",7,,,0.92,"Das Paper erfüllt beide Bedingungen: (1) TECHNIK: Generative_KI (Text-to-Image Modelle), Prompting (Analyse von Prompt-Modifizierern zur Bias-Reduktion) → Ja. (2) SOZIAL: Bias_Ungleichheit (explizit: Analyse gesellschaftlicher Biases), Diversitaet (diversity-reflective prompting), Fairness (ethische KI-Entwicklung) → Ja. Empirische Vergleichsstudie mit substantiellem Fokus auf Prompt-Engineering und algorithmischen Bias.","Agent sieht Relevanz, die Expert:innen nicht sehen | Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Diversitaet, Fairness",,Ja,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja
116,Prompting techniques for reducing social bias in LLMs through System 1 and System 2 cognitive processes,Kamruzzaman (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Prompting, Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness",6,Duplicate,,0.85,"Der Titel deutet auf eine Analyse von ChatGPT (generative KI) in der Sozialen Arbeit hin. Dies erfüllt beide notwendigen Bedingungen: TECHNIK (Generative_KI = Ja, da ChatGPT explizit genannt) und SOZIAL (Soziale_Arbeit = Ja, da direkt im Titel). AI_Literacies ist ebenfalls Ja, da es um Kompetenzen/Risiken im Umgang mit ChatGPT geht. Ohne Abstract kann Studientyp nicht genau bestimmt werden.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies, Prompting | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein
128,Data feminism for AI,Klein (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Prompting, KI_Sonstige, Gender, Diversitaet, Feministisch",6,Duplicate,,0.82,"Paper untersucht LLMs (Generative_KI: Ja) systematisch mit 43.200 Prompts (Prompting: Ja, substantiell). Zentrale Ergebnisse adressieren Bias und Malleabilität sozialer Normen (Bias_Ungleichheit: Ja) sowie Fairness-Aspekte bei moralischen Urteilen (Fairness: Ja). TECHNIK und SOZIAL erfüllt → Include. Kein direkter Soziale-Arbeit-Bezug, aber relevante Erkenntnisse zu KI-Systemen und Ungleichheiten.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies, Prompting, KI_Sonstige | Sozial-Differenz: Gender, Diversitaet, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Nein,Ja,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Ja
140,Digitalität und Digitalisierung als Gegenstand der Sozialen Arbeit,Kutscher (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness",6,Not relevant topic,,0.85,"Paper behandelt XAI als Kompetenz- und Transparenzthema (AI_Literacies), mit Fokus auf algorithmische Systeme (KI_Sonstige). Substantielle Thematisierung von Bias/Ungleichheit durch Marginalisierung, Diversität durch explizite Nennung marginalisierter Gruppen und Fairness durch ethische/gerechte Entscheidungsfindung. TECHNIK und SOZIAL erfüllt → Include.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja
151,Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP),Linnemann (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness",6,Duplicate,,0.92,"Paper erfüllt beide Inklusionskriterien: TECHNIK_OK (Generative_KI, Prompting), SOZIAL_OK (Bias_Ungleichheit, Gender, Fairness). Qualitative Studie zu LLM-Bias mit explizitem Gender-Fokus. Prompting wird als Bias-Mitigationsstrategie thematisiert. Kein Sozialarbeitsbezug, keine explizit feministische Theorie.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja
209,Der Einfluss der Algorithmen: Neue Qualitäten durch Big Data Analytics und Künstliche Intelligenz,Schneider (2018),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness",6,Not relevant topic,,0.75,"Das Paper behandelt Large Language Models (Generative_KI=Ja) und fokussiert auf Bias-Mitigation bezüglich Altersmerkmalen (Bias_Ungleichheit=Ja, Diversitaet=Ja, Fairness=Ja). Titel und Fokus auf 'responsible AI development' und 'mitigating bias' sind substantiell. TECHNIK_OK (Generative_KI) + SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Fairness) = Include. Kein direkter Bezug zu Sozialer Arbeit identifizierbar, aber Bias/Fairness-Fokus ausreichend für Inklusion.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja
213,"Indecision on the use of artificial intelligence in healthcare: A qualitative study of patient perspectives on trust, responsibility and self-determination using AI-CDSS",Schneider (2025),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Fairness",6,Not relevant topic,,0.92,"Paper behandelt systematisch Prompting-Strategien (Ja: substantieller Fokus auf 12 Prompt-Varianten) zur Bias-Reduktion in LLMs (Ja: Generative_KI). Bias-Reduktion und Fairness (Ja: beide Kategorien) sind zentrale Themen. TECHNIK-Bedingung erfüllt (Prompting + Generative_KI), SOZIAL-Bedingung erfüllt (Bias_Ungleichheit + Fairness). Kein Bezug zu Sozialer Arbeit oder Gender-spezifisch, kein feministischer Rahmen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Ja
230,In search of artificial intelligence (AI) literacy in teacher education: A scoping review,Sperling (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Gender, Diversitaet, Feministisch, Fairness",6,Not relevant topic,,0.95,"Paper behandelt KI-Governance (KI_Sonstige: Ja) mit explizit feministischer Theorie (intersektionale Analyse nach Crenshaw-Tradition, Feministisch: Ja). Adressiert strukturelle Ungleichheiten, Bias und Gerechtigkeit (Bias_Ungleichheit, Gender, Diversitaet, Fairness alle Ja). Erfüllt beide Bedingungen: TECHNIK (KI_Sonstige) UND SOZIAL (Feministisch + multiple Dimensionen). Theoretischer Policy-Rahmen mit intersektionalem Fokus.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI | Sozial-Differenz: Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
274,Recommendations for social work researchers and journal editors on the use of generative AI and large language models,Victor (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, Soziale_Arbeit, Diversitaet, Feministisch, Fairness",6,Duplicate,,0.92,"Das Paper behandelt substantiell feministische Theorie und Perspektiven im KI-Kontext (KI_Sonstige: Ja). Es adressiert explizit feministische Ansätze, Machtstrukturen und soziale Gerechtigkeit (Feministisch: Ja). Gender und Diversität sind zentral (Gender: Ja, Diversitaet: Ja). Bias/Ungleichheit wird durch die Fokussierung auf Machtrelationen thematisiert (Bias_Ungleichheit: Ja). TECHNIK erfüllt (KI_Sonstige), SOZIAL erfüllt (multiple Kategorien). → Include","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Generative_KI, Prompting | Sozial-Differenz: Soziale_Arbeit, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja
293,Transparency enhances positive perceptions of social artificial intelligence,Xu (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",6,Not relevant topic,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK (AI_Literacies, Generative_KI, KI_Sonstige durch intersektionale AI-Strategien und Chatbot-Beispiel) und SOZIAL (Bias_Ungleichheit, Gender, Diversitaet, Feministisch durch explizite intersektionale und queer-feministische Theorie nach Crenshaw; Fairness durch Data Nutrition Label für Bias-Assessment). Substantiell behandelt.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Ja,Nein,Ja,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
127,Data Feminism for AI,Klein (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, KI_Sonstige, Gender, Diversitaet, Feministisch",5,Duplicate,,0.85,"Das Paper behandelt substantiell Generative KI (Kategorie erfüllt) und adressiert Bias-Amplifikation, Machtungleichgewichte und Fairness-Fragen (Bias_Ungleichheit und Fairness erfüllt). Es erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI=Ja) und SOZIAL_OK (Bias_Ungleichheit=Ja, Fairness=Ja). Keine Sozialen-Arbeit-Perspektive erkennbar, daher diese Kategorie Nein.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies, KI_Sonstige | Sozial-Differenz: Gender, Diversitaet, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Ja
135,Artificial Intelligence (AI) literacy – an argument for AI literacy in education,Kong (2025),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Diversitaet",5,Not relevant topic,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI: LLMs sind zentral), SOZIAL_OK (Bias_Ungleichheit: Analyse von Prejudice in LLM-Outputs; Diversitaet: Fokus auf marginalized groups; Fairness: Implikationen für vertrauenswürdige KI-Nutzung). Drei preregistrierte experimentelle Studien mit klarem Fokus auf Diskriminierung und deren Auswirkungen auf Nutzervertrauen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Diversitaet",,Ja,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Ja
139,"Positionings, challenges, and ambivalences in children's and parents' perspectives in digitalized familial contexts",Kutscher (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, Bias_Ungleichheit, Diversitaet, Fairness",5,Not relevant topic,,0.85,"Das Paper behandelt Prompting (Dipper-Framework mit diversen Prompts) und Generative KI (LLMs) substantiell. Es adressiert Diversity (marginalisierte Gruppen, Perspektivenvielfalt), Bias_Ungleichheit (Verbesserung von Darstellung minorities) und Fairness (faire Output-Generierung). TECHNIK und SOZIAL sind erfüllt. Kein Soziale_Arbeit-Bezug, kein Gender- oder Feministisch-Fokus.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, Prompting | Sozial-Differenz: Bias_Ungleichheit, Diversitaet, Fairness",,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja
162,Feministische Netzpolitik und Künstliche Intelligenz in der politischen Bildung [Feminist network politics and artificial intelligence in political education],Mosene (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Soziale_Arbeit, Gender, Diversitaet, Feministisch",5,Wrong publication type,,0.92,"Paper erfüllt beide Bedingungen: (1) TECHNIK: AI_Literacies (Rahmenmodell für KI-Integration in Praxis), KI_Sonstige (algorithmische Systeme im Sozialbereich), Fairness (Bias-Mitigation, Transparenz). (2) SOZIAL: Soziale_Arbeit (direkter Fokus auf Integrationsstrategie in sozialarbeiterischer Praxis), Bias_Ungleichheit (explizite Behandlung von Bias-Mitigation), Fairness. EPIC-Modell ist substantielle konzeptuelle Beitrag mit Ethik, Policy und Community-Perspektive für KI in Sozialer Arbeit.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type | Technik-Differenz: AI_Literacies | Sozial-Differenz: Soziale_Arbeit, Gender, Diversitaet, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Ja,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Ja
174,Factoring the matrix of domination: A critical review and reimagination of intersectionality in AI fairness,Ovalle (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Gender, Diversitaet",5,Duplicate,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI=Ja, Prompting=Ja) und SOZIAL_OK (Bias_Ungleichheit=Ja, Fairness=Ja). Substantieller Fokus auf Prompt-Engineering-Strategien zur Bias-Reduktion in LLMs. Direkte Behandlung sozialer Bias und Fairness-Ansätze. Nicht auf Soziale Arbeit fokussiert, aber klar KI-Bias-Thematik mit fairness-Implikation.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Gender, Diversitaet",,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Ja
195,Artificial intelligence in social work: Emerging ethical issues,Reamer (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Prompting, KI_Sonstige, Soziale_Arbeit, Gender, Feministisch",5,Duplicate,,0.85,Das Paper untersucht Bias in GPT (Generative_KI: Ja) durch eine intersektionale Fallstudie (Feministisch: Ja - Intersektionalitätsansatz nach Crenshaw). Es thematisiert Diskriminierung gegen stigmatisierte Gruppen (Bias_Ungleichheit: Ja) und Diversität von Gruppen (Diversitaet: Ja). Fairness ist impliziert durch Bias-Analyse. TECHNIK und SOZIAL sind erfüllt → Include.,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Gender, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Nein,Ja,Ja,Ja
201,Ethical issues related to the use of technology in social work practice: A systematic review,Rodríguez-Martínez (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, Soziale_Arbeit, Bias_Ungleichheit, Fairness",5,Not relevant topic,,0.85,"Paper fokussiert auf Prompting-Techniken (substantiell im Titel) und Generative KI (LLMs). Adressiert social bias reduction - direkt relevant für Bias_Ungleichheit und Fairness. TECHNIK erfüllt (Generative_KI + Prompting), SOZIAL erfüllt (Bias_Ungleichheit + Fairness). Kein Soziale_Arbeit-Bezug, aber algorithmische Bias-Reduktion ist relevant für LLM-Fairness insgesamt.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, Prompting | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Ja
246,A systematic review on digital literacy,Tinmaz (2022),Exclude,Include,Human_Exclude_Agent_Include,2,"Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",5,Not relevant topic,,0.95,"Das Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: algorithmische Governance und AI-Systeme sind substantiell adressiert) und SOZIAL_OK (Bias_Ungleichheit, Gender, Diversität und explizit Feministisch durch Intersektionalitätsanalyse nach Crenshaw-Perspektive, Fairness durch Kritik ungleicher AI-Harm-Verteilung). Kritische Analyse von AI Governance aus intersektionaler, feministischer Perspektive mit Fokus auf marginalisierte Gruppen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
273,Recommendations for social work researchers and journal editors on the use of generative AI and large language models,Victor (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, Soziale_Arbeit, Gender, Fairness",5,Duplicate,,0.85,"Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige=Ja, da es sich um Studie zu AI-Development befasst) und SOZIAL_OK (Bias_Ungleichheit=Ja: 'injustices and inequalities'; Fairness=Ja: Responsibility und strukturelle Herausforderungen). Kein Bezug zu Sozialer Arbeit oder feministischer Theorie erkennbar. Empirische Studie mit N=32 Professionals.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: Generative_KI, Prompting | Sozial-Differenz: Soziale_Arbeit, Gender, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Ja
283,Messung von AI Literacy – Empirische Evidenz und Implikationen,Weber (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",5,Not relevant topic,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies: Ja – Framework für KI-Kompetenzen/Werte-Integration; KI_Sonstige: Ja – Systemische Analyse von AI-Biases). SOZIAL_OK (Bias_Ungleichheit: Ja – adressiert Biases und Injustices; Gender: Ja – expliziter Gender-Fokus; Diversitaet: Ja – Inklusion; Feministisch: Ja – intersektionale Feminismus, feministische Theorie; Fairness: Ja – Gerechtigkeit und Equity als zentrale Werte). Praktische Anwendungen (MIRA, EU AI Act) zeigen Substanz.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja
303,Learning About AI: A Systematic Review of Reviews on AI Literacy,Zhang (2025),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Bias_Ungleichheit, Gender, Diversitaet, Fairness",5,,,0.92,"TECHNIK_OK: KI_Sonstige=Ja (algorithmische Systeme und deren Auswirkungen). SOZIAL_OK: Bias_Ungleichheit=Ja (Gender-Bias in 44% der KI-Systeme), Gender=Ja (expliziter Gender-Fokus), Fairness=Ja (Policy-Empfehlungen). Kein direkter Soziale_Arbeit-Bezug erkennbar. Nicht feministisch theoretisch fundiert, aber empirisch-analytisch zu Gender-Bias.","Agent sieht Relevanz, die Expert:innen nicht sehen | Technik-Differenz: AI_Literacies | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet, Fairness",,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja
131,Large language models are zero-shot reasoners,Kojima (2022),Exclude,Include,Human_Exclude_Agent_Include,2,"Prompting, Bias_Ungleichheit, Gender, Diversitaet",4,Not relevant topic,,0.92,"Paper untersucht systematisch Bias und Diskriminierung in LLM-generierten Narrativen von queeren Personen. Erfüllt TECHNIK-Kriterium (Generative_KI: Fokus auf LLM-Outputs) und SOZIAL-Kriterium (Bias_Ungleichheit: Stereotypisierung marginalisierter Gruppen; Gender: queere Identitäten; Diversitaet: Repräsentation von LGBTQ+-Personen in KI-Systemen). Keine explizite feministische Theorie erkannt, daher Feministisch=Nein.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Prompting | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet",,Nein,Nein,Ja,Ja,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein
183,A Literature Review of Digital Literacy over Two Decades,Peng (2022),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Generative_KI, Prompting, Soziale_Arbeit",4,Not relevant topic,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI=Ja, Prompting=Ja, AI_Literacies=Ja durch Fokus auf Wissen/Kompetenzen für Forschende) und SOZIAL_OK (Soziale_Arbeit=Ja durch expliziten Bezug zu Social-Work-Forschung und -Praxis). Entwickelt Framework für KI-Einsatz in Sozialarbeit mit Empfehlungen für Transparenz, Dokumentation und kontinuierliche Bildung.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, Generative_KI, Prompting | Sozial-Differenz: Soziale_Arbeit | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Nein,Nein
278,Measuring user competence in using artificial intelligence: validity and reliability of artificial intelligence literacy scale,Wang (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Bias_Ungleichheit, Diversitaet, Feministisch, Fairness",4,Not relevant topic,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies, KI_Sonstige, Fairness behandeln KI-Systeme und Kompetenzentwicklung). SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Feministisch durch intersektionale Perspektive, expliziter Fokus auf Machtstrukturen und marginalisierte Gruppen). Intersektionalität ist feministische Theorie (Crenshaw). Framework für verantwortungsvolle AI-Entwicklung mit gesellschaftlichem Kontext.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Sozial-Differenz: Bias_Ungleichheit, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja
284,"Discriminating Systems: Gender, Race, and Power in AI",West (2023),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, Prompting, KI_Sonstige, Fairness",4,,,0.95,"Paper behandelt Generative KI (Bildgeneratoren) mit substantiellem Fokus auf Prompt-Engineering durch automatisierte Prompt-Rewriting. Adressiert demografische Bias-Reduktion explizit durch Gender-, Ethnizität- und Altersrepräsentation. Fairness-Metriken zur Bias-Messung zentral. TECHNIK erfüllt (Generative_KI + Prompting), SOZIAL erfüllt (Bias_Ungleichheit + Gender + Diversitaet + Fairness). Keine feministische Theorie-Nutzung, kein SA-Bezug.","Agent sieht Relevanz, die Expert:innen nicht sehen | Technik-Differenz: Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Fairness",,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Ja
137,How AI hype impacts the LGBTQ+ community,Kumar (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"Generative_KI, KI_Sonstige, Feministisch",3,Not relevant topic,,0.92,"Paper erfüllt TECHNIK-Kriterium (Generative_KI: LLMs) und SOZIAL-Kriterium (Bias_Ungleichheit, Gender, Diversitaet, Fairness). Systematische Analyse von sozialen Biases in LLMs mit Fokus auf Geschlecht, Ethnie, sexuelle Orientierung, Alter und Religion. Behandelt Messungs- und Mitigationsstrategien. Nicht feministisch (keine explizite feministische Theorie), nicht zu Sozialer Arbeit.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: Generative_KI, KI_Sonstige | Sozial-Differenz: Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Ja,Ja
292,What is Feminist AI?,Wudel (2025),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Feministisch, Fairness",3,Duplicate,,0.88,"Paper erfüllt BEIDE Bedingungen: TECHNIK (AI_Literacies: digitale Literacy als Intervention + KI_Sonstige: Bias in Hiring/Healthcare/Finance-Systemen) UND SOZIAL (Gender: expliziter Gender-Bias-Fokus; Bias_Ungleichheit: Underrepresentation von Frauen; Diversitaet: Women-led AI projects; Fairness: algorithmic bias combating). Substantielle Behandlung von Gender und Bias in KI-Systemen. Keine explizit feministische Theorie erkennbar, daher Feministisch=Nein.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies | Sozial-Differenz: Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Ja
291,What is Feminist AI?,Wudel (2025),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, Fairness",2,Duplicate,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: NLP/ML für Datenanalyse; AI_Literacies: feministische digitale Kompetenzen) und SOZIAL_OK (Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness substantiell behandelt). Empirische Analyse von 172K Tweets zu Geschlechter-Perspektiven auf algorithmischen Bias mit explizit feministischem Rahmen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies | Sozial-Differenz: Fairness",,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Ja
299,Tensions in digital welfare states: Three perspectives on care and control,Zakharova (2024),Exclude,Include,Human_Exclude_Agent_Include,2,"AI_Literacies, KI_Sonstige",2,Not relevant topic,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK durch AI_Literacies (Framework für KI-Kompetenzen/ethische Prinzipien) und KI_Sonstige (ML-Design, algorithmische Systeme). SOZIAL_OK durch Feministisch (explizite Data Feminism Theorie nach D'Ignazio), Bias_Ungleichheit (Fokus auf diskriminatorische Systeme), Gender (Geschlechterperspektive), Diversitaet (Pluralismus, marginalisierte Gruppen), Fairness (gerechte KI-Entwicklung). Substantielle Behandlung aller Dimensionen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies, KI_Sonstige",,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Nein,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
136,Feministische KI – Künstliche Intelligenz für alle? [Feminist AI – Artificial intelligence for everyone?],Kubes (2024),Exclude,Include,Human_Exclude_Agent_Include,2,Generative_KI,1,Wrong publication type,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK (Generative_KI + KI_Sonstige: LLM-basierte Entscheidungssysteme), SOZIAL (Bias_Ungleichheit, Gender, Diversitaet, Feministisch: intersektionale Analyse von Geschlechts- und Rassenbias). Explizit intersektionales Design nach Crenshaw-Ansatz (Gender × Rasse). Substanzielle empirische Analyse mit sozialen Implikationen für algorithmic fairness.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type | Technik-Differenz: Generative_KI",,Nein,Nein,Nein,Ja,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja
256,Artificial Intelligence and Intersectionality,Ulnicane (2024),Exclude,Include,Human_Exclude_Agent_Include,2,Fairness,1,Duplicate,,0.95,"Das Paper behandelt substantiell algorithmische Fairness und Bias in ML-Systemen (KI_Sonstige, Fairness). Es greift EXPLIZIT auf Crenshaw's intersektionale Theorie zurück und analysiert Diskriminierungsmechanismen aus intersektionaler Perspektive (Feministisch, Bias_Ungleichheit, Gender, Diversitaet). TECHNIK-Bedingung erfüllt (KI_Sonstige=Ja), SOZIAL-Bedingung erfüllt (Bias_Ungleichheit, Gender, Diversitaet, Feministisch = alle Ja). Include-Schwelle erreicht.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Sozial-Differenz: Fairness",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Ja
257,Intersectionality in Artificial Intelligence: Framing Concerns and Recommendations for Action,Ulnicane (2024),Exclude,Include,Human_Exclude_Agent_Include,2,AI_Literacies,1,Duplicate,,0.92,"Paper behandelt substantiell AI Literacy durch feministische Perspektive (Kubes, Gender-kritisch). Analysiert KI-Anwendungen im Kontext Bias (androzentrisch, eurozentrisch, kapitalistisch-patriarchal), Geschlechterperspektive und Inklusion. Praktischer Bezug durch Curriculum und Workshops. Beide Bedingungen erfüllt: TECHNIK (AI_Literacies, KI_Sonstige), SOZIAL (Feministisch, Gender, Bias_Ungleichheit, Diversitaet).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Technik-Differenz: AI_Literacies",,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Nein
259,Intersectionality in artificial intelligence: Framing concerns and recommendations for action,Ulnicane (2024),Exclude,Include,Human_Exclude_Agent_Include,2,Fairness,1,Duplicate,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK (KI_Sonstige: algorithmische Systeme für Recruitment/Resume-Screening) und SOZIAL (Bias_Ungleichheit, Gender, Diversitaet: explizite Analyse von Rassismus und Geschlechterdiskriminierung; Feministisch: intersektionale Analyse nach Crenshaw-Logik; Fairness: algorithmic fairness in hiring). Substanzielle empirische Studie mit klarem intersektionalem Fokus.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate | Sozial-Differenz: Fairness",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Ja
270,"Introduction to the digital welfare state: Contestations, considerations and entanglements",van Toorn (2024),Exclude,Include,Human_Exclude_Agent_Include,2,AI_Literacies,1,Not relevant topic,,0.82,"Paper behandelt kritische AI Literacies (TECHNIK) und thematisiert strukturelle Ungleichheiten bezüglich Rasse, Geschlecht und Arbeit (SOZIAL). Expliziter Fokus auf Bias/Ungleichheit und Gender. Kritische Perspektive auf Strukturen deutet auf feministische Ansätze hin. Beide Bedingungen erfüllt → Include.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic | Technik-Differenz: AI_Literacies",,Nein,Ja,Nein,Nein,Nein,Nein,,Ja,,Nein,,Ja,,Ja,,Nein,,Ja,,Nein
4,Feminist Perspectives on AI: Ethical Considerations in Algorithmic Decision-Making,Ahmed (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper adressiert zentral AI-Kompetenzen von Fachkräften (AI_Literacies: Ja - Kompetenzrahmen für Jugendhilfe), behandelt Generative AI (Ja - explizit Gen Z und generative Tools), hat direkten Bezug zu Sozialarbeit/Jugendhilfe (Ja - Youth Workers, Jugendhilfesektor). Empirische Studie mit Fokusgruppen und Interviews. Beide Bedingungen erfüllt: Technik (AI_Literacies + Generative_KI) UND Sozial (Soziale_Arbeit).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Ja,,Nein,,Nein,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
34,A formal account of AI trustworthiness: Connecting intrinsic and perceived trustworthiness in an operational schematization,Bisconti (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper erfüllt beide Kriterien: (1) TECHNIK: KI_Sonstige=Ja (NLP für Risikobewertung, algorithmische Systeme im Sozialbereich); (2) SOZIAL: Soziale_Arbeit=Ja (Child Protective Services), Bias_Ungleichheit=Ja (racial bias, automated discrimination), Diversitaet=Ja (Black/Latinx families), Fairness=Ja (bias in risk scoring). Empirische Studie mit substantiellem Fokus auf diskriminatorische Auswirkungen von ML-Systemen in der Jugendhilfe.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Ja,,Ja,,Nein,,Ja,,Nein,,Ja
51,Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Health Care Professionals,Choudhury (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Paper behandelt KI-Kompetenzen und -Integration (AI_Literacies) sowie allgemeine KI-Governance (KI_Sonstige) im Kontext sozialer Innovationen und Dienstleistungen (Soziale_Arbeit). PRISM-Framework adressiert direkt Organisationen in sozialen Sektoren mit Readiness-Assessments. TECHNIK_OK (AI_Literacies + KI_Sonstige) und SOZIAL_OK (Soziale_Arbeit) erfüllt. Framework-Dokument ohne explizite Bias-, Gender-, oder Fairness-Fokussierung.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
55,The influence of mental state attributions on trust in large language models,Colombatto (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Paper erfüllt TECHNIK- und SOZIAL-Kriterien: (1) Generative_KI (LLM-basierter AI Coach), Prompting (strukturiertes Prompting für reflektive Praxis), AI_Literacies (Entwicklung von Self-Reflection-Kompetenzen). (2) Soziale_Arbeit (öffentliche Verwaltung, human services context, Kompetenzentwicklung). Empirische User Study mit klarem Fokus auf KI-gestützte Professionalisierung im sozialen Sektor.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Ja,,Ja,,Nein,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
60,Measuring and identifying factors of individuals' trust in large language models,De Duro (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,Systematic Review mit substanziellem Fokus auf AI Literacy und Computational Thinking in der Sozialen Arbeit (AI_Literacies: Ja). Direkter Bezug zu sozialarbeiterischer Praxis und Profession via Staub-Bernasconi's Triple Mandate (Soziale_Arbeit: Ja). Thematisiert auch algorithmische Systeme/KI-Systeme generell (KI_Sonstige: Ja). TECHNIK und SOZIAL beide erfüllt → Include.,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
80,"Bias, accuracy, and trust: Gender-diverse perspectives on large language models",Gaba (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Das Paper adressiert algorithmic decision-making in Sozialarbeit (KI_Sonstige + Soziale_Arbeit). Der Titel hebt die Competency/Critique-Dilemma hervor, was auf AI Literacies verweist. Bias, Fairness und ethische Bedenken in Algorithmen sind zentral (Bias_Ungleichheit + Fairness). TECHNIK erfüllt (3x Ja), SOZIAL erfüllt (4x Ja). Inklusion gerechtfertigt.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Ja,,Ja,,Nein,,Nein,,Nein,,Ja
82,Bias and fairness in large language models: A survey,Gallegos (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper behandelt substantiell KI-Kompetenzen (AI_Literacies) und generative KI im MSW-Curriculum. Direkter Bezug zu Sozialer Arbeit (Ausbildung, Akkreditierungsstandards). Adressiert Bias, Transparenz und Fairness als zentrale Themen für verantwortungsvolle AI-Nutzung im Kontext von Klientenschutz und Equity. Erfüllt beide Bedingungen: TECHNIK (AI_Literacies + Generative_KI) und SOZIAL (Soziale_Arbeit + Bias_Ungleichheit + Fairness).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Ja,,Nein,,Nein,,Ja,,Ja,,Nein,,Nein,,Nein,,Ja
94,Artificial intelligence in social work: An EPIC model for practice,Goldkind (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Das Paper behandelt KI in der Sozialen Arbeit und adressiert dabei sowohl Kompetenzentwicklung (AI Literacies: reflektierte Implementationsstrategien, professioneller Diskurs) als auch allgemeine KI/algorithmische Systeme (KI_Sonstige) in sozialarbeiterischen Praxisfeldern (Soziale_Arbeit: direkter Bezug zur Praxis). Beide Bedingungen (TECHNIK + SOZIAL) sind erfüllt → Include. Bias/Fairness nicht substantiell behandelt basierend auf Abstract.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
95,Artificial intelligence in social work: An EPIC model for practice,Goldkind (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies, Generative_KI, Prompting sind substantiell) + SOZIAL_OK (Soziale_Arbeit durch expliziten Hochschulbezug zur Soziale-Arbeit-Ausbildung). Prompting als metakognitive Schlüsselkompetenz ist Kernthema. Curriculare Integration in Soziale Arbeit direkt adressiert. Konzept/Werkstattbericht, kein empirisch-experimenteller Nachweis.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Ja,,Ja,,Nein,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
98,Künstliche Intelligenz in der Sozialen Arbeit – Zwischen Bedenken und Optionen,Gravelmann (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper erfüllt TECHNIK-Bedingung: AI_Literacies (Ja - untersucht digitale Kompetenzen und KI-Akzeptanz von Fachkräften) und KI_Sonstige (Ja - behandelt KI-Einsatz in Organisationen). Erfüllt SOZIAL-Bedingung: Soziale_Arbeit (Ja - direkter Fokus auf KI-Akzeptanz und Praxis in der Sozialen Arbeit, Bedenken zu Datenschutz und ethischen Herausforderungen). Empirische Studie mit Berufseinsteiger:innen. Inklusion berechtigt.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Ja,,Nein,,Nein,,Nein,,Nein,,Nein
120,Debiasing prompts for gender bias in large language models,Kaneko (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Other,,0.92,"Das Paper erfüllt beide Bedingungen: TECHNIK: AI_Literacies (digitale Kompetenzen zur Empowerment), KI_Sonstige (algorithmische Systeme in Recruitment, Healthcare, Finance). SOZIAL: Gender (expliziter Gender-Bias-Fokus), Bias_Ungleichheit (Diskriminierung durch biased datasets und unter-representation), Diversitaet (Inklusion in AI-Entwicklung), Fairness (Bias-Mitigation). Kein explizit feministischer Rahmen erkennbar, aber substantielle Behandlung von Gender und Ungleichheit.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Other",,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Nein,,Ja
191,Gender Bias in Artificial Intelligence: Empowering Women Through Digital Literacy,Quaid-i-Azam University (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.72,"Das Paper behandelt Bias-Mitigation in LLMs mit Fokus auf altersbedingte Diskriminierung. Generative_KI (LLMs), Bias_Ungleichheit (Age Bias), Diversitaet (Age-related groups), und Fairness (Debiasing-Strategien) sind substantiell adressiert. TECHNIK_OK (Generative_KI=Ja) und SOZIAL_OK (Bias_Ungleichheit=Ja, Diversitaet=Ja, Fairness=Ja) erfüllt. Ohne Abstract ist Zuordnung unsicher, aber Titel deutet auf relevantes Thema hin.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Ja,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja
192,The Algorithmic Auditing Landscape: A Social Justice Approach,Raji (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Other,,0.75,"Das Paper adressiert explizit Bias-Mitigation in KI-generierten Narrativen mit Fokus auf Gender und Ethnizität. Generative_KI (narratives generation), Bias_Ungleichheit (gender and ethnicity bias), Gender (expliziter Gender-Fokus), Diversitaet (ethnicity representation) und Fairness (bias mitigation) sind substantiell behandelt. TECHNIK (Generative_KI) und SOZIAL (Bias_Ungleichheit, Gender, Fairness) sind erfüllt → Include. Confidence begrenzt durch fehlenden Abstract und unklaren Studientyp.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Other",,,Nein,,Ja,,Nein,,Nein,,Nein,,Ja,,Ja,,Ja,,Nein,,Ja
198,How can feminism inform AI governance in practice?,Ricaurte (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Wrong publication type,,0.85,"BBQ ist ein etablierter Benchmark für Bias-Evaluationen in QA-Systemen (KI-Sonstige: Ja; Generative_KI: Ja, da oft für LLM-Evaluation genutzt). Das Paper adressiert substantiell Bias, Fairness und Diversität mit explizitem Gender-Fokus. Keine Soziale_Arbeit. Technik+Sozial erfüllt → Include.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type",,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Nein,,Ja
211,Das verflixte Problem mit Klassifikationen: Zum Einfluss der Digitalisierung auf die Soziale Diagnostik in der Sozialen Arbeit,Schneider (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,No full text,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI + Prompting substantiell behandelt), SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Fairness adressiert). Systematische Review zu Prompt-Engineering-Techniken für Bias-Mitigation gegen Arabs/Muslims in LLMs mit quantifizierten Ergebnissen. Fokus auf kulturelle Repräsentation und algorithmische Fairness. Kein direkter Sozialarbeitsbezug, aber relevantes Anwendungsfeld für diskriminierungssensible KI-Nutzung.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: No full text",,,Nein,,Ja,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja
212,"AI for decision support: What are possible futures, social impacts, regulatory options, ethical conundrums and agency constellations?",Schneider (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Wrong publication type,,0.92,"Paper erfüllt TECHNIK-Kriterium: Fokus auf Generative KI (ChatGPT-3.5/GPT-4), substantielle Analyse von Prompting-Strategien zur Bias-Reduktion. Erfüllt SOZIAL-Kriterium: Explizite Behandlung von Bias (kulturelle Stereotype), Diversität (diversity-sensitive prompts) und Fairness (Bias-Mitigation-Strategien). Empirische Studie mit drei experimentellen Phasen.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type",,,Nein,,Ja,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja
215,Akzeptanz von KI und organisationale Rahmenbedingungen in der Sozialen Arbeit,Schönauer (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Paper behandelt algorithmische Systeme und deren Schäden (KI_Sonstige=Ja). Community-geleiteter Ansatz zur fairen KI adressiert Fairness, Bias/Ungleichheit und Diversität. Queer-Fokus involviert Gender-Perspektive und intersektionale Analysen (feministisch). Erfüllt beide Bedingungen: Technik (KI_Sonstige) + Sozial (Bias, Gender, Diversität, Fairness, Feministisch).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
217,Gender Bias in Artificial Intelligence: Empowering Women Through Digital Literacy,Shah (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Paper erfüllt TECHNIK-Kriterien (AI_Literacies für KI-Kompetenzen/Beteiligung; KI_Sonstige für allgemeine KI-Entwicklung; Fairness für genderinklusive/faire KI-Systeme) und SOZIAL-Kriterien (Gender explizit im Titel; Bias_Ungleichheit durch Menschenrechtsfokus; Diversitaet durch globale Kooperation und Expertinnenbeteiligung marginalisierter Gruppen). Feministisch=Nein, da keine explizite feministische Theorie erkennbar ist.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Nein,,Ja
224,Feminist Data Set,Sinders (2017),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Wrong publication type,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK (KI_Sonstige: algorithmische Systeme in Robotik, HR-Tools) und SOZIAL (Bias_Ungleichheit, Gender, Diversitaet, Feministisch: Intersektionalität ist etablierter feministischer Forschungsrahmen nach Crenshaw; Fairness). Substantielle Behandlung von Vorurteilen in KI-Systemen und struktureller Benachteiligung.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
232,Mitigating trust-induced inappropriate reliance on AI assistance,Srinivasan (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.85,"Der Bericht adressiert algorithmische Diskriminierung (KI_Sonstige: Ja) und behandelt substantiell Bias/Ungleichheit sowie Fairness im Kontext von Antidiskriminierungsrecht. Er erfüllt beide Bedingungen (TECHNIK + SOZIAL) und ist damit included, obwohl er keinen direkten Soziale-Arbeit-Bezug hat.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Nein,,Nein,,Ja
233,Mitigating trust-induced inappropriate reliance on AI assistance,Srinivasan (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.92,"Paper analysiert EU AI Act durch die Linse von Geschlechtergerechtigkeit und Nichtdiskriminierung. TECHNIK erfüllt: KI_Sonstige (algorithmische Systeme reguliert durch AI Act). SOZIAL erfüllt: Bias_Ungleichheit (Geschlechterverzerrungen, Diskriminierungsrisiken), Gender (expliziter Gender-Fokus), Fairness (Bias-Audits, grundrechtliche Folgenabschätzungen). Keine Soziale_Arbeit, kein expliziter feministischer Theorierahmen erkennbar.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Nein,,Nein,,Ja
237,What large language models know and what people think they know,Steyvers (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.92,"Paper behandelt KI/ML-Systeme (KI_Sonstige: mathematische Fairness-Metriken für Klassifikation). Substantieller Fokus auf intersektionale Fairness und algorithmischen Bias (Bias_Ungleichheit). Intersektionale Analyse nach Crenshaw ist explizit feministisches Konzept (Feministisch). Fairness-Metriken sind Kernthema (Fairness). Diversität durch Fokus auf Untergruppen und marginalisierte Intersektionen adressiert (Diversitaet). Erfüllt TECHNIK (KI_Sonstige) + SOZIAL (Bias_Ungleichheit, Feministisch, Fairness, Diversitaet).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja
238,CAIL – Critical AI Literacy: Kritische Technikkompetenz für konstruktiven Umgang mit KI-basierter Technologie in Betrieben,Strauß (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Not relevant topic,,0.95,"Das Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies, KI_Sonstige) durch Framework-Entwicklung für KI-Kompetenzentwicklung und Machtanalyse in KI-Systemen. SOZIAL_OK (Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness) durch explizite feministische Methodologie nach intersektionalem Ansatz, Bekämpfung struktureller Ungleichheiten und Fairness-Fokus. Das Paper entwickelt substantiell einen feministischen Rahmen für KI-Governance.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic",,Ja,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
239,Homoglyph unlearning: A novel approach to bias mitigation,Struppek (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Other,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: algorithmische Diskriminierungssysteme), SOZIAL_OK (Bias_Ungleichheit + Fairness: systematische Analyse von Diskriminierungstypen, Regelungsansätze, strukturelle Ungleichheiten). Kein direkter Sozialarbeitsbezug, daher nicht als SA-Paper klassifiziert. Substantieller Fokus auf algorithmische Fairness und Bias-Analyse.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Other",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Nein,,Nein,,Ja
249,Shaping feminist artificial intelligence,Toupin (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies, KI_Sonstige) + SOZIAL_OK (Bias_Ungleichheit, Gender, Feministisch, Fairness). Behandelt substantiell feministische Perspektive auf KI (intersektional), Gender-Bias in KI-Systemen, AI-Literacy in politischer Bildung. Kein Sozialarb.-Bezug, daher nicht in dieser Kategorie.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Nein,,Ja,,Ja
250,Shaping feminist artificial intelligence,Toupin (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper behandelt substantiell feministische Perspektiven auf KI-Entwicklung (Feministisch: Ja), thematisiert Gender-Perspektiven und Geschlechtergerechtigkeit (Gender: Ja), adressiert Diversität und Inklusion durch intersektionale Teams und Community-Partizipation (Diversitaet: Ja), diskutiert Bias und Ungleichheit (Bias_Ungleichheit: Ja), und entwickelt KI-Kompetenzen und Methodologien (AI_Literacies: Ja). Erfüllt beide TECHNIK- und SOZIAL-Kriterien.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
251,Shaping feminist artificial intelligence,Toupin (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Das Paper erfüllt beide Bedingungen: TECHNIK-Seite mit AI_Literacies (kritische Kompetenzentwicklung), Generative_KI (Chatbot-Design), Prompting (explizit critical prompting practices), und KI_Sonstige (Datensammlung, Training, Algorithmenauswahl). SOZIAL-Seite mit starkem Feministisch-Fokus (explizit feministische und intersektionale Perspektive), Bias_Ungleichheit (Protest gegen biased AI), Gender und Diversitaet (community-based approach). Substanzielle Behandlung aller Kategorien.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Ja,,Ja,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
253,Trust in artificial intelligence–based clinical decision support systems among health care workers: Systematic review,Tun (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK (AI_Literacies, Prompting) + SOZIAL (Feministisch, Gender, Bias_Ungleichheit, Diversitaet). Explizit feministische Theorie (Rahmenwerk mit 6 Kategorien), Fokus auf Design und Prompting-Praktiken sowie Geschlechterperspektive auf KI-Systeme. Typen-orientierter Literaturreview mit substanziellem feministischem Ansatz.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Ja,,Nein,,Ja,,Nein,,Nein,,Ja,,Ja,,Ja,,Ja,,Nein
260,Intersectionality in Artificial Intelligence: Framing Concerns and Recommendations for Action,Ulnicane (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: analysiert AI-Systeme wie Voice Assistants, Robots, Hiring Tools). SOZIAL_OK (Bias_Ungleichheit: Diskriminierung durch homogene Dev-Teams; Gender + Diversitaet: mehrere Diskriminierungsformen; Feministisch: explizite Anwendung von Crenshaw's Intersektionalitätstheorie). Substantielle intersektionale Analyse von strukturellen KI-Ungleichheiten.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Ja,Nein,Nein
261,Artificial Intelligence and gender equality,UN Women (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Wrong publication type,,0.85,Paper behandelt substantiell AI Literacy durch teacher education und co-discovery-Ansätze (TECHNIK erfüllt). Expliziter Fokus auf kritische Examination von AI's power dynamics und social justice implications erfüllt Bias_Ungleichheit-Kategorie (SOZIAL erfüllt). Beide Bedingungen der Inklusionskriterien sind erfüllt.,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type",,,Ja,,Nein,,Nein,,Nein,,Nein,,Ja,,Nein,,Nein,,Nein,,Nein
263,Women4Ethical AI: Global cooperation for gender-inclusive AI,UNESCO (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Wrong publication type,,0.95,Das Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige=Ja: kritische Analyse von KI-Systemen und deren Entwicklung) UND SOZIAL_OK (Bias_Ungleichheit=Ja: Fokus auf Gender Bias in AI; Gender=Ja: expliziter Gender-Fokus; Diversitaet=Ja: Unterrepräsentation von Frauen; Feministisch=Ja: verwendet feministische Theorie und Kritik von Machtstrukturen). Theoretisches Paper mit substantiellem feministischem Anspruch.,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Wrong publication type",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Nein
265,,Unknown (),Exclude,Include,Human_Exclude_Agent_Include,2,,0,No full text,,0.85,Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies Ja: Pedagogisches Framework für kritische KI-Kompetenzentwicklung; Prompting Ja: Expliziter Fokus auf 'critical prompting' in Explore-Phase). SOZIAL_OK (Bias_Ungleichheit Ja: Substantielle Behandlung von Bias-Erkennung und Sichtbarmachung von Diskriminierung in KI-Outputs). Kein Bezug zu Sozialer Arbeit oder explizit feministischer Theorie; daher nur diese Kategorien Ja.,"Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: No full text",,,Ja,,Nein,,Ja,,Nein,,Nein,,Ja,,Nein,,Nein,,Nein,,Nein
268,Artificial Intelligence in Social Work: An EPIC Model for Practice,Unknown (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Das Paper behandelt substantiell feministische Perspektiven auf KI (KI_Sonstige: Ja), thematisiert Gender-Bias und Machtdynamiken in AI-Systemen (Bias_Ungleichheit: Ja, Gender: Ja) und nutzt explizit feministische Theorie als Analyserahmen (Feministisch: Ja). Erfüllt beide Bedingungen: TECHNIK (KI_Sonstige) und SOZIAL (Bias_Ungleichheit, Gender, Feministisch).","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Nein,,Ja,,Nein
279,Algorithmic discrimination: examining its types and regulatory measures with emphasis on US legal practices,Wang (2024),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Not relevant topic,,0.95,"Das Paper behandelt substantiell AI Fairness und Bias/Ungleichheit im KI-Kontext (KI_Sonstige erfüllt Technik-Bedingung). Bias_Ungleichheit, Diversitaet und Fairness sind zentrale Themen. Explizite feministische Perspektive durch Bezug zu Crenshaw's Intersectionality-Framework und kritische Analyse von Machtstrukturen (Feministisch = Ja). Beide Bedingungen (Technik + Sozial) erfüllt → Include.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Not relevant topic",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja
282,Multilingual Prompting for Improving LLM Generation Diversity,Wang (2025),Exclude,Include,Human_Exclude_Agent_Include,2,,0,Duplicate,,0.95,"Das Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: Ja - behandelt AI-Systeme im Allgemeinen), SOZIAL_OK (Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness alle Ja). Explizit feministische Arbeit (D'Ignazio ist Autorin von Data Feminism), intersektionale Perspektive auf KI-Systeme, Fokus auf ungleiche Machtbeziehungen und Gerechtigkeit. Substantielle Behandlung aller relevanten Kategorien.","Agent sieht Relevanz, die Expert:innen nicht sehen | Human-Exclusion: Duplicate",,,Nein,,Nein,,Nein,,Ja,,Nein,,Ja,,Ja,,Ja,,Ja,,Ja
148,Artificial Intelligence in a Structurally Unjust Society,Lin (2022),Unclear,Include,Human_Unclear,1,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",10,,,0.95,"Paper adressiert substantiell generative KI und LLMs (Generative_KI: Ja), entwickelt ein Framework für kritische Analyse (AI_Literacies: Ja) mit explizitem Fokus auf Prompt-Dokumentation und -Transparenz (Prompting: Ja). Direkter Bezug zu sozialarbeiterischer Forschungspraxis und Journal-Editoren in der Sozialen Arbeit (Soziale_Arbeit: Ja). Alle Bedingungen erfüllt: TECHNIK (3x Ja) UND SOZIAL (1x Ja).","Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein
199,Towards substantive equality in artificial intelligence: Transformative AI policy for gender equality and diversity,Ricaurte Quijano (2024),Unclear,Exclude,Human_Unclear,1,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness",10,,Not_relevant_topic,0.95,"Paper behandelt Chain-of-Thought Prompting für LLMs (Generative_KI=Ja, Prompting=Ja). Dies ist eine rein technische Methoden-Studie ohne Bezug zu sozialen Themen. Keine Kategorien aus dem SOZIAL-Set (Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness) sind erfüllt. Damit fehlt die SOZIAL_OK-Bedingung für Inklusion.","Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Ja,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Ja,Nein
172,Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness,Ovalle (2023),Unclear,Exclude,Human_Unclear,1,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Gender, Diversitaet",7,,"TECHNIK_OK (AI_Literacies, Generative_KI, Prompting, Fairness: alle Ja), aber SOZIAL_OK nicht erfuellt. Keine der Kategorien Soziale_Arbeit, Bias_Ungleichheit, Gender, Diversitaet oder Feministisch erreicht Ja-Status. Fairness allein genuegt nicht fuer SOZIAL_OK.",0.95,"Das Paper behandelt AI Literacy (Benutzervertrauen, Kalibrierung), Generative KI (LLMs) und Prompting-Strategien (Unsicherheitskonveyance). Fairness-relevant bezueglich Transparenz. Jedoch kein direkter Bezug zu Sozialer Arbeit, Bias/Ungleichheit, Gender, Diversitaet oder feministischer Perspektive. Allgemeine KI-HCI-Studie ohne soziale Gerechtigkeitsdimension.","Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Diversitaet",,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja,Ja
290,What is Feminist AI?,Wudel (2025),Unclear,Include,Human_Unclear,1,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Gender, Feministisch, Fairness",7,,,0.92,"Paper erfüllt beide Bedingungen: TECHNIK_OK (AI_Literacies, Generative_KI, Prompting alle Ja), SOZIAL_OK (Bias_Ungleichheit, Diversitaet, Fairness alle Ja). Framework für verantwortungsvolles Prompt Engineering mit explizitem Fokus auf ethische Prinzipien, Menschenrechte und Diversität. Keine Soziale_Arbeit oder feministischen Theoriebezug identifiziert.","Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Gender, Feministisch, Fairness | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Ja,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja,Nein,Nein,Ja
132,Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds,Kong (2021),Unclear,Include,Human_Unclear,1,"AI_Literacies, Generative_KI, Prompting, KI_Sonstige, Bias_Ungleichheit, Fairness",6,,,0.92,"Paper untersucht substantiell LLM-Responses auf LGBTQ+-Prompts (Generative_KI: Ja; Prompting: Ja - systematische Prompt-Variation). Zeigt algorithmischen Bias gegen queer/marginalisierte Communities (Bias_Ungleichheit: Ja), thematisiert Gender/sexuelle Orientierung (Gender: Ja; Diversitaet: Ja - LGBTQ+ als marginalisierte Gruppe; Fairness: Ja - Asymmetrien in Safety-Guardrails). TECHNIK + SOZIAL erfüllt.","Technik-Differenz: AI_Literacies, Generative_KI, Prompting, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Fairness",,Ja,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Ja,Ja,Ja,Nein,Nein,Nein,Ja
134,Developing an artificial intelligence literacy framework: Evaluation of a literacy course for senior secondary students using a project-based learning approach,Kong (2024),Unclear,Exclude,Human_Unclear,1,"AI_Literacies, Generative_KI, KI_Sonstige, Bias_Ungleichheit, Gender, Fairness",6,,"Technik-Bedingung erfüllt (Generative_KI=Ja), aber keine Soziale_Arbeit-Kategorie. Bias_Ungleichheit, Diversitaet und Fairness sind vorhanden, aber der Sozial-Kreis ist nur über allgemeine KI-Ethik-Themen erfüllt, nicht durch Soziale_Arbeit spezifisch. Da das Paper auf allgemeine LLM-Bias-Literatur fokussiert und keinen direkten Sozialarbeit-Bezug hat, wird Soziale_Arbeit korrekt als 'Nein' bewertet.",0.95,"Das Paper ist ein Überblicks-Survey zu Bias und Fairness in LLMs. Es erfüllt die TECHNIK-Bedingung (Generative_KI=Ja) und behandelt substantiell Bias_Ungleichheit und Fairness. Allerdings fehlt die SOZIAL-Bedingung im Sinne der definierten Kategorien: Es gibt keinen direkten Bezug zu Sozialer Arbeit, und die Bias/Fairness-Behandlung ist allgemein auf NLP fokussiert, nicht spezifisch auf sozialarbeiterische Kontexte oder marginalisierte Gruppen im Sozialbereich. Daher: Exclude.","Technik-Differenz: AI_Literacies, Generative_KI, KI_Sonstige | Sozial-Differenz: Bias_Ungleichheit, Gender, Fairness",,Ja,Nein,Nein,Ja,Nein,Nein,Ja,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Ja,Ja,Nein,Nein,Nein,Ja
170,ReflectAI: Design and evaluation of an AI coach to support public servants' self-reflection,Näscher (2025),Unclear,Include,Human_Unclear,1,"Prompting, Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness",5,,,0.95,"Paper erfüllt TECHNIK-Kriterien durch Generative_KI (ChatGPT-Fokus) und Prompting (Empfehlungen zu clarifying prompts). Erfüllt SOZIAL-Kriterien durch expliziten Gender-Fokus (unterschiedliche Geschlechteridentitäten), Bias_Ungleichheit (stereotype responses, verringerte Vertrauenswerte) und Fairness (Bias-Mitigation-Strategien). Qualitative empirische Studie mit substantiellem Bias- und Gender-Fokus.","Technik-Differenz: Prompting | Sozial-Differenz: Soziale_Arbeit, Bias_Ungleichheit, Gender, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Ja,Nein,Ja,Nein,Nein,?,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Ja
223,"""It happened to be the perfect thing"": Experiences of generative AI chatbots for mental health",Siddals (2024),Unclear,Include,Human_Unclear,1,"Soziale_Arbeit, Gender, Diversitaet, Fairness",4,,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (Generative_KI=Ja, LLM-Analyse), SOZIAL_OK (Bias_Ungleichheit, Gender, Diversität, Fairness alle Ja). Dokumentiert Gender-Stereotypen und algorithmischen Bias in LLMs systematisch. Kein explizit feministischer Theorie-Einsatz, daher Feministisch=Nein. Keine Soziale_Arbeit-Dimension erkennbar.","Sozial-Differenz: Soziale_Arbeit, Gender, Diversitaet, Fairness | ACHTUNG: Sozialarbeitsbezug unterschiedlich bewertet",,Nein,Nein,Ja,Ja,Nein,Nein,Nein,Nein,Ja,Nein,Ja,Ja,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Ja
125,Why and What to Teach: AI Curriculum for Elementary School,Kim (2021),Unclear,Exclude,Human_Unclear,1,"AI_Literacies, Bias_Ungleichheit, Gender",3,,Only_Technik_keine_Sozial,0.95,"Paper behandelt philosophische Grundlagen von AI-Explainability und Systematizität (KI_Sonstige: Ja). Dies ist jedoch rein technisch-philosophischer Natur ohne Bezug zu sozialen Auswirkungen, Bias, Ungleichheit, Gender, Diversität, Feminismus oder Fairness. Kein Bezug zu Sozialer Arbeit. TECHNIK erfüllt (KI_Sonstige), SOZIAL nicht erfüllt → Exclude.","Technik-Differenz: AI_Literacies | Sozial-Differenz: Bias_Ungleichheit, Gender",,Ja,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Nein,Ja,Nein,Nein,Nein,Nein,Nein,Nein,Nein
234,Algorithmic Governance and the International Politics of Big Tech,Srivastava (2024),Unclear,Include,Human_Unclear,1,"Gender, Feministisch",2,,,0.95,"Paper erfüllt beide Bedingungen: TECHNIK_OK (KI_Sonstige: Bias in KI-Systemen), SOZIAL_OK (Bias_Ungleichheit, Gender, Diversitaet, Feministisch als intersektionale Kritik an Machtverhältnissen, Fairness). Kritische Analyse von algorithmischen Systemen mit explizitem Gender- und Rassismus-Fokus sowie intersektionaler Perspektive auf Diskriminierung.","Sozial-Differenz: Gender, Feministisch | ACHTUNG: Feministische Perspektive unterschiedlich bewertet",,Nein,Nein,Nein,Nein,Nein,Nein,Ja,Ja,Nein,Nein,Ja,Ja,Nein,Ja,Ja,Ja,Nein,Ja,Ja,Ja
