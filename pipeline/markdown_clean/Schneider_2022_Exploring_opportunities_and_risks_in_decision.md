---
source_file: Schneider_2022_Exploring_opportunities_and_risks_in_decision.pdf
conversion_date: 2026-02-03T09:20:06.900954
converter: docling
quality_score: 95
---

## Exploring Opportunities and Risks in Decision Support Technologies for Social Workers: An Empirical Study in the Field of Disabled People's Services

Diana Schneider* , Angelika Maier** , Philipp Cimiano*** and Udo Seelmeyer****

## Abstract

This paper examines how social care provider professionals could be supported  by  decision  support  systems  (DSSs)  in  social  care  service  planning  (SSP) . Since DSSs are not yet used in Germany, we rely on interviews with social work professionals to explore expectations and fears about DSSs, and how they could be  integrated  into  professional  practice .  Our  findings  support  three  conclusions . First, DSSs providing visualisations of clients' development are perceived to support decision-making . Second, there is a need for DSSs to support shared decision-making . Finally, it is crucial not to confound technical reliability with professional reliability .

Zusammenfassung: Chancen und Risiken von Entscheidungsunterstützungssystemen für Fachkräfte der Sozialen Arbeit: Ergebnisse einer empirischen Studie für das Feld der Teilhabeplanung für Menschen mit Behinderung

Dieser Artikel untersucht, wie Fachkräfte der Leistungserbringer in der Teilhabeplanung  durch  Entscheidungsunterstützungssysteme  (DSSs)  unterstützt werden können . Da DSSs in Deutschland noch nicht etabliert sind, werten wir

* Schneider ,  Diana,  Fraunhofer  Institute  for  Systems  and  Innovation  Research  ISI, Competence  Center  Emerging  Technologies,  Breslauer  Strasse  48,  76139  Karlsruhe, Diana .Schneider@isi .fraunhofer .de .

** Maier ,  Angelika,  Bielefeld  University,  Faculty  of  Technology,  Inspiration  1,  33619 Bielefeld, angelika .maier@uni-bielefeld .de .

*** Cimiano ,  Prof .  Dr .  Philipp,  Bielefeld  University,  Faculty  of  Technology,  Inspiration 1, 33619 Bielefeld, cimiano@cit-ec .uni-bielefeld .de .

**** Seelmeyer ,  Prof . Dr . phil . Udo, FH Bielefeld University of Applied Sciences, Faculty of Social Sciences, Interaktion 1, 33619 Bielefeld, Udo .Seelmeyer@fh-bielefeld .de .

Interviews mit Fachkräften danach aus, welche Erwartungen und Befürchtungen gegenüber DSSs bestehen, und wie diese in die berufliche Praxis integriert werden können . Unsere Ergebnisse erlauben drei Schlussfolgerungen: 1) DSSs, welche die Entwicklung von Klient*innen visualisieren, wird ein großes Potential zugeschrieben, Entscheidungen zu unterstützen; 2) zukünftig müssen integrative Konzepte partizipativer Entscheidungsfindung entwickelt werden, damit partizipative  Entscheidungsprozesse  nicht  durch  die  Integration  von  DSSs unterminiert  werden;  3)  technische  und  professionelle  Zuverlässigkeit  dürfen nicht verwechselt werden .

JEL-Codes: M15

## 1. Introduction

Algorithmic  decision-making  systems  (ADMs)  are  used  in  various  application contexts of social services . They are used to predict the recidivism probability of delinquent persons ( Larson et al . 2016), in predictive policing ( Greilich 2019), or in the management of work and unemployment ( Allhutter et al . 2020) . In social work, such systems are also discussed and partly already used for the detection of child welfare risks ( Foster/Stiffman 2009; Gillingham 2019a; Liedgren et al . 2016) . Overall, the evaluation of these systems seems ambivalent: On the one hand, some scholars emphasise that the inclusion of an ADM is helpful in  gaining  a  more  comprehensive overview of the situation and in visualising helpful  indicators  for  assessing  potential  child  welfare  risks  ( Monnickendam et al . 2005; Schrödter et al . 2018; Shiller/Strydom 2018) . The ADM is primarily used  'as  an  aid  to  thinking  and  reflection  in  atypical  cases'  ( Monnickendam et al . 2005, p . 21) . On the other hand, ADMs have been criticised for 'oversimplifying reality' ( Liedgren et  al .  2016,  p . 2) .  Some  scholars  point  to  the  risk  of false-positive and false-negative results from predictive analyses ( Barocas/Boyd 2017; Gillingham/Graham 2016; van der Put et al . 2016) or they criticise the low informative value of such systems ( Gillingham 2019a) . The criticism of ADMs refers  both  to  an  inappropriate  data  basis,  including  hidden  biases  ( Crawford 2013), systemic discrimination ( Raji 2020), noisy data, errors and failures (German Council for Scientific Information Infrastructures [RfII] 2020), as well as to the lack of transparency and explainability of algorithmic analyses ( Coeckelbergh 2019; Wachter et  al .  2017) .  In  the  debate,  ADMs  are  often  discussed  as systems that undermine human decision making, although it is often ultimately humans who use algorithmic analyses ( Zweig et  al .  2018),  and  translate  them into decisions or interventions . Strictly speaking, most ADMs in contexts of social services are decision support systems (DSSs) ( Schneider in press) designed to assist experts in their professional assessment by providing them with additional new information ( Gillingham 2019b; Zweig et al . 2018) . However, it is un-

clear what the process of support looks like in exact terms: For example, some studies not only point to erroneous algorithmic analyses being adopted 'in spite of other evidence to the contrary' ( Neri et al . 2020, p . 519) . In addition, there is evidence  that  people  who  interact  professionally  with  ADMs  sometimes  purposefully modify their input to the system ( Kolleck/Orwat 2020, p . 8) . In fact, it is  often not even clear whether and, if so, in what way algorithmic support in the  specialised  process  of  decision-making  makes  sense .  Since  ADMs  are  applied in more and more socially relevant contexts, they 'affect almost all kinds of human activities, and, most notably, the distribution of services to millions of European citizens - and their access to their rights' ( Chiusi et  al .  2020,  p . 6), which makes the investigation of the conditions under which it is reasonable to deploy such systems in the welfare sector particularly important .

In Germany, the integration of algorithmic systems and risk assessment tools in decision-making processes in social work has so far been discussed mainly in theoretical  and  exemplary  terms  ( Ackermann 2020; Schneider/Seelmeyer 2019; Schrödter et  al .,  2018) .  In  a  recent  study, Hoose et  al .  (2021,  p . 102)  point  out that the use of web-based digital tools in areas such as diagnostics, counselling, and  therapy  recommendation  in  the  everyday  professional  practice  of  social workers, social pedagogues, geriatric nurses, and educators in Germany is negligible .  At  the  same time, many areas of social work and social (care) services administration are being digitised (cf . Evans/Hilbert 2020; Ückert , Sürgit/Diesel 2020), for example, to increase the exchange of information within an institution, or to facilitate contact with department staff for citizens . As a result, the processes  of  integration  assistance  for  disabled  people,  comprising  of  a  wide range of different social benefits (e . g .,  benefits  for  participation  in  education, benefits for participation in working life) that disabled people can claim in order to mitigate the effects of their disability on their participation in social life, are also becoming increasingly digitised .

In the interdisciplinary project MAEWIN (Decision Support Systems in Welfare Institutions, 2018 - 2021), we explore the use of DSSs in the field of disabled people's services . The project investigates how DSSs could be used in the process of social care service planning (SSP), which is an instrument for determining the individual needs of a beneficiary . According to the Bundesteilhabegesetz (BTHG) 1 , beneficiaries' needs are to be assessed with the help of systematic tools that are based on the International Classification of Functioning, Disability and Health (ICF) . This means that various areas of beneficiaries' life are examined to determine whether and, if so, to what extent supporting social care services are necessary so that they can perform as independently and autono-

1  The Bundesteilhabegesetz (BTHG) is a comprehensive package of legislation that reforms opportunities for participation for people with disabilities until 2023 .

mously as possible . The beneficiaries can apply for support at the department of integration  assistance  (usually  every  year  or  every  two  years) .  Frequently,  the beneficiaries are supported in the application by social care providers who provide the corresponding services or support after they have been approved . The MAEWIN project, therefore, addresses the question of how professionals of social care providers could be supported in the context of SSP by DSSs . Due to the lack of adoption of DSSs in practice, especially in the field of integration assistance, we are interested in involving professionals early on in the DSS development process so that both their concerns and expectations with respect to DSSs as well as (unintended) ethical, legal, and social implications of ADMs can be addressed (see also section 2, methodology) . The questions we are concerned with include: What expectations and fears do professionals have about DSSs? What importance is attributed to algorithmic analyses in the decision-making process? And how could DSSs be integrated into professional practice?

In this article, we first outline the methodology of the project explaining why anticipation by professionals is helpful in the early stages of technology development and how we use different stimuli to elucidate these expectations and assessments  (section  2) .  After  a  short  description  of  our  empirical  data  and methods (section 3), we present findings of our interviews with professionals of social care providers (section 4) . On the basis of our findings from the empirical study, we provide a discussion (5 .1) in regards the perceived potentials and drawbacks of DSSs by social workers, (5 .2) requirements on the application scenario and environment and (5 .3) perceived impacts on professionalism .

## 2. Approach to Considering Unintended Implications in DSS Development

Although ADMs are discussed widely at an international level, the actual use of such systems in Germany is not established ( Schneider ,  in  press; Schneider/ Seelmeyer 2019) . Our research of how DSSs could be used in the process of social  care  service  planning  (SSP)  is  not  only  about  (technical)  potentials  and risks, but also about possible future visions for the use of DSSs in the context of integration assistance and the assessment of their intended and unintended implications . Therefore, ethical, legal, social and professional implications (ELSI) of technology need to be identified early in the process of DSS development this  approach  is  internationally  recognised,  e . g .,  in  the  Responsible  Research and Innovation (RRI) framework ( Schomberg 2015) . However, unintended consequences of technology often only reveal themselves in the course of technology  development  and  implementation . Collingridge (1980,  p . 11)  speaks  of  a control problem of technology: 'When change is easy, the need for it cannot be foreseen; when the need for change is apparent, change has become expensive,

difficult  and  time-consuming' .  In  order  to  identify  implications  at  an  early stage of development, methods of prospective technology assessment (including future studies methods), such as scenario methods, are useful ( Grunwald 2019) . This includes the theoretical examination or anticipation of potential available technology such as the use of DSSs in integration assistance .

'Anticipation is a broad notion covering, e . g ., model-based simulations, prospective knowledge about how the world would or could look if the respective technology was developed, produced, and implemented, but also containing more speculative visions, hopes,  expectations,  fears,  and  even  utopias  and  dystopias .  […]  Prospective  knowledge in TA [technology assessment] addresses consequences which do not yet exist and perhaps will never become a reality . ' ( Grunwald 2019, p . 93)

By conceptualising possible futures not as linear outcomes of the present, but as  ideas  of  the  present  time  about  the  future  ( Börjeson et  al .  2006; Grunwald 2019), conclusions can be drawn about the values and preconditions for future developments ( Grunwald 2019) .  Therefore,  it  does  not  matter  'whether  statements about the future will come true, but only whether their coming true can arguably be expected on the basis of present knowledge' ( Grunwald 2019, p . 116, emphasis in original) .

This article presents an empirical study with the goal of elucidating how professionals  of  social  care  providers  could  be  supported  in  the  context  of  social care service planning (SSP) . The first part of the study (ESI study) 2  takes a more general view on both ethical and social implications and anticipation of DSSs in integration assistance, and, in this context, addresses a wide range of aspects, such as SSP for disabled people, professional judgement, data collection and data  security,  as  well  as  the  (potential  and  hypothetic)  use  of  and  dealing  with technical artefacts . The second part of the study (user study) explores how professionals would use information provided by a prototype DSS about the client's need for assistance in SSP  . Particularly in the first part of the MAEWIN project study (ESI study), the involvement of experts (professionals of social care providers,  and  members  of  integration  assistance  departments)  was  a  priority  in order  to  include  'different  perspectives,  values,  and  pieces  of  knowledge' ( Grunwald 2019, p . 92) about DSSs and their potential use in integration assistance, so that the most diverse perspectives possible could be captured .

In order to carry out the user study, a DSS prototype was developed based on 22  client  files  comprising  of  295,812  records  from  two  residential  homes  and residential groups . The system relies on an artificial intelligence (AI) based system trained to predict levels of need for assistance (LONA) from textual documentations entered by social workers into the client information system (CIS) (see Maier/Cimiano 2020), and visualises the predictions on a timeline so that

2  At this point, the legal aspects are left aside .  These  are  addressed  elsewhere  in  the MAEWIN project .

social workers can visually inspect the progress of a client . The DSS has three components: First, a start page providing an overview of the needs of the client in  question  in  different  life  areas;  second,  a  timeline  showing  the  LONA  for each report in the CIS; third, a comparison page allowing to compare the progress across up to three different areas of life . It is also possible to zoom in on the timeline and comparison page, or search for the LONA on a specific date or time  frame .  A  compilation  of  the  most  important  parts  of  the  three  pages  is shown in the figure below .

In both studies, semi-structured interviews were conducted in which stimuli were used to be able to elicit certain aspects about the use of DSSs in integration assistance . In the first study, the definition of an AI-based DSS was given to the respondents, while respondents in the second study were presented with a concrete  service  planning  scenario  and  then  tried  out  the  functions  of  the  aforementioned prototype DSS themselves while 'thinking aloud' (method based on Van Someren et al . 1994) . The DSS prototype that was used as a stimulus in the interviews has been developed as a web-based tool . This enabled respondents to access the DSS with appropriate access data and to test it for themselves .

Although it would be conceivable to present each sub-study separately to provide  detailed  coverage  of  all  the  findings,  for  this  paper,  we  have  decided  to present these two sub-studies together . This approach allows us thus to capture the  perceptions  of  social  workers  independent  of  a  specific  solution/tool  and

<!-- image -->

Source : own depiction .

Figure: Compilation from the pages of the prototype DSS . The upper section on the start page displays visualisations and statistics for different categories of life . Below that, the comparison of the trend for levels of needs for assistance (LONA) for different life categories is shown on the left . The display of the LONA scores for the individual report over time is shown on the right .

contrast these perceptions when being presented with a particular tool . The insights gained in this way take into account the fact that the developed system still has a number of weaknesses and unintended implications, such as the undefined requirements on the introduction and operation of DSS (see section 5) .

## 3. Data and Methods

The studies were conducted in Germany between January and June 2020 (ESI study) and in March 2021 (user study) . Respondents of the first study were recruited by means of a previously compiled list of social care providers, specifically from welfare institutions in North Rhine-Westphalia and Berlin . In addition, further respondents were identified using the snowball method . The staff of the facilities was requested for interviews, whereby participation in the interviews  was  voluntary .  In  total,  13  people  agreed  to  be  interviewed,  but  due  to contact  restrictions  and  special  requirements  related  to  the  COVID-19  pandemic only 10 persons were interviewed via face-to-face (5), video-telephony (2) and telephone (3) . Respondents worked in the field of integration assistance and were between 29 and 57 years old (average age 36 .7 years) .

Respondents  in  the  second  study  were  recruited  through  the  organisations whose clients' data were used to develop the prototype DSS . Although all client data had already been pseudonymised by the organisation and only aggregated data,  consisting  of  anonymised  data  as  well  as  machine-generated  data,  were used in the process of DSS development, we followed this approach to ensure that any unrecognised personal data could not fall into the hands of unauthorised third parties . In addition, this approach avoided potential barriers, as respondents  were  presented  with  a  system  based  on  structures  and  procedures they were acquainted with . In total, 5 social workers were interviewed via video-telephony in the user study . All respondents were responsible for social care service  planning  (SSP)  and  were  between  25  and  60  years  old  (average  age 47 .8 years) . The transcribed interviews were analysed using qualitative content analysis .  The  total  data  set  comprises  of  about  24,5  hours  of  audio  recording, 19,5 hours in the ESI study and 5 hours in the user study . In case of the user study, interviews were also video-recorded, but only audio material was used, referring to the video only in cases in which the visual context is needed to see what actions the person does with the tool while speaking .

## 4. Results

In the following, we present the results with regard to expectations and fears about DSSs before a confrontation with a (prototype) DSS (4 .1) first . After that, the actual reactions on a prototype DSS are reported (4 .2) .

## 4.1  General Expectations of Social Workers Regarding DSSs in Integration Assistance

Since the application of ADMs in social work is not widespread in Germany, the focus of the ESI study was on eliciting professionals' expectations and fears of such new technologies . Although the respondents had not yet any experience with DSSs, they certainly had an idea of what can be accomplished with DSSs: Some respondents pointed out that algorithms operate according to clearly defined  individual  steps  or  that  self-learning  algorithms  have  the  possibility  of pattern recognition or of being able to make predictive statements . Nevertheless,  the  exact procedure/operation of the algorithms often was rather unclear to  them .  In  almost  all  interviews,  respondents  were  initially  sceptical  as  to whether using DSSs would also make sense in their field of action: 'For us , here personally  at  the  base,  it  doesn't  make  that  much  sense'  (Professional  8,  ESI 2020) . While they could imagine potential benefits for the practice of employees within integration assistance departments, they feared that the standardisation necessary for algorithmic processing might jeopardise the consideration of individual needs . Most respondents highlighted that medical diagnosis (according  to  International  Statistical  Classification  of  Diseases  and  Related  Health Problems, ICD) cannot be used to infer a person's individual needs - and they suggest  that  this  is  exactly  the  kind  of  predictive  inference  that  a  DSS  would make: 'That is exactly the problem that I see . For example, when you look at the  field  of  disability .  Because  not  all  disabilities  are  the  same .  As  I  said,  not every  diagnosis  has  the  same  functional  limitations  or  the  same  character' (Professional 1, ESI 2020) .

As described above, anticipation plays a major role in this part of the study . Therefore, the respondents were asked to describe a situation during the interview in which they had found it difficult to make a decision . In particular, they were  asked  to  imagine  having  a  DSS  to  support  them  in  this  situation .  They were asked to think about how a DSS could help them and what information could be provided by a system to support in the decision-making process . Various expectations were named by respondents: from the rejection of DSSs due to their lack of benefits (e . g ., because support in research and evaluation is not considered necessary) to the idea of the potential replacement of professionals by a DSS . For one, DSSs are not supposed to make any decisions at all (this also

includes the categorisation of clients with regard to their need for assistance) . For another, these DSSs should in no way be weighted higher than the clinical judgments of the professionals, so that human judgment is always preferred to algorithmic judgement in case of doubt . Some respondents found it difficult to imagine a DSS in their practice because decisions in the sense of inference (cf . Abbott 1988)  are  perceived  as  an  elementary  core  of  professional  action,  i . e ., professionals do not perceive themselves as operational agencies of other people's decisions . Even if this aspect is frequently addressed in the interaction with employees of integration assistance departments, it can also be easily adapted to the interaction with DSSs . Nevertheless, almost all respondents agreed that algorithmic results would be integrated into their own decision-making process if they had to use DSSs in their daily practice . Most respondents saw potential for DSSs as a welcomed help for inexperienced personnel, as well as for themselves in case of low confidence . However, they remained unspecific regarding the exact vision of what this help could look like . The following quote is representative  of  this  line  of  reasoning:  'I  think  for  many  people  it  would  be  helpful  if there was something like that . If one is personally uncertain, in fact . […] But I actually  believe  that  most  of  us,  some  of  whom  have  been  with  us  for  thirty years or so, tend to say: Well, I trust my instincts . ' (Professional 1, ESI 2020) . In case of doubt, however, respondents agree that they would rather trust a competent colleague than an algorithm .

In addition, respondents perceived an advantage in technical support of documentation  obligations .  For  instance,  they  imagined  that  interconnected  systems,  intelligent  mobile  voice  recordings,  or  even  sensor-based  technology could  be  useful  tools  to  make  daily  documentation  easier .  Technical  support was highly associated with the expectation of better documentation in the CIS, as documentation could be done more frequently and more accurately . A benefit  was  also  seen  in  reminders  of  tasks  (appointments,  provision  of  one's  own documentation) or professional  standards  in  the  form  of  a  checklist .  Overall, respondents  preferred  DSSs  that  work  with  data  collected  by  professionals themselves, so that one can be more confident that analyses are correct .

However, with regard to the many free texts that are common in social work, some respondents wondered whether the database could be used for algorithmic analyses at all . Further, a few respondents questioned the intelligent pattern recognition of self-learning algorithms: 'There are things there that I think you can then read differently . Like this . Y es . So yes, just by this value-free, not value-free [documentation] . That there a system comes - also very quickly via certain keywords - then possibly also to different conclusions [than professionals]' (Professional 5,  ESI  2020) .  Do  self-learning  algorithms  only  recognise  certain keywords and, if so, can the algorithm be manipulated by these keywords? Can DSSs  safely  distinguish  innovative  ideas  or  outdated  concepts  of  professional action?  Due  to  the  fact  that  documentation  is  subject  to  certain  functions

( Merchel/Tenhaken 2015), some respondents also questioned whether the existing documentation could be used at all to assess the individual needs of disabled persons . Some also emphasised the subjective, partly prejudiced documentation in the CIS: 'And, they are always human judgments . And they can also be  really  mean,  wrong,  unprofessional,  scurrilous .  I've  experienced  that,  too' (Professional 3, ESI 2020) . Furthermore, some respondents noted that accurate algorithms  require  large  amounts  of  data .  However,  they  were  critical  of  the generation of large amounts of data about their clients and stressed that not all information should be stored in the CIS . For example, some intimate aspects are only documented 'on a meta-level' (Professional 9, ESI 2020) or not at all (for more details, see Cairns et  al .  2018; Schneider 2022) .  Therefore, a few respondents pointed out the need to provide developers with professional background  information  and  manual  assignments  between  documented  events  to ensure that their algorithms deliver accurate results .

Although the integration of DSSs into professional practice will undoubtedly bring about some changes, these changes were rarely directly addressed by respondents . In general, algorithms were criticised for enabling the evaluation of professionals, but few explicitly addressed the fear of losing one's job due to a DSS: 'So it's interpreted as help, but, once you're specific, the device has made a decision based on data . And you know that the decision today is even better than your own . And then you have to compete or interact with the computer, so to speak . ' (Professional 4, ESI 2020) . Rather, respondents emphasised that the relationship and interaction with clients plays an essential role in the context of professional action, in which empathy is a core element . Yet, the role of clients in addressing DSSs is rarely addressed .

## 4.2  Interaction with a Prototype DSS

The  practical  experience  with  the  prototype  DSS  was  the  first  contact  for many respondents with a DSS . Respondents considered the presented DSS useful for looking up practical information in reports more effectively, for example, which support is needed when clients have a medical appointment . 4 of the 5 respondents could imagine using such a system in their daily work in order to prepare for SSP before discussions with stakeholders . Furthermore, respondents stated that using the DSS might make it easier for them to gather detailed information about the independence of clients in different life areas for writing support  plans .  They  appreciated  the  overview  functions  provided  by  the  tool  in order to have more focused and informed discussions about support plans as well as in weekly team meetings about a client's current state (e . g ., in terms of emotions, independence, interests) and progress: 'Then, you have an overview . Zack, and then quickly . Otherwise it's annoying: Then I scroll and scroll' (Professional 5, user study, 2021) . In this context, respondents were interested in the

overall course of a client's development in order to monitor how the level of independence evolved in different areas of life over time . From their perspective, this monitoring function could be a complement to the yearly assessment of the need for assistance routinely carried out once a year to gain a holistic view of the clients . Respondents preferred information about the frequency of interventions used and their effectiveness, as indicated by the LONA scores, in order to identify and develop interventions as needed . 'We can look back and see what happened and for what reasons . And what interventions have been taken? And are there perhaps others?' (Professional 4, user study, 2021) . They also saw an opportunity in tracking agreed targets . That results from the parallel visualisation of the LONA assessments together with their respective documentations and  applied  measures .  Through  the  more  transparent  overview  it  is  easier  to track  those  targets  in  the  DSS . Therefore,  respondents  saw  potential  applications  for  the  prototype  DSS  both  on  the  management  level  and  in  the  daily work  of  social  workers .  Moreover,  they  proposed  that  the  DSS  could  also  be used as a quality self-monitoring tool to ensure that all clients receive adequate attention  from  professionals,  regardless  of  temperament .  Besides  the  benefits discussed, respondents saw further potential for expanding the system to consider an overview of clients' personal and financial resources or of their support system (consisting of relatives, friends, and acquaintances) .

On the one hand, all respondents stated that they had confidence in the LONA scores assigned by the DSS to each report in the documentation . For example, respondents answered the question of how they would deal with the automatically predicted LONA scores by suggesting that they would trust the information given by the DSS . On the other hand, 4 out of 5 respondents expressed a  preference  for  being  able  to  correct  the  DSS  in  case  of  an  error  in  order  to 'have a kind of safety function' (Professional 4, user study, 2021) . Only one respondent dismissed the opportunity to correct the DSS, seeing a risk in falsifying the annotation assumptions on which the algorithm's predictions were originally based, leading to a loss of comparability and reliability of the scores .

Despite the above-mentioned opportunities and advantages, some respondents criticised the data basis that the system was developed with as inadequate, as the documentation used to train the system reflects the professional's rather than the client's perspective, which might lead to biased perceptions: 'The documentation is documentation of the professionals and not from the perspective of  clients'  (Professional  1,  user  study,  2021) .  One  solution  from  the  respondents'  point  of  view  is  to  make  this  problem  transparent  in  discussions  about support plans: 'it has to be made clear in the conversation: This [information in the DSS] is coming from us, the professionals right now . This is the institution's view  of  the  whole  situation,  it's  not  their  [clients]  view . '  (Professional  1,  user study, 2021) . In addition, another limitation results from the fact that some information  is  omitted  in  the  documentation  and  that  the  length  of  text  varies

depending on the amount of work professionals invest into each client . Moreover,  respondents  expressed  a  desire  to  have  the  final  decision  whether  DSSs would be used directly in an interaction with clients, depending on their cognitive ability to process information . Considerations may include whether a DSS is  used  for  the  preparation  of  or  during  face-to-face  conversations  in  general (including with participants other than clients) as well as if the social worker has concerns regarding the fact that using DSSs might create a burden on them and their clients .

Finally, some respondents criticised the design of the DSS tool itself . For instance, one respondent criticised that the negative and positive trends of LONA for different life areas are shown on the start page of the DSS . The respondent feared that this can lead professionals to focus on life areas where clients have deficits instead of seeing their resources . In addition, some respondents saw the possibility of employee control if the tool is used by supervisory authorities .

## 5. Discussion

The most obvious and expected finding from our study is that experience in dealing with DSSs simultaneously changes expectations and fears about DSSs . Respondents in the first study used their own experiences to envision possible benefits  of  a  DSS . Their  answers  were  in  many  cases  quite  sketchy  and  vague due to the inability to imagine potential situations in which DSSs might be applied . The respondents in the second study, on the other hand, found it much easier to envision scenarios in which they could use the functionality provided by  the  tool,  e .  g .,  to  look  up  information  more  quickly,  to  obtain  quick  overviews, or to monitor their own work . Referring back to Hoose et al . (2021), one could  come  to  the  simple  conclusion:  Unfamiliar  technology  such  as  DSS  is rarely in use and therefore met with a much stronger scepticism and potential rejection compared to more familiar and known technologies . The more experience that can be gained with a particular technique, the more its use becomes normalised and demystified . In terms of more specific findings, we would like to highlight that the findings presented here shed new light on the discussion of DSSs in social work by using professionals' expectations as an opportunity to question the requirements and expectations of a DSS . These new aspects relate to the handling of subjective data, the implementation of DSSs in shared decision-making  processes,  and  trust  in  technology .  In  the  following,  we  present our observations and considerations in the form of three tentative conclusions, each combining different aspects of the findings, and derive implications for future technology development and implementation .

## 5.1  Clarify Different Perspectives Using Data-Driven DSSs

The  most  obvious  finding  concerns  the  discrepancy  between  the  data  that DSSs can use for algorithmic analyses in SSP and the added value that professionals attribute to that data . On the one hand, as mentioned in the literature review and highlighted by the respondents of both studies, documentation may contain hidden biases ( Crawford 2013), biased perspectives, or prejudices ( Raji 2020; Schneider 2020); noisy data, de-contextualisation, and documentation inattention,  errors,  or  omissions  also  have  a  lasting  impact  on  data  quality (cf . German  Council  for  Scientific  Information  Infrastructures  [RfII]  2020, p . 10 ff .) .  Respondents  criticised  the  quality  of  existing  documentation .  For example, they pointed out that important information within the documentation could be missing (e . g ., due to technical or organisational framework conditions; cf . also Gillingham 2019b; Merchel/Tenhaken 2015), or that there might be  deliberate  omissions  within  the  documentation  ( Schneider 2022) .  Furthermore, respondents of both studies emphasised that free-text entries common in social  work  represent  subjective  assessments  of  a  situation  (cf . Merchel/Tenhaken 2015; Schneider 2022) . Subjectivity arises, for example, 'since each entry is made with the awareness that it might be used later to assess the adequacy of the actions 'recorded'' ( Berg 1996, p . 518; cf . Gillingham 2019c) . This becomes problematic  when  these  subjectively  documented  contents  are  presented  as facts ( Schneider/Seelmeyer 2019) .

On the other hand, respondents perceived great advantages in graphical presentations of existing information or summaries of large free-text entries in order to obtain compact information about important stages in the development of clients . Some respondents associated this with the promotion of inter-professional advice (e . g ., in the context of team meetings or supervisions) or with the opportunity of reflection (e . g ., in case of their own uncertainty or for inexperienced colleagues) . The visual summaries of clients' trajectories were clearly perceived as a low-effort approach to support the continuous recapitulation of the development of clients . User study respondents seemed to prefer the visualised overview representations of documented contents to (conditional) probability statements .  Something  similar  can  be  deduced  from  the  ESI  study:  Some  respondents were critical of the inclusion of general statistical statements about disabled people in their decision-making process . Instead, they emphasised that algorithmic analyses should be based on their own documentation in order to make valid statements  regarding  the  clients'  cases .  In  this  way,  they  could  be more certain that the recognised correlations are really meaningful for the persons concerned .

There are several possible explanations for this result . First, this rather contradictory result may simply be due to the fact that respondents do not see a connection between their biased data and the output of the system . Second, re-

spondents could also be referring to two different systems with their answers: Here is the current CIS, which may include biased data; there is the future DSS, which will also, but possibly not only, work with an organisation's data, but will also draw on general statistics, models, and professional concepts .

On the premise that respondents may very well refer to a single DSS in their responses that works with their actual documentation, a third conclusion would also be conceivable: The respondents might have interpreted the graphs, summaries, and overviews that a DSS provides as information in terms of a professional  second  opinion  -  something  similar  to  the  opinion  of  a  colleague,  although with less importance . In this sense, the different perspectives on clients' cases could be made transparent through visualisations . By explicating implicit assumptions and subjective perspectives of professionals on a case with the help of  algorithmic  analyses,  this  could  help  to  promote  reflection  among  professionals in the context of supervision, collegial advice, or team meetings . Visualisation of professional documentation considering the different perspectives of those who document could be a useful technical support in the specialised procedure of SSP . Using data in this way would also help to increase the value of otherwise unused data, because sometimes professionals criticise that they cannot  understand  the  purpose  of  the  many  documentation  requirements  (cf . Merchel/Tenhaken 2015, p . 178) . Furthermore, visualisation of implicit assumptions, subjective perspectives and unused data creates incentives for improving documentation processes and quality . One consequence of this approach would be  to  emphasise  the  visualising  rather  than  decision-supporting  function  of DSSs .

## 5.2  Promoting the Development of DSSs in (Shared) Decision-Making Processes

Another  interesting  finding  concerns  the  embedding  of  DSSs  in  the  decision-making process during SSP . We observe that those respondents providing their  professional  assessment  towards  DSSs  without  technical  stimulus  (ESI study)  tend  to  assume  a  setting  in  which  professionals  alone  interact  with  a DSS . As this use is the most frequently addressed both within literature and in public  discourse  ( Chiusi et  al .,  2020; Spielkamp 2019),  such  an  association  is obvious . According to Braun et al . (2020, p . 2), this is characteristic for a 'conventional  DSS,  [in  which]  an  algorithm  takes  patient  data  as  input  and  informs decision-making by delivering a statement for consideration to the clinician' .  Conventional  DSSs  complement  or,  within  limits,  replace  the  experience  and  knowledge  of  professionals  ( Braun et  al .  2020) .  The  respondents  of both studies often associated decision support with the graphical presentation of existing information or with the system encouraging professional reflection through  hints  or  questions .  However,  assuming  a  conventional  DSS,  other

forms of involvement, e . g . shared decision-making processes with the persons entitled  to  benefits  using  DSSs,  are  rarely  or  not  at  all  discussed  by  those  respondents .

At the same time, respondents to the ESI study repeatedly emphasised that decisions made in the context of SSP are made only in shared decision-making processes  with  the  persons  entitled  to  benefits .  In  the  user  study,  as  well,  the professional's role was seen in a shared decision-making process, with the client's perspective taken into account . Considering this, conventional DSSs seem less appropriate in this area since only professionals, but not the persons affected, are supported in their decision . It would therefore be conceivable for DSSs to work not only with information provided by professionals, but also with data generated by clients (e . g . their diary entries) . Systems that 'provide a direct link between patient  data  […]  and  the  clinician ' s  diagnostic  toolbox,  and  thereby add to the evidence base at the centre of shared decision-making' are equivalent to integrative DSSs ( Braun et al . 2020, p . 2 f .) . Shared decision-making has the advantage that the additional information can enrich the decision-making process ( Braun et  al .  2020,  p . 2) .  Client-generated  documentation,  however, is not provided in most cases . In the ESI study, for example, it is pointed out that clients hardly have any possibilities to digitally record their perspective on situations . In the user study, this criticism of the clients' lack of documentation possibilities  is  underlined  by  the  fear  that  the  institution's  perspective  could  be overrepresented in a DSS . Besides this existing limitation in practice, there is also the additional risk within the framework of integrative DSSs of exacerbating existing tensions between actors 'in that the quality of such additional evidence  is  not  immediately  transparent  to  all  participants  and  stakeholders' ( Braun et  al .  2020,  p . 3) .  Therefore,  integrative  DSSs  are  only  successful  if  all actors are willing 'to reassess and to render beliefs, preferences and intentions coherent' ( Braun et al . 2020, p . 3) .

In the light of these reflections, there is a need to develop practical concepts of shared decision-making in the future, considering the involvement of (integrative) DSSs, so that shared decision-making is not undermined by integrating a DSS . There are two things to keep in mind here: On the one hand, the concepts should be resilient enough to take the interaction between humans and technology into account, e . g ., being aware that DSS involvement could contribute  to  an  increased  imbalance  of  power  between  professionals  and  clients ( Braun et al . 2020, p . 3) . Positions that assume a strict dualism between technology on the one hand and humans as decision-makers on the other hand should be critically examined, in addition to concepts which regard technology as an executive  (and  accountable)  decision-maker,  following Latour 's  (1996)  Actor-Network-Theory (ANT) . Instead, we have to keep in mind the multifaceted relationships between professionals and DSSs during the shared decision-making process with clients ( Bastian 2019), but without losing sight of the human

being as the responsible entity . Otherwise, this position can also contribute to the mystification of technical systems (see premise 5 .3) .

On the other hand, the development and use of integrative DSSs that would actually  allow  client-generated  data  in  the  algorithm's  calculations  would  also potentially impact established practices within welfare institutions . The consequences could range from a change in documentation routines (e . g ., the democratisation of documentation) to a restructuring of the legal framework . Kreidenweis (2018),  for  example,  predicted  similarly  disruptive  effects  for  the  social economy if social services were to be offered via digital platforms in the future . By addressing clients, such technologies may ignore entrenched responsibilities and standardised service entitlements ( Kreidenweis 2018, p . 123) .

## 5.3  De-Mystifying Technical Reliability

With the  third  conclusion,  we  point  to  the  risks  for  professional  work  that may arise when not enough attention is paid to the first two conclusions . On the one hand, the above fundamental criticism towards (digital) documentation must be understood as a limitation of ADMs: If no other sources of information are integrated into DSSs (e . g ., external databases, professional guidelines), they can only represent those data that have previously been discussed and noted by professionals . In other words, a prediction can be only as good as the underlying data that it mirrors . On the other hand, this obvious limitation was given little  importance  by  respondents  of  both  studies  when  thinking  of  DSSs  that would use only data from their own organisation . Instead, they focused on the potentially  objective  character  of  algorithmic  analyses .  For  example,  some  respondents of the ESI study expected algorithmic analyses to be more reliable and valid when using their own data . In the user study, one respondent pointed out that algorithms only reproduce the rules that are entered and can therefore only come to correct results . However, most respondents of the ESI study emphasised that they would rather trust a competent colleague than an algorithm . A  possible  explanation  for  this  behaviour  might  be  that  algorithmic  analyses displayed  by  DSSs  are  perceived  by  professionals  as  reliable  statements  about concrete relationships . Such a hypothesis not only appears to require explanation against the background of the data basis previously discussed by respondents but it also addresses a core challenge of algorithmic analyses: the routine use of DSSs in professional practice under the assumption of confusion between technical and professional reliability .

With regard to the academic discourse in technical science, it can be stated that the term 'reliability' is used to define the 'ability of a system […] to perform  its  required  functions  under  stated  conditions  for  a  specified  period  of time'  (IEEE  1990,  p . 62; Nami/Bertels 2007) .  For  example,  if  a  DSS  outputs  a

correct result with a probability of 95 percent, this means that this DSS is able to select exactly those categories that should be selected according to programming in 95 out of 100 cases, always and even under unfavourable conditions . Correct prediction is thus primarily a technical challenge . Therefore, the quality of training data, classifications, and models in the algorithmic system must be consistent with each other ( Zweig et al . 2018) .

All in all, reliability in the technical sense refers to the functions of a system and its ability to perform even under adverse conditions . However, it says nothing  about  the  reliability  of  both  the  data  used  by  a  DSS  and  professional  assumptions stored in the system by means of code . By professional reliability, we therefore rather mean that actions are perceived by professionals as appropriate and in accordance with professional standards . Such a conclusion, however, refers to professional assumptions and/or normative values of professionalism, as well as to theories about what constitutes good decisions . Moreover, this assessment reflects both the relevant context and the consequences of decisions . For such a classification to be possible, there would have to be evidence in the DSS as well as in the data whether and, if so, to what extent these decisions are professionally adequate . However, this judgment is applied retrospectively to completed measures and appears highly situational . Therefore, complex trade-offs of professional reliability seem unrealistic or even impossible to us based on the existing documentation alone .

In  any  case,  if  technical  and  professional  reliability  are  confused  with  each other, this will have a huge impact on professionalism . However, this is not because algorithmic analysis is being used, but because its results are misinterpreted as a decision in the sense of inference (cf . Abbott 1988; Bastian 2014) - decisions for which humans are responsible . On the one hand, human tendency to mystify technology also contributes to not keeping the limits of technology in mind ( Weizenbaum 1976) . Mystification means that human characteristics such as intelligence or reasoning ability are attributed to machines/technologies because there is no other way to explain what the  machine does and, above all, how it  does  it  (cf . Weizenbaum 1976,  p . 23,  emphasis  in  original) .  As Weber (2013, p . 488) pointed out, this behaviour is not intended by system designers or  manufacturers,  but  rather  an  ascription  from  those  humans  who  interact with systems . 'In case of human-computer interaction, one can easily conceive many situations […] in which it would make sense to invoke or strengthen humans' believe that their mechanical counterparts are well-informed, morally responsible,  and  trustworthy  agents  performing  only  in  the  best  interest  of  the human counterpart' ( Weber 2013,  p . 488) .  On  the  other  hand,  lack  of  knowledge in data literacy to interpret data-driven and/or statistical analyses is certainly a cause of this misinterpretation . However, even professions that routinely  deal  with statistical analyses misinterpret statistical analyses . Some scholars point  out  that  routine  use  of  DSSs  risks  errors  of  omission  and  commission

( Geis et al . 2019; Neri et al . 2020) . For example, '[o]mission errors occur when humans fail to notice, or disregard, the failure of an AI tool . […] Commission errors occur when one erroneously accepts or implements a machine's decision despite other evidence to the contrary' ( Geis et al . 2019, p . 439) . Currently, such challenges still seem a long way off . However, it is already becoming apparent that this will be a future challenge in social work practice with respect to the study's findings presented above .

Therefore, the future challenge is not only to contribute to an awareness of the  difference  between  technical  and  professional  reliability  during  a  routine use of algorithmic analysis results . In addition, concepts must be developed to map professional reliability via algorithmic analyses . Schneider et al . (2022) emphasise  that,  especially  in  case  of  unsupervised  learning  algorithms,  there  are few possibilities to subject the analysis results to critical, profession-specific scientific scrutiny beyond technical correctness . This form of quality control has several challenges: First, it is unclear what the result is to be measured against . Should it be based on general, professional standards and criteria, or on tacit knowledge of experienced professionals? Second, it is unclear how to proceed in case of erroneous analysis results: Is there the possibility to intervene with and correct inferences by a DSS? If so, to what extent is it ensured that this access is not  abused?  Last  but  not  least,  the  handling  of  change  within  the  profession must be regulated . To what extent can it be ensured, for example, that outdated concepts  of  professional  action  are  not  evaluated  better  than  currently  valid concepts by algorithmic analyses simply because more data points are available?

## 6. Conclusion

The aim of the present paper was to examine how professionals of social care providers  could  be  supported  in  the  process  of  social  care  service  planning (SSP) using decision support systems (DSSs) . Due to the fact that DSSs are not widespread in Germany, we rely on the anticipation of social work professionals to  explore  expectations  and  fears  about  DSSs,  the  importance  of  algorithmic analyses in the decision-making process, and how DSSs could be integrated into professional practice .

On the basis of our results, we devise three tentative conclusions, each combining different aspects of the findings . First, DSSs that provide visualisations on  client's  development  are  perceived  by  professionals  to  be  very  suitable  to support and enhance their decision-making process, as they provide access to analyses and data that is normally not available in this form . Here, new functional  principles  associated  with  artificial  intelligence  (AI)  open  up  a  wider range of possibilities that converge better with those professional forms of action and knowledge that are complex and hard to standardise . While conventional client information systems (CISs) presuppose comprehensive formalisation of social reality and draw only on quantified and categorised data for automated processing, but not on the vast amounts of data from the professional's free-text  documentation,  AI-based  DSSs  open  up  access  to  information  contained in unstructured text data for analyses and visualisation to support professional  reflection .  Second,  a  need  arises  to  develop  practical  concepts  of shared decision-making in the future, considering the involvement of (integrative)  DSSs,  so  that  shared  decision-making  is  not  undermined  by  integrating DSSs .  According  to Braun et  al .  (2020),  integrative  DSSs  work  not  only  with information provided by professionals, but also with data generated by clients . Finally,  it  is  crucial  not  to  confound  technical  reliability,  which  is  related  to the  intrinsic  performance  of  a  DSS  within  its  own  logical  sphere,  with  the concept  of  professional  reliability,  which  requires  taking  decisions  according to established professional standards . Keeping this crucial distinction in mind and accounting for it in daily work with algorithms requires data literacy and an  understanding  of  the  technical  processes,  and  the  basic  mechanism  and logic  that  algorithms  use  to  make  predictions  and  how  they  differ  from  professional  standards .  In  addition,  consideration  should  be  given  to  whether professional  reliability  could  be  mapped  through  algorithmic  analyses  in  the future .  In  doing  so,  it  is  critical  to  ensure  that  the  data  basis  used  by  algorithms  is  quality  controlled  and  free  of  biases  caused  by  data  reflecting  the perceptions  of  specific  stakeholders .  Here,  social  professions  are  called  upon to  help  shape  the  development  of  DSSs  in  order  to  make  targeted  use  of  all named potentials .

## Acknowledgements

This research was supported by the Digital Society research program funded by the Ministry of Culture and Science of the German State of North Rhine-Westphalia .

## References

- Abbott ,  A .  (1988):  The  system  of  professions .  An  essay  on  the  division  of  expert  labor, Chicago .
- Ackermann ,  T  .  (2020): Risikoeinschätzungsinstrumente und professionelles Handeln im Kinderschutz:  Wie  Sozialarbeiter\_innen  mit  'Kinderschutzbögen'  interagieren  und was  das  mit  Professionalität  zu  tun  hat,  Sozial  Extra,  Advance  online  publication, https://doi .org/10 .1007/s12054-020-00351-x .
- Allhutter , D ./ Mager , A ./ Cech , F ./ Fischer , F ./ Grill , G . (2020): Der AMS-Algorithmus . Eine Soziotechnische Analyse des Arbeitsmarktchancen-Assistenz-Systems (AMAS): Endbericht, Wien, epub .oeaw .ac .at/ita/ita-projektberichte/2020-02 .pdf .

- Barocas , S ./ Boyd , D . (2017): Engaging the ethics of data science in practice . Communications of the ACM, 60(11), pp . 23 - 25, https://doi .org/10 .1145/3144172 .
- Bastian ,  P  .  (2014):  Statistisch  urteilen  -  professionell  handeln .  Überlegungen  zu  einem (scheinbaren) Widerspruch, Zeitschrift für Sozialpädagogik, 12(4), pp . 145 - 164 .
- Bastian ,  P  .  (2019):  Sozialpädagogische  Entscheidungen . Professionelle Urteilsbildung in der Sozialen Arbeit, Leverkusen .
- Berg , M . (1996): Practices of reading and writing . The constitutive role of the patient record in medical work, Sociology of Health &amp; Illness, 18(4), pp . 499 - 524 .
- Börjeson , L ./ Höjer , M ./ Dreborg , K .-H ./ Ekvall , T ./ Finnveden , G . (2006): Scenario types and techniques: Towards a user's guide . Futures, 38(7), pp . 723 - 739, https://doi . org/10 .1016/j .futures .2005 .12 .002 .
- Boyd ,  D .  (2016): Undoing the neutrality of big data, Florida Law Review Forum, 67(1), pp . 226 - 232 .
- Braun , M ./ Hummel , P  ./ Beck , S ./ Dabrock , P  . (2020): Primer on an ethics of AI-based decision support systems in the clinic, Journal of medical ethics, https://doi .org/10 .1136/ medethics-2019-105860 .
- Cairns ,  I ./ Jonas ,  M ./ Wallis ,  K .  (2018): The ethics of sharing: How do social workers decide  what  to  record  in  shared  health  records?  Ethics  and  Social  Welfare,  12(4), p . 348 - 369, https://doi .org/10 .1080/17496535 .2017 .1384849 .
- Chiusi , F ./ Fischer , S ./K ayser-Bril , N ./ Spielkamp , M . (eds .) (2020): Automating society report  2020,  AlgorithmWatch,  Berlin/Gütersloh,  https://automatingsociety .algorithmwatch .org/ [15 .12 .2020] .
- Coeckelbergh ,  M .  (2019):  Artificial  Intelligence,  Responsibility  Attribution,  and  a  Relational Justification of Explainability . Science and Engineering Ethics, pp . 2051 - 2068, https://doi .org/10 .1007/s11948-019-00146-8 .
- Collingridge ,  D .  (1980):  The  social  control  of  technology,  The  Open  University  Press, Milton Keynes .
- Crawford , K . (2013): The hidden biases in big data, https://hbr .org/2013/04/the-hiddenbiases-in-big-data [29 .03 .2019] .
- Evans ,  M ./ Hilbert ,  J .  (2020):  Zur  Zukunft  der  Arbeit  in  der  Sozial-  und  Gesundheitswirtschaft in der Digitalisierungsära, in:  Nadia  Kutscher/Thomas  Ley/Udo Seelmeyer  et  al .  (eds .),  Handbuch  Soziale  Arbeit  und  Digitalisierung,  Weinheim, pp . 76 - 88 .
- Foster , K . A ./ Stiffman , A . R . (2009): Child welfare workers' adoption of decision support technology . Journal of Technology in Human Services, 27(2), pp . 106 - 126, https://doi . org/10 .1080/15228830902749039 .
- Geis , J . R ./ Brady , A ./ Wu , C . C ./ Ranschaert , E . et al . (2019): Ethics of artificial intelligence in radiology . Summary of the joint European and North American multisociety statement, Insights into Imaging 10: 101 .
- German Council for Scientific Information Infrastructures (RfII) (2020): The data quality challenge . Recommendations for sustainable research in the digital turn, Göttingen, https://rfii .de/?p=4203 [3 .8 .2021] .

- Gillingham , P  . (2019a): Decision support systems, social justice and algorithmic accountability in social work . A new challenge, Practice, 31(4), pp . 277 - 290 .
- Gillingham ,  P  .  (2019b): The development of algorithmically based decision-making systems  in  children's  protective  services .  Is  administrative  data  good  enough?  British Journal of Social Work, 50(2), pp . 565 - 580 .
- Gillingham ,  P  .  (2019c): Can predictive algorithms assist decision-making in social work with  children  and  families? Child  Abuse  Review ,  28(2),  pp . 114 - 126,  https://doi . org/10 .1002/car .2547 .
- Gillingham , P  . (2016): Big data in social welfare . The development of a critical perspective on social work's latest 'electronic turn', Australian Social Work, 70(2), pp . 135 - 147 .
- Greilich ,  T .  (2019):  Predictive  Policing .  Wenn  die  Polizei  in  die  Zukunft  schaut .  Serie: Digitalisierung der Polizeiarbeit . Wegweiser Verwaltung Der Zukunft, Wegweiser Media  &amp;  Conferences  GmbH  Berlin,  https://www .vdz .org/oeffentliche-sicherheit/predic tive-policing .
- Grunwald , A . (2019): Technology assessment in practice and theory, London/New York .
- Hoose , F ./ Schneiders , K ./ Schönauer , A .-L . (2021): Von Robotern und Smartphones . Stand und  Akzeptanz  der  Digitalisierung  im  Sozialsektor,  in:  Wunder,  M .  (ed .),  Digitalisierung und Soziale Arbeit: Transformationen, Beharrungen, Herausforderungen, Bad Heilbrunn, pp . 97 - 109, https://doi .org/10 .35468/5909-07 .
- Institute of Electrical and Electronics Engineers (Ed .) (1990): IEEE standard glossary of software  engineering  terminology,  www .informatik .htw-dresden .de/~hauptman/SEI/ IEEE\_Standard\_Glossary\_of\_Software\_Engineering\_Terminology %20 .pdf [9 .8 .2021] .
- Kolleck , A ./ Orwat , C . (2020): Mögliche Diskriminierung durch algorithmische Entscheidungssysteme  und  maschinelles  Lernen  -  ein  Überblick:  TAB-Hintergrundpapier Nr . 24 .
- Kreidenweis , H . (2018): Digitalisierung ändert nichts - außer alles: Chancen und Risiken für Einrichtungen der Behindertenhilfe . Praxis Und Management, 57(3), pp . 122 - 125 .
- Larson , J ./ Mattu , S ./ Kirchner , L ./ Angwin , J . (2016): How we analyzed the COMPAS recidivism algorithm, https://www .propublica .org/article/how-we-analyzed-the-compasrecidivism-algorithm .
- Latour ,  B .  (1996):  On  actor-network  theory .  A  few  clarifications,  Soziale  Welt,  47(4), pp . 369 - 381 .
- Liedgren ,  P  ./ Elvhage ,  G ./ Ehrenberg ,  A ./ Kullberg ,  C .  (2016):  The  use  of  decision  support systems  in  social  work:  A  scoping  study  literature  review .  Journal  of  Evidence-Informed Social Work, 13(1), pp . 1 - 20, https://doi .org/10 .1080/15433714 .2014 .914992 .
- Maier ,  A ./ Cimiano ,  P  .  (2020):  Predicting  independent living outcomes from written reports  of  social  workers,  Proceedings  of  the  Fourth  Workshop  on  Natural  Language Processing and Computational Social Science, Association of Computational Linguistics, pp . 139 - 148 .
- Merchel , J ./ Tenhaken , W . (2015): Dokumentation pädagogischer Prozesse in der Sozialen Arbeit .  Nutzen  durch  digitalisierte  Verfahren,  in:  Kutscher,  N ./Ley,  T ./Seelmeyer,  U . (eds .), Mediatisierung (in) der sozialen Arbeit, Baltmannsweiler, pp . 171 - 191 .

- Monnickendam , M ./ Savaya , R ./ Waysman , M . (2005): Thinking processes in social workers'  use  of  a  clinical  decision  support  system:  A  qualitative  study .  Social  Work  Research, 29(1), pp . 21 - 30, https://doi .org/10 .1093/swr/29 .1 .21 .
- Nami ,  M . R ./ Bertels ,  K .  (2007): A survey of autonomic computing systems, Third international conference on autonomic and autonomous  systems (ICAS'07), IEEE, pp . 26 - 31 .
- Neri , E ./ Coppola , F ./ Miele , V  ./ Bibbolino , C ./ Grassi , R . (2020): Artificial intelligence . Who is responsible for the decision? Radiol med, 125, pp . 517 - 521 .
- Raji ,  D .  (2020):  How  our  data  encodes  systematic  racism .  Technologists  must  take  responsibility  for  the  toxic  ideologies  that  our  data  sets  and  algorithms  reflect,  MIT Technology  Review,  https://www .technologyreview .com/2020/12/10/1013617/racismdata-science-artificial-intelligence-ai-opinion/ [21 .01 .2021] .
- Schneider , D . (2020): Decision Support Systeme in der Sozialen Arbeit . Herausforderungen an die Rolle der TA in Innovationsprozessen, in: Nierling, L ./Torgersen, H . (eds .), Die  neutrale  Normativität  der  Technikfolgenabschätzung .  Konzeptionelle  Auseinandersetzung und praktischer Umgang, Baden-Baden, pp . 117 - 138 .
- Schneider , D . (2022): 'das braucht die Technik nicht alles zu wissen' . Digitale Datenerfassung im Spannungsfeld zwischen Privatheit, Datenschutz und gesellschaftlichem Auftrag, in: Friedewald, M ./Kreutzer, M ./Hansen, M . (eds .), Selbstbestimmung, Privatheit und  Datenschutz .  Gestaltungsoptionen  für  einen  europäischen  Weg .  DUD  Fachbeiträge, Wiesbaden, pp . 241 - 260 .
- Schneider ,  D .  (in  press):  Ethische  und  professionsspezifische  Herausforderungen  im Diskurs um algorithmische Systeme der Entscheidungsunterstützung im Kontext der Teilhabeplanung  für  Menschen  mit  Behinderung,  in:  Sonar,  A ./Weber,  K .  (eds .), Künst  liche Intelligenz und Gesundheit, Stuttgart, pp . 87 - 132 .
- Schneider , D ./ Seelmeyer , U . (2019): Challenges in using big data to develop decision support systems for social work in Germany, Journal of Technology in Human Services, 37(2 - 3), pp . 113 - 128 .
- Schneider ,  D ./ Sonar ,  A ./ Weber ,  K .  (2022):  Zwischen  Automatisierung  und  ethischem Anspruch . Disruptive Effekte des KI-Einsatzes in und auf Professionen der Gesundheitsversorgung, in: Pfannstiel, M . (ed .), Künstliche Intelligenz im Gesundheitswesen, Wiesbaden, pp . 325 - 348 .
- Schomberg , R . von (2015): Responsible Innovation: The new paradigm for science, technology  and  innovation  policy,  in:  Bogner,  A ./Decker,  M ./Sotoudeh,  M .  (eds .),  Gesellschaft - Technik - Umwelt . Neue Folge: Vol . 18 . Responsible Innovation: Neue Impulse für die Technikfolgenabschätzung? Baden-Baden, pp . 47 - 70 .
- Schrödter , M ./ Bastian , P  ./ Taylor , B . (2018): Risikodiagnostik in der Sozialen Arbeit an der Schwelle zum 'digitalen Zeitalter' von Big Data Analytics, Preprint, Advance online publication, https://doi .org/10 .13140/RG .2 .2 .22119 .14240 .
- Shiller ,  U ./ Strydom ,  M . (2018): Evidence-based practice in child protection services: Do we have time for this? Social Work, 54(4), https://doi .org/10 .15270/54-4-669 .
- Spielkamp ,  M .  (Ed .)  (2019):  Automating  society .  Taking  stock  of  automated  decision making  in  the  EU,  A  report  by  AlgorithmWatch  in  cooperation  with  Bertelsmann

- Stiftung, supported by the Open Society Foundations, AW AlgorithmWatch gGmbH, www .algorithmwatch .org/automating-society [18 .03 .2019] .
- Ückert ,  S ./ Sürgit ,  H ./ Diesel ,  G .  (Eds .)  (2020):  Digitalisierung  als  Erfolgsfaktor  für  das Sozial- und Wohlfahrtswesen, Baden-Baden .
- van der Put , C . E ./ Hermanns , J ./ van Rijn-van Gelderen , L ./ Sondeijker , F  . (2016): Detection of unsafety in families with parental and/or child developmental problems at the start of family support, BMC Psychiatry, 16, 15, https://doi .org/10 .1186/s12888-016-0715-y .
- Van Someren , M . W  ./ Barnard , Y . F  ./ Sandberg , J . A . C . (1994): The think aloud method . A practical approach to modelling cognitive processes, London .
- Wachter, S ./ Mittelstadt ,  B ./ Floridi ,  L .  (2017):  Transparent,  explainable,  and  accountable AI for robotics: To create fair and accountable AI and robotics, we need precise regulation  and  better  methods  to  certify,  explain,  and  audit  inscrutable  systems,  Science Robotics, 2(6), https://doi .org/10 .1126/scirobotics .aan6080 .
- Weber , K . (2013): What is it like to encounter an autonomous artificial agent? AI &amp; Soc, 28(4), pp . 483 - 489 .
- Weizenbaum , J . (1976): Computer power and human reason . From judgement to calculation, W . H . Freeman &amp; Co Ltd .
- Zweig ,  K . A ./ Fischer ,  S ./ Lischka ,  K .  (2018):  Wo  Maschinen  irren  können .  Fehlerquellen und  Verantwortlichkeiten  in  Prozessen  algorithmischer  Entscheidungsfindung,  Arbeitspapier, Bertelsmann Stiftung .