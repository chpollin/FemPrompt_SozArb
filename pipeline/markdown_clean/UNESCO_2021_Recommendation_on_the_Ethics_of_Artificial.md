---
source_file: UNESCO_2021_Recommendation_on_the_Ethics_of_Artificial.pdf
conversion_date: 2026-02-03T09:27:17.266085
converter: docling
quality_score: 95
---

<!-- image -->

## Recommendation on the ethics of artificial intelligence

## PREAMBLE

The General Conference of the United Nations Educational, Scientific and Cultural Organization (UNESCO), meeting in Paris from 9 to 24 November 2021, at its 41st session,

Recognizing the profound and dynamic positive and negative impacts of artificial intelligence (AI) on societies, environment, ecosystems and human lives, including the human mind, in part because of the new ways in which its use influences human thinking, interaction and decision-making and affects education, human, social and natural sciences, culture, and communication and information,

Recalling that,  by  the  terms  of  its  Constitution,  UNESCO  seeks  to  contribute  to  peace  and  security  by promoting  collaboration  among  nations  through  education,  the  sciences,  culture,  and  communication  and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world,

Convinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic  justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction,

Guided by the purposes and principles of the Charter of the United Nations,

Considering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic,  political  and  cultural  processes,  scientific  and  engineering  practices,  animal  welfare,  and  the environment and ecosystems,

Also recognizing that AI technologies can deepen existing divides and inequalities in the world, within and between countries, and that justice, trust and fairness must be upheld so that no country and no one should be left behind, either by having fair access to AI technologies and enjoying their benefits or in the protection against their negative implications, while recognizing the different circumstances of different countries and respecting the desire of some people not to take part in all technological developments,

Conscious of the fact that all countries are facing an acceleration in the use of information and communication technologies and AI technologies, as well as an increasing need for media and information literacy, and that the digital economy presents important societal, economic and environmental challenges and opportunities of benefit-sharing,  especially for low- and middle-income countries (LMICs), including but not limited to least developed countries (LDCs), landlocked developing countries (LLDCs) and small island developing States (SIDS), requiring the recognition, protection and promotion of endogenous cultures, values and knowledge in order to develop sustainable digital economies,

Further recognizing that  AI  technologies  have  the  potential  to  be  beneficial  to  the  environment  and ecosystems, and in order for those benefits to be realized, potential harms to and negative impacts on the environment and ecosystems should not be ignored but instead addressed,

Noting that addressing risks and ethical concerns should not hamper innovation and development but rather provide  new  opportunities  and  stimulate  ethically-conducted  research  and  innovation  that  anchor  AI technologies  in  human  rights  and  fundamental  freedoms,  values  and  principles,  and  moral  and  ethical reflection,

Also recalling that in November 2019, the General Conference of UNESCO, at its 40th session, adopted 40 C/Resolution  37,  by  which  it  mandated  the  Director-General  'to  prepare  an  international  standard-setting instrument on the ethics of artificial intelligence (AI) in the form of a recommendation', which is to be submitted to the General Conference at its 41st session in 2021,

Recognizing that the development of AI technologies necessitates a commensurate increase in data, media and information literacy as well as access to independent, pluralistic, trusted sources of information, including as part of efforts to mitigate risks of misinformation, disinformation and hate speech, and harm caused through the misuse of personal data,

Observing that  a  normative  framework  for  AI  technologies  and  its  social  implications  finds  its  basis  in international and national legal frameworks, human rights and fundamental freedoms, ethics, need for access to data, information and knowledge, the freedom of research and innovation, human and environmental and ecosystem well-being, and connects ethical values and principles to the challenges and opportunities linked to AI technologies, based on common understanding and shared aims,

Also recognizing that  ethical  values  and  principles  can  help  develop  and  implement  rights-based  policy measures and legal norms, by providing guidance with a view to the fast pace of technological development,

Also convinced that globally accepted ethical standards for AI technologies, in full respect of international law, in particular human rights law, can play a key role in developing AI-related norms across the globe,

Bearing in mind the Universal Declaration of Human Rights (1948), the instruments of the international human rights  framework,  including  the  Convention  Relating  to  the  Status  of  Refugees  (1951),  the  Discrimination (Employment and Occupation) Convention (1958), the International Convention on the Elimination of All Forms of Racial Discrimination (1965), the International Covenant on Civil and Political Rights (1966), the International Covenant on Economic, Social and Cultural Rights (1966), the Convention on the Elimination of All Forms of Discrimination against Women (1979), the Convention on the Rights of the Child (1989), and the Convention on the Rights of Persons with Disabilities (2006), the Convention against Discrimination in Education (1960), the Convention on the Protection and Promotion of the Diversity of Cultural Expressions (2005), as well as any other relevant international instruments, recommendations and declarations,

Also noting the  United  Nations  Declaration  on  the  Right  to  Development  (1986);  the  Declaration  on  the Responsibilities of the Present Generations Towards Future Generations (1997); the Universal Declaration on Bioethics and Human Rights (2005); the United Nations Declaration on the Rights of Indigenous Peoples (2007); the United Nations General Assembly resolution on the review of the World Summit on the Information Society (A/RES/70/125) (2015); the United Nations General Assembly Resolution on Transforming our world: the 2030 Agenda for Sustainable Development (A/RES/70/1) (2015); the Recommendation Concerning the Preservation of, and Access to, Documentary Heritage Including in Digital Form (2015); the Declaration of Ethical  Principles  in  relation  to  Climate  Change  (2017);  the  Recommendation  on  Science  and  Scientific Researchers (2017); the Internet Universality Indicators (endorsed by UNESCO's International Programme for the Development of Communication in 2018), including the ROAM principles (endorsed by UNESCO's General Conference  in  2015);  the  Human  Rights  Council's  resolution  on  'The  right  to  privacy  in  the  digital  age' (A/HRC/RES/42/15)  (2019);  and  the  Human  Rights  Council's  resolution  on  'New  and  emerging  digital technologies and human rights' (A/HRC/RES/41/11) (2019),

Emphasizing that specific attention must be paid to LMICs, including but not limited to LDCs, LLDCs and SIDS, as they have their own capacity but have been underrepresented in the AI ethics debate, which raises concerns  about  neglecting  local  knowledge,  cultural  pluralism,  value  systems  and  the  demands  of  global fairness to deal with the positive and negative impacts of AI technologies,

Also conscious of the many existing national policies, other frameworks and initiatives elaborated by relevant United Nations entities, intergovernmental organizations, including regional organizations, as well as those by the private sector, professional organizations, non-governmental organizations, and the scientific community, related to the ethics and regulation of AI technologies,

Further convinced that AI technologies can bring important benefits, but that achieving them can also amplify tension around innovation, asymmetric access to knowledge and technologies, including the digital and civic literacy deficit that limits the public's ability to engage in topics related to AI, as well as barriers to access to information  and  gaps  in  capacity,  human  and  institutional  capacities,  barriers  to  access  to  technological

innovation, and a lack of adequate physical and digital infrastructure and regulatory frameworks, including those related to data, all of which need to be addressed,

Underlining that the strengthening of global cooperation and solidarity, including through multilateralism, is needed to facilitate fair access to AI technologies and address the challenges that they bring to diversity and interconnectivity of cultures and ethical systems, to mitigate potential misuse, to realize the full potential that AI can bring, especially in the area of development, and to ensure that national AI strategies are guided by ethical principles,

Taking fully into account that the rapid development  of  AI  technologies  challenges  their  ethical implementation and governance, as well as the respect for and protection of cultural diversity, and has the potential to disrupt local and regional ethical standards and values,

1. Adopts the present Recommendation on the Ethics of Artificial Intelligence on this twenty-third day of November 2021;

2. Recommends that Member States apply on a voluntary basis the provisions of this Recommendation by taking appropriate steps, including whatever legislative or other measures may be required, in conformity with the constitutional practice and governing structures of each State, to give effect within their jurisdictions to the principles and norms of the Recommendation in conformity with international law, including international human rights law;

3. Also recommends that  Member States engage all stakeholders, including business enterprises, to ensure that they play their respective roles  in the  implementation  of this  Recommendation; and  bring the Recommendation to the attention of the authorities, bodies, research and academic organizations, institutions and  organizations  in  public,  private  and  civil  society  sectors  involved  in  AI  technologies,  so  that  the development and use of AI technologies are guided by both sound scientific research as well as ethical analysis and evaluation.

## I. SCOPE OF APPLICATION

1. This Recommendation addresses ethical issues related to the domain of Artificial Intelligence to the extent that they are within UNESCO's mandate. It approaches AI ethics as a systematic normative reflection, based on a holistic, comprehensive, multicultural and evolving framework of interdependent values, principles and  actions  that  can  guide  societies  in  dealing  responsibly  with  the  known  and  unknown  impacts  of  AI technologies on human beings, societies and the environment and ecosystems, and offers them a basis to accept or reject  AI  technologies.  It  considers  ethics  as  a  dynamic  basis  for  the  normative  evaluation  and guidance of AI technologies, referring to human dignity, well-being and the prevention of harm as a compass and as rooted in the ethics of science and technology.

2. This Recommendation does not have the ambition to provide one single definition of AI, since such a definition would need to change over time, in accordance with technological developments. Rather, its ambition is to  address  those  features of AI systems  that are of central ethical relevance. Therefore, this Recommendation approaches AI systems as systems which have the capacity to process data and information in a way that resembles intelligent behaviour, and typically includes aspects of reasoning, learning, perception, prediction, planning or control. Three elements have a central place in this approach:

- (a) AI  systems  are  information-processing  technologies  that  integrate  models  and  algorithms  that produce a capacity to learn and to perform cognitive tasks leading to outcomes such as prediction and decision-making in material and virtual environments. AI systems are designed to operate with varying  degrees  of  autonomy  by  means  of  knowledge  modelling  and  representation  and  by exploiting data and calculating correlations. AI systems may include several methods, such as but not limited to:
- (i) machine learning, including deep learning and reinforcement learning;
- (ii) machine reasoning, including planning, scheduling, knowledge representation and reasoning, search, and optimization.

AI systems can be used in cyber-physical systems, including the Internet of things, robotic systems, social robotics, and human-computer interfaces, which involve control, perception, the processing

of data collected by sensors, and the operation of actuators in the environment in which AI systems work.

- (b) Ethical questions regarding AI systems pertain to all stages of the AI system life cycle, understood here  to  range  from  research,  design  and  development  to  deployment  and  use,  including maintenance,  operation,  trade,  financing,  monitoring  and  evaluation,  validation,  end-of-use, disassembly and termination. In addition, AI actors can be defined as any actor involved in at least one stage of the AI system life cycle, and can refer both to natural and legal  persons, such as researchers, programmers, engineers, data scientists, end-users, business enterprises, universities and public and private entities, among others.
- (c) AI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of  law,  security  and  policing,  dual  use,  and  human rights and fundamental  freedoms,  including freedom of expression, privacy and non-discrimination. Furthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping. Some of these issues are related to the capacity of AI systems to perform tasks which previously only living beings could do, and which were in some cases even limited to human beings only. These characteristics give AI systems a profound, new role in human practices and society, as well as in their relationship with the environment and ecosystems, creating a new context for children and young people to grow up in, develop an understanding of the world and themselves, critically understand media and information, and learn to make decisions. In the long term, AI systems could challenge humans' special sense of experience and agency, raising additional concerns about, inter alia, human selfunderstanding, social, cultural and environmental interaction, autonomy, agency, worth and dignity.
3. This Recommendation pays specific attention to the broader ethical implications of AI systems in relation to  the  central  domains  of  UNESCO:  education,  science,  culture,  and  communication  and  information,  as explored  in  the  2019  Preliminary  Study  on  the  Ethics  of  Artificial  Intelligence  by  the  UNESCO  World Commission on Ethics of Scientific Knowledge and Technology (COMEST):
- (a) Education,  because  living  in  digitalizing  societies  requires  new  educational  practices,  ethical reflection, critical thinking, responsible design practices and new skills, given the implications for the labour market, employability and civic participation.
- (b) Science, in the broadest sense and including all academic fields from the natural sciences and medical sciences to the social sciences and humanities, as AI technologies bring new research capacities  and  approaches,  have  implications  for  our  concepts  of  scientific  understanding  and explanation, and create a new basis for decision-making.
- (c) Cultural identity and diversity, as AI technologies can enrich cultural and creative industries, but can also lead to an increased concentration of supply of cultural content, data, markets and income in the hands of only a few actors, with potential negative implications for the diversity and pluralism of languages, media, cultural expressions, participation and equality.
- (d) Communication  and  information,  as  AI  technologies  play  an  increasingly  important  role  in  the processing, structuring and provision of information; the issues of automated journalism and the algorithmic provision of news and moderation and curation of content on social media and search engines are just a few examples raising issues related to access to information, disinformation, misinformation, hate speech, the emergence of new forms of societal narratives, discrimination, freedom of expression, privacy and media and information literacy, among others.

4. This Recommendation is addressed to Member States, both as AI actors and as authorities responsible for developing legal and regulatory frameworks throughout the entire AI system life cycle, and for promoting business  responsibility.  It  also  provides  ethical  guidance  to  all  AI  actors,  including  the  public  and  private sectors, by providing a basis for an ethical impact assessment of AI systems throughout their life cycle.

## II. AIMS AND OBJECTIVES

5. This Recommendation aims to provide a basis to make AI systems work for the good of humanity, individuals, societies and the environment and ecosystems, and to prevent harm. It also aims at stimulating the peaceful use of AI systems.

6. In addition to the existing ethical frameworks regarding AI around the world, this Recommendation aims to  bring  a  globally  accepted  normative  instrument  that  focuses  not  only  on  the  articulation  of  values  and principles, but also on their practical realization, via concrete policy recommendations, with a strong emphasis on inclusion issues of gender equality and protection of the environment and ecosystems.

7. Because the complexity of the ethical issues surrounding AI necessitates the cooperation of multiple stakeholders across the various levels and sectors of international, regional and national communities, this Recommendation aims to enable stakeholders to take shared responsibility based on a global and intercultural dialogue.

8. The objectives of this Recommendation are:
2. (a) to provide a universal framework of values, principles and actions to guide States in the formulation of their legislation, policies or other instruments regarding AI, consistent with international law;
3. (b) to guide the actions of individuals, groups, communities, institutions and private sector companies to ensure the embedding of ethics in all stages of the AI system life cycle;
4. (c) to  protect,  promote  and  respect  human  rights  and  fundamental  freedoms,  human  dignity  and equality, including gender equality; to safeguard the interests of present and future generations; to preserve  the  environment,  biodiversity  and  ecosystems;  and  to  respect  cultural  diversity  in  all stages of the AI system life cycle;
5. (d) to foster multi-stakeholder, multidisciplinary and pluralistic dialogue and consensus building about ethical issues relating to AI systems;
6. (e) to promote equitable access to developments and knowledge in the field of AI and the sharing of benefits, with particular attention to the needs and contributions of LMICs, including LDCs, LLDCs and SIDS.

## III. VALUES AND PRINCIPLES

9. The values and principles included below should be respected by all actors in the AI system life cycle, in the first place and, where needed and appropriate, be promoted through amendments to the existing and elaboration of new legislation, regulations and business guidelines. This must comply with international law, including the United Nations Charter and Member States' human rights obligations, and should be in line with internationally  agreed  social,  political,  environmental,  educational,  scientific  and  economic  sustainability objectives, such as the United Nations Sustainable Development Goals (SDGs).

10. Values play a powerful role as motivating ideals in shaping policy measures and legal norms. While the set of values outlined below thus inspires desirable behaviour and represents the foundations of principles, the  principles  unpack  the  values  underlying  them  more  concretely  so  that  the  values  can  be  more  easily operationalized in policy statements and actions.

11. While all the values and principles outlined below are desirable per se, in any practical contexts, there may be tensions between these values and principles. In any given situation, a contextual assessment will be necessary to manage potential tensions, taking into account the principle of proportionality and in compliance with  human  rights  and  fundamental  freedoms.  In  all  cases,  any  possible  limitations  on  human  rights  and fundamental  freedoms  must  have  a  lawful  basis,  and  be  reasonable,  necessary  and  proportionate,  and consistent with States' obligations under international law. To navigate such scenarios judiciously will typically require engagement with a broad range of appropriate stakeholders, making use of social dialogue, as well as ethical deliberation, due diligence and impact assessment.

12. The trustworthiness and integrity of the life cycle of AI systems is essential to ensure that AI technologies will work for the good of humanity, individuals, societies and the environment and ecosystems, and embody

the values and principles set out in this Recommendation. People should have good reason to trust that AI systems can bring individual and shared benefits, while adequate measures are taken to mitigate risks. An essential requirement for trustworthiness is that, throughout their life cycle, AI systems are subject to thorough monitoring by the relevant stakeholders as appropriate. As  trustworthiness is an outcome  of  the operationalization of the principles in this document, the policy actions proposed in this Recommendation are all directed at promoting trustworthiness in all stages of the AI system life cycle.

## III.1 VALUES

## Respect, protection and promotion of human rights and fundamental freedoms and human dignity

13. The  inviolable  and  inherent  dignity  of  every  human  constitutes  the  foundation  for  the  universal, indivisible, inalienable, interdependent and interrelated system of human rights and fundamental freedoms. Therefore, respect, protection and promotion of human dignity and rights as established by international law, including international human rights law, is essential throughout the life cycle of AI systems. Human dignity relates to the recognition of the intrinsic and equal worth of each individual human being, regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.

14. No  human  being  or  human  community  should  be  harmed  or  subordinated,  whether  physically, economically,  socially,  politically,  culturally  or  mentally  during  any  phase  of  the  life  cycle  of  AI  systems. Throughout the life cycle of AI systems, the quality of life of human beings should be enhanced, while the definition of 'quality of life' should be left open to individuals or groups, as long as there is no violation or abuse of human rights and fundamental freedoms, or the dignity of humans in terms of this definition.

15. Persons may interact with AI systems throughout their life cycle and receive assistance from them, such as care for vulnerable people or people in vulnerable situations, including but not limited to children, older persons, persons with disabilities or the ill. Within such interactions, persons should never be objectified, nor should their dignity be otherwise undermined, or human rights and fundamental freedoms violated or abused.

16. Human rights and fundamental freedoms must be respected, protected and promoted throughout the life  cycle  of  AI  systems.  Governments,  private  sector,  civil  society,  international  organizations,  technical communities and academia must respect human rights instruments and frameworks in their interventions in the  processes surrounding the life cycle of AI systems. New technologies need to provide new means to advocate, defend and exercise human rights and not to infringe them.

## Environment and ecosystem flourishing

17. Environmental and ecosystem flourishing should be recognized, protected and promoted through the life cycle of AI systems. Furthermore, environment and ecosystems are the existential necessity for humanity and other living beings to be able to enjoy the benefits of advances in AI.

18. All  actors involved in the life cycle of AI systems must comply with applicable international law and domestic legislation, standards and practices, such as precaution, designed for environmental and ecosystem protection and restoration, and sustainable development. They should reduce the environmental impact of AI systems, including but not limited to its carbon footprint, to ensure the minimization of climate change and environmental  risk  factors,  and  prevent  the  unsustainable  exploitation,  use  and  transformation  of  natural resources contributing to the deterioration of the environment and the degradation of ecosystems.

## Ensuring diversity and inclusiveness

19. Respect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle  of  AI  systems,  consistent  with  international  law,  including  human  rights  law.  This  may  be  done  by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds.

20. The scope of lifestyle choices, beliefs, opinions, expressions or personal experiences, including the optional use of AI systems and the co-design of these architectures should not be restricted during any phase of the life cycle of AI systems.

21. Furthermore, efforts, including international cooperation, should be made to overcome, and never take advantage  of,  the  lack  of  necessary  technological  infrastructure,  education  and  skills,  as  well  as  legal frameworks, particularly in LMICs, LDCs, LLDCs and SIDS, affecting communities.

## Living in peaceful, just and interconnected societies

22. AI actors should play a participative and enabling role to ensure peaceful and just societies, which is based  on  an  interconnected  future  for  the  benefit  of  all,  consistent  with  human  rights  and  fundamental freedoms. The value of living in peaceful and just societies points to the potential of AI systems to contribute throughout their life cycle to the interconnectedness of all living creatures with each other and with the natural environment.

23. The notion of humans being interconnected is based on the knowledge that every human belongs to a greater whole, which thrives when all its constituent parts are enabled to thrive. Living in peaceful, just and interconnected societies requires an organic, immediate, uncalculated bond of solidarity, characterized by a permanent search for peaceful relations, tending towards care for others and the natural environment in the broadest sense of the term.

24. This value demands that peace, inclusiveness and justice, equity and interconnectedness should be promoted throughout the life cycle of AI systems, in so far as the processes of the life cycle of AI systems should not segregate, objectify or undermine freedom and autonomous decision-making as well as the safety of human beings and communities, divide and turn individuals and groups against each other, or threaten the coexistence between humans, other living beings and the natural environment.

## III.2 PRINCIPLES

## Proportionality and Do No Harm

25. It  should  be  recognized  that  AI  technologies  do  not  necessarily,  per  se,  ensure  human  and environmental and ecosystem flourishing. Furthermore, none of the processes related to the AI system life cycle shall exceed what is necessary to achieve legitimate aims or objectives and should be appropriate to the context. In the event of possible occurrence of any harm to human beings, human rights and fundamental freedoms,  communities  and  society  at  large  or  the  environment  and  ecosystems,  the  implementation  of procedures for risk assessment and the adoption of measures in order to preclude the occurrence of such harm should be ensured.

26. The choice to use AI systems and which AI method to use should be justified in the following ways: (a) the AI method chosen should be appropriate and proportional to achieve a given legitimate aim; (b) the AI method chosen should not infringe upon the foundational values captured in this document, in particular, its use must not violate or abuse human rights; and (c) the AI method should be appropriate to the context and should be based on rigorous scientific foundations. In scenarios where decisions are understood to have an impact  that  is  irreversible  or  difficult  to  reverse  or  may  involve  life  and  death  decisions,  final  human determination should apply. In particular, AI systems should not be used for social scoring or mass surveillance purposes.

## Safety and security

27. Unwanted harms (safety risks), as well as vulnerabilities to attack (security risks) should be avoided and should be addressed, prevented and eliminated throughout the life cycle of AI systems to ensure human, environmental and ecosystem safety and security. Safe and secure AI will be enabled by the development of sustainable, privacy-protective data access frameworks that foster better training and validation of AI models utilizing quality data.

## Fairness and non-discrimination

28. AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance  with  international  law.  This  implies  an  inclusive  approach  to  ensuring  that  the  benefits  of  AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups,  cultural  systems,  different  language  groups,  persons  with  disabilities,  girls  and  women,  and disadvantaged, marginalized and vulnerable people or people in vulnerable situations. Member States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content

and services, and with respect for multilingualism and cultural diversity. Member States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI. At the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle. At the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability.

29. AI  actors  should  make  all  reasonable  efforts  to  minimize  and  avoid  reinforcing  or  perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of  such  systems.  Effective  remedy  should  be  available  against  discrimination  and  biased  algorithmic determination.

30. Furthermore,  digital  and  knowledge  divides  within  and  between  countries  need  to  be  addressed throughout an AI system life cycle, including in terms of access and quality of access to technology and data, in  accordance  with  relevant  national,  regional  and  international  legal  frameworks,  as  well  as  in  terms  of connectivity, knowledge and skills and meaningful participation of the affected communities, such that every person is treated equitably.

## Sustainability

31. The development of sustainable societies relies on the achievement of a complex set of objectives on a continuum of human, social, cultural, economic and environmental dimensions. The advent of AI technologies can either benefit sustainability objectives or hinder their realization, depending on how they are applied across countries  with  varying  levels  of  development.  The  continuous  assessment  of  the  human,  social,  cultural, economic and environmental impact of AI technologies should therefore be carried out with full cognizance of the implications of AI technologies for sustainability as a set of constantly evolving goals across a range of dimensions, such as currently identified in the Sustainable Development Goals (SDGs) of the United Nations.

## Right to Privacy, and Data Protection

32. Privacy, a right essential to the protection of human dignity, human autonomy and human agency, must be respected, protected and promoted throughout the life cycle of AI systems. It is important that data for AI systems be collected, used, shared, archived and deleted in ways that are consistent with international law and in line with the values and principles set forth in this Recommendation, while respecting relevant national, regional and international legal frameworks.

33. Adequate data protection frameworks and governance mechanisms should be established in a multistakeholder  approach  at  the  national  or  international  level,  protected  by  judicial  systems,  and  ensured throughout the life cycle of AI systems. Data protection frameworks and any related mechanisms should take reference  from  international  data  protection  principles  and  standards  concerning  the  collection,  use  and disclosure of personal data and exercise of their rights by data subjects while ensuring a legitimate aim and a valid legal basis for the processing of personal data, including informed consent.

34. Algorithmic systems require adequate privacy impact assessments, which also include societal and ethical considerations of their use and an innovative use of the privacy by design approach. AI actors need to ensure that they are accountable for the design and implementation of AI systems in such a way as to ensure that personal information is protected throughout the life cycle of the AI system.

## Human oversight and determination

35. Member States should ensure that it is always possible to attribute ethical and legal responsibility for any stage of the life cycle of AI systems, as well as in cases of remedy related to AI systems, to physical persons or to existing legal entities. Human oversight refers thus not only to individual human oversight, but to inclusive public oversight, as appropriate.

36. It may be the case that sometimes humans would choose to rely on AI systems for reasons of efficacy, but the decision to cede control in limited contexts remains that of humans, as humans can resort to AI systems

in  decision-making  and  acting,  but  an  AI  system  can  never  replace  ultimate  human  responsibility  and accountability. As a rule, life and death decisions should not be ceded to AI systems.

## Transparency and explainability

37. The  transparency  and  explainability  of  AI  systems  are  often  essential  preconditions  to  ensure  the respect, protection and promotion of human rights, fundamental freedoms and ethical principles. Transparency is necessary for relevant national and international liability regimes to work effectively. A lack of transparency could also undermine the possibility of effectively challenging decisions based on outcomes produced by AI systems and may thereby infringe the right to a fair trial and effective remedy, and limits the areas in which these systems can be legally used.

38. While efforts need to be made to increase transparency and explainability of AI systems, including those with  extra-territorial  impact,  throughout  their  life  cycle  to  support  democratic  governance,  the  level  of transparency and explainability should always be appropriate to the context and impact, as there may be a need to balance between transparency and explainability and other principles such as privacy, safety and security.  People  should  be  fully  informed  when  a  decision  is  informed  by  or  is  made  on  the  basis  of  AI algorithms, including when it affects their safety or human rights, and in those circumstances should have the opportunity  to  request  explanatory  information  from  the  relevant  AI  actor  or  public  sector  institutions.  In addition, individuals should be able to access the reasons for a decision affecting their rights and freedoms, and have the option of making submissions to a designated staff member of the private sector company or public sector institution able to review and correct the decision. AI actors should inform users when a product or service is provided directly or with the assistance of AI systems in a proper and timely manner.

39. From a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help  detect  and  prevent  negative  impacts  on  human  rights.  Transparency  aims  at  providing  appropriate information to the respective addressees to enable their understanding and foster trust. Specific to the AI system, transparency can  enable  people  to  understand  how  each  stage  of  an  AI  system  is  put  in  place, appropriate to the context and sensitivity of the AI system. It may also include insight into factors that affect a specific  prediction  or  decision,  and  whether  or  not  appropriate  assurances  (such  as  safety  or  fairness measures) are in place. In cases of serious threats of adverse human rights impacts, transparency may also require the sharing of code or datasets.

40. Explainability refers to making intelligible and providing insight into the outcome of AI systems. The explainability of AI systems also refers to the understandability of the input, output and the functioning of each algorithmic building block and how it contributes to the outcome of the systems. Thus, explainability is closely related to transparency, as outcomes  and  sub-processes  leading  to outcomes  should  aim  to be understandable  and  traceable,  appropriate  to  the  context.  AI  actors  should  commit  to  ensuring  that  the algorithms developed are explainable. In the case of AI applications that impact the end user in a way that is not temporary, easily reversible or otherwise low risk, it should be ensured that the meaningful explanation is provided  with  any  decision  that  resulted  in  the  action  taken  in  order  for  the  outcome  to  be  considered transparent.

41. Transparency and explainability relate closely to adequate responsibility and accountability measures, as well as to the trustworthiness of AI systems.

## Responsibility and accountability

42. AI  actors  and  Member  States  should  respect,  protect  and  promote  human  rights  and  fundamental freedoms,  and  should  also  promote  the  protection  of  the  environment  and  ecosystems,  assuming  their respective  ethical  and  legal  responsibility,  in  accordance  with  national  and  international  law,  in  particular Member  States'  human  rights  obligations,  and  ethical  guidance  throughout  the  life  cycle  of  AI  systems, including with respect to AI actors within their effective territory and control. The ethical responsibility and liability for the decisions and actions based in any way on an AI system should always ultimately be attributable to AI actors corresponding to their role in the life cycle of the AI system.

43. Appropriate  oversight,  impact  assessment,  audit  and  due  diligence  mechanisms,  including  whistleblowers' protection, should be developed to ensure accountability for AI systems and their impact throughout their  life  cycle.  Both  technical  and  institutional  designs  should  ensure  auditability  and  traceability  of  (the

working of) AI systems in particular to address any conflicts with human rights norms and standards and threats to environmental and ecosystem well-being.

## Awareness and literacy

44. Public  awareness and understanding of AI  technologies and the value  of data  should be  promoted through open and accessible education, civic engagement, digital skills  and  AI ethics training,  media  and information  literacy  and  training  led  jointly  by  governments,  intergovernmental  organizations,  civil  society, academia, the media, community leaders and the private sector, and considering the existing linguistic, social and cultural diversity, to ensure effective public participation so that all members of society can take informed decisions about their use of AI systems and be protected from undue influence.

45. Learning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems.

## Multi-stakeholder and adaptive governance and collaboration

46. International law and national sovereignty must be respected in the use of data. That means that States, complying with international law, can regulate the data generated within or passing through their territories, and take measures towards effective regulation of data, including data protection, based on respect for the right to privacy in accordance with international law and other human rights norms and standards.

47. Participation  of  different  stakeholders  throughout  the  AI  system  life  cycle  is  necessary  for  inclusive approaches to AI  governance, enabling  the  benefits  to  be  shared  by  all,  and  to  contribute  to  sustainable development. Stakeholders include but are not limited to governments, intergovernmental organizations, the technical community, civil society, researchers and academia, media, education, policy-makers, private sector companies, human rights institutions and equality bodies, anti-discrimination monitoring bodies, and groups for youth and children. The adoption of open standards and interoperability to facilitate collaboration should be in place. Measures should be adopted to take into account shifts in technologies, the emergence of new groups of stakeholders, and to allow for meaningful participation by marginalized groups, communities and individuals and, where relevant, in the case of Indigenous Peoples, respect for the self-governance of their data.

## IV. AREAS OF POLICY ACTION

48. The policy actions described in the following policy areas operationalize the values and principles set out  in  this  Recommendation.  The  main  action  is  for  Member  States  to  put  in  place  effective  measures, including, for example, policy frameworks or mechanisms, and to ensure that other stakeholders, such as private sector companies, academic and research institutions, and civil society adhere to them by, among other actions, encouraging all stakeholders to develop human rights, rule of law, democracy, and ethical impact assessment and due diligence tools in line with guidance including the United Nations Guiding Principles on Business and Human Rights. The process for developing such policies or mechanisms should be inclusive of all  stakeholders  and  should  take  into  account  the  circumstances  and  priorities  of  each  Member  State. UNESCO can  be  a  partner  and  support  Member  States  in  the  development  as  well  as  monitoring  and evaluation of policy mechanisms.

49. UNESCO recognizes that Member States will be at different stages of readiness to implement this Recommendation, in terms of scientific, technological, economic, educational, legal, regulatory, infrastructural, societal, cultural and other dimensions. It is noted that 'readiness' here is a dynamic status. In order to enable the  effective  implementation  of  this  Recommendation,  UNESCO  will  therefore:  (1)  develop  a  readiness assessment methodology to assist interested Member States in identifying their status at specific moments of their readiness trajectory along a continuum of dimensions; and (2) ensure support for interested Member States in terms of developing a UNESCO methodology for Ethical Impact Assessment (EIA) of AI technologies, sharing of best practices, assessment guidelines and other mechanisms and analytical work.

## POLICY AREA 1: ETHICAL IMPACT ASSESSMENT

50. Member  States  should  introduce  frameworks  for  impact  assessments,  such  as  ethical  impact assessment, to identify and assess benefits, concerns and risks of AI systems, as well as appropriate risk prevention,  mitigation  and  monitoring  measures,  among  other  assurance  mechanisms.  Such  impact assessments should identify impacts on human rights and fundamental freedoms, in particular but not limited

to  the  rights  of  marginalized  and  vulnerable  people  or  people  in  vulnerable  situations,  labour  rights,  the environment and ecosystems and ethical and social implications, and facilitate citizen participation in line with the values and principles set forth in this Recommendation.

51. Member States and private sector companies should develop due diligence and oversight mechanisms to identify, prevent, mitigate and account for how they address the impact of AI systems on the respect for human rights, rule of law and inclusive societies. Member States should also be able to assess the socioeconomic impact of AI systems on poverty and ensure that the gap between people living  in wealth and poverty, as well as the digital divide among and within countries, are not increased with the massive adoption of  AI  technologies at present and in the future. In order to do this, in particular, enforceable transparency protocols should be implemented, corresponding to the access to information, including information of public interest held by private entities. Member States, private sector companies and civil society should investigate the sociological and psychological effects of AI-based recommendations on humans in their decision-making autonomy. AI systems identified as potential risks to human rights should be broadly tested by AI actors, including in real-world conditions if needed, as part of the Ethical Impact Assessment, before releasing them in the market.

52. Member States and business enterprises should implement appropriate measures to monitor all phases of an AI system life cycle, including the functioning of algorithms used for decision-making, the data, as well as AI actors involved in the process, especially in public services and where direct end-user interaction is needed, as part of ethical impact assessment. Member States' human rights law obligations should form part of the ethical aspects of AI system assessments.

53. Governments should adopt a regulatory framework that sets out a procedure, particularly for public authorities, to carry out ethical impact assessments on AI systems to predict consequences, mitigate risks, avoid harmful consequences, facilitate citizen participation and address societal challenges. The assessment should also establish appropriate oversight mechanisms, including auditability, traceability and explainability, which enable the assessment of algorithms, data and design processes, as well as includeâ€¯external review of AI systems. Ethical impact assessments should be transparent and open to the public, where appropriate. Such assessments should also be multidisciplinary, multi-stakeholder, multicultural, pluralistic and inclusive. The public authorities should be required to monitor the AI systems implemented and/or deployed by those authorities by introducing appropriate mechanisms and tools.

## POLICY AREA 2: ETHICAL GOVERNANCE AND STEWARDSHIP

54. Member States should ensure that AI governance mechanisms are inclusive, transparent, multidisciplinary, multilateral (this includes the possibility of mitigation and redress of harm across borders) and  multi-stakeholder.  In  particular,  governance  should  include  aspects  of  anticipation,  and  effective protection, monitoring of impact, enforcement and redress.

55. Member States should ensure that harms caused through AI systems are investigated and redressed, by enacting strong enforcement mechanisms and remedial actions, to make certain that human rights and fundamental freedoms and the rule of law are respected in the digital world and in the physical world. Such mechanisms  and  actions  should  include  remediation  mechanisms  provided  by  private  and  public  sector companies. The auditability and traceability of AI systems should be promoted to this end. In addition, Member States should strengthen their institutional capacities to deliver on this commitment and should collaborate with researchers and other stakeholders to investigate, prevent and mitigate any potentially malicious uses of AI systems.

56. Member States are encouraged to develop national and regional AI strategies and to consider forms of soft  governance  such  as  a  certification  mechanism  for  AI  systems  and  the  mutual  recognition  of  their certification, according to the sensitivity of the application domain and expected impact on human rights, the environment and ecosystems, and other ethical considerations set forth in this  Recommendation.  Such a mechanism might include different levels of audit of systems, data, and adherence to ethical guidelines and to procedural requirements in view of ethical aspects. At the same time, such a mechanism should not hinder innovation or disadvantage small and medium enterprises or start-ups, civil society as well as research and science organizations, as a result of  an excessive administrative burden. These mechanisms should also include a regular monitoring component to ensure system robustness and continued integrity and adherence to ethical guidelines over the entire life cycle of the AI system, requiring re-certification if necessary.

57. Member States and public authorities should carry out transparent  self-assessment  of  existing  and proposed AI systems, which, in particular, should include the assessment of whether the adoption of AI is appropriate and, if so, should include further assessment to determine what the appropriate method is, as well as assessment as to whether such adoption would result in violations or abuses of Member States' human rights law obligations, and if that is the case, prohibit its use.

58. Member  States  should  encourage  public  entities,  private sector companies  and  civil society organizations to involve different stakeholders in their AI governance and to consider adding the role of an independent AI Ethics Officer or some other mechanism to oversee ethical impact assessment, auditing and continuous  monitoring  efforts  and  ensure  ethical  guidance  of  AI  systems.  Member  States,  private  sector companies and civil society organizations, with the support of UNESCO, are encouraged to create a network of independent AI Ethics Officers to give support to this process at national, regional and international levels.

59. Member States should foster the development of, and access to, a digital ecosystem for ethical and inclusive development of AI systems at the national level, including to address gaps in access to the AI system life cycle, while contributing to international collaboration. Such an ecosystem includes, in particular, digital technologies and infrastructure, and mechanisms for sharing AI knowledge, as appropriate.

60. Member  States  should  establish  mechanisms,  in  collaboration  with  international  organizations, transnational  corporations,  academic  institutions  and  civil  society,  to  ensure  the  active  participation  of  all Member  States,  especially  LMICs,  in  particular  LDCs,  LLDCs  and  SIDS,  in  international  discussions concerning AI governance. This can be through the provision of funds, ensuring equal regional participation, or any other mechanisms. Furthermore, in order to ensure the inclusiveness of AI fora, Member States should facilitate the travel of AI actors in and out of their territory, especially from LMICs, in particular LDCs, LLDCs and SIDS, for the purpose of participating in these fora.

61. Amendments to the existing  or  elaboration  of  new  national  legislation  addressing  AI  systems  must comply  with  Member  States'  human  rights  law  obligations  and  promote  human  rights  and  fundamental freedoms throughout the AI system life cycle. Promotion thereof should also take the form of governance initiatives,  good  exemplars  of  collaborative  practices  regarding  AI  systems,  and  national  and  international technical and methodological guidelines as AI technologies advance. Diverse sectors, including the private sector,  in  their  practices  regarding  AI  systems  must  respect,  protect  and  promote  human  rights  and fundamental freedoms using existing and new instruments in combination with this Recommendation.

62. Member States that acquire Al systems for human rights-sensitive use cases, such as law enforcement, welfare,  employment,  media  and  information  providers,  health  care  and  the  independent  judiciary  system should  provide  mechanisms  to  monitor  the  social  and  economic  impact  of  such  systems  by  appropriate oversight authorities, including independent data protection authorities, sectoral oversight and public bodies responsible for oversight.

63. Member States should enhance the capacity of the judiciary to make decisions related to AI systems as per the rule of law and in line with international law and standards, including in the use of AI systems in their deliberations, while ensuring that the principle of human oversight is upheld. In case AI systems are used by the judiciary, sufficient safeguards are needed to guarantee inter alia the protection of fundamental human rights, the rule of law, judicial independence as well as the principle of human oversight, and to ensure a trustworthy, public interest-oriented and human-centric development and use of AI systems in the judiciary.

64. Member States should ensure that governments and multilateral organizations play a leading role in ensuring  the  safety  and  security  of  AI  systems,  with  multi-stakeholder  participation.  Specifically,  Member States,  international  organizations  and  other  relevant  bodies  should  develop  international  standards  that describe measurable, testable levels of safety and transparency, so that systems can be objectively assessed and  levels  of  compliance  determined.  Furthermore,  Member  States  and  business  enterprises  should continuously support strategic research on potential safety and security risks of AI technologies and should encourage research into transparency and explainability, inclusion and literacy by putting additional funding into those areas for different domains and at different levels, such as technical and natural language.

65. Member States should implement policies to ensure that the actions of AI actors are consistent with international human rights law, standards and principles throughout the life cycle of AI systems, while taking into full consideration the current cultural and social diversities, including local customs and religious traditions, with due regard to the precedence and universality of human rights.

66. Member States should put in place mechanisms to require AI actors to disclose and combat any kind of stereotyping in the outcomes of AI systems and data, whether by design or by negligence, and to ensure that training data sets for AI systems do not foster cultural, economic or social inequalities, prejudice, the spreading of  disinformation  and  misinformation,  and  disruption  of  freedom  of  expression  and  access  to  information. Particular attention should be given to regions where the data are scarce.

67. Member States should implement policies to promote and increase diversity and inclusiveness that reflect their populations in AI development teams and training datasets, and to ensure equal access to AI technologies and their benefits, particularly for marginalized groups, both from rural and urban zones.

68. Member States should develop, review and adapt, as appropriate, regulatory frameworks to achieve accountability and responsibility for the content and outcomes of AI systems at the different phases of their life cycle. Member States should, where necessary, introduce liability frameworks or clarify the interpretation of existing  frameworks  to  ensure  the  attribution  of  accountability  for  the  outcomes  and  the  functioning  of  AI systems. Furthermore, when developing regulatory frameworks, Member States should, in particular, take into account that ultimate responsibility and accountability must always lie with natural or legal persons and that AI systems should not be given legal personality themselves. To ensure this, such regulatory frameworks should be consistent with the principle of human oversight and establish a comprehensive approach focused on AI actors and the technological processes involved across the different stages of the AI system life cycle.

69. In order to establish norms where these do not exist, or to adapt the existing legal frameworks, Member States should involve all AI actors (including, but not limited to, researchers, representatives of civil society and  law  enforcement,  insurers,  investors,  manufacturers,  engineers,  lawyers  and  users).  The  norms  can mature into best practices, laws and regulations. Member States are further encouraged to use mechanisms such as policy prototypes and regulatory sandboxes to accelerate the development of laws, regulations and policies, including regular reviews thereof, in line with the rapid development of new technologies and ensure that laws and regulations can be tested in a safe environment before being officially adopted. Member States should support local governments in the development of local policies, regulations and laws in line with national and international legal frameworks.

70. Member States should set clear requirements for AI system transparency and explainability so as to help ensure the trustworthiness of the full AI system life cycle. Such requirements should involve the design and  implementation  of  impact  mechanisms  that  take  into  consideration  the  nature  of  application  domain, intended use, target audience and feasibility of each particular AI system.

## POLICY AREA 3: DATA POLICY

71. Member States should work to develop data governance strategies that ensure the continual evaluation of  the  quality  of  training  data  for  AI  systems  including  the  adequacy  of  the  data  collection  and  selection processes, proper data security and protection measures, as well as feedback mechanisms to learn from mistakes and share best practices among all AI actors.

72. Member States should put in place appropriate safeguards to protect the right to privacy in accordance with international law, including addressing concerns such as surveillance. Member States should, among others, adopt or enforce legislative frameworks that provide appropriate protection, compliant with international law. Member States should strongly encourage all AI actors, including business enterprises, to follow existing international standards and, in particular, to carry out adequate privacy impact assessments, as part of ethical impact  assessments,  which  take  into  account  the  wider  socio-economic  impact  of  the  intended  data processing,  and  to  apply  privacy  by  design  in  their  systems.  Privacy  should  be  respected,  protected  and promoted throughout the life cycle of AI systems.

73. Member States should ensure that individuals retain rights over their personal data and are protected by a framework, which notably foresees: transparency; appropriate safeguards for the processing of sensitive data;  an  appropriate  level  of  data  protection;  effective  and  meaningful  accountability  schemes  and mechanisms; the full enjoyment of the data subjects' rights and the ability to access and erase their personal data in AI systems, except for certain circumstances in compliance with international law; an appropriate level of  protection  in  full  compliance  with  data  protection  legislation  where  data  are  being  used  for  commercial purposes such as enabling micro-targeted advertising, transferred cross-border; and an effective independent oversight as part of a data governance mechanism which keeps individuals in control of their personal data and fosters the benefits of a free flow of information internationally, including access to data.

74. Member States should establish their data policies or equivalent frameworks, or reinforce existing ones, to ensure full security for personal data and sensitive data, which, if disclosed, may cause exceptional damage, injury  or  hardship  to  individuals.  Examples  include  data  relating  to  offences,  criminal  proceedings  and convictions, and related security measures; biometric, genetic and health data; and -personal data such as that relating to race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other characteristics.

75. Member States should promote open data. In this regard, Member States should consider reviewing their policies and regulatory frameworks, including on access to information and open government to reflect AI-specific requirements and promoting mechanisms, such as open repositories for publicly funded or publicly held data and source code and data trusts, to support the safe, fair, legal and ethical sharing of data, among others.

76. Member  States  should  promote  and  facilitate  the  use  of  quality  and  robust  datasets  for  training, development and use of AI systems, and exercise vigilance in overseeing their collection and use. This could, if  possible  and  feasible,  include  investing  in  the  creation  of  gold  standard  datasets,  including  open  and trustworthy datasets, which are diverse, constructed on a valid legal basis, including consent of data subjects, when required by law. Standards for annotating datasets should be encouraged, including disaggregating data on gender and other bases, so it can easily be determined how a dataset is gathered and what properties it has.

77. Member States, as also suggested in the report of the United Nations Secretary-General's High-level Panel on Digital Cooperation, with the support of the United Nations and UNESCO, should adopt a digital commons approach to data where appropriate, increase interoperability of tools and datasets and interfaces of  systems  hosting  data,  and  encourage  private  sector  companies  to  share  the  data  they  collect  with  all stakeholders, as appropriate, for research, innovation or public benefits. They should also promote public and private efforts to create collaborative platforms to share quality data in trusted and secured data spaces.

## POLICY AREA 4: DEVELOPMENT AND INTERNATIONAL COOPERATION

78. Member States and transnational corporations should prioritize AI ethics by including discussions of AIrelated ethical issues into relevant international, intergovernmental and multi-stakeholder fora.

79. Member States should ensure that the use of AI in areas of development such as education, science, culture,  communication  and  information,  health  care,  agriculture  and  food  supply,  environment,  natural resource and infrastructure management, economic planning and growth, among others, adheres to the values and principles set forth in this Recommendation.

80. Member States should work through international organizations to provide platforms for international cooperation on AI for development, including by contributing  expertise, funding, data, domain knowledge, infrastructure,  and  facilitating  multi-stakeholder  collaboration  to  tackle  challenging  development  problems, especially for LMICs, in particular LDCs, LLDCs and SIDS.

81. Member  States  should  work  to  promote  international  collaboration  on  AI  research  and  innovation, including research and innovation centres and networks that promote greater participation and leadership of researchers from LMICs and other countries, including LDCs, LLDCs and SIDS.

82. Member States should promote AI ethics research by engaging international organizations and research institutions, as well as transnational corporations, that can be a basis for the ethical use of AI systems by public and private entities, including research into the applicability of specific ethical frameworks in specific cultures and contexts, and the possibilities to develop technologically feasible solutions in line with these frameworks.

83. Member States should encourage international cooperation and collaboration in the field of AI to bridge geo-technological  lines.  Technological  exchanges  and  consultations  should  take  place  between  Member States and their populations, between the public and private sectors, and between and among the most and least technologically advanced countries in full respect of international law.

## POLICY AREA 5: ENVIRONMENT AND ECOSYSTEMS

84. Member States and business enterprises should assess the direct and indirect environmental impact throughout the AI system life cycle, including, but not limited to, its carbon footprint, energy consumption and

the environmental impact of raw material extraction for supporting the manufacturing of AI technologies, and reduce  the  environmental  impact  of  AI  systems  and  data  infrastructures.  Member  States  should  ensure compliance of all AI actors with environmental law, policies and practices.

85. Member States should introduce incentives, when needed and appropriate, to ensure the development and  adoption  of  rights-based  and  ethical  AI-powered  solutions  for  disaster  risk  resilience;  the  monitoring, protection and regeneration of the environment and ecosystems; and the preservation of the planet. These AI systems should involve the participation of local and indigenous communities throughout the life cycle of AI systems and should support circular economy type approaches and sustainable consumption and production patterns. Some examples include using AI systems, when needed and appropriate, to:

- (a) Support the protection, monitoring and management of natural resources.
- (b) Support the prediction, prevention, control and mitigation of climate-related problems.
- (c) Support a more efficient and sustainable food ecosystem.
- (d) Support the acceleration of access to and mass adoption of sustainable energy.
- (e) Enable and promote the mainstreaming of sustainable infrastructure, sustainable business models and sustainable finance for sustainable development.
- (f) Detect pollutants or predict levels of pollution and thus help relevant stakeholders identify, plan and put in place targeted interventions to prevent and reduce pollution and exposure.

86. When choosing AI methods, given the potential data-intensive or resource-intensive character of some of them and the respective impact on the environment, Member States should ensure that AI actors, in line with  the  principle  of  proportionality,  favour  data,  energy  and  resource-efficient  AI  methods.  Requirements should be developed to ensure that appropriate evidence is available to show that an AI application will have the intended effect, or that safeguards accompanying an AI application can support the justification for its use. If  this  cannot  be  done,  the  precautionary  principle  must  be  favoured,  and  in  instances  where  there  are disproportionate negative impacts on the environment, AI should not be used.

## POLICY AREA 6: GENDER

87. Member States should ensure  that  the  potential  for  digital  technologies  and  artificial  intelligence  to contribute  to  achieving  gender  equality  is  fully  maximized,  and  must  ensure  that  the  human  rights  and fundamental freedoms of girls and women, and their safety and integrity are not violated at any stage of the AI system life cycle. Moreover, Ethical Impact Assessment should include a transversal gender perspective.

88. Member States  should  have  dedicated  funds  from  their  public  budgets  linked  to  financing  genderresponsive schemes, ensure that national digital policies include a gender action plan, and develop relevant policies, for example, on labour education, targeted at supporting girls and women to make sure they are not left  out  of  the  digital  economy  powered  by  AI.  Special  investment  in  providing  targeted  programmes  and gender-specific  language,  to  increase  the  opportunities  of  girls'  and  women's  participation  in  science, technology, engineering, and mathematics (STEM), including information and communication technologies (ICT) disciplines, preparedness, employability, equal career development and professional growth of girls and women, should be considered and implemented.

89. Member States should ensure that the potential of AI systems to advance the achievement of gender equality is realized. They should ensure that these technologies do not exacerbate the already wide gender gaps existing in several fields in the analogue world, and instead eliminate those gaps. These gaps include: the  gender  wage  gap;  the  unequal  representation  in  certain  professions  and  activities;  the  lack  of representation  at  top  management  positions,  boards  of  directors,  or  research  teams  in  the  AI  field;  the education gap; the digital and AI access, adoption, usage and affordability gap; and the unequal distribution of unpaid work and of the caring responsibilities in our societies.

90. Member States should ensure that gender stereotyping and discriminatory biases are not translated into AI systems, and instead identify and proactively redress these. Efforts are necessary to avoid the compounding negative  effect  of  technological  divides  in  achieving  gender  equality  and  avoiding  violence  such  as harassment, bullying or trafficking of girls and women and under-represented groups, including in the online domain.

91. Member States should encourage female entrepreneurship, participation and engagement in all stages of an AI system life cycle by offering and promoting economic, regulatory incentives, among other incentives and  support  schemes,  as  well  as  policies  that  aim  at  a  balanced  gender  participation  in  AI  research  in academia, gender representation on digital and AI companies' top management positions, boards of directors and  research  teams.  Member  States  should  ensure  that  public  funds  (for  innovation,  research  and technologies) are channelled to inclusive programmes and companies, with clear gender representation, and that private funds are similarly encouraged through affirmative action principles. Policies on harassment-free environments should be developed and enforced, together with the encouragement of the transfer of best practices on how to promote diversity throughout the AI system life cycle.

92. Member States should promote gender diversity in AI research in academia and industry by offering incentives to girls and women to enter the field, putting in place mechanisms to fight gender stereotyping and harassment within the AI research community, and encouraging academic and private entities to share best practices on how to enhance gender diversity.

93. UNESCO can help form a repository of best practices for incentivizing the participation of girls, women and under-represented groups in all stages of the AI system life cycle.

## POLICY AREA 7: CULTURE

94. Member States are encouraged to  incorporate  AI  systems,  where  appropriate,  in  the  preservation, enrichment, understanding, promotion, management and accessibility of tangible, documentary and intangible cultural  heritage,  including  endangered  languages  as  well  as  indigenous  languages  and  knowledges,  for example by introducing or updating educational programmes related to the application of AI systems in these areas, where appropriate, and by ensuring a participatory approach, targeted at institutions and the public.

95. Member States are encouraged to examine and address the cultural impact of AI systems, especially natural language processing (NLP) applications such as automated translation and voice assistants, on the nuances of human language and expression. Such assessments should provide input for the design and implementation of strategies that maximize the benefits from these systems by bridging cultural gaps and increasing human understanding, as well as addressing the negative implications such as the reduction of use, which  could  lead  to  the  disappearance  of  endangered  languages,  local  dialects,  and  tonal  and  cultural variations associated with human language and expression.

96. Member States should promote AI education and digital training for artists and creative professionals to assess  the  suitability  of  AI  technologies  for  use  in  their  profession,  and  contribute  to  the  design  and implementation of suitable AI technologies, as AI technologies are being used to create, produce, distribute, broadcast and consume a variety of cultural goods and services, bearing in mind the importance of preserving cultural heritage, diversity and artistic freedom.

97. Member States should promote awareness and evaluation of AI tools among local cultural industries and small and medium enterprises working in the field of culture, to avoid the risk of concentration in the cultural market.

98. Member States should engage technology companies and other stakeholders to promote a diverse supply of and plural access to cultural expressions, and in particular to ensure that algorithmic recommendation enhances the visibility and discoverability of local content.

99. Member States should foster new research at the intersection between AI and intellectual property (IP), for  example  to  determine  whether  or  how  to  protect  with  IP  rights  the  works  created  by  means  of  Al technologies. Member States should also assess how AI technologies are affecting the rights or interests of IP owners, whose works are used to research, develop, train or implement AI applications.

100. Member States should encourage museums, galleries, libraries and archives at the national level to use AI systems to highlight their collections and enhance their libraries, databases and knowledge base, while also providing access to their users.

## POLICY AREA 8: EDUCATION AND RESEARCH

101. Member States should work with international organizations, educational institutions and private and non-governmental entities to provide adequate AI literacy education to the public on all levels in all countries

in order to empower people and reduce the digital divides and digital access inequalities resulting from the wide adoption of AI systems.

102. Member States should promote the acquisition of 'prerequisite skills' for AI education, such as basic literacy, numeracy, coding and digital skills, and media and information literacy, as well as critical and creative thinking, teamwork, communication, socio-emotional and AI ethics skills, especially in countries and in regions or areas within countries where there are notable gaps in the education of these skills.

103. Member States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children's rights. These programmes should be accessible to non-technical as well as technical groups.

104. Member  States  should  encourage  research  initiatives  on  the  responsible  and  ethical  use  of  AI technologies in teaching, teacher training and e-learning, among other issues, to enhance opportunities and mitigate the challenges and risks involved in this area. The initiatives should be accompanied by an adequate assessment of the quality of education and impact on students and teachers of the use of AI technologies. Member States should also ensure that AI technologies empower students and teachers and enhance their experience, bearing in mind that relational and social aspects and the value of traditional forms of education are vital in teacher-student and student-student relationships and should be considered when discussing the adoption of AI technologies in education. AI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners' behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards. The data handed over to acquire knowledge collected during the learner's interactions with the AI system must not be subject to misuse, misappropriation or criminal exploitation, including for commercial purposes.

105. Member States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States.

106. Member States should develop, in accordance with their national education programmes and traditions, AI ethics curricula for all levels, and promote cross-collaboration between AI technical skills education and humanistic,  ethical  and  social  aspects  of  AI  education.  Online  courses  and  digital  resources  of  AI  ethics education should be developed in local languages, including indigenous languages, and take into account the diversity of environments, especially ensuring accessibility of formats for persons with disabilities.

107. Member  States  should  promote  and  support  AI  research,  notably  AI  ethics  research,  including  for example through investing in such research or by creating incentives for the public and private sectors to invest in this area, recognizing that research contributes significantly to the further development and improvement of AI  technologies  with  a  view  to  promoting  international  law  and  the  values  and  principles  set  forth  in  this Recommendation. Member States should also publicly promote the best practices of, and cooperation with, researchers and companies who develop AI in an ethical manner.

108. Member States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications.

109. Member States should encourage private sector companies to facilitate the access of the scientific community to their data for research, especially in LMICs, in particular LDCs, LLDCs and SIDS. This access should conform to relevant privacy and data protection standards.

110. To ensure a critical evaluation of AI research and proper monitoring of potential misuses or adverse effects, Member States should ensure that any future developments with regards to AI technologies should be based on rigorous and independent scientific research, and promote interdisciplinary AI research by including disciplines other than science, technology, engineering and mathematics (STEM), such as cultural studies, education,  ethics,  international  relations, law,  linguistics,  philosophy,  political  science,  sociology  and psychology.

111. Recognizing that AI technologies present great opportunities to help advance scientific knowledge and practice,  especially  in  traditionally  model-driven  disciplines,  Member  States  should  encourage  scientific communities to be aware of the benefits, limits and risks of their use; this includes attempting to ensure that conclusions drawn from data-driven approaches, models and treatments are robust and sound. Furthermore, Member States should welcome and support the role of the scientific community in contributing to policy and in cultivating awareness of the strengths and weaknesses of AI technologies.

## POLICY AREA 9: COMMUNICATION AND INFORMATION

112. Member States should use AI systems  to  improve  access  to  information  and  knowledge.  This  can include support to researchers, academia, journalists, the general public and developers, to enhance freedom of expression, academic and scientific freedoms, access to information, and increased proactive disclosure of official data and information.

113. Member States should ensure that AI actors respect and promote freedom of expression as well as access to information with regard to automated content generation, moderation and curation. Appropriate frameworks,  including  regulation,  should  enable  transparency  of  online  communication  and  information operators  and  ensure  users  have  access  to  a  diversity  of  viewpoints,  as  well  as  processes  for  prompt notification to the users on the reasons for removal or other treatment of content, and appeal mechanisms that allow users to seek redress.

114. Member  States  should  invest  in  and  promote  digital  and  media  and  information  literacy  skills  to strengthen critical thinking and competencies needed to understand the use and implication of AI systems, in order to mitigate and counter disinformation, misinformation and hate speech. A better understanding and evaluation of both the positive and potentially harmful effects of recommender systems should be part of those efforts.

115. Member States should create enabling environments for media to have the rights and resources to effectively report on the benefits and harms of AI systems, and also encourage media to make ethical use of AI systems in their operations.

## POLICY AREA 10: ECONOMY AND LABOUR

116. Member  States  should  assess  and  address  the  impact  of  AI  systems  on  labour  markets  and  its implications for education requirements, in all countries and with special emphasis on countries where the economy is labour-intensive. This can include the introduction of a wider range of 'core' and interdisciplinary skills at all education levels to provide current workers and new generations a fair chance of finding jobs in a rapidly changing market, and to ensure their awareness of the ethical aspects of AI systems. Skills such as 'learning how to learn', communication, critical thinking, teamwork, empathy, and the ability to transfer one's knowledge across domains, should be taught alongside specialist, technical skills, as well as low-skilled tasks. Being transparent about what skills are in demand and updating curricula around these are key.

117. Member States should support collaboration agreements among governments, academic institutions, vocational education and training institutions, industry, workers' organizations and civil society to bridge the gap of skillset requirements to align training programmes and strategies with the implications of the future of work and the needs of industry, including small and medium enterprises. Project-based teaching and learning approaches for AI should be promoted, allowing for partnerships between public institutions, private sector companies, universities and research centres.

118. Member  States  should  work  with  private  sector  companies,  civil  society  organizations  and  other stakeholders, including workers and unions to ensure a fair transition for at-risk employees. This includes putting in place upskilling and reskilling programmes, finding effective mechanisms of retaining employees during those transition periods, and exploring 'safety net' programmes for those who cannot be retrained. Member States should develop and implement programmes to research and address the challenges identified that  could  include  upskilling  and  reskilling,  enhanced  social  protection,  proactive  industry  policies  and interventions, tax benefits, new taxation forms, among others. Member States should ensure that there is sufficient public funding to support these programmes. Relevant regulations, such as tax regimes, should be carefully examined and changed if needed to counteract the consequences of unemployment caused by AIbased automation.

119. Member States should encourage and support researchers to analyse the impact of AI systems on the local labour environment in order to anticipate future trends and challenges. These studies should have an interdisciplinary  approach  and  investigate  the  impact  of  AI  systems  on  economic,  social  and  geographic sectors,  as  well  as  on  human-robot  interactions  and  human-human  relationships,  in  order  to  advise  on reskilling and redeployment best practices.

120. Member States should take appropriate steps to ensure competitive markets and consumer protection, considering possible measures and mechanisms at national, regional and international levels, to prevent abuse of dominant market positions, including by monopolies, in relation to AI systems throughout their life cycle, whether  these  are  data,  research,  technology,  or  market.  Member  States  should  prevent  the  resulting inequalities, assess relevant markets and promote competitive markets. Due consideration should be given to LMICs, in particular LDCs, LLDCs and SIDS, which are more exposed and vulnerable to the possibility of abuses of market dominance as a result of a lack of infrastructure, human capacity and regulations, among other  factors.  AI  actors  developing  AI  systems  in  countries  which  have  established  or  adopted  ethical standards on AI should respect these standards when exporting these products, developing or applying their AI systems in countries where such standards may not exist, while respecting applicable international law and domestic legislation, standards and practices of these countries.

## POLICY AREA 11: HEALTH AND SOCIAL WELL-BEING

121. Member States should endeavour to  employ  effective  AI  systems  for  improving  human  health  and protecting the right to life, including mitigating disease outbreaks, while building and maintaining international solidarity to tackle global health risks and uncertainties, and ensure  that their deployment of AI systems in health care be consistent with international law and their human rights law obligations. Member States should ensure that actors involved in health care AI systems take into consideration the importance of a patient's relationships with their family and with health care staff.

122. Member States should ensure that the development and deployment of AI systems related to health in general and mental health in particular, paying due attention to children and youth, is regulated to the effect that they are safe, effective, efficient, scientifically and medically proven and enable evidence-based innovation and medical progress. Moreover, in the related area of digital health interventions, Member States are strongly encouraged to actively involve patients and their representatives in all relevant steps of the development of the system.

123. Member States should pay particular attention in regulating prediction, detection and treatment solutions for health care in AI applications by:

- (a) ensuring oversight to minimize and mitigate bias;
- (b) ensuring  that  the  professional,  the  patient,  caregiver  or  service  user  is  included  as  a  'domain expert' in the team in all relevant steps when developing the algorithms;
- (c) paying due attention to privacy because of the potential need for being medically monitored and ensuring that all relevant national and international data protection requirements are met;
- (d) ensuring effective mechanisms so that those whose personal data is being analysed are aware of and provide informed consent for the use and analysis of their data, without preventing access to health care;
- (e) ensuring the human care and final decision of diagnosis and treatment are taken always by humans while acknowledging that AI systems can also assist in their work;
- (f) ensuring, where necessary, the review of AI systems by an ethical research committee prior to clinical use.

124. Member States should establish research on the effects and regulation of potential harms to mental health  related  to  AI  systems,  such  as  higher  degrees  of  depression,  anxiety,  social  isolation,  developing addiction, trafficking, radicalization and misinformation, among others.

125. Member States should develop guidelines for human-robot interactions and their impact on humanhuman relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for

use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a humanrobot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases.

126. Member States should ensure that human-robot interactions comply with the same values and principles that  apply  to  any  other  AI  systems,  including  human  rights  and  fundamental  freedoms,  the  promotion  of diversity, and the protection of vulnerable people or people in vulnerable situations. Ethical questions related to AI-powered systems for neurotechnologies and brain-computer interfaces should be considered in order to preserve human dignity and autonomy.

127. Member States should ensure that users can easily identify whether they are interacting with a living being,  or  with  an  AI  system  imitating  human  or  animal  characteristics,  and  can  effectively  refuse  such interaction and request human intervention.

128. Member States should implement policies to raise awareness about the anthropomorphization of AI technologies and technologies that recognize and mimic human emotions, including in the language used to mention  them,  and  assess  the  manifestations,  ethical  implications  and  possible  limitations  of  such anthropomorphization, in particular in the context of robot-human interaction and especially when children are involved.

129. Member States should encourage  and  promote  collaborative  research  into  the  effects  of  long-term interaction of people with AI systems, paying particular attention to the psychological and cognitive impact that these systems can have on children and young people. This should be done using multiple norms, principles, protocols, disciplinary approaches, and assessment of the modification of behaviours and habits, as well as careful  evaluation  of  the  downstream  cultural  and  societal  impacts.  Furthermore,  Member  States  should encourage research on the effect of AI technologies on health system performance and health outcomes.

130. Member States, as well as all stakeholders, should put in place mechanisms to meaningfully engage children and young people in conversations, debates and decision-making with regard to the impact of AI systems on their lives and futures.

## V. MONITORING AND EVALUATION

131. Member States should, according to their specific conditions, governing structures and constitutional provisions, credibly and transparently monitor and evaluate policies, programmes and mechanisms related to ethics  of  AI,  using  a  combination  of  quantitative  and  qualitative  approaches.  To  support  Member  States, UNESCO can contribute by:

- (a) developing a UNESCO methodology for Ethical Impact Assessment (EIA) of AI technologies based on rigorous scientific research and grounded in international human rights law, guidance for its implementation in all stages of the AI system life cycle, and capacity-building materials to support Member States' efforts to train government officials, policy-makers and other relevant AI actors on EIA methodology;
- (b) developing a UNESCO readiness assessment methodology to assist Member States in identifying their status at specific moments of their readiness trajectory along a continuum of dimensions;
- (c) developing  a  UNESCO  methodology  to  evaluate  ex  ante  and  ex  post  the  effectiveness  and efficiency of the policies for AI ethics and incentives against defined objectives;
- (d) strengthening the research- and evidence-based analysis of and reporting on policies regarding AI ethics;
- (e) collecting and disseminating progress, innovations, research reports, scientific publications, data and  statistics  regarding  policies  for  AI  ethics,  including  through  existing  initiatives,  to  support sharing  best practices  and  mutual  learning,  and  to advance  the  implementation  of  this Recommendation.

132. Processes for monitoring and evaluation should ensure broad participation of all stakeholders, including, but not limited to, vulnerable people or people in vulnerable situations. Social, cultural and gender diversity should be ensured, with a view to improving learning processes and strengthening the connections between findings, decision-making, transparency and accountability for results.

133. In the interests of promoting best policies and practices related to ethics of AI, appropriate tools and indicators  should  be  developed  for  assessing  the  effectiveness  and  efficiency  thereof  against  agreed standards,  priorities  and  targets,  including  specific  targets  for  persons  belonging  to  disadvantaged, marginalized populations, and vulnerable people or people in vulnerable situations, as well as the impact of AI systems at individual and societal levels. The monitoring and assessment of the impact of AI systems and related AI ethics policies and practices should be carried out continuously in a systematic way proportionate to the relevant risks. This should be based on internationally agreed frameworks and involve evaluations of private and public institutions, providers and programmes, including self-evaluations, as well as tracer studies and the development of sets of indicators. Data collection and processing should be conducted in accordance with international law, national legislation on data protection and data privacy, and the values and principles outlined in this Recommendation.

134. In particular, Member States may wish to consider possible mechanisms for monitoring and evaluation, such as an ethics commission, AI ethics observatory, repository covering human rights-compliant and ethical development of AI systems, or contributions to existing initiatives by addressing adherence to ethical principles across UNESCO's areas of competence, an experience-sharing mechanism, AI regulatory sandboxes, and an assessment guide for all AI actors to evaluate their adherence to policy recommendations mentioned in this document.

## VI. UTILIZATION AND EXPLOITATION OF THE PRESENT RECOMMENDATION

135. Member States and all other stakeholders as identified in this Recommendation should respect, promote and protect the ethical values, principles and standards regarding AI that are identified in this Recommendation, and should take all feasible steps to give effect to its policy recommendations.

136. Member  States  should  strive  to  extend  and  complement  their  own  action  in  respect  of  this Recommendation,  by  cooperating  with  all  relevant  national  and  international  governmental  and  nongovernmental organizations, as well as transnational corporations and scientific organizations, whose activities fall within the scope and objectives of this Recommendation. The development of a UNESCO Ethical Impact Assessment methodology and the establishment of national commissions for the ethics of AI can be important instruments for this.

## VII. PROMOTION OF THE PRESENT RECOMMENDATION

137. UNESCO has the vocation to be the principal United Nations agency to promote and disseminate this Recommendation, and accordingly will work in collaboration with other relevant United Nations entities, while respecting their mandate and avoiding duplication of work.

138. UNESCO, including its bodies, such as the World Commission on the Ethics of Scientific Knowledge and Technology (COMEST), the International Bioethics Committee (IBC) and the Intergovernmental Bioethics Committee  (IGBC),  will  also  work  in  collaboration  with  other  international,  regional  and  sub-regional governmental and non-governmental organizations.

139. Even  though,  within  UNESCO,  the  mandate  to  promote  and  protect  falls  within  the  authority  of governments and intergovernmental bodies, civil society will be an important actor to advocate for the public sector's interests and therefore UNESCO needs to ensure and promote its legitimacy.

## VIII. FINAL PROVISIONS

140. This Recommendation needs to be understood as a whole, and the foundational values and principles are to be understood as complementary and interrelated.

141. Nothing  in  this  Recommendation  may  be  interpreted  as  replacing,  altering  or  otherwise  prejudicing States' obligations or rights under international law, or as approval for any State, other political, economic or social actor, group or person to engage in any activity or perform any act contrary to human rights, fundamental freedoms, human dignity and concern for the environment and ecosystems, both living and non-living.