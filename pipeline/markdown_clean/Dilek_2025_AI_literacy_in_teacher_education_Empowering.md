---
source_file: Dilek_2025_AI_literacy_in_teacher_education_Empowering.pdf
conversion_date: 2026-02-03T08:47:08.828144
converter: docling
quality_score: 95
---

research-article

2025

1325083

<!-- image -->

## AI Literacy in Teacher Education: Empowering Educators Through Critical Co-Discovery

Melis Dilek 1 , Evrim Baran 1 , and Ezequiel Aleman 2

## Abstract

Teacher education increasingly  requires  educators  to  engage  with  generative  AI  technologies,  yet  critical  and  reflective engagement opportunities remain scarce. While AI is often framed as a tool for automation, its broader pedagogical and ethical implications receive less attention. To address this gap, we implemented a critical co-discovery approach within an online AI in Education (AIEd) course to enhance educators' AI literacy. This illustrative case study examines which AI literacy components can be developed through critical co-discovery and how this approach fosters educators' reflective, critical, and participatory engagement with AI. Findings revealed that through co-discovery activities, educators co-constructed an understanding of AI concepts, ethical considerations, and context-specific applications. The study highlights the need for prolonged engagement with AI literacy by integrating it into teacher education program to ensure educators can critically navigate and assert their agency in AI's complex role in education.

## Keywords

AI in education, AI literacy, teacher education, critical co-discovery

Artificial intelligence (AI) is increasingly shaping the educational landscape, transforming both classroom practices and broader  institutional  policies.  In  classrooms,  AI-powered personalized learning systems are being utilized to address learners'  diverse  needs  (U.S.  Department  of  Education, Office of Educational Technology, 2023). For teaching and administrative  tasks,  AI  promises  to  assist  educators  with lesson planning, generating assessment questions, and providing  automated  feedback  to  reduce  teachers'  workload (Mondal et al., 2023). AI is also applied in accessibility support, where intelligent personal assistants assist individuals with disabilities in communication and learning (Zdravkova et al., 2022). As AI technologies become more pervasive, it is imperative that educators are not merely passive users but active  participants  in  the  design  and  decision-making  processes that govern these tools for education. This requires the development  of  teachers'  AI  literacy  through  engaging, hands-on activities that  empower them with the agency to critically assess, integrate, and influence AI applications in their practice.

AI literacy defined as the ability to understand AI's essential features, evaluate its inherent biases, and assess its societal impacts (Strauß, 2021) is particularly urgent in today's context, where AI technologies frequently operate in opaque and unaccountable ways (Langran et al., 2024). The need for educator preparation that integrates technical, pedagogical, and ethical dimensions of AI is clear, as echoed in calls for professional development programs that balance theoretical knowledge, practical skills, and professional judgment (Chan, 2023; Sperling et al., 2024). In response to these calls, we propose critical co-discovery as a pedagogical approach that not only facilitates AI literacy for educators (AIEd) but also  equips  educators  with  the  critical,  reflective  skills needed  to  shape  AI  integration  in  education  in  ways  that align with their values and specific contexts.

While  generative AI  promises  to  reduce  teachers'  workloads  by  automating  tasks  like  lesson  planning  and  grading (Srinivasa et al., 2022) and creating more personalized learning opportunities for students (Xie et al., 2019), these narratives  often  reflect  a  narrow  framing.  Commercial  EdTech discourses frequently prioritize marketable features of AI-assisted  tools  over  addressing  the  real  needs  of  teachers and students (Chan &amp; Hu, 2023; Williamson &amp; Eynon, 2020). Such  mechanisms,  defined  as  discursive  closures  (Deetz, 1992), perpetuate technological determinism and overshadow critical  considerations  of  pedagogy  and  educators'  roles. Discursive closure highlights how dominant narratives constrain educators' agency and critical engagement with AI. For

1 Iowa State University, Ames, USA 2 Universidad Tecnológica de Uruguay, Montevideo, Uruguay

## Corresponding Author:

Evrim Baran, Professor, School of Education, College of Human Sciences, Affiliate Faculty-Human Computer Interaction (HCI), Iowa State University, 0624B Lagomarcino Hall, Ames, IA 50011, USA. Email: ebaran@iastate.edu

<!-- image -->

<!-- image -->

<!-- image -->

https://doi.org/10.1177/00224871251325083 Journal of Teacher Education 2025, Vol. 76(3) 294  -311 © 2025 American Association of Colleges for Teacher Education Article reuse guidelines: sagepub.com/journals-permissions DOI: 10.1177/00224871251325083 journals.sagepub.com/home/jte

<!-- image -->

instance, educators' voices are often disqualified due to their perceived lack of technical expertise, and technological determinism  positions AI  as  an  inevitable  driver  of  educational progress, sidelining pedagogical considerations  (Aleman, 2024; Markham, 2021). These mechanisms restrict nuanced explorations of AI's role, reinforcing false dilemmas, such as choosing  between  protecting  student  agency  and  adopting data-driven assessment tools. As such, generative AI's potential  for  pedagogical  transformation  remains  limited  unless teachers are empowered to critically engage with these technologies and challenge their embedded assumptions.

Generative AI  is  frequently  conceptualized  in  multiple, often conflicting, ways. One perspective sees it as a transformative  tool  that  drives  personalized  learning  and  fosters innovation  in  educational  practices  (Moya  &amp;  Camacho, 2024), while another critiques it as a socio-technical system that reinforces existing power structures and deepens social inequities  (Joyce  &amp;  Cruz,  2024).  Limiting  its  description solely as a tool for pedagogical innovation or exclusively as a system embedded within existing power structures fails to capture its inherent complexity. These differing perspectives create a tension between viewing generative AI as an enabler of efficient, tailored teaching practices and understanding it as a manifestation of systems that perpetuate inequalities and biases.  Consequently,  addressing  this  duality  demands  a nuanced analysis of how these technologies are both shaped by-and actively  shape-the  sociocultural,  economic,  and political contexts of education (Williamson &amp; Eynon, 2020).

By framing generative AI as both a tool and a socio-technical  system,  we  seek  to  find  common  ground  where  discourses in education move beyond technical affordances and market-driven  solutions,  fostering  a  critical  and  reflective engagement that empowers educators to shape a more equitable, innovative, and contextually responsive future. There are opportunities to engage educators in imagining futures shaped by AI to uncover hidden biases, challenge deterministic  narratives,  and  co-create  solutions  that  align  with diverse educational needs (Selwyn, 2016). This perspective invites  us  to  broaden  our  inquiry  beyond  AI's  immediate capabilities  and  consider  how  its  integration  reshapes  the sociocultural, historical, and political dimensions of education. More attention is needed on how educators can engage with AI in ways that transcend its perceived inevitability and move beyond the simplistic binaries often promoted by dominant technocentric narratives. In response to these complexities,  approaches  like  critical  co-discovery  can  provide educators  with  a  framework  to  engage  with  and  navigate these  conflicting  perspectives  while  developing  their  AI literacy.

This study explores how critical co-discovery approach can facilitate educators' engagement with AIEd focusing on the following research questions: (a) What key components of AI literacy can be addressed through critical co-discovery? (b) How does the critical co-discovery approach foster educators' active and reflective engagement with AI in educational settings?

## Critical Co-Discovery as a Pedagogical Approach for Developing Educators' AI Literacy

We propose critical co-discovery as a pedagogical approach that is rooted in constructivism and speculative design. This approach empowers educators to construct a comprehensive understanding  of  generative  AI  by  actively  engaging  in hands-on, reflective experiences that build on their existing knowledge  and  challenge  preconceived  notions  (Dunne  &amp; Raby, 2013). Drawing from constructivist principles, educators  collaboratively  construct  meaning  and  insights  about AI's role in education through social interaction, dialogue, and  reflection,  enabling  them  to  become  active  agents  in shaping their professional practices and aligning AI integration with their pedagogical values and contexts.

Meanwhile,  by  incorporating  elements  of  speculative design,  critical  co-discovery  pushes  educators  to  challenge dominant narratives and envision alternative futures (Aleman et  al.,  2024). Through speculative exercises, critical co-discovery fosters curiosity, doubt, and critical reflection, encouraging educators to anticipate and interrogate the unexpected consequences  of  emerging  technologies.  Together,  these intertwined approaches equip educators with the intellectual and practical tools needed to navigate the complexities of AI adoption and to drive transformative, context-sensitive innovation in education.

Critical  co-discovery  encourages  educators  to  uncover preexisting  knowledge  through  exploration  and  hands-on engagement. In that way, co-discovery creates an interactive learning environment where educators actively engage with discussions on AI in education, collaboratively question their implications,  and  reimagine  their  roles  in  educational  settings. We identified four tenets of this approach: collective inquiry, critical reflection, participatory engagement, and cocreation of knowledge (Figure 1).

## Collective Inquiry

Collective  inquiry  refers  to  a  process  where  individuals engage in reflection and collaborative activities to generate new knowledge and improve practice. It involves integrating individual  and  collective  knowledge-building  processes. Collective  inquiry  emphasizes  collaboration  and  sharing ideas to build learning communities that foster both individual  growth  and  collective  innovation  in  teaching  practices (Michos &amp; Hernández-Leo, 2020). In the context of AIEd, it may refer to bringing educators together to inquire into the implementation and implications of AI technologies in education. This collaborative process helps educators to share their  opinions,  examine AI technologies' potential benefits

Figure 1. Critical Co-Discovery Components.

<!-- image -->

and limitations, and explore ethical concerns. With collective inquiry,  educators  can  co-develop  strategies  to  understand AI's impact, and address societal challenges AI poses in educational  settings.  For  example,  educators  might  collaboratively investigate how specific AI tools impact educational settings and how bias in the system might influence equitable learning outcomes in educational settings.

## Critical Reflection

Critical reflection is the process of examining and questioning beliefs, actions, and the systems to understand how they might impact others. It encourages taking action to create a more fair and just society (Gorski &amp; Dalton, 2020). In the context of AI, critical reflection starts with learners' analyzing and questioning their assumptions about AI technologies in education. It requires them to evaluate if AI tools might influence teaching practices, learning outcomes, and equity in the classroom. Apart from evaluating the immediate impact of AI, critical reflection also prompts educators to  consider  broader  questions  such  as:  Is  AI  integration truly  a  necessity  in  education,  or  are  there  alternative approaches to addressing these challenges? Could AI unintentionally widen the gap in access? These broader reflections  encourage  educators  to  engage  with  the  idea  of AI itself by critically examining whether its integration aligns with the goals of education and questioning what kind of future it might create.

## Participatory Engagement

Participatory engagement ensures active involvement from all  participants  by  encouraging  them  to  shape  discussions, share unique perspectives rooted in their professional contexts, and contribute lived experiences to the discovery process  (Cook-Sather  et  al.,  2014).  In  the  context  of  AIEd, educators from diverse backgrounds might actively evaluate how AI  impacts  students.  This  tenet  prioritizes  including diverse  voices,  such  as  teachers,  pre-service  teachers,  and instructional  designers,  creating  an  environment  where  all participants feel valued and contribute to critical discussions. By fostering active participation, educators are encouraged to  ask  questions,  critique  assumptions,  and  propose  strategies  reflecting  their  personal  experiences  and  collective understanding. This  enables  them  to  own  how AIEd  technologies impact their contexts.

## Co-Creation of Knowledge

Co-creation of knowledge refers to a process in which participants actively develop new understandings, insights, and strategies  through  shared  inquiry,  dialogue,  and  reflection (Vygotsky, 1978). Unlike expert-driven learning approaches, co-creation  emphasizes  mutual  contribution,  ensuring  that knowledge is dynamically constructed through diverse perspectives. Through this process, educators explore, challenge assumptions, and build a shared understanding that evolves as they interact with different viewpoints.

## AI Literacy in Teacher Education

AI literacy is increasingly recognized as a crucial component of  education,  yet  it  remains  insufficiently  integrated  into teacher education programs. While there is growing interest in this area, existing literature often lacks a cohesive strategy for incorporating AI literacy into teacher training (Sperling et al., 2024). Various definitions and frameworks have been proposed  to  conceptualize AI  literacy.  Long  and  Magerko (2020)  define  AI  literacy  as  'a  set  of  competencies  that enables  individuals  to  critically  evaluate  AI  technologies, communicate effectively with AI, and use AI as a tool across various contexts' (p. 2). Ng et al. (2021), in their scoping review,  identified  four  core  components  of  AI  literacy: understanding AI, applying AI, evaluating and creating AI, and addressing AI ethics.

To address the need for AI literacy in education, several frameworks have been developed. UNESCO has published an  AI  Competency  Framework  for  global  audience  of teachers, which equips educators with the necessary skills to integrate AI into their teaching in a human-centered perspective (Miao &amp; Cukurova, 2024). The European Union's updated DigComp 2.2 framework also incorporates AI literacy  as  a  crucial  aspect  of  digital  competence,  guiding citizens  in  responsibly  engaging  with  AI  technologies (Vuorikari et al., 2022).

In this study, we conceptualize AI literacy for educators as an evolving set of knowledge, skills, and critical awareness that  empowers  them  to  progressively  understand,  evaluate, and  teach  with AI  in  an  informed,  reflective,  and  ethically grounded manner (Laupichler et al., 2022). Drawing on existing AI literacy frameworks and definitions (e.g., Bali, 2023; Miao &amp; Cukurova, 2024; Ng et al., 2021), we synthesized a set of core components that capture this developmental process. These synthesized components, detailed in Table 1, reflects educators' growing proficiency and nuanced understanding of

Table 1. AI Literacy Components in the Literature.

| Components                               | Descriptions                                                                                                                                                                                                                                                                                                                                       | Related literature                                                      |
|------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| Fundamental AI concepts and applications | Understanding the essential AI concepts, including its capabilities and underlying algorithms. Recognizing how AI systems function, their potential applications in education, and their technological constraints.                                                                                                                                | Cope et al. (2020), Miao & Cukurova (2024), Ng et al. (2021)            |
| Ethical awareness and reflection         | Recognizing the ethical considerations with AI, such as privacy concepts, data security, algorithmic bias, and transparency. Assessing how AI technologies might inadvertently perpetuate discrimination and inequality in educational settings.                                                                                                   | Schiff et al. (2020), Archambault et al. (2024), Miao & Cukurova (2024) |
| Pedagogical integration                  | Integrating AI into pedagogy by critically reflecting on how AI could transform teaching practices and classroom dynamics. Developing strategies to teach students about AI in a way that encourages critical thinking and ethical awareness.                                                                                                      | Nazaretsky et al. (2022), Miao & Cukurova (2024)                        |
| Empowerment for advocacy and action      | Recognizing how AI might influence teachers' roles while retaining agency in making pedagogical choices in educational settings. Advocating for responsible and equitable AI practices in their educational environments and beyond by staying informed about AI policy and participating in discussions about the ethical use of AI in education. | Mouta et al. (2025)                                                     |
| Societal implications                    | Understanding the broader societal impacts of AI, such as its influence on employment, social structures, and power dynamics. Developing strategies for preparing students to navigate social, cultural, and economical challenges in an informed and socially responsible manner.                                                                 | Zhang et al. (2023), Walter (2024), Nguyen et al. (2023)                |

both the technical and sociocultural dimensions of AI integration in education.

Despite the availability of AI literacy frameworks, teachers' AI literacy remains unevenly developed, with significant variations in understanding and application across different educational contexts. Ding et al. (2024) examined the impact of case-based AI professional development on teachers' AI literacy,  finding  that  direct  instruction  and  collaborative problem-solving  improved  their  competencies.  However, teachers often struggled to apply this knowledge in practice, highlighting the need for sustained and situated professional development. Similarly, Ayanwale et  al.  (2024)  found  low levels of AI literacy among pre-service teachers, emphasizing  the  importance  of  aligning  curricula  with  established pedagogical frameworks like TPACK.

While  these  studies  emphasize  foundational AI  competencies, there is a growing recognition that teachers require a more critical and reflective approach to AIEd. As educators redefine  their  agency  in  a  technological  landscape,  new forms of interaction and collaboration emerge between AI, learners,  and  teachers.  A  critical  perspective  ensures  that teachers are not only technically competent but also capable of engaging with AI technologies to promote equity, inclusion, and ethical decision-making in education.

A substantial body of research highlights the risks associated with AI in education, including the exacerbation of systemic biases, increased inequalities for minoritized and underrepresented groups, and barriers to achieving equitable  education  (Akgun  &amp;  Greenhow,  2022;  Veletsianos et al., 2024). Issues related to data transparency and ownership further complicate these challenges, raising concerns about who controls the data generated by AI systems and how it is used. Similarly, Holmes et al. (2022) emphasize the ethical implications of AI in education, such as privacy risks and data biases, which necessitate targeted training for teachers. Educators who critically evaluate the ethical, pedagogical, and political dimensions of AI (Bali, 2024) will be better equipped to foster reflective practices among their students. This, in turn, necessitates thoughtful and informed engagement  with AI  technologies  in  educational  settings and  AI  literacy development  opportunities  tailored  to educators.

## Method

This illustrative case presents a comprehensive depiction of the  critical  co-discovery  approach  implemented  within  a newly designed online course titled 'Introduction to Artificial Intelligence in Education,,' the first course on AIEd offered in the  Fall  2023  within  the  Learning  Technologies  minor  program  at  a  research  university  in  Midwest  U.S.  The  course aimed to encourage learners to critically examine the role of AIEd and create a space for them to explore and reflect on its implications. This four-module, one-credit online course was delivered through Canvas learning management system and included both synchronous and asynchronous components. In total, two synchronous sessions were held within the scope of the course in the first and the last week of the course. In synchronous sessions, educators engaged in hands-on collaborative  activities  and  discussions  with  their  peers.  Discussions were  facilitated  through  critical  co-discovery  activities.  In addition, the course instructor shared weekly videos to guide

Figure 2. Course Module Content and Activities.

<!-- image -->

students  on  course  expectations  in  each  module  to  ensure teacher  presence  throughout  the  course.  Course  materials included  example  videos,  short  newspaper  articles,  slides, reading materials, labs, and discussion board activities integrated with online learning tools such as Padlet and Jamboard. Each week educators completed a module with asynchronous, reflective, and inquiry-based activities with their peers through discussion boards, and online digital tools. The learning objectives included: (a) Understanding the fundamental concepts of AI and its impact on education, (b) exploring the role of AI in the future of education, (c) analyzing the ethical implications of AI, including data privacy, ethics, and algorithmic bias, (d) developing  plans  for  thoughtfully  integrating  AI  tools  into educational settings, and (e) analyzing real-world cases, models, and tools for responsible AI adaptation in education. The present study focuses on critical co-discovery activities implemented within the course.

## Critical Co-Discovery Activities

Getting the underpinnings from critical co-discovery approach, we designed the following activities: (a) Collaborative Collage, which explored the future of AIEd;

(b) Teachable Machine, focusing on training algorithms; (c) Polarity  Management,  examining  controversies  in AI  integration; (d) Experimenting with Algorithmic Bias, analyzing biases present in generative AI tools; and (e) The Hype Cycle of AI, categorizing AI applications using the Gartner Hype Cycle model. These activities were facilitated through online tools such as Padlet, DALL-E, and Jamboard and were further  enriched  with  online  discussions  to  promote  deeper engagement and critical dialogue. Figure 2 provides an overview of the course module content and activities.

Collaborative Collage: The Future of AIEd. This activity aims to engage educators in a collaborative and imaginative process by using an AI image generator to create visual representations (collages), envisioning the future of AIEd (Figure 3 provides the  instructions  of  the  activity). While  educators  share  their individual  perspectives  about  how  they  envision  the  future educational setting, they also engage in a collective inquiry process  by  interacting  with  each  other's  alternative  futures. These AI-generated collages catalyze discussions on educators' perspectives regarding the role of AIEd, focusing on topics such as how AI might transform teaching and learning, its impact on the role of teachers, and broader societal

## Discussion: Visual Collage - The Future of Al A

TherearemanyattemptstopredictthefutureofAl.StartthisassignmentbyaddingapostonthisPadletdescribinghowyouimaginethe roleofAledintheyear2045.Onceyouaredone,takealookatyourclassmates'postsanddescribehowtheyaresimilarand/ordifferent. WhatcanwelearnaboutourperspectivesofAlinthefuturebasedonthisPadlet?

PadletincludesanoptiontocreateAl-generated imagesbasedonyourprompts.You need toclickonthe(..)iconandthengoto"I Can't Draw"

## DONOTFORGETTOADDYOURNAMETOYOURPOST.

Whenyouaredone,clicknexttoseethenextsection.

## What is the futureofAI?

Figure 3. Instructions for the Collaborative Collage Activity.

implications.  By  looking  at  these  future  images,  educators examine the present realities of AIEd, bridging future possibilities with current educational contexts. By centering discussions around AI-generated images, educators are encouraged to critique and challenge dominant narratives about AI, fostering a critical space where they can comfortably contest ideas and  reflect.  Through  these  reflective  discussions,  educators discover  different  stances  and  dynamically  build  their  own understanding.

Teachable  Machine. The  Teachable  Machine  activity  helps educators understand how machine learning works through hands-on experience and exploration. Using Teachable Machine, an interactive tool that allows users to train a simple machine learning model with their webcams (teachablemachine.withgoogle.com), educators engage in collective inquiry by experimenting with how AI processes data and discussing  potential  risks.  The  activity  invites  educators  to design a machine learning process that labels data fostering participatory engagement as they explore how machine learning works and its limitations. Each educator trains their own algorithm, reflecting on how accurately the machine identifies inputs and recognizing potential biases in the data. This process  encourages  critical  reflection  on  the  limitations  of machine learning in capturing complex social dynamics. Figure 4 provides an example of an educator's training page for a  model  recognizing  images  of  the  numbers  '1'  and  '2.' Through this activity, educators without technical expertise can gain insight into machine learning mechanisms and cocreate knowledge by examining its broader implications for teaching, equity, and decision-making.

Polarity  Management. This  activity  helps  educators  understand  and  navigate  the  complexities  of  AI  integration  in education through polarity mapping. Polarity mapping allows  participants  to  explore  the  interplay  between  two seemingly opposing viewpoints in a speculative scenario, in this case, one educator fully embracing AI and another resisting  its  integration.  Instead  of  choosing  one  side  over  the other, educators examine how these perspectives are interdependent, recognizing potential benefits and unintended consequences.  It  aims  to  develop  a  balanced  approach  to  AI integration in education.

The  activity  begins  with  an  online  discussion  board, where each educator reflects on the positives and negatives of AI integration. Then, during a synchronous session, educators  are  introduced  to  polarity  mapping  as  a  method  for balancing two interdependent values or objectives that may appear contradictory but are, in reality, complementary. After this introduction, educators use Jamboard to complete their polarity maps, visually organizing their reflections. Educators are  involved  in  collective  inquiry  by  sharing  insights  and challenging  assumptions.  The  activity  also  fosters  critical reflection as participants assess AI's impact on teaching and learning. By actively engaging in the discussion and mapping  process,  educators  collaboratively  shape  their  understanding of AI integration in education and build knowledge together.  Figure  5  illustrates  the  activity  page  for  polarity management.

Experimenting With Algorithmic Bias. In this activity, educators explore the concept of algorithmic bias in generative AI tools by conducting experiments with AI image generators. The activity can build on prior discussions about how AI can reflect  cultural  biases,  particularly  in  language  and  image generation. Educators first select a generative AI tool, such as ChatGPT (40), Padlet, Bing Image Creator, or Adobe Firefly,  allowing  them  to  engage  with  different  platforms  and

Figure 4. Teachable Machine Example Artifact.

<!-- image -->

Figure 5. Activity Page for Polarity Management.

<!-- image -->

observe how each handles image generation. They then generate images based on prompts like 'a person,' 'a woman,' 'a  house,'  'a  street,'  and  'a  plate  of  food,'  incorporating variations  with  cultural  or  geographical  descriptors.  This step aims to uncover how the AI interprets these prompts and whether  it  introduces  cultural  biases. After  generating  the images, educators collaboratively analyze how AI systems interpret human input, fostering a deeper understanding of inherent biases and enabling them to critique AI-generated speculations in light of their own lived experiences. The collaborative  and  investigative  nature  of  this  activity  invites participants to co-create knowledge about algorithmic bias

Figure 6. Experimenting With AI Bias Discussion Board Example.

<!-- image -->

and  build  critical  awareness  through  experimentation  and reflection.  Figure  6  presents  an  example  artifact  from  the activity.

The AI Hype Cycle. This activity aims to help educators critically  evaluate  the  current  state  and  future  potential  of  AI technologies in education using the Gartner Hype Cycle. The Gartner Hype Cycle Model provides a graphical representation of the maturity, adoption, and social application of specific  technologies  over  time  (Fenn  &amp;  Raskino,  2008).  It illustrates five key phases: the Innovation Trigger, Peak of Inflated Expectations, Trough of Disillusionment, Slope of Enlightenment,  and  Plateau  of  Productivity.  For  the  asynchronous activity 'Create Your Hype Cycle,' educators are first introduced to the Gartner Hype Cycle Model in the context  of  various  technologies.  After  this  introduction,  each educator creates their own hype cycle using Jamboard, shares it  on  the  discussion  board,  and  participates in peer discussions. By examining how technologies evolve through these stages,  educators  are  encouraged  to  critically  reflect  on whether AI tools are likely to become integral to educational systems or pass as temporary trends. The Hype Cycle activity invites educators to speculate on the future development and  impact  of AI  tools,  critically  assessing  whether  these technologies will become foundational in education or fade away like other trends, envisioning potential futures based on current trends.

Participatory engagement is fostered through peer discussions,  where  educators  share  insights  and  challenge  each other's perspectives. This activity contrasts educators' lived experiences regarding the life cycles of different technologies with potential long-term implications, promoting critical  evaluation  rather  than  passive  acceptance  of  AI  in education. Figure 7 provides a template of the Hype Cycle activity.

## Participants

Nine educators consented to participate in the study ( N = 9). Participants were selected based on their enrollment in the course and willingness to engage in the study. The participants  included  two  pre-service  teachers  enrolled  in  the Learning Technologies minor program, one PhD student in science  education,  one  instructional  designer,  and  five  inservice teachers. Due to their diverse backgrounds and levels of  experience,  we  refer  to  all  participants  as  'educators' throughout  the  paper. Among  the  in-service  teachers,  five had between 1 and 5 years of experience, while one had over 10 years of experience. The undergraduate students had limited  teaching  experience,  primarily  through  field  teaching. Regarding prior AI use, three of the six educators had integrated AI tools into their teaching, commonly using ChatGPT and Grammarly. Similarly, all undergraduate students showed some familiarity with these AI tools.

## Data Sources and Analysis

Data sources for the study included various artifacts created by students during critical co-discovery activities: Collaborative  Collage  images  ( n = 27),  reflections  on  a

Figure 7. The Hype Cycle Example.

<!-- image -->

teachable machine assignment ( n = 9), Polarity Management activity images ( n = 1), and Hype Cycle images and reflections ( n = 8).  Prior  to  the  study's  implementation,  Institutional Review Board (IRB) approval was obtained. Artifact analysis  was  the  primary  method  used,  involving  a  systematic examination of physical and digital artifacts that participants interacted with or produced. The analysis began with identifying and selecting relevant artifacts, such as student assignments, posts, and visuals. These artifacts were then categorized according to predetermined critical AI literacy components (e.g., foundations, ethics). Finally, we synthesized the findings to draw conclusions about the participants' experiences.

## Trustworthiness

Reflexivity protocols were utilized throughout the research process.  These  included  conducting  peer  debriefing  sessions (Lincoln &amp; Guba, 1985) and engaging in regular team discussions  to  examine  researchers'  positionalities  and minimize  potential  influence  on  the  research  process. Reflective memos were maintained to document research decisions and contextual observations. Measures to enhance transferability  included  providing  rich,  detailed  descriptions  of  study  activities  to  allow  other  teacher  educators and  researchers  the  applicability  of  the  findings  to  their own teacher education contexts. Author 1 was responsible for  communicating  with  participants  regarding  researchrelated tasks and also contributed to data analysis. Author 2 ensured the course's alignment with research goals and the interpretation of findings. Author 3 was the primary instructor of the course, facilitating discussions and data analysis.

The  instructor  was  not  involved  in  any  research-related communication  with  participants  to  diminish  the  instructor's  influence  on  participants'  responses.  In  addition,  to address potential issues about the dual roles of researcher, instructor  involvement  in  data  collection  was  systematically limited.

## Findings

Course  artifacts,  including  images  and  assignment  reflections were analyzed to illustrate how co-discovery activities engaged educators with  AI literacy elements: (a) Foundations, (b) ethics, (c) pedagogy, (d) empowerment, and (e) societal impact. Figure 8 shows the alignment between these AI literacy components and the corresponding activities.

## Foundational Knowledge of AI

Critical co-discovery activities, particularly 'Teachable Machine' and 'Experimenting with AI Bias,' aimed to facilitate educators' critical engagement with the fundamentals of AI. Apart from merely training the algorithms, all educators reflected on how machine learning produces adverse impacts by questioning the underlying reasons for these biases and its broader implications. For example, in the Teachable Machine activity, educators engaged in hands-on learning to deepen their understanding of how AI systems function. Once each educator  had  trained  their  algorithms,  they  reflected  on which  limitations  they  encountered  while  they  trained  the algorithms.

One  educator  reflected,  'I  learned  that  the  quality  of machine learning is dependent on the quality of the

Figure 8. Activity Alignment.

<!-- image -->

|                                           | ACTIVITIES            | ACTIVITIES        | ACTIVITIES          | ACTIVITIES               | ACTIVITIES         |
|-------------------------------------------|-----------------------|-------------------|---------------------|--------------------------|--------------------|
| AI LITERACY COMPONENTS                    | COLLABORATIVE COLLAGE | TEACHABLE MACHINE | POLARITY MANAGEMENT | EXPERIMENTING WITHAIBIAS | THE HYPECYCLE OFAI |
| FoundationalKnowledge ofAl                |                       |                   |                     |                          |                    |
| Ethical Awarenessand Reflection           |                       |                   |                     |                          |                    |
| Pedagogical Integration                   |                       |                   |                     |                          |                    |
| Empowermentfor advocacy and action        |                       |                   |                     |                          |                    |
| Societal Impactand Political Implications |                       |                   |                     |                          |                    |

Figure 9. AI Images Representing CEOs.

<!-- image -->

information and the variety of information that is input into the machine. Your outputs are dependent on the inputs that the machine starts with. This is particularly important when thinking  about  the  ethical  concerns  of AI.  If  a  machine  is only trained using inputs from one perspective (race, ethnicity, political, and religious), then the outputs will also be limited by that bias. We need to carefully consider the sources of information used to train machines to appropriately value the results we are given.'

'Experimenting with AI Bias' activity also aimed to reinforce  these  foundational  concepts  by  providing  educators with illustrative examples of how bias in training data can manifest  in AI  outputs. This  collaborative  activity  encouraged educators to engage in collective inquiry, critically analyze AI-generated content, and reflect on the socio-technical implications of bias. By interacting with each other's posts, educators  explored  different  dimensions  of  AI  bias.  One notable  bias  uncovered  by  some  participants  was  gender bias.  For  example,  one  participant  noted,  when  generating images of CEOs, the AI predominantly produced images of men. The participant commented, 'I noticed all of the generated images were of men. If I wanted to create an image of women  CEOs,  I  would  have  to  specifically  type  'women CEOs.' I believe there is a stereotype around men and women and their roles in society.' Figure 9 shows the AI-generated image created by the educator.

These  findings  suggest  that  while  critical  co-discovery activities  were  helpful  in  helping  educators  engage  with foundational AI concepts, they also highlighted challenges in addressing biases within AI systems. Educators were able to

Figure 10. Educator Artifact Illustrating Students From Different Countries.

<!-- image -->

collaboratively  explore  and  question  key  concepts  like machine  learning  and  algorithms.  All  educator  reflections revealed ongoing concerns about the ethical implications of biased  data  and  the  reinforcement  of  stereotypes.  These activities  appeared  to  have  opened  up  space  for  critical reflection  by  prompting  educators  to  think  more  deeply about the complexities of AI integration in education.

## Ethical Awareness

The ethics  component was under discovery throughout all critical co-discovery activities and course modules. Educators were engaged in a collective inquiry process for various ethical concerns associated with AI in educational settings, such as potential dilemmas in AI integration, privacy issues, transparency,  accountability  in  AI  decision-making  processes, and the risk of perpetuating inequalities or silencing minoritized  voices.  For  example,  in  the  'Algorithmic  Bias  in Generative AI' activity, one participant observed that the AI often relied on stereotypical indicators, such as flags to signify locations, and defaulted to common visuals like backpacks to identify students. This critical reflection uncovered significant ethical concerns about how AI-generated content can reinforce stereotypes and provide misleading representations of different cultures. One educator noted that a student from  Kenya  appeared  in  similar  clothing  across  various countries, reflecting a lack of cultural specificity and diversity  in  the  AI's  outputs.  Reflecting  on  the  AI-generated images, the participant commented, 'It would be nice to see the text 'student' represented as people in classrooms or with books, and what about students of different ages (all mine came out looking like college students!)? I wonder how the results  could  be  improved  by  adding  more  details,  and  if accuracy could be achieved with a bit of research and a more descriptive prompt?' Figure 10 illustrates the educator's artifact  representing  students  from  Kenya,  the  United  States, China, and Mexico.

Although co-discovery activities prompted critical reflection  on  the  ethical  aspects  of  AI,  educators  findings  also revealed a sense of optimism toward AI developments, situating  bias  in  a  more  historical  context  and  systematic inequalities  embedded  in  the  society.  For  example,  while reflecting  on  AI  Generated  images  depicting  a  person,  a woman, and a man from Brazil, one educator noted, 'As you all can see, these AI image generators still have a lot to learn, and this activity shows how important it is to educate ourselves  about  the  limitations  of  these  systems.  However,  I have to say that these biases have been part of American education  long  before  the  arrival  of  AI.  The  misinformation about other countries and cultures in the United States has always been a concern, and hopefully now, with the progress of AI generators and the implementation of unbiased policies, they may educate future generations more accurately.'

These findings suggest that activities were helpful for initiating an exploration of the ethical implications of AI tools by providing educators with opportunities for critical engagement. However, the collaborative inquiry process revealed limited  insights  into  the  broader  ethical  impacts  of  AI. Discussions primarily centered on the immediate effects of algorithmic bias in AI technologies and strategies for mitigating these biases, rather than addressing long-term ethical and sociopolitical consequences.

## Pedagogical Integration

The AI  pedagogy  component  was  also  addressed  through various  activities.  For  example,  the  'Hype  Cycle  of  AI' activity  aimed  to  support  collective  inquiry  by  prompting educators  to  critically  examine  how AI  technologies  have evolved over time and whether they genuinely contribute to education as promised. Through this activity, educators analyzed the impact of these tools within their own educational settings,  questioning  whether  AI  tools  are  truly  fulfilling their intended roles. The findings revealed a prevailing sense of  optimism  regarding AI's  potential  to  streamline  certain tasks and alleviate educators' workloads.

One  educator,  reflecting  on  her  Hype  Cycle,  noted,  'I have heard and expect to hear more success stories that come

Figure 11. Educator Hype Cycle Artifact.

<!-- image -->

with these AI integrations. We have heard that ChatGPT can write lesson plans for teachers, but we must provide it with a sufficient amount of information to get the lesson plan we want.'  Figure  11  illustrates  the  Hype  Cycle  shared  by  the educator's discussion board activity.

One educator noted,  'I  believe  we  are  making  positive advancements with AIEd, so my Hype Cycle may look too optimistic to some. But I believe some ideas have already progressed and are here to stay. I see writing helpers (like Grammarly and others) on the Plateau of Productivity-they are on our emails, phone messages, document writing, etc., and are becoming more effective at a fast pace. I doubt you would find  someone that  totally  ignores  it  when  editing  a writing piece.' This finding indicates a sense of acceptance for certain AI tools. Another educator shared her optimism about AI and a need for educating themselves about it by stating that while these tools are advancing rapidly, their true potential in education could only be realized if teachers and students received proper guidance on how to use them effectively. One stated, '. . . As we are educated on what tools to use and how to use them, and tools are improved upon, AI can help teachers and students in many ways.'

This activity helped educators to evaluate the pedagogical value of various AI tools and their potential impact on their educational settings. It also helped them distinguish between overhyped tools and those with genuine educational benefits. However, the findings also revealed that educators might still face challenges in assessing the real pedagogical benefits of these  technologies,  as  reflected  in  their  demand  for  more excellent knowledge about how to use them effectively. The Polarity  Management  activity  provided  educators  with  an opportunity to collaboratively assess both the positive and negative aspects of integrating AI in the classroom and to find a balanced approach to using these tools in their educational settings. In this activity, educators evaluated the benefits  and  potential  unintended  consequences  of  AI  and worked to identify a more balanced strategy for incorporating AI into their  pedagogy. See Figure 12 for the Polarity Management artifact that was created out of educators' discussion posts.

Discussion posts for Polarity Management activity revealed a spectrum of perspectives on how AI can influence pedagogy. One of the perceived advantages of AI integration was  its  ability  to  handle  administrative  and  instructional tasks, allowing educators to dedicate more time to providing emotional support for students and engaging in the creative aspects of teaching. For example, one educator shared, referring to the characters in the polarity map, 'David's Positives: 'He has more free time to prepare the class for the lesson and focus  on  ways  to  support  struggling  students.'  The  same educator  also  reflected  negatives  as:  'David's  Negatives: Too much trust in the system. He may ignore checking facts, biases, and fake information because the result he is getting looks just perfect.' Another concern regarding the AI usage was a need for a human-centered approach while integrating AI in the classrooms. One educator noted that while AI could save  time,  it  could  also  reduce  the  human  aspect  of  the teacher. The Polarity Management activity helped educators pause and reflect on both the positive and negative consequences of AI integration, allowing them to carefully consider its pedagogical implications without fully rejecting or embracing  AI  in  their  teaching  practices.  These  findings

Figure 12. The Polarity Management Activity Artifact.

<!-- image -->

Figure 13. Collaborative Collage Artifacts.

<!-- image -->

demonstrate  the  importance  of  a  balanced  approach  in AI pedagogy.

## Empowerment for Advocacy and Action

Critical  co-discovery  activities  offer  educators  a  way  to reflect on their autonomy in integrating AI and making pedagogical decisions in educational settings. For example, in the Collaborative Collage activity, educators considered how AI might shape the future of education by analyzing  AI-generated images they created in Padlet. These images depicted future scenarios such as students learning alone by a screen, classrooms  without  teachers,  and  robots  accompanying  human teachers. Figure 13 presents examples of these artifacts.

Findings  revealed  a  tension  between  integrating  AI  in educational settings and the potential for AI to diminish their roles in the classroom. In their discussion board reflections, one  educator  remarked,  'There  is  also  a  common  thread between our ideas when it comes to AI taking over jobs. It's interesting to ponder the idea of AI being in a teacher role

Figure 14. Educator Artifact Examples: (A) Images Depicting the United States, India, and Canada, (B) Christmas Shopping in Different Countries.

<!-- image -->

versus physical human beings or AI as a tool/resource for teachers.'  Educators  also  expressed  hopes  that  AI  could reduce their workload, allowing them to focus more on tasks that require creativity and human insight, such as collaboration,  decision-making,  and  critical  thinking.  One  educator noted,  'Although  teachers  may  soon  rely  on AI  to  create class activities and structure lesson plans with objectives and standards, the teachers themselves will still need to understand how to help students work together as a team, manage time wisely, and persist when their first idea doesn't work out.'  Findings  suggested  that  some  educators  merely  perceived AI as an assistive technology that can automize certain  tasks.  For  example,  one  educator  noted,  'By  2040,  I hope that AI is working hard at all levels of our educational system so that teachers feel less burdened, and students feel they each have an equal opportunity to succeed.' These discussions helped educators envision the future of education and encouraged them to critically reflect on their role in educational settings.

## Societal Implications

Throughout  the critical co-discovery sessions provided opportunities for inquiring societal implications of  AI. Educators expressed concerns about the unpredictability of AI, which they believed could affect various societal arenas, including the future of jobs, the economy, culture, politics, and the environment. The Algorithmic Bias in Generative AI activity  specifically  addressed  recognizing  cultural  issues arising from AI. One educator shared their experience from the activity: 'I think the general bias is that AI has to determine one thing that makes individuals stand out in each of these countries, and by doing so, the people are less realistic and more stereotypical. The United States is viewed as being very patriotic, which can be seen in the image with the 4th of July fireworks on the top left. India is known for its culture, which can be seen in the cultural dress of the woman on the top right. Canada is known for its topography, such as the waterfalls and mountains seen in the picture on the bottom left. There can be individuals from these countries who look and act very similar, and yet AI has to determine something that signifies what country you are asking it to depict, which is why there is a bias and generalization.' Another educator reflected  on  the  broader  implications  of AI  in  educational applications and the need for awareness of AI bias, stating, 'Regarding educational applications and the need for awareness of bias in AI, I think it is important to remember our own entrenched cultural and consumerist biases when presenting images in an international teaching environment. It may be that when we introduce value concepts into the international environment, it may be significant to identify consumerist  bias  in  the  foundational  thinking  of  'Western' countries.' Figure 14 shows examples of educator artifacts.

## Discussion and Implications for Teacher Educators

In  this  study,  we  examined  how  the  critical  co-discovery approach-integrating inquiry-based, reflective, and critical activities-can  facilitate  key  components  of AI  literacy  in teacher education contexts. Our goal was to empower educators to build agency, critically analyze prevailing AI structures and discourses, and navigate the multifaceted impacts of AI on education. By creating a reflective space through

co-discovery, we investigated what aspects of AI literacy can be  effectively  addressed  and  how  this  approach  can  foster active, critical engagement with AI in educational settings.

Existing AI literacy literature encompasses fundamental AI  knowledge  while  addressing  its  broader  sociopolitical dimensions. Unlike other emerging technologies, AI presents unique ethical challenges, requiring a more complex and layered competency framework. UNESCO AI Literacy Framework for Teachers (Miao &amp; Cukurova, 2024) frames AI literacy in progressive competency levels, emphasizing that engagement with AI requires iterative and progressive learning experiences that evolve over time. In our study, educators engaged with AI in a structured learning environment through a four-module online course. Given this, our findings revealed that while AI literacy includes multiple dimensions, educators' discovery of deeper sociopolitical aspects of AI remained limited. Instead, their discovery process primarily  centered  on  their  immediate  educational  contexts. These findings not only echo the call for iterative and progressive  competency  development  (Miao  &amp;  Cukurova, 2024), but also underscore the imperative to extend teacher knowledge development beyond immediate educational contexts, thereby cultivating a more comprehensive and sophisticated understanding of AI's broader impacts (e.g., social, political, and economic).

The  study  findings  revealed  that  educators,  often  burdened by heavy workloads, directed their reflective process toward practical concerns, such as whether AI could plan lessons or redefine classroom roles. In addition, ethical discussions  in AI  literacy  primarily  revolved  around  algorithmic bias and issues of cultural and gender representation. However, these discussions remained anchored in preexisting  narratives  of  AI's  risks  and  challenges,  rather  than extending into critical examinations of its systemic and societal implications-such as data ownership, the commercialization  of  education,  and  massive  energy  consumption (Selwyn,  2024).  This  highlights  the  need  for  sustained engagement  with AI  literacy  through  critical  co-discovery approaches. Short-term exposure alone may not be sufficient for educators to move beyond the dominant framing of AI; instead, a more progressive, deeper ongoing inquiry is essential to foster a deeper exploration of its broader sociopolitical dimensions (Williamson, 2023).

The findings revealed that educators in this study felt significant  pressure  to  integrate  AI  into  their  teaching practices,  leading  to  confusion  and  uncertainty,  particularly since AI remains a relatively new concept for many. This sense of obligation suggests that teachers often perceive  AI  integration  as  a  mandatory  requirement  (Lee et al., 2024). By fostering an environment that prioritizes exploration  over  enforcement,  the  critical  co-discovery approach can help alleviate the anxiety associated with AI adoption and empower educators to make informed, confident decisions about when and how to incorporate AI into their classrooms.

Contrary to concerns raised in recent literature (Yang &amp; Appleget, 2024), our findings indicate that many educators viewed AI as a supportive tool rather than a threat to their job security. During the co-discovery activities, educators repeatedly expressed hope that AI could help alleviate their workload, allowing them more time to focus on supporting their students. Holmes et al. (2023) also observed similar sentiments  among  participants,  reflecting  a  common  narrative surrounding emerging technologies. This perspective on AI integration  reveals  that  educators  prioritize  the  socio-emotional  aspects  of  teaching-elements  that  cannot  be  replicated  by  machines.  Although  discussions  about  AI  often evoke a sense of uncertainty about the future, educators recognize the essential nature of the teacher-student relationship  and  understand  that  their  role  in  the  classroom  is irreplaceable.

Another highlight of the findings was educators' perception of AI as primarily within the domain of data scientists or engineers, leading them to feel that AI is not something they can easily understand or apply. This perception creates a barrier to engagement, and a feeling of disqualification as educators may view AI as overly complex or technical for their expertise. This sense of complexity might also foster skepticism about the unknown, with some educators fearing that AI may further complicate, rather than enhance, their teaching practices (Selwyn, 2022). These concerns are grounded in  the  prevalent  narrative  that AI,  framed  in  deterministic terms,  could  fundamentally  reshape  education  and  potentially push out those unable to adapt to its demands (Campolo &amp; Crawford, 2020).

To alleviate these concerns, it is essential to develop AI literacy curricula specifically tailored to educators, making them directly relevant to their professional contexts. While emerging curricula for students, particularly in K-12 settings (e.g., Su &amp; Zhong, 2022), address AI, there is still a significant need for professional development programs designed with educators in mind. Approaches such as co-design can help  create  a  community  of  practice  where  educators  can share  their  experiences  and  deepen  their  understanding beyond just the technological aspects of AI. By continuously questioning AI's affordances, limitations, and broader societal implications, educators can engage in ongoing critique and dialogue, ultimately fostering greater confidence in their role within an AI-integrated educational landscape.

Incorporating AI training into the curriculum for pre-service teachers is also essential for preparing future educators for this complex AI environment. This need can be addressed in  several  ways. Integrating hands-on AI literacy activities into existing in-pre-service courses can ensure new teachers enter the profession with a strong foundation in AI literacy. These experiences can enable them to engage with AI, aligning  with  their  pedagogical  goals  and  enhancing  student learning. As Lan (2024) suggested, a balanced approach to AI literacy, being open to AI technologies while remaining critical  of  their  potential  limitations  and  impacts,  can  help

teachers  become  autonomous  agents  in  AI  integration. Building  on  Mishra  et  al.'s  (2023)  reconceptualization  of TPACK, GenAI is more than an automation tool; it can act as a  collaborative partner for tasks like building counterarguments, analyzing data, and generating analogies. As teachers enact  their  agency,  they  can  reimagine  their  pedagogical approaches, viewing AI as an aid rather than a source of pressure or obligation. The critical co-discovery approach used in this study acknowledges that AI integration is not merely a  pedagogical tool but a socio-technical system embedded within existing power structures. This duality, as we emphasized,  both  calls  for  alternative  approaches  to  engagement and necessitates more spaces where educators can express their emotions, vulnerabilities, and fears-an essential factor in  fostering  their  agency  and  professional  development (Nazari &amp; Hu, 2024).

As teacher educators integrate similar critical co-discovery approaches into their courses and programs, they must be mindful of certain limitations. The approach requires careful facilitation to balance the critical and collaborative aspects and to ensure that all participants are actively engaged. In addition, the iterative and reflective nature of critical co-discovery  can  be  time-demanding,  posing  challenges  in  fastpaced educational settings. Integrating diverse perspectives can lead to conflicts or difficulty in reaching a consensus, requiring skilled mediation. Similar activities can be incorporated into professional development programs for teacher educators  to  address  these  challenges.  Enhancing  teacher educators' critical AI literacy can better equip them to implement  critical  co-discovery  activities  effectively  in  their courses and programs, maximizing their potential to foster critical AI literacy among pre-service teachers.

## Conclusions and Future Research

This paper presents a case where teacher education course activities grounded in a critical co-discovery approach could help  facilitate  educators'  AIEd  literacy.  While  this  paper examines educators' engagement with critical co-discovery activities without differentiating between educational backgrounds and contexts, future research could explore how a separate group of educators engage with AI. As pre-service teachers and instructional designers have different needs and interactions with AI technologies, future studies could provide deeper insights into their specific experiences and challenges. Moreover, diverse educator groups including teacher trainers, school administrators, and faculty members should also be explored in future research to understand their unique roles,  perspectives,  and  engagement  with  AI  literacy  in education.

Teacher educators play a pivotal role in identifying ethical, responsible, and pedagogically meaningful practices for pre-service teacher education. By being the first to engage with  these  practices,  they  can  effectively  translate  this knowledge into instructional methods that prepare their students  to  be  critically  aware  and  responsible  practitioners. This paper presents an adaptable approach that can be utilized by teacher educators across various teacher education contexts,  fostering  the  development  of AIEd  literacy  and ensuring that future educators are equipped to navigate the complexities of AI in educational settings.

## Acknowledgments

We acknowledge the use of AI tools in the preparation of this manuscript. ChatGPT supported the ideation by assisting in brainstorming the  article's  structure  and  outlining  key  sections.  Grammarly  was also utilized for grammar and language editing to enhance clarity and readability. In addition, as part of the course activities, students generated AI-created images, which were included as artifacts in the findings section to illustrate their experiences. The authors carefully reviewed all content generated or refined using AI tools to ensure accuracy, originality, and compliance with ethical guidelines.

## Declaration of Conflicting Interests

The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.

## Funding

The author(s) received no financial support for the research, authorship, and/or publication of this article.

## ORCID iDs

<!-- image -->

Melis Dilek

https://orcid.org/0000-0001-5678-931X

Evrim Baran

https://orcid.org/0000-0002-1935-0188

Ezequiel Aleman

https://orcid.org/0000-0002-0912-2210

<!-- image -->

## References

- Akgun, S., &amp; Greenhow, C. (2022). Artificial intelligence in education: Addressing  ethical  challenges  in  K-12  settings. AI  and  Ethics , 2 (3), 431-440. - Aleman, E. (2024). Exploring alternative discourses about datafication in a speculative youth participatory action research curriculum. Information and Learning Sciences , 125 (3/4), 190-208.
- Aleman, E., Dilek, M., &amp; Baran, E. (2024). Generative AI as a mirror: Educators exploring and challenging dominant discourses about the future of AI in education. In Proceedings of the 18th International Conference of the Learning Sciences-ICLS 2024 (pp. 857-864). International Society of the Learning Sciences.
- Archambault,  S.  G.,  Ramachandran,  S.,  Acosta,  E.,  &amp;  Fu,  S. (2024). Ethical dimensions of algorithmic literacy for college students: Case studies and cross-disciplinary connections. The Journal of Academic Librarianship , 50 (3), 102865. https://doi. org/10.1016/j.acalib.2024.102865
- Ayanwale, M. A., Adelana, O. P., Molefi, R. R., Adeeko, O., &amp; Ishola, A. M. (2024). Examining artificial intelligence literacy among pre-service teachers for future classrooms. Computers and  Education  Open , 6 ,  100179.  https://doi.org/10.1016/j. caeo.2024.100179

<!-- image -->

- Bali, M. (2023, April 1). What I mean when I say critical AI literacy. Reflecting Allowed . https://blog.mahabali.me/educationaltechnology-2/what-i-mean-when-i-say-critical-ai-literacy/
- Bali, M. (2024, February 26). Where are the crescents in AI? LSE Higher  Education  Blog .  https://blogs.lse.ac.uk/highereducation/2024/02/26/where-are-the-crescents-in-ai/
- Campolo,  A., &amp;  Crawford,  K. (2020). Enchanted  determinism:  Power  without  responsibility  in  artificial  intelligence. Engaging Science, Technology, and Society , 6 , 1-19.
- Chan,  C.  K.  Y.  (2023).  A  comprehensive  AI  policy  education framework for university teaching and learning. International Journal of Educational Technology in Higher Education , 20 , 38. - Chan, C. K. Y., &amp; Hu, W. (2023). Students' voices on generative AI: Perceptions, benefits, and challenges in higher education. International  Journal  of  Educational  Technology  in  Higher Education , 20 (1), 43.
- Cook-Sather,  A.,  Bovill,  C.,  &amp;  Felten,  P.  (2014). Engaging  students as partners in learning and teaching: A guide for faculty . Wiley.
- Cope, B., Kalantzis, M., &amp; Searsmith, D. (2020). Artificial intelligence  for  education:  Knowledge  and  its  assessment  in AI-enabled  learning  ecologies. Educational  Philosophy  and Theory , 53 (12),  1229-1245.  https://doi.org/10.1080/0013185 7.2020.1728732
- Deetz, S. A. (1992). Democracy in an age of corporate colonization: Developments in communication and the politics of everyday life . State University of New York Press.
- Ding, A. C. E., Shi, L., Yang, H., &amp; Choi, I. (2024). Enhancing teacher AI literacy and integration through different types of cases in teacher  professional  development. Computers  and  Education Open , 6 , 100178. - Dunne, A., &amp; Raby, F. (2013). Speculative everything: Design, fiction, and social dreaming . MIT Press.
- Fenn, J., &amp; Raskino, M. (2008). Mastering the hype cycle: How to choose the right innovation at the right time . Harvard Business Press.
- Gorski, P. C., &amp; Dalton, K. (2020). Striving for critical reflection in multicultural and social justice teacher education: Introducing a  typology  of  reflection  approaches. Journal  of  Teacher Education , 71 (3), 357-368.
- Holmes, W., Iniesto, F., Anastopoulou, S., &amp; Boticario, J. G. (2023). Stakeholder perspectives on the ethics of AI in distance-based higher  education. International  Review  of  Research  in  Open and Distributed Learning , 24 (2), 96-117.
- Holmes,  W., Porayska-Pomsta, K., Holstein, K., Sutherland, E.,  Baker,  T.,  Shum,  S.  B.,  Santos,  O.  C.,  Rodrigo,  M.  T., Cukurova, M., Bittencourt, I. I., &amp; Koedinger, K. R. (2022). Ethics of AI in education: Towards a community-wide framework. International Journal of Artificial Intelligence in Education , 32 , 504-526.
- Joyce,  K.,  &amp;  Cruz,  T.  M.  (2024).  A  sociology  of  artificial  intelligence: Inequalities, power, and data justice. Socius , 10 , 1-6.
- Lan,  Y.  (2024).  Through  tensions  to  identity-based  motivations: Exploring teacher professional identity in artificial intelligenceenhanced teacher training. Teaching and Teacher Education , 151 , 104736.
- Langran,  E.,  Searson,  M.,  &amp;  Trumble,  J.  (2024).  Transforming teacher education in the age of generative AI. In M. Searson, E.  Langran,  &amp;  J.  Trumble  (Eds.), Exploring  new  horizons:
- Generative  artificial  intelligence  and  teacher  education (pp. 2-13).  Association  for  the  Advancement  of  Computing  in Education.
- Laupichler, M. C., Aster,  A.,  Schirch,  J.,  &amp;  Raupach,  T.  (2022).  Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence , 3 , 100101. - Lee,  D.,  Arnold,  M.,  Srivastava,  A.,  Plastow,  K.,  Strelan,  P., Ploeckl, F., Lekkas, D., &amp; Palmer, E. (2024). The impact of generative  AI  on  higher  education  learning  and  teaching:  A study  of  educators'  perspectives. Computers  and  Education Artificial  Intelligence , 6 ,  100221.  https://doi.org/10.1016/j. caeai.2024.100221
- Lincoln, Y., &amp; Guba, E. G. (1985). Naturalistic inquiry . Sage. Long, D., &amp; Magerko, B. (2020, April 25-30). What is AI literacy? Competencies and design considerations [Conference session]. 2020 CHI conference on human factors in computing systems, Honolulu, HI, United States, pp. 1-16.
- Markham, A. (2021). The limits of the imaginary: Challenges to intervening in future speculations of memory, data, and algorithms. New  Media  &amp;  Society , 23 (2),  382-405.  https://doi. org/10.1177/14614448209293
- Miao, F., &amp; Cukurova, M. (2024). AI competency framework for teachers . UNESCO. - Michos,  K.,  &amp;  Hernández-Leo,  D.  (2020).  CIDA:  A  collective inquiry framework to study and support teachers as designers in technological environments. Computers &amp; Education , 143 , 103679.
- Mishra, P., Warr, M., &amp; Islam, R. (2023). TPACK in the age of ChatGPT and Generative AI. Journal of Digital Learning in Teacher Education , 39 (4), 235-251.
- Mondal,  H.,  Marndi,  G.,  Behera,  J.  K.,  &amp;  Mondal,  S.  (2023). ChatGPT for teachers: Practical examples for utilizing artificial  intelligence  for  educational  purposes. Indian  Journal  of Vascular and Endovascular Surgery , 10 (3), 200-205.
- Mouta,  A.,  Torrecilla-Sánchez,  E.  M.,  &amp;  Pinto-Llorente,  A.  M. (2025). Comprehensive professional learning for teacher agency  in  addressing  ethical  challenges  of  AIED:  Insights from educational design research. Education and Information Technologies . 30 ,  3343-3387. - Moya, S., &amp; Camacho, M. (2024). Leveraging AI-powered mobile learning:  A  pedagogically  informed  framework. Computers and  Education  Artificial  Intelligence , 7 ,  100276.  https://doi. org/10.1016/j.caeai.2024.100276
- Nazaretsky,  T.,  Ariely,  M.,  Cukurova,  M.,  &amp;  Alexandron,  G. (2022). Teachers' trust in AI-powered educational technology and a professional development program to improve it. British Journal  of  Educational  Technology , 53 (4),  914-931.  https:// doi.org/10.1111/bjet.13232
- Nazari, M., &amp; Hu, G. (2024). Novice language teachers steer their emotional  vulnerabilities  toward  exercising  agency:  A  dialogical-community  of  practice  study. Teaching  and  Teacher Education , 152 , 104759.
- Ng,  D.  T.  K.,  Leung,  J.  K.  L.,  Chu,  S.  K.  W.,  &amp;  Qiao,  M.  S. (2021).  Conceptualizing  AI  literacy:  An  exploratory  review. Computers and Education: Artificial Intelligence , 2 ,  100041. - Nguyen,  A.,  Ngo,  H.  N.,  Hong,  Y.,  Dang,  B.,  &amp;  Nguyen,  B.  P. T. (2023).  Ethical principles for artificial intelligence in

- education. Education  and  Information  Technologies , 28 (4), 4221-4241.
- Schiff, D., Rakova, B., Ayesh, A., Fanti, A., &amp; Lennon, M. (2020). Principles  to  practices  for  responsible  AI:  Closing  the  gap . arXiv Preprint. arXiv: 2006 .04707
- Selwyn, N. (2016). Is technology good for education? Wiley.
- Selwyn, N. (2022). The future of AI and education: Some cautionary  notes. European  Journal  of  Education , 57 (4),  620-631. - Selwyn, N. (2024). On the limits of artificial intelligence (AI) in education. Nordisk tidsskrift for pedagogikk og kritikk , 10 (1), 3-14. - Sperling, K., Stenberg, C. J., McGrath, C., Åkerfeldt, A., Heintz, F., &amp; Stenliden, L. (2024). In search of artificial intelligence (AI) literacy  in  teacher  education:  A  scoping  review. Computers and  Education  Open , 6 ,  100169.  https://doi.org/10.1016/j. caeo.2024.100169
- Srinivasa, K. G., Kurni, M., &amp; Saritha, K. (2022). Harnessing the power of AI to education. In K. G. Srinivasa, M. Kurni, &amp; K. Saritha (Eds.), Learning, teaching, and assessment methods for contemporary  learners:  Pedagogy  for  the  digital  generation (pp. 311-342). Springer.
- Strauß,  S.  (2021).  'Don't  let  me  be  misunderstood':  Critical  AI literacy  for  the  constructive  use  of  AI  technology. TATuPZeitschrift für Technikfolgenabschätzung in Theorie und Praxis/Journal  for  Technology  Assessment  in  Theory  and Practice , 30 (3), 44-49.
- Su,  J.,  &amp;  Zhong,  Y.  (2022).  Artificial  intelligence  (AI)  in  early childhood education: Curriculum design and future directions. Computers and Education: Artificial Intelligence , 3 , 100072.
- U.S. Department of Education, Office of Educational Technology. (2023). Artificial intelligence and future of teaching and learning: Insights and recommendations .
- Veletsianos,  G.,  Houlden,  S.,  &amp;  Johnson,  N.  (2024).  Is  artificial intelligence  in  education  an  object  or  a  subject?  Evidence from  a  story  completion  exercise  on  learner-AI  interactions. TechTrends , 68 (3), 411-422.
- Vuorikari,  R.,  Kluzer,  S.,  &amp;  Punie,  Y.  (2022). DigComp  2.2: The  digital  competence  framework  for  citizens .  European Commission.
- Vygotsky, L. S. (1978). Mind in society: The development of higher psychological processes (Vol. 86). Harvard University Press.
- Walter, Y. (2024). Embracing the future of Artificial Intelligence in the classroom: The relevance of AI literacy, prompt engineering,  and  critical  thinking  in  modern  education. International Journal  of  Educational  Technology  in  Higher  Education , 21 (1), 15. - Williamson,  B. (2023). The  social life of AI  in education. International  Journal  of  Artificial  Intelligence  in  Education , 34 (1), 97-104. - Williamson, B., &amp; Eynon, R. (2020). Historical threads, missing links, and future directions in AI in education. Learning Media and Technology , 45 (3), 223-235. https://doi.org/10.1080/1743 9884.2020.1798995
- Xie, H., Chu, H. C., Hwang, G. J., &amp; Wang, C. C. (2019). Trends and development in technology-enhanced adaptive/personalized learning: A systematic review of journal publications from 2007 to 2017. Computers &amp; Education , 140 , 103599.
- Yang,  S.,  &amp;  Appleget,  C.  (2024).  An  exploration  of  preservice teachers'  perceptions  of  Generative  AI:  Applying  the  technological Acceptance Model. Journal of Digital Learning in Teacher Education , 40 (3), 159-172.
- Zdravkova,  K.,  Krasniqi,  V.,  Dalipi,  F.,  &amp;  Ferati,  M.  (2022). Cutting-edge communication and learning assistive technologies  for  disabled  children:  An  artificial  intelligence  perspective. Frontiers in Artificial Intelligence , 5 , 970430. https://doi. org/10.3389/frai.2022.970430
- Zhang, H.,  Lee,  I.,  Ali,  S.,  DiPaola,  D.,  Cheng,  Y.,  &amp;  Breazeal, C. (2023). Integrating ethics and career futures with technical learning  to  promote  AI  literacy  for  middle  school  students: An  exploratory  study. International Journal of Artificial Intelligence in Education , 33 (2), 290-324. https://doi. org/10.1007/s40593-022-00293-3

## Author Biographies

Melis Dilek , is a PhD student in educational technology co-majoring in human-computer interaction at Iowa State University. Her research investigates artificial intelligence in educational practices, online learning environments, and teacher education.

Evrim  Baran , PhD  is  a  professor  of  educational  technology  and human-computer education at Iowa State University. The overarching goal of her research is to advance theories, research, tools and practices of learning technologies within teacher education, engineering education, and STEM learning contexts. she investigates humancentered  design  methods  in  designing,  developing,  and  evaluating technology-enhanced teacher learning environments.

Ezequiel  Aleman , PhD  is  an  assistant  professor  at  Universidad Tecnológica de Uruguay and the director of the Eastern Technological  Institute.  His  research  and  teaching  focus  on  the intersections of play, speculative civic literacies, and communitybased knowledge to explore and resist oppressive structures in digital platforms.