---
source_file: Biagini_2024_Less_knowledge,_more_trust_Exploring_potentially.pdf
conversion_date: 2026-02-03T08:43:22.324732
converter: docling
quality_score: 95
---

<!-- image -->

<!-- image -->

## Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education

Minor conoscenza, maggiore fiducia? Una esplorazione degli atteggiamenti potenzialmente acritici verso l'IA nell'istruzione universitaria

Gabriele Biagini*, Stefano Cuomo, Maria Ranieri

University of Florence, Italy, gabriele.biagini@unifi.it*, stefano.cuomo@unifi.it, maria.ranieri@unifi.it * Corresponding author

HOW TO CITE Biagini,  G.,  Cuomo,  S.,  &amp;  Ranieri,  M.  (2024).  Less  knowledge,  more  trust?  Exploring  potentially uncritical attitudes towards AI in higher education. Italian Journal of Educational Technology , 32 (1), 37-52. https://doi. org/10.17471/2499-4324/1337

Received: January 5, 2024; Accepted: July 19, 2024; First Published: July 24, 2024

ABSTRACT Artificial intelligence (AI) has the potential to transform various aspects of our lives, but its development has been accompanied by several social and ethical concerns. T o comprehend the implications and underlying mechanisms, it is essential to acquire a broad understanding of its benefits and drawbacks. T o this purpose, AI literacy is a fundamental driver for more aware attitudes towards AI development and implications. However, AI literacy research is still in its infancy.  T o contribute to advances in the sector, this paper presents the results of a study aimed at assessing students' AI literacy in the context of higher education, focusing on doctoral students. A survey on AI literacy was performed in four dimensions: cognitive, operational, critical and ethical. The results show that while participants had little AI knowledge, they were overconfident of the technology's capabilities. The study highlights the need for a more comprehensive approach to AI literacy that encompasses a deeper understanding of its ethical, social and economic implications.

KEYWORDS Artificial Intelligence in Education; Artificial Intelligence Literacy; Education; Ethics.

SOMMARIO L'intelligenza artificiale (IA) ha il potenziale per trasformare vari aspetti delle nostre vite, ma il suo sviluppo è stato accompagnato da numerose preoccupazioni sociali ed etiche. Per comprendere le implicazioni e i meccanismi sottostanti, è essenziale acquisire una comprensione ampia dei suoi benefici e svantaggi. A questo scopo, l'alfabetizzazione all'IA è un fattore fondamentale per promuovere atteggiamenti più consapevoli verso lo sviluppo dell'IA e delle sue implicazioni. Tuttavia, la ricerca sulla literacy all'IA è ancora agli esordi. Per contribuire ai progressi del settore, questo articolo presenta i risultati di uno studio volto a valutare l'alfabetizzazione all'IA degli studenti nel contesto dell'istruzione universitaria, concentrandosi su dei dottorandi. L'indagine sulla loro literacy all'IA è stata condotta su quattro dimensioni: cognitiva, operativa, critica ed etica. I risultati mostrano che, sebbene i partecipanti avessero poca conoscenza dell'IA, erano eccessivamente fiduciosi nelle capacità della tecnologia. Lo studio evidenzia la necessità di un approccio più completo all'alfabetizzazione all'IA, che includa una comprensione più profonda delle sue implicazioni etiche, sociali ed economiche.

PAROLE CHIAVE Intelligenza Artificiale nell'Educazione; Alfabetizzazione all'IA; Istruzione; Etica.

## 1. Introduction

In an era where technology's influence is hardly deniable, Artificial Intelligence (AI) stands at the forefront, shaping multiple sectors from business to the arts and, notably, education (Casal-Otero et al., 2023; Laupichler et al., 2023; Liu et al., 2023; JRC &amp; OECD, 2021; UNESCO, 2021; Zawacki-Richter et  al.,  2019).  Our  daily  interactions - from adjusting settings on smart home devices to seeking help from virtual assistants like Siri and Google - highlight AI's ubiquitous presence in modern life. This widespread incorporation of AI amplifies the urgency for a comprehensive understanding, leading to a pressing call for robust AI literacy across the population (Kong et al., 2023 to cultivate a broad awareness  and  comprehension of  both  AI's  potential  benefits  and  drawbacks  (Gašević,  Siemens,  &amp;  Sadiq, 2023; Selwyn, 2022; Perrotta &amp; Selwyn., 2020).

However, despite the growing consensus on the significance of AI literacy, research in this domain is  still  in  its  infancy,  the  exact definition of AI literacy remains elusive, and there is a notable gap in the development of coherent strategies for promoting and evaluating it (Cuomo et al., 2022; Kong &amp; Zhang,  2021.  At  its  core,  AI  literacy  is  believed  to  champion  ethical  use,  ensure  adaptability  in  an ever-evolving technological landscape, and address societal inequalities (Selwyn, 2023; Wilton et al., 2022). Such a foundation supports a community in making informed decisions, especially in the face of AI's societal and ethical implications (Floridi et al, 2021, UNESCO, 2019; UNICEF, 2021; Zhang et al.,  2022). Research has consistently highlighted the necessity of introducing AI literacy from the early stages of education (Long &amp; Magerko, 2020; Su &amp; Zhong, 2022). Countries worldwide have started weaving AI concepts into primary and secondary education, preparing younger generations for the challenges and opportunities of the future (Williams et al., 2019). However, when focusing on higher education, particularly among doctoral students, research is even scarcer (Hazell et al, 2020; Gouseti, 2017).  Doctoral  students  are  a  niche  representing  the  next  generation  of  researchers  and  professors. Given this position in academia, doctoral students' perceptions can provide invaluable insights into the understanding and potential integration of AI literacy into academic curricula. This paper seeks to bridge this knowledge gap by presenting the results of a survey that delves into doctoral students' perceptions of AI literacy. By doing so, we aim to contribute substantially to the ongoing discourse on how best to navigate a future deeply interwoven with AI, ensuring that the next generation of scholars and leaders are adequately prepared. To assess the level of self-perceived literacy, in this study, we administered a previously validated questionnaire (Biagini et al, 2023) to a sample of 66 Italian PhD students from different programmes, mainly but not exclusively, in the field of educational sciences. The AI literacy perception was assessed by measuring their knowledge and understanding of the topic across four dimensions: the cognitive, operational, critical and ethical dimensions. These are regarded as the key dimensions in many AI Literacy frameworks (Cuomo et al., 2022; Ng et al., 2021). The questionnaire includes both close-ended and open-ended questions, allowing a comprehensive analysis of participants' understanding of AI aimed at providing valuable insights into the current level of AI literacy among students.

## 2. Background

## 2.1. AI Literacy Frameworks and definitions

Even though there is still no consensus on a definitive description of AI literacy, various attempts have been made to frame it within the broader context of digital literacy. The diverse range of definitions, such as Kandlhofer and colleague's (2016) emphasis on grasping basic AI techniques and applications, showcases the foundational aspects of AI literacy. Authors like Druga et al. (2019 &amp; 2022) and Wong et al. (2020) highlighted the importance of AI literacy's ethical aspects and awareness of its societal influence. Long &amp; Magerko (2020) defined AI literacy as a range of skills that enable critical evaluation and productive collaboration with AI technologies. Liu &amp; Xie (2021) expanded AI literacy to include digital literacy and computational thinking. Kim et al. (2021) emphasised knowledge, skill and attitude, while Kong &amp; Zhang (2021) and Cetindamar et al. (2022) discussed AI literacy in the context of career readiness. Yi (2021) discussed AI literacy's cultural and subjective dimensions, implying that AI literacy is more than a set of technical abilities but also includes the ability to navigate and modify one's life  amid AI's transformations. Deuze &amp; Beckett (2022) and Hermann (2022) examined AI literacy's applicability and influence from normative and practical perspectives. Laupichler et al. (2023) and Wang, Rau and Yuan (2022) emphasised informed AI use and implications for decision-making. Finally, Weber and colleagues (Weber, Pinski &amp; Baum, 2023) provided a comprehensive view, encompassing data and algorithm literacy as key components.

Our earlier research led to the development of a framework described by Cuomo and colleagues (2022), which consists of four essential dimensions that, combined, cover the entire range of AI literacy skills mentioned above. To be more specific, the framework is made up of:

- -a Knowledge-related Dimension: this encompasses the understanding of fundamental AI concepts, focusing on basic skills and attitudes that do not require preliminary technological knowledge (Ng et al., 2021). It includes understanding AI types, machine learning principles, and various AI applications such as artificial vision and voice recognition.
- -an  Operational  Dimension:  focused  on  applying  AI  concepts  in  various  contexts  (Druga  et  al., 2019; Lee et al., 2021); it emphasises the ability to solve problems using existing AI tools and develop  simple  applications  that  incorporate  AI  modules  to  enhance  analytical  and  critical  thinking (Kim et al., 2021).
- -a Critical Dimension: highlighting AI's potential to engage students in cognitive, creative, and critical discernment activities (Su &amp; Zhong, 2022); it underscores the importance of effective communication and collaboration with AI technologies and critical evaluation of their impact on society.
- -an  Ethical  Dimension:  concerning  the  responsible  and  conscious  use  of  AI  technologies,  this dimension stresses the balanced view of delicate ethical issues raised by AI, such as the delegation of personal decisions to a machine [e.g., job placement or therapeutic pathways], and emphasises the growing attention towards 'AI Ethics', encompassing transparency, fairness, responsibility, privacy and security.

These factors work together to create a multifaceted perspective to investigate, evaluate and develop AI literacy. They stress the importance of going beyond only consuming AI passively to a more active and responsible knowledge, providing a comprehensive, integrative method to addressing AI literacy.

## 2.2. Assessment tools

The central focus of our approach to measuring this specific construct lies in the development of a comprehensive framework. This framework is essential to address the multiple components and their interconnections that are fundamental to understanding AI. Such a framework is necessary due to the complexity and multifaceted nature of AI literacy. Several efforts have been made to develop tools to measure different aspects of AI literacy. These tools mostly focus on some components of AI literacy (e.g.,

Table 1. Summary of the AI literacy questionnaires reviewed.

| Tool name                                                       | Author                    | Questionnaire purpose Questionnaire Target                                                 | Questionnaire purpose Questionnaire Target   | Validation process EFA=explorative factor analysis; CFA=confirmative factor analysis AVE=Average Variance Extraction   | No. of items   |
|-----------------------------------------------------------------|---------------------------|--------------------------------------------------------------------------------------------|----------------------------------------------|------------------------------------------------------------------------------------------------------------------------|----------------|
| Assessment of non- experts' AI literacy                         | (Laupichler et al., 2023) | Support the development of a scale for the assessment of AI literacy.                      | Non-experts                                  | Content validation but no factor loadings                                                                              | 38 items       |
| Critical AI literacy scale (CAILS)                              | Biagini et al., 2023      | Evaluate critical skills in AI use, covering knowledge, operation, criticism, and ethics.  | Non-experts, Academics                       | Complete validation, EFA, CFA, AVE and Reliability)                                                                    | 40 items       |
| Artificial intelligence literacy (AILS scale)                   | (B. Wang et al., 2022)    | Assess the self- reported competence of users in using AI                                  | AI Users (Expert and non-expert)             | Complete validation (EFA, CFA, Reliability)                                                                            | 12 items       |
| AI anxiety (AIAS scale)                                         | (Y.-Y. Wang & Wang, 2022) | Measure AI anxiety                                                                         | Citizens (Expert and non-expert)             | Complete validation (EFA, CFA, Reliability)                                                                            | 21 items       |
| Attitude Towards Artificial Intelligence (ATAI scale)           | (Sindermann et al., 2021) | Trust in and Usage of Several Specific AI Products                                         | Citizens (Expert and non-expert)             | Complete validation (EFA, CFA, Reliability)                                                                            | 5 items        |
| General Attitudes towards Artificial Intelligence (GAAIS scale) | (Schepman & Rodway, 2020) | Inform legislators and organisations developing AI about their acceptance by the end users | Citizens (Expert and non-expert)             | Complete validation (EFA, CFA, Reliability)                                                                            | 20 items       |

affective factors or collaborative variables), while neglecting its intricate nature (Laupichler et al., 2023). Examples that demonstrate this tendency include the 'Attitudes Towards Artificial Intelligence Scale' (Sindermann et al.,  2021),  the  'General  Attitudes  Towards  Artificial  Intelligence  Scale'  (Schepman  &amp; Rodway, 2023), and the 'Artificial Intelligence Anxiety Scale' (Wang &amp; Wang, 2022).  In order to address this constraint, based on the comprehensive framework for AI literacy created by Cuomo et al. (2022), we developed a questionnaire that includes items from preexisting assessment tools as well as new or modified ones. Moreover, to choose elements that may be altered to assess AI literacy as a result, we also looked at validated questionnaires on comparable themes, including technical competence or digital literacy. An all-encompassing technique for assessing AI literacy could offer valuable insights into the efficacy of educational interventions. This widely applicable scale could serve as a significant tool for researchers and educators to test and improve AI literacy in many contexts. Table 1 shows the tools reviewed.

## 3. Method

## 3.1. Research questions

The variability in AI education methods and objectives stems from the diverse target demographics, each presenting unique learning needs and challenges. Interestingly, a preliminary scan of the academic

landscape on this topic uncovers two predominant categories of publications. One delves into the practical aspects of AI education, detailing course designs and evaluations for non-experts (Long &amp; Magerko, 2020, Lin et al., 2021; Shih et al., 2021), while the other ventures into the theoretical aspects, exploring definitions and the relationship between AI literacy and other literacies (Kandlhofer et al., 2016; Wienrich &amp; Carolus, 2021). Both research strands, with their distinctive focuses, are essential for a complete grasp of AI literacy. Thus, this research aims to investigate the doctoral students' AI literacy perceptions by measuring their knowledge and understanding of the topic across the cognitive, operational, critical and ethical dimensions. The research questions (RQ) addressed in this study are as follows:

RQ1. What are the levels of self-perceived awareness of doctoral students regarding the dimensions of AI literacy? RQ2. Are there differences in the perceived trustworthiness of AI in relation to the knowledge reported by the students?

## 3.2. Survey and measures

To  address  the  research  questions,  a  validated  questionnaire  (Biagini  et  al,  2023)  was  administered. The questionnaire scale consists of 10 items on AI ethics, 10 on AI critical assessment, 12 on AI applications, and 8 focused on AI knowledge and explores the opinions and perceptions of respondents regarding AI literacy in the context of education. Its aim is to understand the varying degrees of importance assigned to different education-related opportunities and challenges associated with AI. The survey gathered responses from multiple participants varying across different questions. The survey covered a range of topics, beginning with general questions that gather demographic information about the respondents, including their gender, age, educational background, years of professional experience, and their propensity towards technology. Given the questionnaire's focus on AI in education, it included questions specifically tailored to the respondents' involvement in the education sector. Thus, a few items explored whether they work in education, the location of their workplace, and the number of years they have been working in the field. This information helped contextualise their responses and identify any potential correlations between AI literacy and professional experience in education. To comprehensively evaluate AI literacy, the questionnaire is further divided into four sections aligned with the theoretical framework (Cuomo et al, 2022). Respondents could answer according to a 5-value Likert scale from the minimum level 1 ('None at all') to the maximum level 5 ('A great deal') of agreement with the proposed statement. The first section delves into the respondents' knowledge of AI, assessing their understanding of core concepts and principles related to artificial intelligence. The second section examines the respondents' application abilities in AI. It aims to assess their practical skills in applying AI techniques or utilising  AI  tools  effectively.  The  third  section  focuses  on  their  critical  evaluation  of  AI.  It seeks to measure the respondents' capacity to critically evaluate AI technologies, including their potential  benefits, limitations and implications. Lastly, a fourth section addresses the ethical considerations associated with AI. This section aims to determine the respondents' awareness of ethical issues related to AI and their ability to evaluate and navigate ethical dilemmas that arise in the context of AI.

## 3.3. Data analysis: the participants

To understand the demographics of the target students and their academic experiences, we collected  some  broad  information  about  their  profile.  This  article  presents  a  convenience  sample  consisting  of  66  Italian  PhD  students  from  a  socio-educational  background,  aiming  to  investigate  vari-

Table 2. Sample characteristics.

| Characteristic                                  | Items              |     % |   Frequency |
|-------------------------------------------------|--------------------|-------|-------------|
| Gender                                          | Male               | 31.82 |          21 |
|                                                 | Female             | 63.64 |          42 |
|                                                 | Prefer not to say  |  4.55 |           3 |
| Age                                             | 18-24 years        |  5.3  |           3 |
|                                                 | 25-34 years        | 38.6  |          22 |
|                                                 | 35-44 years        | 24.6  |          14 |
|                                                 | 45-54 years        | 24.6  |          14 |
|                                                 | 55-65 years        |  5.3  |           3 |
| Geographic Provenance                           | Tuscany            | 66.67 |          44 |
|                                                 | Lombardy           | 13.64 |           9 |
|                                                 | Puglia             |  7.58 |           5 |
|                                                 | Sicily             |  6.06 |           4 |
|                                                 | Liguria            |  3.03 |           2 |
|                                                 | Piedmont           |  1.52 |           1 |
|                                                 | Emilia-Romagna     |  1.52 |           1 |
| School level of employment (if already working) | University         | 15.8  |           9 |
|                                                 | Elementary School  | 14    |           8 |
|                                                 | High School        | 14    |           8 |
| Highest degree or level of education completed  | University Degree  | 42.1  |          29 |
|                                                 | Master's Degree    | 43.9  |          30 |
|                                                 | Doctorate          |  7    |           5 |
| Professional experience (in years):             | Less than 5 Years  | 17.5  |          10 |
|                                                 | 5 to 10 Years      | 12.3  |           7 |
|                                                 | 10 to 20 Years     |  7    |           4 |
|                                                 | More than 20 Years |  7    |           4 |

ous factors influencing their academic experiences. The sample included 21 males (31.82%), 42 females (63.64%), and 3 participants preferring not to disclose their gender (4.55%). Age-wise, the largest group fell  within  the  25-34  years  range,  making  up  38.6%  of  the  sample  with  22  respondents.  Geographically,  the  sample  was  predominantly  from  Tuscany  (66.7%,  44  respondents)  and  Lombardy  (13.6%, 9 respondents). The highest level of education completed varied, with 29 holding a university degree (42.1%) and 30 possessing a master's degree (43.9%). Additionally, 5 respondents had completed a doctorate (therefore, attending a second doctorate), making up 7.0% of the sample. Among the respondents who already work in education (n=25), professional experience in teaching varied, with 10 participants reporting less than 5 years of experience (17.5%). Table 2 displays the sample details.

## 4. Results

## 4.1. What are the levels of self-perceived awareness of doctoral students regarding the dimensions of AI literacy? (RQ1)

## 4.1.1. Knowledge dimension: AI Literacy and Theoretical Foundations

In  this  study,  while  we  administered  the  comprehensive  survey  encompassing  all  40  items across the four dimensions of AI literacy, we report results for only 25 items that are relevant for

Less knowledge, more trust? Exploring potentially uncritical attitudes towards AI in higher education

Table 3. AI - Knowledge perception.

| Sub-Dimensions                                                                                                        | None at all   | A little     | A moderate amount   | A lot     | A great deal   |   Mean |   SD |
|-----------------------------------------------------------------------------------------------------------------------|---------------|--------------|---------------------|-----------|----------------|--------|------|
| Know and understand AI definitions and theoretical foundations (Knowledge-related dimension)                          | 2 (3.8%)      | 13 (25%)     | 17 (32.7%)15        | (28.8%)   | 5 (9.6%)       |   3.15 | 1.03 |
| Know and understand AI basic mathematical functions behind the algorithms (Knowledge-related dimension)               | 20 (38.5%)    | 13 (25%)     | 13 (25.0%)          | 4 (7.7%)  | 2 (3.8%)       |   2.13 | 1.13 |
| Use and apply AI knowledge, concepts and applications (Operational dimension)                                         | 9 (17.3%)     | 22 (42.3%)11 | (21.2%)             | 7 (13.5%) | 3 (5.8%)       |   2.48 | 1.1  |
| Evaluate, appraise, and critically assess AI applications (Critical dimension)                                        | 14 (26.9%)11  | (21.2%)16    | (30.8%)             | 8 (15.4%) | 3 (5.8%)       |   2.52 | 1.2  |
| Create AI, design and build AI applications (Operational dimension)                                                   | 30 (57.7%)10  | (19.2%)      | 5 (9.6%)            | 2 (3.8%)  | 5 (9.6%)       |   1.88 | 1.3  |
| Understanding ethical issues related to AI such as fairness, accountability, transparency, safety (Ethical dimension) | 3 (5.8%)      | 13 (25%)     | 12 (23.1%)10        | (19.2%)14 | (26.9%)        |   3.37 | 1.27 |

the research questions addressed. To gauge the participants' knowledge of AI principles, they were asked to assess their perceptions of the various AI framework sub-dimensions (e.g., ' When it comes to Artificial Intelligence (AI), I feel my knowledge on … would be: 1/None at all, 2/A little, 3/A moderate  amount, 4/A lot, 5/A great deal', where the sentence was differently completed according to the framework dimension considered, e.g., 'Evaluation, appraisal and critical assessment of AI applications ') (Cuomo et al., 2022). Understanding the definitions and theoretical foundations of AI is relatively  well-distributed  among the respondents. A majority, 67%, claim to have at least a moderate understanding, but a significant 33% feel they grasp AI concepts from none to a very little extent. Furthermore, when delving into the basic mathematical functions underpinning AI algorithms, the respondents feel considerably less confident. A significant 38.5% admit they have no understanding at all, and another 20% state they have only a little knowledge. The percentage of those who believe they know a lot, or a great deal drops to 11.5%, when compared to the previous answer. In terms of applying AI knowledge and concepts, the results lean more toward the basic side, with 59.6% having either no or just a little experience. The advanced end of the spectrum remains narrow, with only 19.3% feeling they can use or apply AI knowledge to a considerable extent. Evaluating, appraising and critically assessing AI applications shows a moderate distribution, with 30.8% having a moderate amount of confidence in their capabilities. A combined 25% believe they can evaluate AI applications extensively, while 26.9% have no experience. The ability to create, design and build AI applications  shows  a  distinct  trend:  a  clear  majority,  57.7%,  admit  that  they  have  no  experience  at  all. Combining this with the 19.2% with minimal experience, it's evident that hands-on AI development remains specialised, though 9.6% claim a high degree of proficiency. Finally, ethical issues related to AI show an interesting distribution. While only 5.8% have no understanding of it, a noteworthy 26.9% feel they understand these issues to a great extent. The results hint at a heightened awareness or interest in AI ethics among the group, with 45.1% claiming to understand these issues a lot or a great deal. Table 3 summarises the results.

## 4.1.2. Operational dimension: Perceptions of AI Task Performances

The results suggest a mixed perception regarding the acceptance of AI performing various tasks (Table 4). Emergency services garner significant confidence with 64% of participants leaning towards AI support, either probably or definitely. Educational sectors also witnessed a strong inclination with 72%  leaning  towards  a  positive  stance.  When  it  comes  to  more  intricate  procedures  like  performing surgeries, the acceptance decreases with 50% probably or definitely endorsing it. News reporting emerges as a divisive field, with nearly half (48%) of the participants remaining neutral. The most significant confidence is observed in AI's potential for medical and scientific research with a commanding  66% probably or definitely advocating its role. However, emotional support showcased the most pronounced scepticism. A staggering 46% of respondents probably or definitely would not rely on AI for  emotional sustenance. Assisting in surgical procedures fared better than performing them, with 64% leaning towards positive support.

Table 4. Allowing AI Performance.

| Dimensions                     | Definitely not   | Probably not   | Might or might not   | Probably yes   | Definitely yes   |   Mean |   SD |
|--------------------------------|------------------|----------------|----------------------|----------------|------------------|--------|------|
| Supporting emergency services  | 1 (2%)           | 4 (8%)         | 13 (26%)             | 18 (36%)       | 14 (28%)         |   3.8  | 1    |
| School / educational support   | 1 (2%)           | 4 (8%)         | 9 (18%)              | 23 (46%)       | 13 (26%)         |   3.86 | 0.96 |
| Performing surgical procedures | 1 (2%)           | 5 (10%)        | 19 (38%)             | 16 (32%)       | 9 (18%)          |   3.54 | 0.96 |
| News reporting                 | 3 (6%)           | 2 (4%)         | 24 (48%)             | 12 (24%)       | 9 (18%)          |   3.44 | 1.02 |
| Medical/scientific research    | 1 (2%)           | 3 (6%)         | 13 (26%)             | 25 (50%)       | 8 (16%)          |   3.72 | 0.87 |
| Emotional support              | 12 (24%)         | 11 (22%)       | 13 (26%)             | 9 (18%)        | 5 (10%)          |   2.68 | 1.29 |
| Assisting surgical procedures  | 2 (4%)           | 2 (4%)         | 14 (28%)             | 19 (38%)       | 13 (26%)         |   3.78 | 1.01 |

## 4.1.3. Critical dimension: Analysing AI's Risks and Benefits

The excitement surrounding AI is palpable with 64.59% of respondents feeling that AI is exciting  either  a  lot  or  a  great  deal.  This  enthusiasm  likely  stems  from  AI's  potential  to  revolutionise industries, improve efficiency and solve the complex problems facing society. However, alongside this optimism, apprehensions also surface. When asked whether AI is considered dangerous, a notable 43.75% of  participants  believe  it  is  to  a  moderate  extent,  and  an  additional  20.83%  believe  it  is  a lot,  totalling 64.58%. Reflecting on the error rates of AI systems, a majority of 52.08% feel that AI systems make many errors to a moderate extent, and an additional 25% believe it's a little, totalling 77.08%.  Regarding  AI's  performance  compared  to  humans,  opinions  are  varied,  with  the  highest, 43.75%, believing that AI can perform better than humans. On the topic of AI replacing humans in routine jobs, a significant 35.42% believe this would be a lot better, and an additional 27.08% believe it  to  a  moderate  extent.  This  adds  up  to  62.5%,  a  considerable  majority  recognising  AI's  potential to efficiently handle routine tasks. In the economic context, a significant 41.67% think that AI can provide a lot of new economic opportunities, with an additional 29.17% believing it to a moderate extent, totalling 70.84%. Lastly, when considering the broader societal benefit from AI, a plurality of 45.83% feel that much of society will benefit moderately from a future filled with AI. Table 5 summarises the results.

Table 5. Perception toward AI.

| Dimensions                                                        | None at all   | A little    | A moderate amount   | A lot       | A great deal   | Mean   |   SD |
|-------------------------------------------------------------------|---------------|-------------|---------------------|-------------|----------------|--------|------|
| AI is exciting                                                    | 3 (6.25%)     | 4 (8.33%)   | 10 (20.83%)         | 17 (35.42%) | 14 (29.17%)    | 3.80   | 1.11 |
| I think AI is dangerous                                           | 7 (14.58%)    | 9 (18.75%)  | 21 (43.75%)         | 10 (20.83%) | 1 (2.08%)      | 2.80   | 1    |
| I think AI systems make many errors                               | 3 (6.25%)     | 12 (25%)    | 25 (52.08%)         | 6 (12.5%)   | 2 (4.17%)      | 2,87   | 0.86 |
| AI systems can perform better than humans                         | 5 (10.42%)    | 13 (27.08%) | 21 (43.75%)         | 6 (12.5%)   | 3 (6.25%)      | 2.80   | 1    |
| An AI agent would be better than an employee in many routine jobs | 4 (8.33%)     | 11 (22.92%) | 13 (27.08%)         | 17 (35.42%) | 3 (6.25%)      | 3.13   | 1.07 |
| AI can provide new economic opportunities                         | 4 (8.33%)     | 7 (14.58%)  | 14 (29.17%)         | 20 (41.67%) | 3 (6.25%)      | 3.28   | 1.03 |
| Much of society will benefit from a future full of AI             | 4 (8.33%)     | 10 (20.83%) | 22 (45.83%)         | 8 (16.67%)  | 4 (8.33%)      | 3.00   | 1.01 |

## 4.1.4. Ethical dimension: Perceptions of AI's Ethical impacts

When asked about the future impact of AI (Table 6) the results show that regarding personal and individual privacy, about 60.41% of respondents express concerns that AI will negatively impact this area. For equity and fairness, 41.67% of respondents feel that AI's impact will leave this aspect about the same, with an additional 25% expressing a belief in potential improvements. Concerning workforce and labour displacement, optimism emerges as 41.67% believe AI will make the situation somewhat better. When considering relevant risks, 72.91% feel the situation will remain the same or improve with AI. Lastly, focusing on cybersecurity, a combined 47.92% of respondents harbour concerns that AI will make matters worse.

Table 6. Future impact of AI.

| Dimensions                    | Much worse   | Somewhat worse   | About the same   | Somewhat better   | Much better   |   Mean |   SD |
|-------------------------------|--------------|------------------|------------------|-------------------|---------------|--------|------|
| Personal/individual privacy   | 7 (14.58%)   | 22 (45.83%)      | 12 (25%)         | 5 (10.42%)        | 2 (4.17%)     |   2.46 | 1    |
| Equity and fairness           | 4 (8.33%)    | 12 (25%)         | 20 (41.67%)      | 11 (22.92%)       | 1 (2.08%)     |   2.89 | 0.92 |
| Workforce/labour displacement | 7 (14.58%)   | 8 (16.67%)       | 12 (25%)         | 20 (41.67%)       | 1 (2.08%)     |   3.04 | 1.11 |
| Relevant risks                | 6 (12.5%)    | 5 (10.42%)       | 16 (33.33%)      | 19 (39.58%)       | 2 (4.17%)     |   3.17 | 1.06 |
| Cybersecurity                 | 6 (12.5%)    | 17 (35.42%)      | 8 (16.67%)       | 14 (29.17%)       | 3 (6.25%)     |   2.83 | 1.16 |

## 4.1.5. Corollary: Nuanced understanding of the AIL dimensions from a pedagogical perspective

The survey responses reveal a mix of positive and cautious attitudes toward the integration of AI in  teaching  (Table  7).  To  aid  accuracy  in  teaching,  a  combined  66.67%  of  respondents  either  somewhat or strongly agree that AI could help teachers be more accurate. However, apprehension is apparent regarding the learning curve associated with AI tools. A total of 66.67% (43.75% somewhat agree and 22.92% strongly agree) acknowledge that a substantial effort would be necessary to learn how to effectively  use  AI  in  teaching.  In  terms  of  pedagogical  tasks  like  reviewing  homework,  a  significant 64.58% believe that AI could help save time. Despite these positives, scepticism and concerns persist. A combined 53.33% of respondents express distrust in AI's ability to execute tasks without errors. Job

security fears are also notable, with 37.5% of respondents expressing concerns that AI could take someone's job. When considering lesson planning, a substantial 56.25% feel that AI could aid in time saving,  again  highlighting  AI's  potential  efficiency  contributions  in  various  teaching  aspects.  Similarly, for content and material sourcing, a 66.67% of respondents see AI as a time-saving tool. Despite these perceived advantages, a considerable 43.75% of respondents either somewhat or strongly believe that teaching fundamentally requires human involvement, which AI cannot replicate.

Table 7. Use of AI in the teaching field.

| Statement                                                                       | Strongly disagree   | Some-what disagree   | Neither agree nor disagree   | Some-what agree   | Strongly agree   |   Mean |   SD |
|---------------------------------------------------------------------------------|---------------------|----------------------|------------------------------|-------------------|------------------|--------|------|
| It could help the teacher to be more accurate                                   | 1 (2.08%)           | 8 (16.67%)           | 7 (14.58%)                   | 20 (41.67%)       | 12 (25%)         |   3.78 | 1.03 |
| It would require effort to learn how to use it                                  | 1 (2.08%)           | 3 (6.25%)            | 12 (25%)                     | 21 (43.75%)       | 11 (22.92%)      |   3.87 | 0.86 |
| It could help to save time when reviewing homework                              | 2 (4.17%)           | 6 (12.5%)            | 9 (18.75%)                   | 19 (39.58%)       | 12 (25%)         |   3.76 | 1.06 |
| I don't trust it to carry out tasks without error                               | 4 (8.33%)           | 14 (29.17%)          | 16 (33.33%)                  | 11 (22.92%)       | 3 (6.25%)        |   2.93 | 1.04 |
| I'm scared it could take someone else's job                                     | 4 (8.33%)           | 11 (22.92%)          | 15 (31.25%)                  | 13 (27.08%)       | 5 (10.42%)       |   3.13 | 1.11 |
| It could help to save time when creating a time plan for a lesson               | 2 (4.17%)           | 5 (10.42%)           | 14 (29.17%)                  | 19 (39.58%)       | 8 (16.67%)       |   3.61 | 0.98 |
| It could help to save time when looking for materials/content for a lesson      | 1 (2.08%)           | 2 (4.17%)            | 13 (27.08%)                  | 17 (35.42%)       | 15 (31.25%)      |   3.98 | 0.88 |
| Teaching requires human involvement, and I don't think AI can do what is needed | 2 (4.17%)           | 15 (31.25%)          | 10 (20.83%)                  | 14 (29.17%)       | 7 (14.58%)       |   3.24 | 1.14 |

## 4.2. Are there differences in the perceived trustworthiness of AI in relation to the knowledge reported by the students? (RQ2)

In order to answer this research question, we compared the answers of two clusters, one (Group 1) composed  of  students  who  perceived  a  high  literacy  on  AI,  and  another  (Group  2),  comprising  the remaining students who declared a low knowledge on AI. In our study, the distinction between Group 1 and Group 2 was based on participants' self-reported levels of AI literacy. To categorise participants into these two groups, we employed a mean score calculation derived from responses to the 8 items specifically designed to measure 'AI Knowledge'. This methodological choice was made to quantitatively differentiate between and compare participants exhibiting a high self-reported level of AI literacy ('Moderate', 'A lot', 'A great deal') and those indicating a lower level of knowledge ('None at all', 'A little'). For that task, we used Student's T for a significance check of the two categories, we prioritised the presentation of comparisons between groups based on the presence of statistically significant differences across the items surveyed. Upon reviewing the results (Table 8), a trend emerges that emphasises the significance of AI literacy in shaping individuals' attitudes toward AI's capabilities and limitations. Group 2, with a lower perceived literacy on the knowledge-related dimension, consistently shows higher mean scores across various tasks performed by AI compared to Group 1. This pattern indicates a greater willingness in Group 2 to allow AI to undertake diverse roles, including sensitive ones like performing surgeries or assisting in surgical procedures and providing emotional support. For example, in the task of AI performing surgeries, Group 2's mean score is 3.96, compared to 3.39 in Group 1, highlighting a higher level of trust in AI's capabilities in this critical area. Similarly, for emotional support, Group 2 demonstrates a greater reliance

on AI with a mean score of 3.38 compared to Group 1's 2.66. This consistent trend across various tasks underscores a potential lack of critical assessment of AI's capabilities and limitations by individuals in Group 2, possibly leading to an unjustified elevation in trust and dependence on AI technologies.

Table 8. Comparison of allowing AI performance. *p&lt;0.05 **p&lt;0.001.

| Would you allow AI to perform the following tasks?   | Group 1 (Perceived literacy on knowledge-related dimension >2) N=44   | Group 1 (Perceived literacy on knowledge-related dimension >2) N=44   | Group 2 (Perceived literacy on knowledge-related dimension ≤ 2) N=22   | Group 2 (Perceived literacy on knowledge-related dimension ≤ 2) N=22   | Student's T   |
|------------------------------------------------------|-----------------------------------------------------------------------|-----------------------------------------------------------------------|------------------------------------------------------------------------|------------------------------------------------------------------------|---------------|
|                                                      | Mean                                                                  | SD                                                                    | Mean                                                                   | SD                                                                     |               |
| Supporting emergency services                        | 3.61                                                                  | 1.00                                                                  | 3.98                                                                   | 1.09                                                                   | 0.998         |
| School / educational support                         | 3.66                                                                  | 0.96                                                                  | 3.90                                                                   | 1.22                                                                   | 0.827         |
| Performing surgical procedures                       | 3.39                                                                  | 0.96                                                                  | 3.96                                                                   | 1.11                                                                   | 1.760*        |
| News reporting                                       | 3.18                                                                  | 1.02                                                                  | 4.00                                                                   | 1.22                                                                   | 2.797**       |
| Medical/scientific research                          | 3.45                                                                  | 0.87                                                                  | 4.14                                                                   | 1.20                                                                   | 2.458**       |
| Emotional support                                    | 2.66                                                                  | 1.29                                                                  | 3.38                                                                   | 1.56                                                                   | 2.127*        |
| Assisting surgical procedures                        | 3.6                                                                   | 1.01                                                                  | 4.00                                                                   | 1.26                                                                   | 1.341         |

Analysing Table 9, it emerges that the attitudes and beliefs regarding AI differ between the two groups, but not as drastically as observed in the previous table (Table 8). Both groups find AI exciting with nearly identical mean scores (Group 1: 3.73, Group 2: 3.75). Group 2 has a generally more positive or trusting view of AI. For example, they slightly disagree more with the statement that AI is dangerous, with a mean of 2.80 compared to Group 1's mean of 3.02. Similarly, Group 2 is more favourable to the idea that AI systems can perform better than humans (4), compared to Group 1 (3.08). This pattern is consistent with the idea that Group 2 has a higher, potentially unjustified trust in AI, possibly due to their lower literacy on the knowledge-related dimension. While the differences in mean scores for each statement between the two groups are not vastly distinct, the consistently higher trust and optimism toward AI in Group 2 reinforce the notion that lower AI literacy could lead to uncritical attitudes and unjustified trust in AI technologies.

Table 9 . Comparison of attitudes toward AI. *p&lt;0.05 **p&lt;0.001.

| How much do you agree with the following statements?              | Group 1 (Perceived literacy Group 2 (Perceived literacy   | Group 1 (Perceived literacy Group 2 (Perceived literacy   | Group 1 (Perceived literacy Group 2 (Perceived literacy   | Group 1 (Perceived literacy Group 2 (Perceived literacy   | Student's T   |
|-------------------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------------|-----------------------------------------------------------|---------------|
|                                                                   | Mean                                                      | SD                                                        | Mean                                                      | SD                                                        |               |
| AI is exciting                                                    | 3.73                                                      | 1.11                                                      | 3.75                                                      | 1.02                                                      | 0.281         |
| I think AI is dangerous                                           | 3.02                                                      | 1.00                                                      | 2.80                                                      | 1.54                                                      | -0.069        |
| I think AI systems make many errors                               | 2.93                                                      | 0.86                                                      | 3.10                                                      | 1.12                                                      | 1.174         |
| AI systems can perform better than humans                         | 3.08                                                      | 1.02                                                      | 4                                                         | 1.22                                                      | 2.897**       |
| An AI agent would be better than an employee in many routine jobs | 3.23                                                      | 1.07                                                      | 4.10                                                      | 1.12                                                      | 2.258**       |
| AI can provide new economic opportunities                         | 3.34                                                      | 1.03                                                      | 3.25                                                      | 1.33                                                      | 0.214         |
| Much of society will benefit from a future full of AI             | 3.02                                                      | 1.01                                                      | 3.20                                                      | 1.32                                                      | 1.113         |

Examining Table 10, a consistent pattern emerges again with Group 2 showing a generally more optimistic view regarding the impact of increased AI use on various aspects of life compared to Group

1. Regarding personal/individual privacy, both groups have similar mean scores (Group 1: 2.73, Group 2: 2.75), indicating comparable expectations. However, for aspects like workforce/labour displacement, Group 2 anticipates less negative impact with a mean of 2.80, compared to Group 1's mean of 3.25, underscoring their more optimistic outlook. Significantly, Group 2 expects more improvement in relevant risks with a mean of 3.45, contrasting with Group 1's mean of 3.09. This is another reflection of Group 2's potentially unwarranted trust in AI, underlining their expectation that AI will handle relevant risks better, possibly without fully grasping the complexities and challenges involved.

Table 10. Comparison of AI future impact. *p&lt;0.05 **p&lt;0.001.

| Please indicate whether you expect that the increased use of Artificial Intelligence (AI) will make each of the   | Group 1 (Perceived literacy on dimension Group 2 (Perceived literacy   | knowledge-related N=44   | on dimension   | knowledge-related N=22   | Student's T   |
|-------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|--------------------------|----------------|--------------------------|---------------|
| following? (1 - Much worse, 5 - Much better)                                                                      | Mean                                                                   | SD                       | Mean           | SD                       |               |
| Personal/individual privacy                                                                                       | 2.73                                                                   | 1.00                     | 2.75           | 1.45                     | 0.647         |
| Equity and fairness                                                                                               | 2.98                                                                   | 0.92                     | 3.05           | 1.10                     | 0.842         |
| Workforce/labour displacement                                                                                     | 3.25                                                                   | 1.11                     | 2.80           | 1.44                     | -0.729        |
| Relevant risks                                                                                                    | 3.09                                                                   | 1.06                     | 3.45           | 1.39                     | 1.540*        |
| Cybersecurity                                                                                                     | 2.91                                                                   | 1.16                     | 2.95           | 1.39                     | 0.676         |

## 5. Discussion

In this paper, we explored the perceptions, and the attitudes toward AI among students, shedding light on the complex nature of AI understanding and utilisation in various domains, particularly in education. The findings of the questionnaire revealed a spectrum of perspectives, highlighting both the  potential  and  the  concerns  related  to  AI  and  its  integration.  The  results  show  a  trend  of  awareness regarding the ethical issues surrounding AI, including fairness, accountability, transparency and safety (Gašević et al., 2023; Selwyn, 2022; Perrotta &amp; Selwyn, 2020). This ethical consciousness, which aligns with Druga et al. (2019 &amp; 2022) and Wong et al. (2020)'s emphasis on the ethical aspect of AI literacy and its societal influence, which is fundamental in navigating the complexities of AI, ensuring that advancements are aligned with societal values and norms. Nevertheless, the continued effort to boost this awareness is crucial to fostering responsible and informed AI application and development. Respondents' attitudes towards AI, marked by both openness and caution, further unveil the multifaceted perceptions of AI integration. While a general positivity towards AI's involvement was reported, hesitations, especially regarding more sensible and personalised tasks, underscore the prevailing uncertainty surrounding AI's role in diverse contexts.

In the educational field, the findings emphasise the cautious optimism regarding AI's potential role. The recognition of AI's capabilities to enhance administrative and some pedagogical aspects is promising. However, the persistent reluctance to fully entrust AI with personalised responsibilities highlights the ongoing debate and uncertainty surrounding the balance between technological efficiency and the indispensable human element in education, this balance is crucial, as mentioned by Kim et al. (2021) and Kong &amp; Zhang (2021), in ensuring career readiness and developing essential skills and attitudes. The exploration and understanding of this balance are essential in optimising the integration of AI in educational settings, ensuring the enhancement of educational outcomes while preserving the unique

value of human involvement. The anticipation of positive impacts, as mentioned by Laupichler and colleagues (2023), must be balanced against concerns related to privacy and equity, as noted by Hermann (2022). These findings highlight the need for a measured and ethical approach to AI implementation, aiming to harness its benefits while minimising potential drawbacks. It is worth noting, for example, how Weber et al. (2023)'s insights into data and algorithm literacy could play a crucial role. Such literacy serves as the foundation for building an informed and critically thinking AI user base.

Nevertheless, despite the apparent balance between scepticism and trustworthiness, a deeper analysis  reveals  that  a  significant  proportion  of  respondents  report  only  a  moderate  understanding  of  AI definitions and theoretical foundations. This reflects a baseline level of AI literacy. This gap in knowledge levels might influence the perceived utility and trustworthiness of AI technologies among students.  This  might  show  an  interesting  emerging  pattern:  the  manifestation  of  the  Dunning-Kruger effect within the responses (Kruger &amp; Dunning, 1999). This psychological principle suggests that individuals  with  low  competences  overestimate  their  knowledge  on  the  subject.  Applied  to  the  AI  context,  the  respondents with lower AI literacy, display a higher trust in AI's capabilities across various tasks, reflecting a possible overestimation of their understanding of AI technologies. This reflects the observed data, where, despite demonstrating an uncritical attitude, there is a high level of unjustified trust in AI's capability to manage diverse and sensitive tasks. Such a trend underscores the importance of comprehensive AI literacy education which considers not only technical abilities but also cultural and subjective dimensions (Yi, 2021) and highlights that educational initiatives need to emphasise not only AI's capabilities but also their limitations and potential biases, as suggested by the multidimensional approach to AI literacy (Cuomo et al., 2022).

## 6. Limitations

One significant limitation of this study lies in the convenience sample and in its size: with only 66 students participating, the sample is not adequately representative of the broader population. A larger and more diverse sample would be necessary to draw more generalisable conclusions about AI literacy and attitudes across various segments of society. Furthermore, the study focuses on a specific educational setting, which limits its applicability to other contexts. The experiences and perceptions of students in this setting may differ markedly from those in other educational environments or in different cultural or socioeconomic contexts. Another limitation is the reliance on self-reported measures, which can be subject to biases such as social desirability or self-assessment inaccuracies. While the survey method provides valuable insights, it inherently relies on the participants' own perceptions and understanding, which might not always align with objective measures of AI literacy. Finally, the study did not investigate past AI technology exposure outside academia. Our research did not examine how participants' daily AI experiences affected their perceptions and knowledge. Given these limitations, future  studies  should  use  larger  and  more  demographically  diverse  samples,  emphasise  a  variety  of educational and cultural backgrounds, and use a mix of qualitative and quantitative research methods to reduce self-reported data biases.

## 7. Conclusions

This  study's  comprehensive  analysis  of  student  AI  comprehension  and  attitudes  shows  the  complex relationship between AI literacy and AI technology perception and trust. The report shows that

AI literacy is  essential  in  today's  fast-changing  landscape  of  technology  role  in  society.  This  literacy helps people understand and manage AI's advances, threats and possibilities, enabling them to make educated decisions and participate in relevant discussions. It plays a significant role in contributing to shaping the ethical, societal, and educational dimensions of AI, safeguarding against uninformed and potentially detrimental reliance on AI technologies in diverse and sensitive domains. Despite varying levels  of  understanding showcased in the survey, the participants' anticipation for AI's positive contributions, coupled with concerns regarding privacy, equity and cybersecurity, highlights the critical necessity for promoting AI literacy. The findings from our study underscore the need for an integrative approach to AI literacy, blending technical know-how with ethical, social and humanistic understanding. This essential literacy and awareness can be fostered through robust educational initiatives, professional development programmes and the provision of accessible resources. Such efforts will improve AI literacy and equip people to productively and critically use AI technologies and constructively contribute to the growing narrative of AI integration in diverse areas. Educational and policy stakeholders must emphasise AI literacy programme creation and distribution in the future. The ultimate goal is the balanced and judicious use of AI, where its benefits are exploited, and its negatives are carefully managed to benefit society. This balanced approach will be instrumental in guiding the ethical integration of  AI  into  our  daily  lives  and  societal  structures,  paving  the  way  for  a  future  where  technology and humanity coexist in constructive collaboration.

## 8. Authors' contributions

Although the present work was jointly conceived and carried out by the authors, for attribution purposes, M. Ranieri wrote paragraphs 1,5 and 6, G. Biagini wrote paragraphs 2.2, 3, 4.1 and S. Cuomo wrote paragraphs 2.1, 4.2, 7.

## 9. References

- Biagini, G., Cuomo, S., &amp; Ranieri, M. (2023). Developing and validating a multidimensional AI literacy questionnaire: Operationalizing AI literacy for higher education. Proceedings of the First International Workshop on High-performance Artificial Intelligence Systems in Education (AIxIA 2023), Rome, Italy, Novembre 6, 2023.
- Casal-Otero, L., Catala, A., Fernández-Morante, C., Taboada, M., Cebreiro, B., &amp; Barro, S. (2023). AI literacy in K-12: a systematic literature review. International Journal of STEM Education , 10 (1), 29.
- Cetindamar, D.,  Kitto,  K.,  Wu,  M.,  Zhang,  Y.,  Abedin,  B.,  &amp;  Knight,  S.  (2022).  Explicating  AI  Literacy  of  Employees  at  Digital  Workplaces. IEEE  Transactions  on  Engineering  Management ,  1-14.  https://doi.org/10.1109/ TEM.2021.3138503
- Cuomo, S., Biagini, G., &amp; Ranieri, M. (2022). Artificial Intelligence Literacy, che cos'è e come promuoverla. Dall'analisi della letteratura ad una proposta di Framework. Media Education. - Deuze, M., &amp; Beckett, C. (2022). Imagination, Algorithms and News: Developing AI Literacy for Journalism. Digital Journalism , 10 (10), 1913-1918. - Druga, S., Christoph, F. L., &amp; Ko, A. J. (2022, April). Family as a Third Space for AI Literacies: How do children and parents  learn  about  AI  together?. In  Proceedings  of  the  2022  CHI  Conference  on  Human  Factors  in  Computing Systems (pp. 1-17).
- Druga, S., Vu, S. T., Likhith, E., &amp; Qiu, T. (2019). Inclusive AI literacy for kids around the world. In Proceedings of FabLearn 2019 (pp. 104-111).
- Joint  Research  Centre  &amp;  Organisation  for  Economic  Co-operation  and  Development  (JRC,  &amp;  OECD).  (2021). AI watch,  national  strategies  on  artificial  intelligence:  a  European  perspective .  Publications  Office  of  the  European Union. - Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P ., Dignum, V ., Luetge, C., Madelin, R., Pagallo, U., Rossi, F.,  Schafer, B., Valcke, P ., &amp; Vayena, E. (2018). AI4People-An Ethical Framework for a Good AI Society: Opportunities,  Risks,  Principles,  and  Recommendations. Minds and Machines , 28 (4),  689-707.  http://doi.org/10.1007/ s11023-018-9482-5
- Gašević, D., Siemens, G., &amp; Sadiq, S. (2023). Empowering learners for the age of artificial intelligence. Computers and Education: Artificial Intelligence , 100130. - Gouseti, A. (2017). Exploring doctoral students' use of digital technologies: what do they use them for and why?. Educational Review , 69 (5), 638-654. - Hazell, C.M., Chapman, L., Valeix, S.F., Roberts, P ., Niven, J. E., &amp; Berry, C. (2020). Understanding the mental health of  doctoral  researchers:  a  mixed  methods  systematic  review  with  meta-analysis  and  meta-synthesis. Systematic Reviews , 9 , 197. - Hermann, E. (2022). Artificial intelligence and mass personalization of communication content-An ethical and literacy perspective. New Media &amp; Society , 24 (5), 1258-1277. - Kandlhofer, M., Steinbauer, G., Hirschmugl-Gaisch, S., &amp; Huber, P . (2016). Artificial intelligence and computer science in education: From kindergarten to university. In IEEE Frontiers in Education Conference. (pp. 1-9). https://doi. org/10.1109/FIE.2016.7757570
- Kim, S., Jang, Y., Kim, W ., Choi, S., Jung, H., Kim, S., &amp; Kim, H. (2021). Why and What to Teach: AI Curriculum for Elementary School. Proceedings of the AAAI Conference on Artificial Intelligence , 35 (17), 15569-15576. https://doi. org/10.1609/aaai.v35i17.17833
- Kong, S. C., Cheung, W. M. Y., &amp; Zhang, G. (2023). Evaluating an artificial intelligence literacy programme for developing university students' conceptual understanding, literacy, empowerment and ethical awareness. Educational Technology &amp; Society , 26 (1), 16-30.
- Kong, S.-C., &amp; Zhang, G. (2021). A Conceptual framework for designing artificial intelligence literacy programmes for educated citizens. In S. C. Kong, Q. Wang, R. Huang, Y. Li, &amp; T.-C. Hsu (Eds.), Conference proceedings (English paper) of the 25th Global Chinese Conference on Computers in Education (GCCCE 2021) (pp.  11-15).  Centre  for Learning, Teaching and Technology, The Education University of Hong Kong.
- Kruger, J., &amp; Dunning, D. (1999). Unskilled and unaware of it: how difficulties in recognizing one's own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology , 77 (6), 1121.
- Laupichler, M. C., Aster, A., Haverkamp, N., &amp; Raupach, T. (2023). Development of the 'Scale for the assessment of non-experts' AI literacy'- An exploratory factor analysis. Computers in Human Behavior Reports , 12 , 100338.
- Liu, B. L., Morales, D., Roser-Chinchilla, J., Sabzalieva, E., Valentini, A., Vieira do Nascimento, D., &amp; Yerovi, C. (2023). Harnessing the era of artificial intelligence in higher education: a primer for higher education stakeholders . UNESCO. unesdoc.unesco.org/ark:/48223/pf0000386670/PDF/386670eng.pdf.multi
- Liu, S., &amp; Xie, X. (2021, July). AI quality cultivation and application ability training for normal university students. In 2021 7th Annual International Conference on Network and Information Systems for Computers (ICNISC) (pp.  116120). IEEE.
- Long, D., &amp; Magerko, B. (2020, April). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI conference on human factors in computing systems (pp. 1-16).
- Ng, D. T. K., Leung, J. K. L., Chu, S. K. W ., &amp; Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence , 2 , 100041. - Perrotta, C., &amp; Selwyn, N. (2020). Deep learning goes to school: Toward a relational understanding of AI in education. Learning, Media and Technology , 45 (3), 251-269.
- Schepman, A., &amp; Rodway, P. (2020). Initial validation of the general attitudes towards Artificial Intelligence Scale. Computers in Human Behavior Reports , 1 , 100014.
- Schepman, A., &amp; Rodway, P. (2023). The General Attitudes towards Artificial Intelligence Scale (GAAIS): Confirmatory validation and associations with personality, corporate distrust, and general trust. International Journal of HumanComputer Interaction , 39 (13), 2724-2741.
- Selwyn, N. (2022). The future of AI and education: Some cautionary notes. European Journal of Education , 57 (4), 620631. - Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., &amp; Montag, C. (2021). Assessing the attitude towards artificial intelligence: Introduction of a short measure in German, Chinese, and English language. KI-Künstliche Intelligenz , 35 , 109-118. - Su,  J.,  &amp;  Zhong,  Y.  (2022).  Artificial  Intelligence  (AI)  in  early  childhood  education:  Curriculum  design  and  future directions. Computers and Education: Artificial Intelligence , 3 , 100072.
- United Nations Educational, Scientific and Cultural Organization (UNESCO). (2019). Beijing  consensus  on  artificial intelligence and education . https://unesdoc.unesco.org/ark: /48223/pf0000368303
- United Nations Educational, Scientific and Cultural Organization (UNESCO). (2021). AI and education: Guidance for policy makers . https://unesdoc.unesco.org/ark: /48223/pf0000376709
- Wang, B., Rau, P.-L. P ., &amp; Yuan, T. (2022). Measuring user competence in using artificial intelligence: Validity and reliability of artificial intelligence literacy scale. Behaviour &amp; Information Technology , 1-14. https://doi.org/10.1080/014 4929X.2022.2072768
- Wang, Y. Y., &amp; Wang, Y. S. (2022). Development and validation of an artificial intelligence anxiety scale: An initial application in predicting motivated learning behavior. Interactive Learning Environments , 30 (4), 619-634.
- Weber, P., Pinski, M., &amp; Baum, L. (2023). Toward an objective measurement of AI literacy. Weber, P., Pinski, M., &amp; Baum,  L.C.  (2023). Toward  an  Objective  Measurement  of  AI  Literacy .  Pacific  Asia Conference  on  Information Systems .
- Wienrich, C., &amp; Carolus, A. (2021). A more holistic view of literacy specifications in the context of speech-based systems. Proceedings 2021 ISCA Symposium on Security and Privacy in Speech Communication , 73-75
- Williams, R., Park, H. W., Oh, L., &amp; Breazeal, C. (2019). Popbots: Designing an artificial intelligence curriculum for early  childhood  education.  In Proceedings  of  the  AAAI  Conference  on  Artificial  Intelligence, Vol.  33,  No.  01,  (pp. 9729-9736).
- Wong, G. K., Ma, X., Dillenbourg, P., &amp; Huan, J. (2020). Broadening artificial intelligence education in K-12: where to start?. ACM Inroads , 11 (1), 20-29.
- Yi, Y. (2021). Establishing the concept of AI literacy: Focusing on competence and purpose. JAHR- European Journal of Bioethics , 12 (2), 353-368. - Zawacki-Richter, O., Marín, V . I., Bond, M., &amp; Gouverneur, F. (2019). Systematic review of research on artificial intelligence applications in higher education-where are the educators? International Journal of Educational Technology in Higher Education , 16 (1), 1-27. https://dx.doi.org/10.1186/s41239-019-0171-0
- Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., &amp; Breazeal, C. (2022). Integrating Ethics and career futures with technical learning to promote AI literacy for Middle School students: An Exploratory Study. International Journal of Artificial Intelligence in Education . https://doi.org/10.1007/s40593-022-00293-3