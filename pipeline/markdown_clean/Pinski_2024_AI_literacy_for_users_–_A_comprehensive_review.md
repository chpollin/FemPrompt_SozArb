---
source_file: Pinski_2024_AI_literacy_for_users_–_A_comprehensive_review.pdf
conversion_date: 2026-02-03T09:16:06.943317
converter: docling
quality_score: 95
---

<!-- image -->

## Computers in Human Behavior: Artificial Humans

## AI literacy for users -A comprehensive review and future research directions of learning methods, components, and effects

Marc Pinski * , Alexander Benlian

Technische Universit ¨ at Darmstadt, Information Systems and E-Services, Hochschulstra ß e 1, 64289, Darmstadt, Germany

## A R T I C L E  I N F O

Keywords: Systematic literature review Scoping literature review Artificial intelligence literacy Learning methods AI literacy components AI literacy effects

## 1. Introduction

' Building an AI-powered society that benefits all requires each of us to become literate about AI. ' -  World Economic Forum (2022) in ' Without universal AI literacy, AI will fail us '

In the past decade, the rapid advancement of artificial intelligence (AI) has brought transformative changes to how humans work, interact, and live -thereby significantly increasing the number of AI users (Jain et al., 2021). The AI-powered large language model ChatGPT released in November 2022, based on the novel generative pre-trained transformer (GPT)  technology,  broke  the  all-time  record  in  technology  adoption speed with 100 million users in only two months (Milmo, 2023). However, AI ' s transformative changes come with challenges unseen by users, such as, in the GPT-based AI context, phenomena like ' hallucinations, ' describing incorrect output appearing logical and cohesive at first sight (Brynjolfsson et al., 2023; Peng et al., 2023). Research and practice are eager to develop technological solutions to address these challenges, such as large language models warning users about potential hallucinations (Ortiz, 2023). Still, technological features alone do not ensure successful  human-AI  collaboration.  Human-centered  approaches  are

## A B S T R A C T

The rapid advancement of artificial intelligence (AI) has brought transformative changes to various aspects of human life, leading to an exponential increase in the number of AI users. The broad access and usage of AI enable immense benefits but also give rise to significant challenges. One way for AI users to address these challenges is to develop AI literacy, referring to human proficiency in different subject areas of AI that enable purposeful, efficient, and ethical usage of AI technologies. This study aims to comprehensively understand and structure the research on AI literacy for AI users through a systematic, scoping literature review. Therefore, we synthesize the literature, provide a conceptual framework, and develop a research agenda. Our review paper holistically assesses  the  fragmented AI literacy research landscape (68 papers) while critically examining its specificity to different user groups and its distinction from other technology literacies, exposing that research efforts are partly not well integrated. We organize our findings in an overarching conceptual framework structured along the learning  methods  leading  to,  the  components  constituting,  and  the  effects  stemming  from  AI  literacy.  Our research agenda -oriented along the developed conceptual framework -sheds light on the most promising research opportunities to prepare AI users for an AI-powered future of work and society.

necessary to complement the technology itself (Marcolin et al., 2000; Torkzadeh &amp; Koufteros, 1993). Researchers from various disciplines at the intersection of humans and technology, such as human-computer interaction  (HCI;  e.g.,  Long &amp; Magerko,  2020),  computer  education (CED; e.g., Ng et al., 2021), or information systems (IS; e.g., Heyder &amp; Posegga, 2021), have recently coined the concept of AI literacy as such a human-centered  approach.  Whereas  multiple  AI  literacy  definitions exist, all refer to some dimension of human proficiency (e.g., knowledge, skills,  competencies)  regarding  different  subject  areas  of  AI  (e.g.,  AI models,  ethical  implications,  knowledge  representations)  that  enable purposeful  usage  of  AI  or  interaction  with  AI  (e.g.,  Hermann,  2021; Kandlhofer et al., 2016; Long &amp; Magerko, 2020). For example, AI literacy empowers AI users to understand the fundamental principles of AI, enabling them to recognize potential biases and understand the ethical considerations involved (Wang et al., 2022).

While  AI  in  the  form  of  large  language  models  received  much attention recently, the new challenges for AI users extend to all AI-based technologies, which can be characterized by three distinguishing facets: learning ability, increased autonomy, and inscrutability (Berente et al., 2021). Technology with these characteristics (i.e., AI tools) has become

* Corresponding author. E-mail addresses: pinski@ise.tu-darmstadt.de (M. Pinski), benlian@ise.tu-darmstadt.de (A. Benlian).

wY/LO/?OX RQOLQX oy b/UYK SfSE

<!-- image -->

<!-- image -->

pervasive. At the same time, AI users have mostly been left ill-prepared to comprehend, utilize, and critically engage with AI -that is, they have been left AI illiterate at large (Maitz et al., 2022; Wilton et al., 2022). This mismatch raises concerns not only about the efficiency and effectiveness of human-AI collaborations but also about privacy, ethics, and bias (Mikalef et al., 2022). Hence, developing a comprehensive understanding of AI literacy is crucial to preparing AI users for an AI-powered future of work and society.

Prior AI literacy research in the emerging literature stream started to build our understanding of AI literacy along three research avenues that can be seen as three logically consecutive steps: The learning methods leading to AI literacy (e.g., Long, Blunt, &amp; Magerko, 2021), the components constituting  AI  literacy  (e.g.,  Ng  et  al.,  2021),  and  the effects resulting from AI literacy (e.g., Pinski, Adam, &amp; Benlian, 2023). Each step is highly relevant for a comprehensive understanding of AI literacy. First, since AI technologies are evolving rapidly, it is essential to understand the most effective learning methods for equipping different AI users with the needed AI literacy. Understanding how AI users can best grasp novel AI concepts relevant to them enables the development of targeted educational initiatives. Therefore, building a broad repertoire of formal and informal learning methods tailored to conveying AI literacy is necessary (Long, Blunt, &amp; Magerko, 2021). Second, much prior research focused on conceptualizing different AI literacy components , for example,  individual  AI  skills  or  knowledge  concerning  different  AI subjects (e.g., Long &amp; Magerko, 2020; Ng et al., 2021). As different AI user groups have different AI literacy requirements, it is vital to understand  and  build  a  repository  of  AI  literacy  components  and  their relevancy to different AI user groups. For example, a manager (Jorzik et al., 2023) needs different AI skills and knowledge than a teacher (Kim &amp; Kwon, 2023). Third, it is important to understand if AI literacy results in the intended effects . For instance, previous research has shown that AI literacy can positively affect the performance of human-AI collaboration while simultaneously reducing humans ' intention to use AI in the future (Pinski, Adam, &amp; Benlian, 2023). Given that AI might affect humans differently compared to what we have learned with non-AI technology, it is imperative to better understand the diverse effects of AI literacy to foster desired effects and prevent unwanted effects.

While research  has  accumulated  within  these  three  research  avenues,  the  overall  AI  literacy  research  landscape  remains  fragmented, with  many  questions  unanswered  (Pinski,  Adam, &amp; Benlian,  2023). Therefore, we need a comprehensive assessment of the recent scientific discourse that systemizes existing knowledge  and  guides future research.  Prior  reviews  focused  on  one  particular  research  avenue, identifying  several  relevant  AI  literacy  components  (e.g.,  Long &amp; Magerko, 2020; Ng et al., 2021). Other studies focused on a particular proficiency  dimension  or  selected  subject  areas  within  the  research avenue  of  AI  literacy  components  (Carolus  et  al.,  2023;  Laupichler, Aster, Haverkamp, &amp; Raupach, 2023). However, the field has matured significantly in the past three years, and research has also been conducted in the other two avenues (learning methods and effects) (e.g., Chiang &amp; Yin, 2022; Long, Blunt, &amp; Magerko, 2021; Pinski, Adam, &amp; Benlian, 2023).

Furthermore, as AI users are growing in number across and within domains, it becomes apparent that there is no one AI literacy solution for all different AI user groups (Benlian et al., 2022; Meske et al., 2020). There is a notion in the AI literacy literature to distinguish expert users, predominantly from the organizational context, and non-expert users, predominantly  from  the  personal  context,  like  humans  using  their smartphones (Laupichler, Aster, Haverkamp, &amp; Raupach, 2023; Pinski, Haas, &amp; Franz, 2023). These two broad user group categories comprise different, more specific individual AI user groups, for example, managers, teachers, and medical doctors within the expert category. As of now, we lack oversight of which individual AI user groups the literature has covered so far.

In addition, many studies assume an implicit understanding of AI, making  it  difficult  to  distinguish  AI  literacy  from  other  technology literacies, like digital literacy. As a research community, we need to be specific about AI literacy. To our knowledge, no prior work has scrutinized the AI literacy literature regarding its AI-specificity using a wellgrounded  AI  understanding,  such  as  the  introduced  AI  facets  of Berente et al. (2021): autonomy, inscrutability, and learning.

This  study  aims  to  assess  the  scope  of  the  fragmented  research landscape in each of the introduced AI literacy research avenues and organize the research into a conceptual framework by answering the following research questions. Furthermore, it aims to assess the scope of AI user groups covered by the literature and scrutinize what we understand under the construct of AI literacy by leveraging established facets of AI (Berente et al., 2021).

- RQ1: Which learning methods have been identified leading to AI literacy for AI users?
- RQ2: Which components have been identified as constituting AI literacy for AI users?
- RQ3: Which effects have been identified that AI literacy has on AI users?

We attempt to answer these research questions using a systematic, scoping literature review approach (Par ´ e et al., 2015). Particularly in emerging research fields such as AI literacy, a (scoping) literature review can  help  to  establish ' a  firm  foundation  for  advancing  knowledge ' (Webster &amp; Watson, 2002, p. 13). With this scoping literature review, we make the following contributions:

- (1)  While prior research focused on particular aspects of AI literacy (e.g., Long &amp; Magerko, 2020 for components), our review extends this by developing an overarching conceptual framework comprising detailed conceptualizations for each AI literacy aspect (learning methods, components, and effects). To our knowledge, no reviews regarding learning methods and the effects of AI literacy  have  been  conducted.  Our  scoping  review  extends  the conceptual  understanding  of  AI  literacy  by  structuring  the currently fragmented discourse.
- (2)  Drawing  from  our  comprehensive  conceptual  framework,  we outline a research agenda that identifies the key areas of opportunity for scholars in the field of AI literacy. We outline different future research directions for the learning methods, components, and effects of AI literacy.
- (3) Prior studies either have not accounted for AI user group differences or have focused on individual AI user groups (e.g., Charow et al., 2021). This review contributes a holistic analysis of AI user groups discussed within both the expert and non-expert domains, shifting the discourse to consider AI user group differences more thoroughly. Further, the holistic user group analysis uncovers yet unexplored AI user groups.
- (4)  Much prior research investigated highly relevant aspects of AI literacy while leaving it unclear how the AI literacy construct is distinct from prior technology literacies, such as digital or data literacy.  Our  review  departs  from  this  by  assessing  the  AIspecificity  of  the  components  (e.g.,  different  skills  and  knowledge) ascribed to AI literacy by the literature. Therefore, we use three AI facets from an established AI definition (Berente et al., 2021): autonomy, inscrutability, and learning. We use the facets for  a  structured  distinction  of  AI  from  non-AI  technology, enabling us to distinguish AI literacy from other technology literacies. By applying this AI lens, we contribute to a more thorough understanding of what AI literacy refers to and how the construct relates to other literacies.
- (5)  Concerning  practice,  this  review  also  provides  a  reference  for educators,  policymakers,  and  business  decision-makers  who make crucial decisions concerning the standards of AI literacy in educational institutions, society, and business.

## 2. Conceptual background

## 2.1. Artificial intelligence

While the concept of AI was first mentioned in the 1950s (McCarthy et al., 1955; Turing, 1950), attention to the topic fluctuated over the years, including periods with very little attention known as AI winters (Hendler,  2008).  In  recent  years,  increased  computing  capacity  and major  technological  breakthroughs  like  the  transformer  technology (Vaswani et al., 2017) enabled new AI technologies, such as large language models (Brynjolfsson et al., 2023), which led to massive attention paid to the topic not only by the academic and business communities but also  by  large  (non-expert)  parts  of  society  (Nguyen  et  al.,  2022). Nevertheless,  AI  remains  a  diffuse  concept,  and  manifold  definitions exist even within research fields (Collins et al., 2021). For example, Rai et  al.  (2019,  p.  iii)  see  AI  as  the ' ability  of  a  machine  to  perform cognitive functions that we associate with human minds [ … ], ' whereas Duan et al. (2019, p. 1) refer to AI as ' the ability of a machine to learn from experience, adjust to new inputs and perform human-like tasks. '

However, when aiming to conceptualize AI literacy and delineate it from related concepts, such as digital or data literacy, it is purposeful to use criteria that enable a distinction between AI technologies and non-AI technologies. Most AI definitions have a reference to humans and human skills in common (Collins et al., 2021). Berente et al. (2021, p. 1435) make this explicit in their AI definition, viewing AI as ' the frontier of computational  advancements  that  references  human  intelligence  in addressing ever more complex decision-making problems. ' Building on their definition, they provide three facets of AI technologies that one can use  as  a  framework  to  assess  AI-specificity:  autonomy,  learning,  and inscrutability.

AI technologies are increasingly more autonomous , as they can act without human intervention (Baird &amp; Maruping, 2021). The autonomous decisions of these technologies have tangible effects, often without humans being  aware  that  these  decisions  have  been  made  by  an  AI technology (Murray et al., 2021). Examples include self-driving vehicles (Fernandez Domingos et al., 2022), robo-advisors for investments (Lee &amp; Shin, 2018), and AI underwriters for loans (Markus, 2017). Learning is fundamental  to  AI,  with  data  and  experience  enabling  automatic improvement (Turing, 1950). Recent breakthroughs in big data (Chen &amp; Storey,  2012)  have  led  to  advancements  in  deep  and  reinforcement learning  (Janiesch  et  al.,  2021),  allowing  AI  to  handle  complex decision-making involving complex audio, text, and object recognition as well as generative capacities (Brynjolfsson et al., 2023). Inscrutability accompanies AI ' s progress, generating algorithmic models and outputs that are intelligible only to select audiences or sometimes remain opaque to all humans (Arrieta et al., 2020). Rising computing capacities allowed  developers  to  construct  AI  technologies,  such  as  neural  networks, based on so many intertwined parameters that decision-making is often incomprehensible to the human mind (Brasse et al., 2023).

## 2.2. Prior technology literacies

Literacy is not a static concept but is under constant evolution based on  the  technological  and  social  developments  of  society  (Leu  et  al., 2013).  Literacy  in  the  technology  context  has  evolved  significantly beyond its traditional definition of being able to read and write (Leu et al., 2004). The broader literacy notion now encompasses specialized literacies  tailored  to  specific  technological  domains,  such  as  digital, data, and media literacy (Eshet-Alkalai, 2004; Potter, 2013; Wolff et al., 2016), which are, however, continuously evolving (Leu et al., 2013). While each literacy concept evades an agreed-upon definition in the literature,  scholars  have  identified  common  themes  of  the  literacy construct  within  each  discourse  (Eshet-Alkalai,  2004;  Potter,  2013; Wolff et al., 2016).

Digital  literacy  is  among  the  most  prominent  technology  literacy concepts (Gilster, 1997; Neumann  et  al., 2016; Njenga, 2018).

Eshet-Alkalai (2004, p. 1) characterizes digital literacy as comprising a ' large variety of complex cognitive, motor, sociological, and emotional skills, which users need in order to function effectively in digital environments. ' However, the literature goes beyond viewing digital literacy merely as a skill-based construct. Research also emphasizes that digital literacy should empower humans ' to appropriately respond, in socially recognised ways, to even future challenges through sharing and creating knowledge and eventually participating in the society ' (Njenga, 2018, p. 2). This holistic perspective elevates digital literacy beyond a mere set of skills by setting the technology it relates to in the social context (Feerrar, 2019). One can find similar themes of defining ' literacy ' holistically in other  literacy  concepts  (Livingstone,  2004).  When  conceptualizing media literacy, Potter (2004) argues that the literacy concept encompasses knowledge and skills in different domains as well as ' personal locus, ' which refers to emotional commitment and drive to search for information and experiences to attain your goals. Regarding data literacy, on the one hand, research mentions that it encompasses knowledge and skill  components, such as data analysis techniques (Kerpedzhiev et al., 2020). On the other hand, the literature also emphasizes that data literacy contains ethical and critical judgment (Someh et al., 2019) and an  understanding  of  how  data  literacy  impacts  society  (Wolff  et  al., 2016).

Taken together, the different literacies share common elements that transcend  their  specific  domains.  They  all  emphasize  holistic  proficiency, which means going beyond merely accumulating knowledge or skills. Through knowledge and skill, technology literacies should enable efficient and effective usage. Individuals must be able to use technology productively, maximizing its potential benefits. Beyond that, technology literacies must connect the technology to its social context, which means ethical, responsible, and critical interaction. Ethical considerations and responsible behavior are integral to these literacy concepts, ensuring individuals engage with technology morally and conscientiously. This view is underlined by the World Economic Forum (2018, 2020), contending  that  everyday  life  and  employment  skills  have  shifted  from technology-centered skills to a broader set, including analytical thinking, active self-driven learning, and (global) citizenship. In summary, technological literacies can be described as holistic constructs of human proficiency, including reflection and deliberation, that enable humans to use technology purposefully, efficiently, and ethically (Deuze &amp; Beckett, 2022).

## 2.3. The need for AI literacy

AI ' s specific facets (autonomy, learning, and inscrutability) caused the invalidation of multiple core assumptions fundamental to humantechnology interaction held for decades (Berente et al., 2021; Schuetz &amp; Venkatesh, 2020). For example, AI technologies break the assumption of functional consistency because they can learn from processed data, thus behaving differently over time. Furthermore, they remove the necessity of an artificial interface through more natural interactions like speech, thus enabling the possibility that humans might not be aware of their interactions with AI technologies, such as with voice assistants like Alexa or chatbots (Schuetz &amp; Venkatesh, 2020). This invalidation of human-technology  interaction  assumptions,  in  combination  with  the increasingly widespread implementation of AI in the broader work-related and societal context (Berente et al., 2021), makes the need for  a  revised  technology  literacy  concept  apparent,  i.e.,  AI  literacy. Furthermore, the ethical challenges of AI are looming larger than before due to the increasingly human-like and beyond-human capacities (e.g., due  to  deep-fakes).  In  other  words,  AI  literacy  is  necessary  for  the broader user base to comprehend and respond to this human-technology interaction paradigm shift.

Similar to prior literacy concepts, different definitions of AI literacy for AI users exist in the literature (see Table 1). One can observe that these definitions also emphasize holistic proficiency regarding different subject  areas  of  AI.  As  part  of  AI  literacy,  scholars  mention  AI

Table 1

## AI Literacy Definitions (in alphabetical order).

| Source                            | AI User Domain      | Definition                                                                                                                                                                                                                                                                                                                                          |
|-----------------------------------|---------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Carolus et al. (2023, p. 1)       | Non-expert          | AI literacy covers ' competencies needed to interact with AI technology in a self-determined and rational manner. '                                                                                                                                                                                                                                 |
| Cetindamar et al. (2022, p. 11)   | Expert              | Employees ' AI literacy is ' a collection of technology, work, human-machine, and learning capabilities. These capabilities could allow employees to actively join in on designing and utilizing AI at their workplaces. '                                                                                                                          |
| Dai et al. (2020, p. 3)           | Non-expert          | Student ' s AI literacy is the ' ability to access and use AI-related knowledge and skills. '                                                                                                                                                                                                                                                       |
| Deuze and Beckett (2022, p. 1)    | Expert              | AI literacy is ' the knowledge and beliefs about artificial intelligence which aid their recognition, management, and application. '                                                                                                                                                                                                                |
| Hermann (2021, p. 1270)           | Non-expert          | AI literacy is an ' individuals ' basic understanding of (a) howandwhich data are gathered; (b) the way data are combined or compared to draw inferences, create, and disseminate content; c) the own capacity to decide, act, and object; (d) AI ' s susceptibility to biases and selectivity; and (e) AI ' s potential impact in the aggregate. ' |
| Laupichler et al. (2022, p. 1)    | Non-expert          | AI literacy is ' the ability to understand, use, monitor, and critically reflect on AI applications without necessarily being able to develop AI models themselves. '                                                                                                                                                                               |
| Kong et al. (2021, p. 2)          | Non-expert          | AI literacy ' includes three components: AI concepts, using AI concepts for evaluation, and using AI concepts for understanding the real world through problem solving. '                                                                                                                                                                           |
| Long and Magerko (2020, p. 2)     | Expert & Non-expert | AI literacy is ' a set of competencies that enables individuals to critically evaluate AI technologies, communicate and collaborate effectively with AI, and use AI as a tool online, at home, and in the workplace. '                                                                                                                              |
| Ng et al. (2022, p. 1)            | Non-expert          | AI literacy is ' a new set of technological attitudes, abilities and competencies that people use AI effectively and ethically in everyday life. '                                                                                                                                                                                                  |
| Pinski and Benlian (2023, p. 169) | Expert & Non-expert | ' General AI literacy is humans ' socio-technical competence consisting of knowledge regarding human and AI actors in human-AI interaction, knowledge of the AI process steps, that is input, processing, and output, and experience in AI interaction. '                                                                                           |

competencies (e.g., Carolus et al., 2023; Long &amp; Magerko, 2020), AI abilities  (e.g.,  Laupichler  et  al.,  2022),  or  AI  knowledge  and  understanding (e.g., Dai et al., 2020; Hermann, 2021). Together, this holistic proficiency should create an understanding of AI, enable self-determined, effective, and ethical interaction with AI, empower to utilize AI actively (in the workplace and everyday life), and allow to critically evaluate AI (Carolus et al., 2023; Cetindamar et al., 2022; Dai et al., 2020; Hermann, 2021; Kong et al., 2021; Laupichler et al., 2022; Long &amp; Magerko, 2020; Ng et al., 2022).

Moreover, the different AI literacy definitions show which AI users the literature refers to (see Table 1). On a fundamental level, researchers distinguish  between  AI  users  as  non-experts  predominantly  in  their personal roles as citizens of society or for their personal usage of AI (e.g., Carolus et al., 2023; Laupichler et al., 2022) and AI users as experts predominantly their organizational roles in a work-related context (e.g., Cetindamar et al., 2022; Long &amp; Magerko, 2020). The AI literacy requirements of different AI user groups are conceivably specific to the respective AI user group based on their usage of AI.

Following the tradition of technological literacies, we view AI literacy  as  a  construct  comprising  multiple  proficiency  dimensions  as expressed by the different definitions in the literature (see Fig. 1 and Table  1).  These  proficiency  dimensions  relate  to  different  AI  subject areas and have together primarily an enabling character for efficient, self-determined, and critical usage of technology that is autonomous, can  learn,  or  is  inscrutable.  By  defining  AI  literacy  as  an  enabling construct,  we  view  it  as  distinct  from  mere  attitudes  towards  AI (Schepman &amp; Rodway, 2022), trust in AI (Kaplan et al., 2023), or the intention to use AI (Pinski, Adam, &amp; Benlian, 2023). While all these constructs might be related to AI literacy, they express, for example, humans ' affective  characteristics  rather  than  an  enabling,  holistic proficiency.

## 3. Method

To answer our research questions on AI literacy, we conducted a scoping  literature  review,  adhering  to  the  established  methodology within  the  family  of  systematic  literature  reviews  (Kitchenham &amp; Charters,  2007;  Par ´ e  et  al.,  2015;  Schryen  et  al.,  2021;  Webster &amp; Watson,  2002).  A  scoping  literature  review  is  characterized  by  a comprehensive search strategy aimed at covering the breadth of the literature, an explicit study selection to eliminate studies that do not address  the  research  questions,  and  a  content  analysis,  which  is topic-centric rather than author-centric (Par ´ e et al., 2015). Furthermore, by employing this approach, we aim to develop a conceptual framework that  organizes  the  AI  literacy  literature  overall  and  more  detailed ' deep-dives ' for individual aspects of the framework where appropriate. We selected the corpus of literature for analysis by following a five-step search and selection process (see Fig. 2). Details on the coding process are available in Appendix A.

## 3.1. Search process

In  the  first  step,  we  conducted  an  initial  search  to  systematically identify relevant papers using the following search parameters. We used the broad search string ' AI literacy ' OR ' artificial intelligence literacy ' to ensure we captured all relevant articles. By including ' literacy ' in the search terms, we deliberately aimed to focus on articles that refer specifically to the broader, more holistic concept. We queried the key academic databases for HCI and IS research (ACM, AIS, Emerald, IEEE, Informs, JSTOR, Science Direct, Taylor &amp; Francis, and Web of Science). We did not apply any date filters. The initial search resulted in 341 articles.

## 3.2. Selection process

To select the relevant articles, we first excluded articles based on three technical exclusion criteria: non-English, duplicate, and non-peerreviewed/non-scientific articles. As a result, 56 articles were excluded at this  stage.  Then,  two  independent  coders  conducted  an  abstract screening of all 285 remaining articles. Discrepancies in the coding were

## Human Proficiency Dimensions:

Fig. 1. AI literacy proficiency dimensions.

<!-- image -->

Fig. 2. Search and selection process.

<!-- image -->

Fig. 3. Overarching conceptual framework.

<!-- image -->

discussed individually until the coders achieved consensus. The exclusion  criteria  at  this  stage  were  that  the  papers  were  either  not  AIliteracy-focused, for example, when only mentioning the term to motivate a different topic, or not user-focused, such as developer-focused papers. As such, we ensured that we only included articles related to this review ' s defined scope. In the fourth step, we read all identified papers fully and applied the same exclusion criteria as in the third step. As a result, 52 papers remained in the selection. Finally, we conducted a forward and backward search of the identified articles, adding 16 papers to the selection, which totals 68 papers included in the final selection. By implementing this rigorous search and screening strategy, we aimed to compile a comprehensive collection of scholarly articles that meet the specific requirements of this study on AI literacy.

## 4. Results

In  the  following,  we  report  the  results  of  our  literature  review. Descriptive literature metrics (e.g., publication year, discipline, applied methodologies) of the compiled corpus are available in Appendix B. We developed an overarching conceptual framework of AI literacy (Fig. 3), which corresponds to the three main avenues of AI literacy research, as well as our two analytical lenses -specificities implied either due to the distinguishing facets of AI or due to the different user groups of AI. The three main avenues of AI literacy research (learning methods, components, and effects) follow a logical order, such that the learning methods enable humans to acquire AI literacy, the components describe what the acquired AI literacy consists of, which then results in the effects for the humans in question. All three are affected by the specific facets of AI (Berente  et  al.,  2021)  and  the  user  group  one  belongs  to.  Before reviewing the results of each of the three AI literacy avenues, we will report our results regarding the different types of AI users found in the literature  (subsection  4.1).  Then,  we  review  the  learning  methods (subsection 4.2), AI literacy components (subsection 4.3), and effects (subsection 4.4).

## 4.1. AI users

Since we focus on AI literacy for AI users, we must distinguish and comprehensively understand the AI user groups discussed in the existing literature. To achieve this, we examined the identified AI literacy literature corpus and other literature structuring the discourse on AI usage

Table 2 AI User Group Framework: Covered by current AI literacy literature.

| Context                           | Domain                              | Eco. activity NAICS code a   | AI user groups       | Sources                                                                                                                                                                                                                                                                                                                                                                                                 |
|-----------------------------------|-------------------------------------|------------------------------|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Non-expert (Personal context)     | Student                             | -                            | Students (K-12)      | Kandlhofer et al. (2016); Khalid et al. (2022); Kong et al. (2021); Lee et al. (2021); Long et al. (2022); Melsi ´ on et al. (2021); Ng et al. (2022); Steinbauer et al. (2021); Su et al. (2023); Xu and Babaian (2021); Yang (2022)                                                                                                                                                                   |
|                                   | Adult                               | -                            | Adults               | Carolus et al. (2023); Chaudhury et al. (2022); Chiang and Yin (2022); Kusuma et al. (2022); Laupichler, Aster, and Raupach (2023); Leichtmann et al. (2023); Long, Blunt, and Magerko (2021); Long et al. (2019); Long and Magerko (2020); Long, Padiyath, et al. (2021); Markauskaite et al. (2022); Ng et al. (2021); Register and Ko (2020); ( Salazar-Gomez et al., 2022); Schneider et al. (2023) |
| Expert (Organi- zational context) | Construction and Energy             | 21 - 23                      | Construction workers | Charow et al. (2021); Maitz et al. (2022)                                                                                                                                                                                                                                                                                                                                                               |
|                                   | Manufacturing                       | 31 - 33                      | Mechanical engineers | Pillay et al. (2018)                                                                                                                                                                                                                                                                                                                                                                                    |
|                                   | Information                         | 51                           | Librarians           | Cox and Mazumdar (2022)                                                                                                                                                                                                                                                                                                                                                                                 |
|                                   | Management                          | 55                           | Managers             | Jorzik et al. (2023), Pinski, Hofmann, and Benlian (2023), Pinski, Hofmann, and Benlian (2024), Yang et al. (2021),                                                                                                                                                                                                                                                                                     |
|                                   | Education                           | 61                           | Teachers             | Kim and Kwon (2023)                                                                                                                                                                                                                                                                                                                                                                                     |
|                                   | Healthcare                          | 62                           | Medical doctors      | Charow et al. (2021), Jussupow et al. (2021)                                                                                                                                                                                                                                                                                                                                                            |
|                                   | Arts, Entertainment, and Recreation | 71                           | Journalists          | Deuze and Beckett (2022)                                                                                                                                                                                                                                                                                                                                                                                |
|                                   | Unspecified Sector                  | -                            | Workers in general   | Cetindamar et al. (2022)                                                                                                                                                                                                                                                                                                                                                                                |

a Unmatched NAICS codes examined in future research directions (see Table 9).

(Jain et al., 2021). AI users can be set apart from AI developers based on their interaction type with AI technology, that is, the usage of existing technology instead of active creation (Meske et al., 2020). Due to the breadth of AI technologies, there is a broad scope of different AI user groups (Berente et al., 2021). In contrast to prior technology, AI technology usage is also not always conscious, extending the scope further. Since AI technology can operate without an artificial interface, which was necessary in previous technology usage, one can use AI without realizing it (Schuetz &amp; Venkatesh, 2020). We have identified two main AI usage domains to structure this broad scope of AI user groups: Expert and non-expert users (Table 2). With this understanding, we define AI users as individuals who use autonomous, self-learning, or inscrutable technology  (i.e.,  AI),  consciously  or  unconsciously,  in  an  expert  or non-expert context to achieve various objectives.

Within  the  non-expert  context,  AI  users  can  also  be  regarded  as ' personal users ' or ' lay users. ' They require AI literacy to use everyday AI tools, such as AI-powered applications on smartphones, self-driving vehicles, and customer service chatbots (Wang et al., 2019). However, it is crucial to acknowledge that AI usage by non-experts increasingly affects  society  as  a  whole,  exemplified  by  the  impact  of  AI-powered social media on political processes, such as democratic elections (Fujiwara et al., 2021). The ' Cambridge Analytica Scandal ' recently showed the  critical  influence  of  targeted,  AI-powered  advertising  on  society, exposing the need for AI-literate social media users (Isaak &amp; Hanna, 2018).  Consequently,  non-expert  AI  usage  also  carries  societal  responsibilities for lay users, encompassing all members of society. Within the  non-expert  context,  the  literature  either  focuses  on  students (including children) (e.g., Kandlhofer et al., 2016; Melsi ´ on et al., 2021; Yang,  2022)  or  follows  a  general  approach  (implicitly  focusing  on adults) (e.g., Carolus et al., 2023; Kusuma et al., 2022; Register &amp; Ko, 2020). Therefore, we summarize these as a student and an adult user group, recognizing their differing needs regarding learning methods and AI literacy components as well as the effects AI literacy has on them. Literature focusing on students includes kindergarten and K-12 because integrating  AI  education  into  curricula  is  essential  for  fostering  an AI-literate future generation (e.g., Casal-Otero et al., 2023). As a complement, studies on adults consider the needs of those who have not received an AI education yet or require reskilling (e.g., Long, Blunt, &amp; Magerko, 2021).

Within the expert context, AI users are typically ' domain experts ' in an organization engaging with specialized AI systems tailored to specific

Table 3 Learning methods for AI literacy framework: Formal methods.

| Subtype (1)     | Subtype (2)           | Examples                                                                             | AI specificity                      | Sources (By AI User Group)                                                                                                         |
|-----------------|-----------------------|--------------------------------------------------------------------------------------|-------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|
| Lecture- based  | -                     | Lectures (weekly), research camp (block format)                                      | AI-specific content                 | Students: Kandlhofer et al. (2016), Xu and Babaian (2021)                                                                          |
| Exercise- based | Traditional exercises | In-class exercises, homework assignments, term projects                              | AI-specific content                 | Students: Xu and Babaian (2021)                                                                                                    |
|                 | Interactive exercises | Group projects, flipped classroom, Story-telling about AI                            | AI-specific content                 | Students: Kong et al. (2021)                                                                                                       |
| Artifact- based | Interaction           | Interacting with AI tools, Learning with explainable AI tools                        | AI is part of the learning artifact | Students: Kandlhofer et al. (2016), Khalid et al. (2022), Melsi ´ on et al. (2021), Ng et al. (2022) Adults : Kusuma et al. (2022) |
|                 | Construction          | Training of AI models (software), construction of robots with AI features (hardware) | AI is part of the learning artifact | Students: Kandlhofer et al. (2016), Burgsteiner et al. (2016), Druga et al. (2019) Adults: Chiang and Yin (2022), Ng et al. (2021) |

use  cases.  For  instance,  a  medical  doctor  utilizing  an  AI  system  for cancer detection falls under this category (Jussupow et al., 2021). A comprehensive and parsimonious system organizing the organizational context is the North American Industry Classification System (NAICS, 2023), which facilitates a structured assessment of the existing literature on  different  AI  expert  user  groups.  NAICS  codes  unmatched  by  the literature expose unexplored user groups and will be assessed regarding their  relevancy  for  future  research  directions.  AI  expert  user  groups explored by the literature include, for example, teachers (e.g., Kim &amp; Kwon, 2023), managers (e.g., Jorzik et al., 2023), construction workers (Maitz et al., 2022) or librarians (Cox &amp; Mazumdar, 2022). Overall, AI is increasingly relevant to users in both the non-expert and expert contexts. Understanding and addressing the specific needs of AI users in these diverse domains are essential for promoting effective AI literacy and responsible AI usage across society and the economy.

## 4.2. Learning methods for AI literacy

Due to AI ' s rapid development, it is essential to understand the most effective  learning  methods  for  equipping  different  AI  users  (Long, Padiyath, et al., 2021). Studies covering learning methods for AI literacy constitute a significant part of the current academic discourse (37% of the identified corpus, n = 25). The trend of AI permeating into society can also be observed regarding the variety of learning methods, which already go far beyond traditional classroom settings (e.g., Casal-Otero et al., 2023) and include learning in public places, such as museums (e. g., Long, 2023).

The learning literature distinguishes between two learning types that can purposefully structure the learning methods for AI literacy: formal and informal learning (Folkestad, 2006; Manuti et al., 2015; Steinbauer et al., 2021). Formal learning occurs through structured, planned activities and usually takes place in classroom-based educational settings (Marsick &amp; Watkins, 2001). Often seen as the learning standard paradigm, it follows characteristics such as designated teachers, awarded qualifications,  and  external  outcome  specifications  (Eraut,  2000).  In contrast, informal learning is often referred to as what is not formal learning (Colley et al., 2002). Informal learning frequently becomes part of daily routines and is a rather unconscious process, sometimes subject to  chance  (Marsick &amp; Watkins,  2001).  Furthermore,  it  involves  an inductive  cycle  of  reflection  and  action  and  is  closely  connected  to learning from others (Marsick &amp; Watkins, 2001).

Regarding AI literacy, both types can be observed within the existing literature. A thorough understanding of both is crucial to determine in which context which AI user group can benefit most from which method. Furthermore, developing a toolkit that allows combining methods into tailored  teaching  approaches  will  be  essential  for  AI  learning  (Markauskaite et al., 2022).

## 4.2.1. Formal learning methods for AI literacy

Based  on  the  identified  literature  corpus,  we  structured  formal learning methods for AI literacy into three subtypes: lecture-, exercise-, and artifact-based learning (see Table 3). Especially regarding formal learning  methods,  it  is  important  to  note  that  individual  learning methods can also appear in combination with other learning methods. For example, lectures are often paired with homework assignments at formal educational institutions (e.g., Xu &amp; Babaian, 2021).

Along with early thinking about AI literacy, the literature discussed well-known learning methods, such as traditional lectures in a weekly or block  format  (Kandlhofer  et  al.,  2016;  Xu &amp; Babaian,  2021). Lecture-based learning as a method is not specific to AI. Instead, the content discussed within the respective lectures is specific to the different AI literacy areas. The type of method has predominantly been discussed in a student context (Kandlhofer et al., 2016). The literature divides the exercise-based learning subtype into traditional and interactive exercises (e.g., Khalid et al., 2022; Kong et al., 2021; Xu &amp; Babaian, 2021). These exercises are similar to lecture-based learning methods not specific to AI but can convey AI-specific content that relates to AI ' s learning abilities, increased autonomy, and inscrutability. Traditional exercises achieve this by requiring students to apply AI concepts individually in homework assignments, in-class exercises, or term projects (Xu &amp; Babaian, 2021).  Further  research  conceptualizes  interactive  exercises,  such  as group projects or flipped classrooms, a learning method that places the introduction  of  all  AI  course  materials  outside  of  classes,  using  the available time in class exclusively for inquiry, application, and assessment of learning materials together with the teacher (Kong et al., 2021). Other  studies  use  story-telling exercises to teach  AI  specificities (Kandlhofer et al., 2016; Khalid et al., 2022; Ng et al., 2022). To tell a story that involves AI, learners must understand how an AI might work and  then  organize  and  analyze  their  understanding  to  produce  a narrative  (Ng  et  al.,  2022).  When  building  their  story,  learners  are encouraged  to  assess  how  AI  might  impact  everyday  human  living (Wong et al., 2020).

Unlike these more generic learning methods tailored to AI content, artifact-based learning utilizes AI as part of the learning method. Different studies explored how learners can comprehend AI concepts by interacting with AI-based learning artifacts. Melsi ´ on et al. (2021) investigated how explainable AI models (XAI) can be utilized to convey AI specificities, such as gender biases, by showing learners visualizations during an interaction in which an AI model is trained. Other examples include interactions with an online facial recognition AI that lets users find a look-alike from a database of portraits from the US Civil War (Kusuma  et  al.,  2022).  Kusuma  et  al.  (2022)  create  an  educational interaction by deliberately designing features that provide context about the dataset ' s composition and origins, gradually explaining the steps for the AI predictions, and actively involving the user to speculate about the implications of facial recognition in the real world. Next to pure interaction, many studies also proposed the construction of AI tools (e.g., Chiang &amp; Yin, 2022; Kandlhofer et al., 2016; Steinbauer et al., 2021). Building  on  constructionism  learning  theory  (Papert,  1993),  these methods aim to convey AI literacy by constructing either hardware- or software-related AI tools (Kandlhofer et al., 2016). For example, Chiang and  Yin  (2022)  let  learners  construct  customized  test  datasets  to

Table 4 Learning methods for AI literacy framework: Informal methods.

| Subtype (1)                  | Subtype (2)   | Examples                                                                                           | AI specificity                      | Sources (By AI User Group)                                                                       |
|------------------------------|---------------|----------------------------------------------------------------------------------------------------|-------------------------------------|--------------------------------------------------------------------------------------------------|
| Community-based              | -             | Book club, family learning talk, online community forums                                           | AI-specific content                 | Families: Druga (2023), Long et al. (2022) Adults: Chaudhury et al. (2022), Lee et al. (2022)    |
| Self-directed exercise-based | -             | Mobile learning applications, self-chosen exercises                                                | AI-specific content                 | Adults: Chaudhury et al. (2022), Pinski, Haas, and Franz (2023), (Pinski, Haas, & Benlian, 2024) |
| Self-directed artifact-based | Interaction   | Interactive museum exhibits, interactive home learning artifacts, interaction with online AI tools | AI is part of the learning artifact | Adults: Long et al. (2019, 2021a), Long et al. (2021), Ng et al. (2021)                          |
|                              | Construction  | Development of ' pet projects, ' usage of AI for programming simulations                           | AI is part of the learning artifact | Adults: Chaudhury et al. (2022), Ng et al. (2021)                                                |

evaluate an AI model ' s performance, enabling them to experience how the same model performs on different data sets.

## 4.2.2. Informal learning methods for AI literacy

Based on the identified corpus of literature, we structured informal learning methods for AI literacy into three subtypes: community-based, self-directed  exercise-based,  and  self-directed  artifact-based  learning (see Table 4). These informal learning methods have in common that no instructor is present at the time of learning and that they rely on the learners themselves initiating the learning rather than an educational institution governing the learning. Community-based learning is characterized by a shared learning experience with other learners and an exchange on the topic of AI (Druga, 2023; Lee et al., 2022; Long et al., 2022). These can include face-to-face learning in the form of a book club, which focuses on adults (Lee et al., 2022), or a family learning talk, which focuses on children and adults (Druga, 2023; Long et al., 2022). However, learners can also engage in online communities, such as discussion forums, to expand their AI literacy (Chaudhury et al., 2022). In self-directed  exercise-based  learning ,  learners  seek  exercises  to  further their  AI  literacy.  This  includes  mobile  learning  applications  (Pinski, Haas, &amp; Franz, 2023) or online resources (Chaudhury et al., 2022) built to facilitate  small  exercises  regarding  AI.  Both  community-  and self-directed exercise-based learning are only AI-specific regarding the content taught and have been conceptualized mostly for adults or families (see Table 4).

In contrast, self-directed artifact-based learning often leverages AI as part of the learning artifact to convey AI literacy (e.g., Long, Blunt, &amp; Magerko,  2021).  We  find  that  self-directed  artifact-based  learning methods focused on interaction and construction, similar to the division within formal artifact-based learning methods.  Informal  learning methods focused on artifact interaction are situated in diverse settings, such as museums (Long et al., 2019, 2021a) or at home (Ng et al., 2021). For  instance,  Long,  Blunt,  and  Magerko  (2021)  developed  a  public museum  exhibit  called ' LuminAI ' that  lets  learners  dance  with  an AI-generated projection in order to comprehend how the AI could learn from  the  learners ' movements.  Some  informal  learners  also  aim  to construct an AI themselves to acquire AI literacy in a self-directed way (Chaudhury et al., 2022). Chaudhury et al. (2022) find that a common self-directed  artifact-based  learning  method  is  for  some  informal learners to pursue ' pet projects. ' By creating an AI tool ' as a hobby, ' enabled  through  AI  literacy  acquired  via  an  online  course  or  other self-directed resources, informal learners hope to better understand the topic. However, Carroll and Rosson (1987) point out that self-directed learning can come with drawbacks, like a focus on quick results that might lead to only a superficial grasp of the subject (production bias). Additionally, learners ' prior educational backgrounds play a role in their learning approach, such as favoring math-related AI courses for those with a math background (assimilation bias).

## 4.3. Components of AI literacy

The literature views AI literacy as a holistic concept of human proficiency  regarding  a  specific  type  of  technology  with  the  facets  of autonomy, learning, and inscrutability (see Table 1). A large part of the current academic discourse (68% of the identified corpus, n = 46) focuses on exploring and conceptualizing the components of this holistic proficiency  concept.  When  conceptualizing  AI  literacy  as  a  holistic proficiency  concept,  the  literature  can  be  organized  into  AI  literacy proficiency  dimensions ,  such  as  knowledge,  skill,  or  experience  (e.g., Cheney et al., 1990; Marcolin et al., 2000); and AI literacy subject areas , which relate to the content of the respective proficiency dimension, such as AI models, data for AI, AI tools (e.g., Long &amp; Magerko, 2020). While current conceptualizations identify highly relevant components (Carolus et al., 2023; Laupichler, Aster, Haverkamp, &amp; Raupach, 2023), they do not differentiate between proficiency dimensions and subject areas or focus on particular subject areas, thereby lacking those other researchers identified (i.e., they present a relevant but incomplete picture). Fig. 4 summarizes  the  identified  proficiency  dimensions  and  subject  areas from the literature included in our component conceptualization. Some AI literacy subject areas are more prone to be associated with a certain dimension of proficiency, such as knowledge about AI model types or skills in AI tool recognition. However, there are no ' 1:1 ' relationships, and, in principle, all AI literacy proficiency dimensions can relate to all subject areas. For example, one might have knowledge about how to recognize AI tools and also experience and skill in such recognition. The interconnections between the proficiency dimensions and subject areas in Fig. 4 represent their complex, multilateral relationships.

## 4.3.1. Proficiency dimensions

Accounting for the scope of prior technology literacies (sec. 2.2) and

Fig. 4. AI literacy component framework.

<!-- image -->

the different definitions of AI literacy in the literature (see Table 1), we find  that  AI  literacy  as  a  holistic  and  enabling  construct  comprises different human proficiency dimensions. In the following, we will review the proficiency dimensions that the literature has attributed to AI literacy and what the characteristics of these proficiencies are. Despite some  of  the  existing  literature  using  these  proficiency  dimensions inconsistently, we aim to adhere to established definitions to structure the proficiency dimension discussed in the current literature.

Knowledge is a core proficiency dimension of AI literacy (Dai et al., 2020; Deuze &amp; Beckett, 2022). It encompasses an understanding of the content and information concerning a subject area. Usually, it is obtained via studying in formal education (Cheney et al., 1990). Multiple studies include Awareness as a distinct proficiency dimension (Deuze &amp; Beckett, 2022; Heyder &amp; Posegga, 2021; Lee et al., 2021). Awareness also includes an understanding of a particular topic but is more focused on the acknowledgment of its existence and relevance at the given time (Merriam-Webster,  2023). Skills are  integral  to  effective  AI  literacy, encompassing psychomotor processes and the ability to execute specific tasks with precision (Cheney et al., 1990; Markauskaite et al., 2022). They also include the capacity to choose the actions most suited for a given  scenario  from  a  repertoire  of  available  actions  (Cheney  et  al., 1990). Skills are considered part of AI literacy, primarily for working with AI tools in human-AI collaborations (Dai et al., 2020; Pinski &amp; Benlian,  2023).  Most  AI  definitions  draw  on  the  term Competence or Competencies , synonymous with ability (Carolus et al., 2023; Laupichler, Aster, &amp; Raupach, 2023; Long &amp; Magerko, 2020; Ng et al., 2021). The OECD (2019, p. 98) views competence as applying knowledge and skills, referring to ' the application and use of knowledge and skills in common life  situations. ' Leidig  and  Salmela  (2020,  p.  35)  echo  this  notion, stating that such a definition of competence acknowledges ' cognitive and metacognitive skills, demonstrated use of knowledge and applied skills, and interpersonal skills that often work in concert. ' Last, Pinski and Benlian (2023) attribute Experience in interaction with AI tools to AI literacy.  By  interacting  with  AI  tools  one  learns ' hands  on. ' Thus, experience  often  leads  to  the  buildup  of  tacit  knowledge  which,  as opposed  to  explicit  knowledge,  cannot  be  codified  (Bassellier  et  al., 2015).

In conclusion, AI literacy emerges as a multifaceted construct that encompasses  the  proficiency  dimensions  of  knowledge,  awareness, skills,  competencies,  and  experience.  These  proficiency  dimensions collectively contribute to the enabling and human-focused AI literacy construct.

## 4.3.2. Subject areas

The majority of the current literature on AI literacy is concerned with identifying different AI literacy subject areas. AI literacy subject areas denote the content of specific proficiency dimensions, such as knowledge about different AI models. To provide a comprehensive account of the AI literacy subject areas assessed so far, we based our AI literacy subject area conceptualization on a bottom-up assessment of the identified literature corpus. We validated our bottom-up AI literacy subject area  conceptualization  by  assessing  related  concepts,  such  as  the ' Competency Model for Undergraduate Programs in Information Systems ' jointly published by the ACM and AIS to unify wording and ensure compatibility (Leidig &amp; Salmela, 2020).

As  a  result,  we  conceptualized  five  core  AI  literacy  areas  ( ' AI Models, '  ' Data for AI, '  ' AI Interfaces, '  ' AI Tools, '  ' Humans, Organizations, and Society ' ) as well as one ' Cross Area, ' referring to secondlevel literacy in an AI literacy subject area framework (see Fig. 5 for an overview, Table 5 for the detailed account). Research investigating the interaction of humans and technology looks into their social aspects (i.e., relating to the involved humans) as well as their technical aspects (i.e., relating to the involved technology). However, different aspects do not belong strictly to either side; rather, they fall along a socio-technical continuum (Bostrom et al., 2014; Sarker et al., 2019). The five core subject areas can be organized along this socio-technical continuum, addressing  proficiency  in  different  subject  areas  of  the  discipline. Whereas AI Models and Data for AI are rather technical AI literacy areas, AI Interfaces connect this AI technology to humans. AI-based AI Tools instantiate AI as technology in a social context, while Humans, Organizations, and Society refer to literacy regarding the social context of AI. The Cross Area relates to each core area and involves second-level content, such as knowledge about ethics, which can relate to AI Models but also to Data for AI and every other core area. In the following, we review the current literature within each of the six conceptualized AI literacy subject  core  areas,  including  its  subareas.  Moreover,  we  assess  the subareas ' AI-specificity  as  well  as  the  user  groups  that  have  been covered in each subarea.

Fig. 5. AI literacy subject area framework (overview).

<!-- image -->

Table 5

AI literacy subject areas.

| Area          | Subarea                        | Description                                                                                                                                                                                                                                         | AI Specificity                                                                                                                                               | Sources by AI User Group                                                                                                                                                                                                                                                                                                                                                           |
|---------------|--------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| AI Models     | Computer Science Prerequisites | Essential concepts, including abstraction, programmability, algorithmic thinking, basic statistics, and IT infrastructure needed for AI comprehension.                                                                                              | Not AI-specific: However, crucial to comprehend AI specificities.                                                                                            | Students: (Kandlhofer et al., 2016; Khalid et al., 2022; Liu & Xie, 2021; Xu & Babaian, 2021); Adults: (Laupichler, Aster, & Raupach, 2023; Long, Padiyath, et al., 2021; Long & Magerko, 2020; Ng et al., 2021); Medical doctors: (Charow et al., 2021; Wiljer & Hakim, 2019); Workers in general: (Salazar-Gomez et al., 2022)                                                   |
|               | Fundamentals                   | Understanding the nature of various forms of intelligence (human, animal, machine); differentiating AI from non-AI technology; grasping how AI functions, makes decisions, represents knowledge; and acknowledging AI ' s strengths and weaknesses. | AI-specific: Content describes the differences between non-AI and AI models.                                                                                 | Students: (Kandlhofer et al., 2016; Khalid et al., 2022; Lee et al., 2021; Ng et al., 2022; Xu & Babaian, 2021); Adults: ( Carolus et al., 2023; Laupichler et al., 2022, 2023b; Long et al., 2021a, 2021b; Long & Magerko, 2020); Managers : (Jorzik et al., 2023); Medical doctors: (Charow et al., 2021); Teachers: (Lee et al., 2022); Workers in general: (Cetindamar et al., |
|               | Types                          | Understanding the differences between machine learning, deep learning, explainable AI (XAI), and generative AI models, among others, as manifestations of AI concepts and knowledge representations.                                                | AI-specific: Content describes the degree of inscrutability, learning, and autonomy of different AI models.                                                  | 2022; Salazar-Gomez et al., 2022) Students: (Kandlhofer et al., 2016; Khalid et al., 2022; Su et al., 2023; Xu & Babaian, 2021; Yang, 2022); Adults: (Chiang & Yin, 2022; Laupichler, Aster, & Raupach, 2023; Long et al., 2021a, 2021b; Long & Magerko, 2020); Teachers: (Lee et al., 2022)                                                                                       |
|               | Development                    | While not mandatory for AI users, appreciating how AI models are constructed provides a deeper comprehension; it is deemed valuable for specific user groups and applications but not essential for all.                                            | AI-specific: Content describes steps involved in developing AI models.                                                                                       | Adults: (Carolus et al., 2023)                                                                                                                                                                                                                                                                                                                                                     |
| Data for AI   | Fundamentals                   | Understanding of data structures, data sanitization, and the significance of data for various AI technologies, including the connection between input data and AI model predictions.                                                                | AI-specific: Content describes how the relationship between data and technology changes through AI; significance of existing processes increased through AI. | Adults: (Chiang & Yin, 2022; Kusuma et al., 2022; Laupichler, Aster, & Raupach, 2023; Long, Blunt, & Magerko, 2021; Long & Magerko, 2020; Schneider et al., 2023); Medical doctors: (Charow et al., 2021); Teachers: (Olari & Romeike, 2021); Workers in general: (Cetindamar et al.,                                                                                              |
|               | Governance                     | Understanding of control and authority over data management.                                                                                                                                                                                        | Not AI-specific : However, increased relevance through AI due to increased amounts of data.                                                                  | 2022) Medical doctors: (Wiljer & Hakim, 2019); Workers in general: (Salazar-Gomez et al., 2022)                                                                                                                                                                                                                                                                                    |
|               | Interpretation                 | The ability to appropriately interpret output data from AI systems, recognize potential                                                                                                                                                             | Not AI-specific : However, increased relevance through AI due to more potential biases.                                                                      | Students: (Melsi ´ on et al., 2021); Adults: ( Chiang & Yin, 2022; Long, Padiyath, et al., 2021; Long & Magerko, 2020)                                                                                                                                                                                                                                                             |
|               | Visualization                  | biases, and understand that output data. An understanding of how to visualize complex AI-generated results to comprehend and effectively utilize the outcomes of AI technologies.                                                                   | Not AI-specific : However, increased relevance through AI due to increasingly more complex results to be understood and communicated.                        | Students: (Kandlhofer et al., 2016); Medical doctors: (Charow et al., 2021; Wiljer & Hakim, 2019); Workers in general: (                                                                                                                                                                                                                                                           |
| AI Interfaces | Fundamentals                   | Comprehending how AI technologies interact with the physical world and environment, including distinguishing between the AI model (software) and its physical interfaces (hardware) to understand their connection to                               | AI-specific : Content describes how AI interfaces can differ from non-AI interfaces, e.g., through natural communication like voice.                         | Salazar-Gomez et al., 2022) Students: (Khalid et al., 2022; Xu & Babaian, 2021); Adults: (Long & Magerko, 2020); Workers in general: (Salazar-Gomez et al., 2022)                                                                                                                                                                                                                  |
|               | Types                          | Users need to understand the range of AI interface types, including sensors and software interfaces, to recognize how AI technologies interact with the world and                                                                                   | AI-specific : Content describes how AI interfaces differ from each other.                                                                                    | Adults: (Long, Blunt, & Magerko, 2021; Long & Magerko, 2020; Ng et al., 2021); Teachers: (Lee et al., 2022)                                                                                                                                                                                                                                                                        |
| AI Tools      | Fundamentals                   | receive input from users. Understanding the instantiation of AI models in specific (social) contexts in the form of AI tools and assessing which human problems                                                                                     | AI-specific: Content describes fundamentals of AI tools having the facets of inscrutability, learning, and autonomy.                                         | Students: (Kandlhofer et al., 2016; Kong et al., 2021); Adults: (Laupichler, Aster, & Raupach, 2023); Medical doctors: (Charow et al., 2021)                                                                                                                                                                                                                                       |
|               | Recognition                    | can be addressed with specific AI tools. Being able to identify where AI tools are used and to recognize them during interaction as they increasingly imitate humans and                                                                            | AI-specific: Content describes how AI tools are potentially more difficult to recognize because they are more                                                | Students: (Ali, DiPaola, Lee, Sindato, et al., 2021); Adults: (Laupichler, Aster, & Raupach, 2023; Long, Blunt, & Magerko, 2021; Long & Magerko, 2020)                                                                                                                                                                                                                             |
|               | Handling                       | interact through natural communication. Efficiently handling AI tools includes, among others, understanding the tools ' function range and managing privacy during interactions.                                                                    | autonomous than non-AI. AI-specific: Content describes how to handle AI tools that are autonomous, can learn, or are inscrutable.                            | Students: (Ng et al., 2022); Adults: (Carolus et al., 2023; Laupichler, Aster, & Raupach, 2023); Managers: (Jorzik et al., 2023); Workers in general: (Cetindamar et al., 2022; Salazar-Gomez et al., 2022)                                                                                                                                                                        |

( continued on next page )

Table 5 ( continued )

| Area                               | Subarea                                  | Description                                                                                                                                                                                                                                                          | AI Specificity                                                                                                                                          | Sources by AI User Group                                                                                                                                                                                                                                                         |
|------------------------------------|------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Humans, Organizations, and Society | Human Roles in AI Context                | Understanding the various roles humans play in relation to AI tools, including programmers, data providers, evaluators, and those affected by AI tools, and their influence on AI tool development and implementation.                                               | AI-specific: Content describes roles humans in relation to AI, which have shifted partially due to AI that is autonomous, can learn, or is inscrutable. | Adults: (Laupichler, Aster, & Raupach, 2023; Long, Padiyath, et al., 2021; Long & Magerko, 2020); Workers in general: ( Cetindamar et al., 2022)                                                                                                                                 |
|                                    | Human Interactions in AI Context         | Collaborating and communicating with other human stakeholders involved in AI projects, teaching and explaining AI concepts to various stakeholders, and managing the impacts of AI interactions.                                                                     | AI-specific: Content describes how interactions with other human stakeholders are altered due to AI ' s inscrutability, learning, and autonomy.         | Students: (Liu & Xie, 2021); Adults: ( Carolus et al., 2023); Journalists: (Deuze & Beckett, 2022); Medical doctors: (Charow et al., 2021)                                                                                                                                       |
|                                    | Organizational Management of AI          | Effectively managing AI tools within organizations, including understanding their impact on processes, developing AI strategies, anticipating economic and legal implications, identifying opportunities, and recognizing potential impacts on organization members. | AI-specific: Content describes how organizations are impacted differently by AI ' s inscrutability, learning, and autonomy.                             | Students: (Kandlhofer et al., 2016); Adults: ( Laupichler, Aster, & Raupach, 2023); Journalists: (Deuze & Beckett, 2022); Managers: (Jorzik et al., 2023); Medical doctors: (Charow et al., 2021; Wiljer & Hakim, 2019); Workers in general: ( Salazar-Gomez et al., 2022)       |
|                                    | Current and Future Societal Impact of AI | Comprehending AI ' s societal implications enables citizens to be aware of AI ' s influence on democratic societies, anticipate future impacts, and engage in informed debates about                                                                                 | AI-specific: Content describes how societies are impacted differently by AI ' s inscrutability, learning, and autonomy.                                 | Students: (Eguchi et al. , 2021) Adults: (Laupichler, Aster, & Raupach, 2023)                                                                                                                                                                                                    |
| Cross Area                         | Ethical Literacy                         | AI technology implementations. Understanding and addressing ethical issues and risks related to AI, such as misinformation, diversity, and employment, across AI models, data, and tool implementation in organizations.                                             | Not AI-specific : However, increased relevance due to the severity of AI ' s impact on ethical matters.                                                 | Students: (Lee et al., 2021; Melsi ´ on et al., 2021; Su et al., 2023; Xu & Babaian, 2021); Adults: (Laupichler, Aster, & Raupach, 2023; Long & Magerko, 2020; Markauskaite et al., 2022; Ng et al., 2021); Medical doctors: (Charow et al., 2021); Teachers: (Lee et al., 2022) |
|                                    | Critical Literacy                        | Ability to critically assess all core areas, such as AI models, tool outputs, usage needs, and the impact of AI tools.                                                                                                                                               | Not AI-specific : However, increased relevance due to AI ' s complexity.                                                                                | Adults: (Carolus et al., 2023; Laupichler et al., 2022, 2023b; Register & Ko, 2020); Medical doctors: (Charow et al., 2021);                                                                                                                                                     |
|                                    | Meta Literacy                            | Being aware of one ' s own AI literacy level.                                                                                                                                                                                                                        | Not AI-specific : However, increased relevance due to AI ' s increasing human-like capabilities.                                                        | Adults: (Chaudhury et al., 2022; Fügener et al., 2021)                                                                                                                                                                                                                           |
|                                    | Future Literacy                          | Recognizing the dynamic evolution of AI and envisioning its future impact on AI literacy requirements as well as cultivating the learning skills to adapt to these requirements.                                                                                     | Not AI-specific : However, increased relevance due to AI ' s rate of change.                                                                            | Students: (Lee et al., 2021); Adults: (Long & Magerko, 2020; Markauskaite et al., 2022; Ng et al., 2021); Workers in general: ( Cetindamar et al., 2022)                                                                                                                         |

The conceptualized AI literacy subject area framework has several applications. First, it describes the breadth of AI literacy subject areas and their relationship to each other (i.e., cross vs. core areas). Furthermore,  it  provides  a  blueprint  to  define  user-specific  AI  literacy  requirements profiles. Different users necessitate different depths along the subject area dimensions.

Core Area 1: AI models. Different studies emphasize that a certain extent of computer science prerequisites is  necessary to comprehend AI models (e.g., Khalid et al., 2022; Laupichler, Aster, &amp; Raupach, 2023; Salazar-Gomez  et al., 2022). While  these fundamentals  are not AI-specific, the literature seems to view them as a crucial overlap, which led  us  to  include  them  in  the  conceptualization.  As  such,  different studies include core computer  science concepts like abstraction (Kandlhofer et al., 2016) or programmability (Long &amp; Magerko, 2020), algorithmic  and  computational  thinking  (Khalid  et  al.,  2022;  Long, Padiyath, et al., 2021), Long, Padiyath, et al., 2021asic statistics (Wiljer &amp; Hakim, 2019; Xu &amp; Babaian, 2021), and basics regarding IT infrastructure necessary for AI (Salazar-Gomez et al., 2022). Most computer science  fundamentals  are  not  user  group  specific,  i.e.,  relevant  for everyone aiming to develop AI literacy. Individual studies emphasize the special significance of various topics for particular user groups, such as biomedical-specific  computer  science  concepts  for  healthcare  professionals (Charow et al., 2021).

AI  model  fundamentals constitute  the  essential  subarea  for  understanding how AI models work. In this regard, learners must understand the notions of (artificial) intelligence of various ' intelligent ' entities, including an understanding of the distinctions between human, animal, and  machine  intelligence  (Long,  Blunt, &amp; Magerko,  2021;  Long &amp;

Magerko, 2020). Furthermore, it entails distinguishing AI from non-AI technology (Lee et al.,  2021)  as  well  as ' general ' from ' narrow ' AI concepts (Laupichler, Aster, &amp; Raupach, 2023; Long &amp; Magerko, 2020). Next to AI concepts, AI model fundamentals include understanding how AI -in principle -functions (Carolus et al., 2023; Ng et al., 2021) and derives  decisions  (Kandlhofer  et  al.,  2016;  Long &amp; Magerko,  2020). Learners should comprehend what it means when a model learns (Laupichler, Aster, &amp; Raupach, 2023) and how they respond to the environment  (Carolus  et  al.,  2023).  AI  model  fundamentals  also  include recognizing how knowledge is represented within an AI and what limitations these knowledge representations have (Long, Padiyath, et al., 2021;  Xu &amp; Babaian,  2021).  Lastly,  the  literature  asserts  that  it  is fundamental  for  AI  models  to  understand  their  strengths  and  weaknesses, like greater accuracy than non-AI models, the ability to process unstructured  data,  or  AI ' s  inscrutability  (Charow  et  al.,  2021;  Laupichler, Aster, &amp; Raupach, 2023).

Beyond a fundamental comprehension of AI models, AI users must also understand how these intelligence concepts, decision-making processes,  or  knowledge  representation  materialize  in  specific AI  model types. The  literature  emphasizes  the  relevance  of  machine  learning (Chiang &amp; Yin, 2022; Khalid et al., 2022) and deep learning models (Kong et al., 2021; Xu &amp; Babaian, 2021). An example of an AI model leveraging deep learning technology is a neural network (Xu &amp; Babaian, 2021). Furthermore, explainable AI (XAI) models, i.e., AI models that are  inscrutable  but  made  partially  explainable  through  additional technology, are model types discussed by several scholars (Chiang &amp; Yin, 2022; Laupichler, Aster, &amp; Raupach, 2023). More recently, generative AI models, i.e., AI models capable of generating text, images, or

audio,  have  gained  attention  (Lee  et  al.,  2022).  This  subarea  is AI-specific since it equips AI users to understand the degree of inscrutability, learning, and autonomy of different AI models. Even though different AI model types constitute already more advanced AI literacy, the literature agrees that it is relevant for students (Kandlhofer et al., 2016; Khalid et al., 2022) as well as for adult AI users (Chiang &amp; Yin, 2022; Laupichler, Aster, &amp; Raupach, 2023) to build a firm understanding.

AI model development is a counterintuitive subarea in an AI literacy conceptualization focused on AI users. The rationale behind including development as a subarea is that comprehending how things are built enables  a  more  profound  understanding  of  a  specific  topic,  as  also expressed  by  the  artifact-based  construction  learning  methods  for  AI literacy (e.g., Ng et al., 2021). However, AI model development is by no means a requirement for AI users. Carolus et al. (2023, p. 6) state that AI model development is ' useful for certain user groups and application areas but are not necessary for all users. ' AI model development can be seen as AI-specific as it involves building AI models.

Core Area 2: Data for AI . Many extant studies emphasize the relevance of understanding data for AI literacy (Cetindamar et al., 2022; Charow  et  al.,  2021).  While  academics  conceptualized  data  literacy before AI literacy (Wolff et al., 2016), the increased relevance of data for AI compared to non-AI technology closely ties the concepts together, creating overlaps (Olari &amp; Romeike, 2021). As such, the subarea data fundamentals entails basic data knowledge, such as data structures or data  sanitization,  but  also  an  understanding  of  data ' s  meaning  for different  AI  technologies  (Chiang &amp; Yin,  2022;  Laupichler,  Aster, &amp; Raupach, 2023; Long &amp; Magerko, 2020). Most importantly, the literature  emphasizes  understanding  how  input  data  and  predictions  are connected in AI models with learning capabilities (Kusuma et al., 2022; Laupichler, Aster, &amp; Raupach, 2023; Long, Blunt, &amp; Magerko, 2021). In that context, Schneider et al. (2023) note that it is a crucial part of AI literacy  to  understand  the  impact  of  data-sharing  practices,  such  as sharing data, not sharing data, or sharing purposefully biased data, on an AI model. Data in itself is not specific to AI. However, the relationship between data and technology has changed through the introduction of AI because technology can now learn from data and is not dependent on experts codifying how technology should behave. Therefore, non-AI-specific  processes,  like  data  sanitization,  have  received  an elevated significance.

Exercising control and authority over data management is referred to as data governance (Abraham et al., 2019). While it is not AI-specific per se, multiple studies mention its importance for AI literacy (Salazar-Gomez et al., 2022; Wiljer &amp; Hakim, 2019). Since modern AI technologies necessitate enormous amounts of data due to their learning capabilities, managing  these  increasing  data  amounts  becomes  more  relevant. Furthermore, AI can increasingly process unstructured data, which leads to new challenges for data governance processes (Vazhayil et al., 2019). For example, the generative AI ChatGPT has been trained on 300 billion words (Hughes, 2023).

Different studies stress the importance of data interpretation for AI literacy (Chiang &amp; Yin, 2022; Long &amp; Magerko, 2020; Melsi ´ on et al., 2021).  When  working  with  AI,  users  must  be  able  to  appropriately interpret  the  data  an  AI  technology  is  outputting.  That  includes,  for example, recognizing that output data cannot be taken at face value (Long &amp; Magerko, 2020) and being aware of biases or even the ability to detect  potential  biases  (Melsi ´ on et  al.,  2021).  Similar  to  data  governance, data interpretation is not new but has increased significantly in relevance due to AI. Correctly interpreting data is a highly relevant skill due to AI ' s inscrutability.

Since AI technology can be complex and produces counterintuitive results, data visualization is also increasingly important to understand and utilize those results (Kandlhofer et al., 2016; Salazar-Gomez et al., 2022). Users need to be able to understand and present output from AI technologies, for which data visualization is a powerful tool (Charow et al., 2021). However, next to using data effectively for story-telling

(Wiljer &amp; Hakim,  2019),  users  can  also  utilize  data  visualization  to comprehend better how AI technologies are functioning. In the same vein  of  data  governance  and  interpretation,  data  visualization  is  not AI-specific, but its meaning has increased due to more complex underlying models that need to be understood and communicated.

Core Area 3: AI interfaces. Especially, advances in natural language processing  enabled  entirely  new  ways  for  humans  to  interact  with technology,  effectively  removing  the  artificial  interface,  which  was necessary  for  all  non-AI  human-technology  interaction  (Schuetz &amp; Venkatesh, 2020). Therefore, the subarea of AI interface fundamentals comprises a basic understanding of how AI technologies can act in the physical world and interact with their environment (Long &amp; Magerko, 2020). For instance, this includes being able to comprehend the differences between the AI model (i.e., software) and its physical interfaces (i. e., hardware) (Khalid et al., 2022). As such, the subarea represents how the more technological areas of AI Models and Data for AI are connected to humans. While having been explored mostly in the personal domain (Khalid et al., 2022; Xu &amp; Babaian, 2021), the subarea is AI-specific because it highlights how AI interfaces differ from non-AI interfaces.

Furthermore, users need to know which different AI interface types exist. Several studies highlight an understanding of sensors regarding AI (Long, Blunt, &amp; Magerko, 2021; Ng et al., 2021; Pinski &amp; Benlian, 2023). Long and Magerko (2020) assert that it is important to recognize what sensors are, that AI technologies use them to observe the world, and that various  sensors  facilitate  various  forms  of  world  representation  and reasoning. However, understanding AI interfaces extends beyond sensors (Long et al., 2022). Most AI technologies like ChatGPT interact with their  users  through  software interfaces. Therefore,  users must understand  how  different  AI  technologies  receive  input  through  their respective interface types.

Core Area 4: AI tools. With an AI tool (also called ' application ' by some scholars (Kandlhofer et al., 2016)), we refer to the instantiation of an AI model in a specific human context (Long &amp; Magerko, 2020). For example, an AI-based cancer diagnosis tool instantiates the AI model of a neural network in the context of medicine (Tschandl et al., 2020). AI literacy should enable AI users to handle these AI tools proficiently. Such proficient handling requires AI tools fundamentals , providing users with an understanding of the connections between different AI models and common  AI  tools  (Charow  et  al.,  2021;  Kandlhofer  et  al.,  2016). Furthermore,  it  entails  being  able  to  assess  which  human  problem contexts can be addressed with specific AI tools (Laupichler, Aster, &amp; Raupach, 2023) and which application areas exist for AI (Druga et al., 2022).

AI tool recognition has received a special emphasis from academics because AI tools are increasingly capable of imitating humans (e.g., AIbased chatbots) (Adam et al., 2020), and interaction with AI tools is increasingly facilitated via means of natural human communication (e. g., voice-based AI agents) (Carolus et al., 2023). Thus, it has become much more difficult to immediately recognize whether one interacts with  an  AI  tool  or  a  human  (Long &amp; Magerko,  2020).  Therefore, AI-literate  humans  should  have  an  understanding  of  which  tools generally are supported by AI technologies, such as natural language processing, and what to look for to recognize one is interacting with an AI (Laupichler, Aster, &amp; Raupach, 2023). While AI tool recognition is an important area of AI literacy, one should note that AI technologies are becoming increasingly more capable of deceiving humans so that, at some point, even highly AI-literate humans might not be able to detect them anymore. However, similar to deep fakes and misinformation on social media, an awareness of where one might be confronted with AI and how one might spot it is paramount (Ali et al., 2021a, 2021b). AI tool  recognition  is  AI-specific  because  AI  tools  are  potentially  more difficult  to  recognize  due  to  their  increased  autonomy  and  learning ability.

A  central  area  of  AI  literacy  is  efficient AI  tool  handling (Salazar-Gomez et al., 2022; Wang et al., 2022). AI tool handling includes tool-agnostic as well as tool-specific aspects. Independent of the AI tool

one uses, one must manage one ' s own privacy when interacting with the respective AI tool (Carolus et al., 2023; Laupichler, Aster, &amp; Raupach, 2023). Specific to an AI tool, its users need to be aware of the function range and how to operate the AI tool correctly and effectively (Carolus et al., 2023; Salazar-Gomez et al., 2022). For instance, managers need to know how to utilize AI-based decision-support systems (Jorzik et al., 2023). AI tool handling is AI-specific because it is the AI facets (autonomy, learning, and inscrutability) that make handling AI tools different from handling non-AI tools.

Core Area 5: Humans, organizations, and society. Since AI models are instantiated as AI tools in specific human contexts, AI literacy not only  includes  proficiency  regarding  the  isolated  AI  tools  but  also regarding the humans involved. The literature discusses these humanrelated AI literacy subject areas on three different levels: the individual human level (Long &amp; Magerko, 2020), the organizational level, such as firms (Jorzik et al., 2023), and the human society as a whole (Laupichler,  Aster, &amp; Raupach, 2023). First, being aware of the different individual Human roles in the AI context and their respective functions is crucial (Long &amp; Magerko, 2020). For instance, one must acknowledge that humans, in their role as programmers, significantly influence the development  choices,  model  selection,  and  finetuning  of  AI  tools (Cetindamar  et  al.,  2022;  Long &amp; Magerko,  2020).  Beyond  programmers, there are manifold human roles involved when organizations implement AI tools, such as those who provide data for an AI tool (e.g., customers), those who evaluate and approve an AI tool (e.g., managers or government institutions), or those who are replaced by an AI tool (e. g., customer service agents) (Ali, DiPaola, Lee, Sindato, et al., 2021). AI-literates have a comprehensive understanding of the different roles individuals  have  in  relation  to  an  AI  tool  (Pinski,  Adam, &amp; Benlian, 2023). Such an understanding is AI-specific because the human roles in relation to technology have changed due to, for example, the learning capabilities of AI tools.

Next to knowing the human roles in the AI context, a part of AI literacy is proficiency in Human interactions in the AI context. Depending on one ' s  role,  this  can  entail  collaborating  with  other  involved  human stakeholders of an AI project, such as the developers or business counterparts (Charow et al., 2021). Furthermore, it involves communicating about AI tools and their outputs with other stakeholders, such as patients, in the case of medical doctors using AI tools (Carolus et al., 2023; Charow et al., 2021). User groups in the educational sector or leading positions also need the ability to teach and explain AI concepts to other stakeholders (Carolus et al., 2023; Deuze &amp; Beckett, 2022; Liu &amp; Xie, 2021).  The  subarea  is  AI-specific  because  human  interactions  are changed  due  to  AI ' s  facets.  For  example,  a  doctor  might  need  to communicate an AI-based diagnosis differently than a human diagnosis to a patient to get their buy-in for a specific treatment.

Organizational management of AI is required for many AI users who not only use AI tools directly but manage the broader organizational context in which the AI tool is situated. Medical doctors might use AIbased diagnostic tools and must similarly manage their impact on clinical processes (Charow et al., 2021; Wiljer &amp; Hakim, 2019). Corporate executives are urged to develop an AI vision or strategy to successfully implement AI tools in their firms (Jorzik et al., 2023; Salazar-Gomez et al., 2022). Furthermore, executives must anticipate AI ' s economic and legal implications in the organizational context (Charow et al., 2021; Laupichler,  Aster, &amp; Raupach,  2023).  Almost  all  user  groups  would benefit from the ability to identify opportunities that AI enables for their organization  (Deuze &amp; Beckett,  2022;  Pinski,  Hofmann, &amp; Benlian, 2023;  Salazar-Gomez  et  al.,  2022).  Additionally,  many  studies  have shown  how  collaborating  with  AI  can  affect  the  interacting  humans themselves,  such  as  their  cognitive  processes  (Bauer  et  al.,  2021)  or attitudes (Pinski, Adam, &amp; Benlian, 2023). As a result, AI literacy also entails knowledge of the potential impacts that AI tools can have on the members  of  an  organization.  The  subarea  is  AI-specific  because  it highlights how technology that is autonomous, can learn, or is inscrutable affects organizations differently.

On the broadest human scale, the current and future societal impact of AI is part of AI literacy (Laupichler, Aster, &amp; Raupach, 2023). In the role of a citizen of a democratic society, users of AI technology, such as social media networks powered by AI algorithms, must have an awareness of the potential impacts these technologies might have on society (Markauskaite et al., 2022; Ng et al., 2021; Xu &amp; Babaian, 2021). Furthermore, an imaginative ability to project how a society might be impacted in the future can equip citizens to debate how a society might want to (or deliberately not want to) implement specific AI technologies (Long &amp; Magerko, 2020).

Cross areas . Complementary to the five core areas of AI literacy, the literature discusses several proficiencies that can be described as secondlevel  or  cross  areas  because  they  relate  to  each  of  the  core  areas  in distinct ways, such as ethical literacy (e.g., Xu &amp; Babaian, 2021), critical literacy (e.g., Register &amp; Ko, 2020), meta literacy (e.g., Chaudhury et al., 2022), and future literacy (e.g., Lee et al., 2021). Individual academics view some of these areas on the same level as the core areas. However, after assessing the collected corpus of AI literacy literature, we conclude that these cross areas are relevant in relation to each core area. The ethical  literacy cross  area  enables  humans  to  identify,  describe,  and deliberate diverse perspectives on ethical issues and risks around AI, such as misinformation, diversity, or employment (Long &amp; Magerko, 2020; Xu &amp; Babaian, 2021). These issues relate to the core areas, such as the AI models, the data used, or the specific implementation of an AI tool in an organization (Charow et al., 2021; Lee et al., 2021). Markauskaite et al. (2022) state that it will be a critical human task in the future to ensure that we encode human values into the AI tools that we build. As such, ethical thinking will be necessary for each core area leading up to the AI tools we implement and use and, for example, how they integrate into or replace jobs in the current employment landscape. Ethical literacy has also been relevant before AI and is not AI-specific. However, the ethical challenges have multiplied through the introduction of AI due to its increasing scope (Berente et al., 2021), which significantly increased the necessary proficiency in ethical thinking.

Due to AI ' s increasing sphere of influence, critical literacy is a crucial cross area of AI literacy. AI literates should be able to think critically about the AI models (Register &amp; Ko, 2020) and the output of AI tools (Laupichler, Aster, &amp; Raupach, 2023), Laupichler, Aster, &amp; Raupach, 2023valuate their own usage needs and behaviors (Carolus et al., 2023), or  critically  reflect  on  the  impact  of  AI  tools  (Laupichler,  Aster, &amp; Raupach,  2023).  Before  AI,  critical  literacy  has  also  been  relevant. However, due to AI ' s increased complexity and inscrutability, critically assessing the technology and different aspects of human-AI collaborations has become more prominent.

Following the tradition of metaknowledge, meta literacy refers to the awareness of one ' s own AI literacy (Evans &amp; Foster, 2011). Particularly for informal learners, monitoring and reflecting on their AI literacy is important to become AI-literate when engaging in self-directed learning (Chaudhury et al., 2022). Fügener et al. (2021) show that awareness of one ' s own proficiency is crucial in human-AI collaborations. Meta literacy  is  also  not  new,  but  it  has  increased  in  relevance  due  to  AI ' s increasing human-like capabilities, making it more relevant to monitor what one is capable of compared to the technology and what one knows about it (Authors, Forthcoming).

Additionally, scholars assert that one not only needs an awareness of their current AI literacy but also of the needed future (AI) literacy (Lee et al., 2021; Long &amp; Magerko, 2020) . AI is evolving at unprecedented rates  (Berente  et  al.,  2021),  which  also  requires  AI  literacy  to  adapt constantly. Therefore, AI users will need to imagine what the future of AI might look like (Long &amp; Magerko, 2020) and realize what will be relevant to AI literacy (Lee et al., 2021). Furthermore, they must develop the learning skills that allow them to seize this future AI literacy (Cetindamar et al., 2022; Markauskaite et al., 2022). Ng et al. (2021) state that anticipating and realizing future AI literacy requires confidence in one ' s own learning abilities.  Finally,  future  literacy  is  also  not  AI-specific. Nevertheless,  due  to  AI ' s  unprecedented  rate  of  change,  it  gained

significantly in value as part of human technology proficiency.

## 4.4. Effects of AI literacy on AI users

The effects of AI literacy are the least researched area of the three examined steps, with 16% (n = 11) of the reviewed papers addressing them. To structure the explored effects, we draw on a categorization of the effect outcome nature into humanistic and instrumental outcomes introduced  by  Sarker  et  al.  (2019).  Literature  at  the  intersection  of humans and technology emphasizes that socio-technical research should assess  effects  on  humanistic-oriented  outcomes, such as equality and well-being, as well as effects on instrumental-oriented outcomes, such as efficiency and effectiveness (Sarker et al., 2019). On the other hand, AI literacy is often investigated in a context where humans learn, i.e., acquire AI literacy. As such, we also evaluate the so far explored effects along an established framework focused on types of human learning outcome: Kraiger et al. (1993) distinguish the affective, behavioral, and cognitive  effect  types  that  learning  has  on  humans.  By  assessing  the effects  of  AI  literacy  with  these  two  complementary  frameworks, we intend to expose where research has already accumulated and in which dimensions more research is needed (Table 6).

The literature investigated various instrumental effects of AI literacy. AI usage continuance intentions are an AI-specific version of general IS continuance intentions (Bhattacherjee, 2001). The literature presents mixed findings concerning AI literacy and such intentions to continue using AI tools. Pinski, Adam, and Benlian (2023) found a negative association between AI literacy and AI usage continuance intentions after individuals were educated and then interacted with an AI. In another study, Pinski, Haas, and Franz (2023) found a positive association between AI literacy and AI usage continuance intentions after individuals have only been educated on AI.

Looking at the more behavioral-oriented and  closely related  constructs of appropriate delegation behavior towards AI (Pinski, Adam, &amp; Benlian, 2023) and appropriate reliance on AI (Chiang &amp; Yin, 2022), studies identify a positive association with AI literacy. The literature agrees that AI literacy enhances appropriate behavior toward an AI, e.g., to delegate a certain task or to rely on an AI decision when it is favorable to do so (Chiang &amp; Yin, 2022; Pinski, Adam, &amp; Benlian, 2023). Chiang and Yin (2022) qualify this relationship by showing that it is stronger for individuals  with  high  domain  knowledge  of  the  underlying  task. Furthermore, appropriate trust in AI -a rather affective and cognitive construct -has been associated positively with AI literacy (Leichtmann et al., 2023). Surprisingly, the same studies find different results as to how AI literacy materializes in the performance of the underlying task. Whereas Pinski, Adam, and Benlian (2023) and Chiang and Yin (2022)

Table 6 Effects of AI literacy framework.

| Nature of effect   | Affected construct                                                     | Direction         | Human learning outcome type   | Human learning outcome type   | Human learning outcome type   | Sources                                                                                   |
|--------------------|------------------------------------------------------------------------|-------------------|-------------------------------|-------------------------------|-------------------------------|-------------------------------------------------------------------------------------------|
|                    |                                                                        |                   | Affec- tive                   | Behavi- oral                  | Cogni- tive                   |                                                                                           |
| Instrumental       | AI usage continuance intention Appropriate delegation                  | Mixed findings    |                               |                               | ×                             | Adults: Pinski, Adam, and Benlian (2023), Pinski, Haas, and Franz (2023)                  |
|                    | behavior/ reliance                                                     | Increase          |                               | ×                             |                               | Adults: Chiang and Yin (2022), Pinski, Adam, and Benlian (2023)                           |
|                    | Appropriate trust                                                      | Increase          | ×                             |                               | ×                             | Adults: Leichtmann et al. (2023)                                                          |
|                    | Attitude toward AI                                                     | Increase          |                               |                               | ×                             | Adults: Pinski, Haas, and Franz (2023)                                                    |
|                    | Career adaptability skills                                             | Increase          |                               |                               | ×                             | Students: Lee et al. (2021)                                                               |
|                    | Career awareness                                                       | Increase          |                               |                               | ×                             | Students: Lee et al. (2021)                                                               |
|                    | Perceived intelligence                                                 | Mixed findings    |                               |                               | ×                             | Students: Van Brummelen et al. (2021), Druga and Ko (2021)                                |
|                    | Performance in human-AI collaborations                                 | Mixed findings    |                               | ×                             | ×                             | Adults: Chiang and Yin (2022), Leichtmann et al. (2023), Pinski, Adam, and Benlian (2023) |
|                    | Receptivity toward AI                                                  | Decrease          | ×                             |                               | ×                             | Adults: Tully et al. (2023)                                                               |
| Humanistic         | Ability to discern gender bias impact Ability to self-advocate against | Increase Increase |                               |                               | ×                             | Students: Melsi ´ on et al. (2021)                                                        |
|                    | harmful AI                                                             |                   |                               |                               | ×                             | Adults: Register and Ko (2020)                                                            |

find  that  the  overall  performance  of  the  human-AI  collaboration increased with the behavioral change, Leichtmann et al. (2023) found no effect on the performance.

Pinski, Haas, and Franz (2023) find that increasing individuals ' AI literacy in an informal educational setting exhibits an increased (i.e., more positive) attitude toward AI. In contrast, Tully et al. (2023) assert in a survey study across different countries that greater AI literacy leads to  decreased  AI  receptivity  (i.e.,  openness  to  AI-based  products  and services). Regarding the perceived intelligence of AI technology, prior research also presents a mixed picture. Whereas Van Brummelen et al. (2021) found that after learning about AI, perceptions about the intelligence of conversational agents increased, Druga and Ko (2021) found that educational interventions regarding AI can also demystify it and reduce intelligence perceptions. On the other hand, AI literacy has been found  to  increase  career  awareness,  enabling  individuals  to  make informed career choices aligned with the evolving technological landscape  (Lee  et  al.,  2021).  Furthermore,  AI  literacy  enhances  career adaptability  skills,  equipping  individuals  to  navigate  AI-driven  work environments adeptly (Lee et al., 2021).

Humanistic effects have been researched far less than instrumental effects  (Table  6).  Register  and  Ko  (2020)  found  that  AI  literacy  empowers individuals with the proper knowledge to self-advocate against harmful AI, fostering a sense of agency in safeguarding against adverse AI  implications.  Melsi ´ on  et  al.  (2021)  showed  that  individuals  with higher AI literacy possess an increased ability to discern the impact of gender bias, enabling critical evaluation and proactive efforts toward bias mitigation. Overall, the literature tends to support the idea that AI literacy education empowers individuals to achieve humanistic outcomes.

In summary, AI literacy ' s explored instrumental and humanistic effects  are  multifaceted,  spanning  affective,  behavioral,  and  cognitive human learning outcomes. However, we are far from a comprehensive understanding  of  the  effects  of  AI  literacy  that  shape  how  humans navigate the intricate landscape of AI. Past research focused predominantly on instrumental effects that mostly relate to cognitive learning outcomes (Table 6).

## 5. Discussion

In this study, we conducted a scoping review of research on AI Literacy for users. This section outlines a future research agenda offering six future research directions along the three research questions of the study that have not yet been explored but may provide valuable insights into the field. Furthermore, we describe the study ' s contributions and limitations.

Table 7

Future research agenda.

| Type                             | Future research direction   | Future research direction                                                         | Exemplary future research questions                                                                                                                                                                                                                                                               |
|----------------------------------|-----------------------------|-----------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Learning methods for AI literacy | I                           | Include a broader AI user base in the learning method assessment and development. | • Which learning methods are most efficient and effective for workers in transactional relationships with an AI tool to ensure sustainable, efficient, and ethical learning results? • Which learning methods are most successful for workers affected by AI but not directly in contact with AI? |
|                                  | II                          | Evaluate the effectiveness of learning methods concerning AI specificities.       | • Which learning methods are most effective to build a comprehensive awareness of the ethical implications of AI? • What are AI literacy measurement tools that minimize measurement biases?                                                                                                      |
| Components of AI literacy        | III                         | Solidify a specific understanding of what AI literacy constitutes.                | • Which subject areas are essential to gain a specific understanding of AI for using it in the non-expert context? • Which proficiency dimensions of AI literacy are associated with which subject areas most                                                                                     |
|                                  | IV                          | Refine AI literacy needs for diverse AI user groups.                              | • Which technical AI model aspects help adult non-expert users in their AI interactions, and which excessive technicalities hinder overall comprehension? • Which AI literacy proficiency dimensions and areas are relevant for judges?                                                           |
| Effects of AI literacy           | V                           | Explore the humanistic effects of AI literacy.                                    | • How does AI literacy impact the well-being of humans working in human-AI collaborations? • Which AI literacy subject areas have which effect on human well-being in human-AI collaborations?                                                                                                    |
|                                  | VI                          | Consider moderating factors to contextualize AI literacy ' s effects.             | • How does the type of AI affect AI literacy ' s effect on human attitude and receptivity toward AI? • Which moderating factors contribute to AI literacy being positive for humans and which to it being negative?                                                                               |

## 5.1. Future research agenda for AI literacy

By analyzing gaps within the results of  our literature review,  we deducted research directions for each AI literacy step from the conceptual framework (an overview is available in Table 7): Learning methods for AI literacy comprise ' I. Include a broader AI user base in the learning method assessment and development ' and ' II. Evaluate the effectiveness of learning methods concerning AI specificities. ' Components of AI literacy comprise ' III. Solidify a specific understanding of what AI literacy constitutes ' and ' IV. Refine AI literacy needs for diverse AI user groups. ' Lastly, the effects of AI literacy comprise ' V. Explore the humanistic effects of AI literacy ' and ' VI. Consider moderating factors to contextualize AI literacy ' s effects. ' The future research agenda based on these six  future  research  directions  is  by  no  means  exhaustive but  aims  to highlight and demonstrate avenues that look particularly promising to steer the future discourse toward exploring the relevant aspects of AI literacy more specifically.

## 5.1.1. Directions for the learning methods for AI literacy

5.1.1.1. Research direction I. Include a broader AI user base in the development and assessment of learning methods. Research regarding learning methods has been exclusively focused on non-expert AI users, such as K12  students  (e.g.,  Kandlhofer  et  al.,  2016),  adults  in  their  personal (non-work-related) roles (e.g., Kusuma et al., 2022), or families (Druga, 2023). While these user groups are a viable starting point, the literature agrees that AI literacy also needs to be explored for expert AI user groups (e.g., Jorzik et al., 2023; Yang et al., 2021). As such, learning methods to acquire AI literacy must be considered for adults beyond personal roles (e.g.,  Pinski,  Haas, &amp; Franz, 2023) and include expert roles. The requirements  for  effective  learning  might  differ  substantially  for  individuals in their work-related compared to their personal AI user roles. After  assessing  the  existing  research  regarding  the  respective  user groups they address, we can determine which user groups have been omitted  thus  far  and  which  are  particularly  promising  for  future research  in  the  different  steps  of  AI  literacy.  Therefore,  Appendix  C (Table 9) gives an overview of the AI user groups covered and omitted by the literature in the expert context.

For  example,  organizations  may  implement  role-specific  learning objectives that differ from personal learning objectives because they are much more focused on the proper execution of a particular task rather than a broad consumer-centric understanding. Learning focused on taskspecific execution might draw on a specific set of methods to achieve its learning goals. For example, customer service agents utilizing a new knowledge  management  tool  drawing  on  a  large  language  model  to retrieve information for answering customer requests might be better suited to learn through highly practically oriented training exercises. However, it is unclear how much this prepares them to use the tools responsibly.  Therefore,  it  may  be  interesting  to  see  how  learning methods can be combined to convey an ethical understanding of large language models while ensuring task-specific AI proficiency. As such, one potential research question could be, ' Which learning methods are most efficient and effective for workers in transactional relationships with  an  AI  tool  to  ensure  sustainable,  efficient,  and  ethical  learning results? '

Furthermore, there are many user groups concerning workers who might be affected by AI but who will not work directly with the AI or have  no  influence  over  it,  such  as  workers  from  the  transportation sector, like taxi and Uber drivers. This direction prompts the exploration of  effective  learning  methods  for  workers  who  may  not  be  directly involved with AI but are impacted by its influence. It might be interesting to investigate how AI literacy can be best conveyed if workers do not directly use AI in their work. As such, another potential research question  could  be, ' Which  learning  methods  are  most  effective  for workers affected by AI but not directly in contact with AI? '

5.1.1.2. Research  direction II. Evaluate the effectiveness of learning methods concerning AI specificities. Much prior research concerning the learning  methods  for  AI  literacy  has  explored  which  methods  are available to learners, such as mobile apps (Pinski, Haas, &amp; Franz, 2023). However, few studies measure the effectiveness of the learning methods they focus on, while even fewer studies specifically address how they are suitable  to  convey  AI  specificities.  On  the  one  hand,  we  urge  future research to develop different instruments to evaluate the effectiveness of learning methods. The literature has produced various self-assessment (Likert-type)  scales  (e.g.,  Laupichler,  Aster, &amp; Raupach, 2023; Wang et  al.,  2022),  which  are  subject  to  known  biases  in  knowledge self-assessment  like  the  Dunning-Kruger  effect  (Kruger &amp; Dunning, 1999). There are initial developments toward objective measurements, such as a multiple-choice test (Weber et al., 2023). However, we urge researchers to develop more diverse instruments to evaluate the effectiveness  of  learning  methods.  For  example,  one  could  aim  for  a behavior-based  measurement  of  AI  literacy  or  other  innovative  test formats. As such, a potential research question could be, ' What are AI literacy measurement tools that minimize measurement biases? '

On the other hand, research regarding AI literacy learning methods must aim to focus on AI specificities. Therefore, future research should assess which learning methods or combination of learning methods are

particularly  suited  for  comprehending  the  autonomy,  learning,  and inscrutability  particularities  of  AI  technology  as  well  as  their  consequences. For example, government-related user groups, such as policymakers or judges, which have not been explored so far (see Appendix C, Table 9), should specifically ensure that AI complies with the values of a society (Markauskaite et al., 2022). As such, they necessitate an education  geared  toward  identifying  the  potential  implications  resulting from AI ' s specific characteristics and their impact on the ethical standards of a society. This poses potential research questions like, ' Which learning  methods  are  most  effective  for  building  a  comprehensive awareness of the ethical implications of AI? ' .

## 5.1.2. Directions for the components of AI literacy

5.1.2.1. Research direction III. Solidify a specific understanding of what AI literacy constitutes. This review pointed out that AI literacy is a holistic proficiency  concept  comprising  different  proficiency  dimensions  and subject  areas.  We  found  that  many  studies  address  individual  proficiency dimensions (e.g., ' set of competencies ' : Long &amp; Magerko, 2020) or assume an understanding of literacy without explaining it. Furthermore, we found that many subject areas frequently discussed in AI literacy literature, such as data visualization, are not specific to AI (e.g., Kandlhofer et al., 2016). However, many of these subject areas have an increased or shifted relevance due to the introduction of AI, for example, ethical literacy (e.g., Lee et al., 2021) (see Table 5). In pursuit of solidifying a specific understanding of what AI literacy constitutes, it is imperative for future research to use  nuanced  approaches that acknowledge different proficiency dimensions and draw on a subject area understanding that acknowledges AI specificities. Therefore, this direction  seeks  to  pinpoint  the  AI-specific  facets  of  AI  literacy  and distinguish it from other literacy concepts, such as digital or media literacy, more clearly in the future.

Future  research  could,  for  example,  ask, ' Which  proficiency  dimensions of AI literacy are associated with which subject areas most commonly? ' Such a research inquiry would enhance our understanding of AI literacy as a holistic proficiency construct and add valuable insight to the conceptualization as well as how to teach different subject areas. On the other hand, future studies could further explore the differences between AI-specific and non-AI-specific subject areas of AI literacy. One could ask, ' Which subject areas are essential to gain a specific understanding of AI for using it in the non-expert context? ' or ' In how far does AI literacy build on related literacy concepts, such as digital literacy? ' Such inquiries could yield valuable information on the prerequisites for an  AI-specific  understanding.  In  other  words,  future  research  could explore  what  one  needs  to  know  about  non-AI  to  comprehend  AI appropriately.

Research Direction IV. Refine AI literacy needs for diverse AI user groups.

Prior AI literacy research identified AI literacy needs (i.e., required AI literacy proficiency dimensions and subject areas) for different AI user groups, such as medical doctors (Charow et al., 2021) and journalists (Deuze &amp; Beckett, 2022). However, there is a need for further refinement of the specific AI literacy needs of different AI user groups. Studies on individual AI user groups emerged in the constituting phase of AI literacy. As such, they partially draw on incomplete conceptualizations  of  AI  literacy.  Based  on  more  comprehensive  and  AI-specific conceptualizations, we urge future research to refine our thinking on who needs which areas of AI literacy and to what specific depth. The necessary and optimal depth of each AI literacy area (see Table 5) will vary for each user group. Future research could aim to understand better the  optimal  depth  of  rather  technical  AI  literacy  areas,  such  as  AI models, for adult lay users. One could ask, ' Which technical AI model aspects help adult non-expert users in their AI interactions, and which excessive technicalities hinder overall comprehension? '

Furthermore, there are relevant AI user groups that have not yet been explored regarding their AI literacy needs (see Appendix C, Table 9). Complementary to the questions posed in research direction I concerning  learning  methods  for  unexplored  AI  user  groups,  the  AI  literacy needs for these unexplored groups also need to be considered. Omitted but  highly  relevant  user  groups  in  the  AI  context  include  judges, bankers,  or  recruiters,  among  others  (see  Appendix  C,  Table  9).  For example, it  is  crucial  to  identify  which  AI  literacy  needs  judges  and policymakers have before considering how to convey them. As such, one could seek to answer, ' Which AI literacy proficiency dimensions and areas are relevant for judges? '

## 5.1.3. Directions for the effects of AI literacy

5.1.3.1. Research direction  V.  Explore  the  humanistic  effects  of  AI  literacy. When assessing the current research landscape concerning the effects of AI literacy, one notes a strong emphasis on instrumental effects, such  as  appropriate  delegation  (Pinski,  Adam, &amp; Benlian,  2023)  or performance (Chiang &amp; Yin, 2022). However, research urges to explore a socio-technical phenomenon like AI with both an instrumental and a humanistic lens (Sarker et al., 2019). Individual studies looked at highly relevant humanistic outcomes, such as the ability to discern gender bias (Melsi ´ on et al., 2021) or the ability to self-advocate against harmful AI (Register &amp; Ko, 2020). However, there are many more humanistic outcomes that  future  research  should  explore.  Specifically  concerning  a technology like AI, with the potential to adversely impact human life, we urge future research to explore more diverse effects of AI literacy. We need  to  understand  better  which  humanistic  goals  can  be  achieved through  AI  literacy  and  where  we  need  further  measures,  such  as regulation. For instance, one could ask, ' How does AI literacy impact the well-being of humans working in human-AI collaborations? '

In that vein, one could also aim to dissect the impact of individual AI literacy subject areas on such humanistic outcomes. A more granular view of the effects of specific AI literacy areas could then, in turn, inform improved  user-specific  AI  literacy  conceptualizations.  One  could  hypothesize that technical knowledge  about  AI  functionality takes discomfort  about  AI  away  by  demystifying  it.  However,  technical knowledge might also confuse unknowledgeable users more and thus amplify discomfort toward AI. As such, future research could investigate, ' Which AI literacy subject areas have which effect on human wellbeing in human-AI collaborations? '

5.1.3.2. Research  direction  VI.  Consider  moderating  factors  to  contextualize AI literacy ' s effects. Research investigating the effects of AI literacy has so far predominantly focused on the direct effect of possessing or increasing  AI  literacy  on  different  outcomes.  Some  studies  seem  to collectively  confirm  an  underlying  relationship,  such  as  AI  literacy ' s positive influence on appropriate delegation behavior (Pinski, Adam, &amp; Benlian,  2023),  appropriate  reliance  (Leichtmann  et  al.,  2023),  and appropriate trust (Chiang &amp; Yin, 2022), which all support that AI literacy has positive effects for human-AI collaboration. However, other AI literacy effects are not that clear. For example, whereas Pinski, Haas, and Franz (2023) find that AI literacy leads to a more positive attitude toward AI, Tully et al. (2023) find that AI literacy decreases AI receptivity. One might argue that attitude toward AI and AI receptivity are related  constructs,  which  poses  the  question  of  why  the  effects  are opposed to each other. What might explain this puzzle are moderating factors that modify AI literacy ' s effect on affective outcomes, such as the type of AI or the setting in which the participants have been asked. Therefore, we call for future research to identify moderating factors that can increase our understanding of the effects of AI literacy. Also, the findings on AI usage continuance intentions (Pinski et al., 2023a, 2023b) and on performance in human-AI collaborations are mixed (Chiang &amp; Yin, 2022; Leichtmann et al., 2023), i.e., they do not point in the same direction. Therefore, future studies could ask, ' How does the type of AI affect AI literacy ' s effect on human attitude and receptivity toward AI? '

Moreover, there is a general notion in the AI literacy literature that AI literacy is positive for humans. While most effects of AI literacy also seem to support this (see Table 6), there are scenarios imaginable where AI literacy might not be positive. For example, if one belongs to a minority  suffering  from  different  biases  in  the  real  world,  some  might perceive learning about technologies that reinforce these biases as not liberating  but  as  increasing  feelings  of  repression.  As  such,  future research  could  also  ask, ' Which moderating factors  contribute  to  AI literacy being positive for humans and which to it being negative? '

## 5.2. Contributions to research and practice

In this study, we conducted a systematic, scoping literature review to assess the research landscape on AI literacy for AI users with respect to the learning methods for AI literacy, the components of AI literacy, and the effects of AI literacy. Based on our review and assessment of the literature, this study makes the following contributions to AI literacy literature:

First, AI literacy as a research field emerged only recently. However, the field has matured significantly in recent years and produced a variety of new studies. Prior research often focused on the components of AI literacy (e.g., Long &amp; Magerko, 2020). We depart from this approach and  comprehensively  summarize  and  structure  the  existing  research along the three most discussed topics: learning methods, components, and effects of AI literacy. Thereby, we develop an overarching conceptual framework comprising additional detailed conceptualizations for each  relevant  AI  literacy  aspect.  To  our  knowledge,  no  reviews regarding learning methods and the effects of AI literacy are available in the literature. As such, we extend the conceptual understanding of AI literacy by structuring the currently fragmented discourse.

Second,  based  on  our  comprehensive  review,  we  contribute  a research agenda to determine the most promising research opportunities for advancing AI literacy. Along the three core components of the presented framework, we deduce six concrete research directions.

Third,  many  studies  focus  on  individual  AI  user  groups,  such  as medical doctors (Charow et al., 2021) or teachers (Kim &amp; Kwon, 2023). While  important  groups  have  been  covered  regarding  some  aspects, many  relevant  user  groups  have  been  omitted  until  now,  and  a comprehensive  overview  has  been  lacking.  Our  study  contributes  a comparative analysis of different AI user groups, shifting the discourse in a more user-group-sensitive direction. Thus, we ensure that studies focused on specific user groups can learn from each other, and we expose unexplored AI user groups.

Fourth, ' AI ' is an elusive term with different definitions that coexist in the literature (e.g., Berente et al., 2021; Duan et al., 2019; Rai et al., 2019). Much prior AI literacy research does not define the term AI before building  AI  literacy  research  on  it.  In  contrast,  recent  IS  research focusing on AI in general aims to specify the term AI more clearly by conceptualizing facets that distinguish AI from non-AI (Berente et al., 2021). We urge AI literacy research to follow suit to promote a more specific discourse. In our literature review, we applied the AI facets of Berente et al. (2021) to scrutinize our findings, in particular the components of AI literacy, regarding their AI specificity. Thus, we challenge undifferentiated thinking on what constitutes AI literacy and contribute a more specific viewpoint, untangling related literacy concepts, such as digital or data literacy, from AI literacy. Overall, one can observe that AI literacy embodies a shift in the human relationship to technology. Many aspects, such as ethics, have also been important for non-AI technology. However, these aspects gain relevance next to technology proficiency due to AI increasingly impacting more parts of human life to a greater extent. Applying this AI lens, we contribute to a more thorough understanding of what AI literacy refers to and how the construct relates to other technology literacies.

Fifth, concerning practice, this review also provides a reference for educators, policymakers, and business decision-makers, who must make critical  decisions  regarding  the  future  standards  of  AI  literacy  in educational institutions, society, and business. For example, educators could leverage the overview of learning methods to assess if their current  classes  are  utilizing  the  most  suitable  learning  method.  Policymakers  can  leverage  the  AI  literacy  component  conceptualization  to assess if their curricula are addressing all relevant parts of AI literacy. Lastly, business decision-makers can draw on the overview of known effects of AI literacy to better judge where and how to implement AI use cases and AI literacy education interventions in their firms.

## 5.3. Limitations

As with any study, our study comes with several limitations. First, we selected  highly  regarded  databases  within  the  information  systems, human-computer interaction, and computer education research fields for our search, as practiced by other literature review studies from the discipline (e.g., Krath et al., 2021). However, our study is limited by the fact  that  we  cannot  include  databases  from  all  scientific  disciplines. Other databases might have included further studies shedding light on AI literacy from the perspective of a different discipline. Second, our study explicitly focused on AI literacy for users and, hence, used the search  terms ' AI  literacy ' and ' artificial  intelligence  literacy ' and assessed the user focus via manual screening. By focusing on the term ' literacy, ' we aimed to capture studies explicitly referring to the holistic human proficiency construct of literacy. However, given that the field of AI literacy is still emerging and the term is not yet commonly defined, other studies might have used other terms to describe the same phenomena.  As  such,  our  study  is  potentially  limited  by  the  employed search terms. Including other terms might have yielded different results. Third, we structured the identified literature using established conceptualizations,  which  we  deem  purposeful  for  the  respective  research stream  of  AI  literacy  (e.g.,  formal  vs.  informal  learning  methods). However, we note that this way of structuring the literature does not represent  the  only  way  that  the  literature  can  be  structured.  Other concepts or hierarchies of the  structuring dimensions  might yield AI literacy conceptualization with different emphases.

## 6. Conclusion

This study examined the current landscape of AI literacy for users, encompassing learning methods, components, and effects. Through a scoping literature review, it developed a comprehensive account of AI user groups, structured different types of learning methods, identified the different proficiency dimensions and subject areas ascribed to AI literacy, and organized the effect of AI literacy on AI users. Furthermore, we scrutinized the different aspects regarding their AI specificity, using AI ' s facets of inscrutability, learning, and autonomy. This study lays the foundation for tailored educational initiatives, informed policymaking, and strategic business decisions as it refines our understanding of AI literacy ' s  specificity.  Furthermore,  we  deducted  a  research  agenda, including  six  future  research  directions.  As  AI ' s  influence  deepens, equipping  individuals  with  the  ability  to  navigate  AI ' s  complexities emerges  as  a  pivotal  undertaking  for  harnessing  AI ' s  transformative potential and ensuring efficient and ethical human-AI collaborations.

## CRediT authorship contribution statement

Marc  Pinski: Conceptualization, Data curation, Investigation, Methodology, Project administration, Validation, Visualization, Writing -original draft, Writing -review &amp; editing. Alexander Benlian: Project administration, Supervision, Writing -review &amp; editing.

## Declaration of generative AI and AI-assisted technologies in the writing process

During the preparation of this work, the author(s) used Grammarly in order to check spelling and grammar. After using this tool/service, the

author(s) reviewed and edited the content as needed and take(s) full responsibility for the content of the publication.

## Declaration of competing interest

The authors declare that they have no known competing financial

## Appendix A. Coding Process

Beyond the metadata of the results (e.g., year of publication, research method), two independent coders coded in a first iteration the AI user groups, the AI literacy research avenues, and different themes they identified within the research avenues (Table 9). After they completed the open coding, they refined the themes within each research avenue via discussion. In a second iteration, the coders coded the papers again based on the discussion results, concretizing the detailed coding scheme within each research direction. After that, they discussed the results and discrepancies again until a consensus was achieved. In coding the AI literacy research avenues (i.e., learning methods for AI literacy, components of AI literacy, effects of AI literacy), we considered the study ' s contributions holistically without focusing on particular keywords. The research avenues do not mutually exclude each other, i.e., we allowed the assignment of studies to multiple research avenues if they contributed significantly to both. We depict the coding scheme in Table 9.

Table 8

Coding Scheme

| Coding category                          | Coding dimension                                                 | Coding values                                                                                                                                                                                                                                                                                                           |
|------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Metadata                                 | Year of publication Paper type Research method                   | Year [2016 - 2023] Conference proceedings, journal article, dissertation Design science research, literature review, experiment, discussion, interview study, case study, observational study, scale development, survey, secondary data analysis, commentary, taxonomy development, conceptual analysis, mixed methods |
| User groups                              | Research discipline User context Expert domain Non-expert domain | Computer education, HCI, information systems, management, medicine, media studies, computer science Expert domain, non-expert domain NAICS codes [10 - 99] Student, Adult                                                                                                                                               |
| Research avenues Learning methods for AI | AI literacy research avenue Type of learning method              | Learning methods for AI literacy, components of AI literacy, effects of AI literacy Formal learning methods, informal learning methods                                                                                                                                                                                  |
| Components of AI literacy                | Subject areas                                                    | See Table 5 for areas and subareas                                                                                                                                                                                                                                                                                      |
| Effects of AI Literacy                   | Nature of effect                                                 | Humanistic, instrumental                                                                                                                                                                                                                                                                                                |

## Appendix B. Selection Summary

interests or personal relationships that could have appeared to influence the work reported in this paper.

## Identifiedliteraturebypapertype

(numberofpapers)

Fig. 6. Identified literature by paper type and year of publication.

<!-- image -->

Fig. 7. Identified literature by research method (a) and research discipline (b).

<!-- image -->

## Appendix C. User Group Framework for expert context: Refined including Future Research

Table 9

AI User Group Framework for expert context: Refined including Future Research

| Domain                                                             | Eco. Activity NAICS code   | Exemplary AI user groups                       | Sources                                                                       |
|--------------------------------------------------------------------|----------------------------|------------------------------------------------|-------------------------------------------------------------------------------|
| Agriculture, Forestry, Fishing, Hunting                            | 11                         | Farmers, Fishers                               | Not covered yet                                                               |
| Mining, Quarrying, Oil and Gas Extraction; Utilities; Construction | 21 - 23                    | Construction workers, Geologists               | Maitz et al. (2022)                                                           |
| Manufacturing                                                      | 31 - 33                    | Engineers, Factory staff                       | Pillay et al. (2018)                                                          |
| Trade [Wholesale & Retail]                                         | 42 - 45                    | Sales agent, Retailer                          | Not covered yet                                                               |
| Transportation and Warehousing                                     | 48 - 49                    | Warehouse workers, Taxi drivers                | Not covered yet                                                               |
| Information                                                        | 51                         | News publisher, Librarians                     | Cox and Mazumdar (2022)                                                       |
| Finance and Insurance                                              | 52                         | Bankers, Actuaries                             | Not covered yet                                                               |
| Real Estate, Rental, Leasing                                       | 53                         | Brokers, Leasing agents                        | Not covered yet                                                               |
| Professional, Scientific, Technical Services                       | 54                         | Consultants, Scientists, Accountants           | Not covered yet                                                               |
| Management of Companies and Enterprises                            | 55                         | Executives, Middle management                  | Jorzik et al. (2023), Pinski, Hofmann, and Benlian (2023), Yang et al. (2021) |
| Administrative, Support, Waste Management, Remediation Services    | 56                         | Recruiters, Facility managers                  | Not covered yet                                                               |
| Educational Services                                               | 61                         | Teachers, Professors, Counselors               | Kim and Kwon (2023)                                                           |
| Healthcare and Social Assistance                                   | 62                         | Medical doctors, Nurses, Social care providers | Charow et al. (2021), Jussupow et al. (2021)                                  |
| Arts, Entertainment, Recreation                                    | 71                         | Journalists, Screenplay writers                | Deuze and Beckett (2022)                                                      |
| Accommodation and Food Services                                    | 72                         | Cooks, Hoteliers                               | Not covered yet                                                               |
| Public Administration                                              | 92                         | Policymakers, Law enforcers, Judges            | Not covered yet                                                               |

## References

- Abraham, R., Schneider, J., &amp; vom Brocke, J. (2019). Data governance: A conceptual framework, structured review, and research agenda. International Journal of Information Management, 49 , 424 -438. https://doi.org/10.1016/j. ijinfomgt.2019.07.008
- Adam, M., Wessel, M., &amp; Benlian, A. (2020). AI-based chatbots in customer service and their effects on user compliance. Electronic Markets, 31 (2), 427 -445. https://doi.org/ 10.1007/s12525-020-00414-7
- Ali, S., DiPaola, D., Lee, I., Hong, J., &amp; Breazeal, C. (2021). In Exploring generative Models with middle school students proceedings of the 2021 CHI conference on human factors in computing systems .
- Ali, S., DiPaola, D., Lee, I., Sindato, V., Kim, G., Blumofe, R., &amp; Breazeal, C. (2021). Children as creators, thinkers and citizens in an AI-driven future. Computers &amp; Education: Artificial Intelligence, 2 . - Arrieta, A. B., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila, R., &amp; Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion, 58 , 82 -115. https://doi.org/ 10.1016/j.inffus.2019.12.012
- Baird, A., &amp; Maruping, L. M. (2021). The next generation of research on IS use: A theoretical framework of delegation to and from agentic IS artifacts. MIS Quarterly, 45 (1), 315 -341. - Bassellier, G., Reich, B. H., &amp; Benbasat, I. (2015). Information technology competence of business managers: A definition and research model. Journal of Management Information Systems, 17 (4), 159 -182. https://doi.org/10.1080/ 07421222.2001.11045660
- Bauer, K., von Zahn, M., &amp; Hinz, O. (2021). Expl(AI)ned: The impact of explainable artificial intelligence on cognitive processes . Leibniz Institute for Financial Reserach SAFE. SAFE Working Paper No. 315 .
- Benlian, A., Wiener, M., Cram, W. A., Krasnova, H., Maedche, A., M ¨ ohlmann, M., Recker, J., &amp; Remus, U. (2022). Algorithmic management. Business &amp; Information Systems Engineering, 64 , 825 -839. - Berente, N., Gu, B., Recker, J., &amp; Santhanam, R. (2021). Managing artificial intelligence. MIS Quarterly, 45 (3), 1433 -1450. - Bhattacherjee, A. (2001). Understanding information systems continuance: An expectation-confirmation model. MIS Quarterly, 25 (3), 351 -370. https://doi.org/ 10.2307/3250921
- Bostrom, R. P., Gupta, S., &amp; Thomas, D. (2014). A meta-theory for understanding information systems within sociotechnical systems. Journal of Management Information Systems, 26 (1), 17 -48. - Brasse, J., Broder, H. R., F ¨ orster, M., Klier, M., &amp; Sigler, I. (2023). Explainable artificial intelligence in information systems: A review of the status quo and future research directions. Electronic Markets, 33 (1). https://doi.org/10.1007/s12525-023-00644-5 Brynjolfsson, E., Li, D., &amp; Raymond, L. R. (2023). Generative AI at work . National Bureau of Economic Research.

Burgsteiner, H., Kandlhofer, M., &amp; Steinbauer, G. (2016). IRobot: Teaching the Basics of artificial Intelligence in high schools sixth symposium on educational advances in artificial intelligence (EAAI-16) .

Carolus, A., Augustin, Y., Markus, A., &amp; Wienrich, C. (2023). Digital interaction literacy model -conceptualizing competencies for literate interactions with voice-based AI systems. Computers &amp; Education: Artificial Intelligence, 4 . https://doi.org/10.1016/j. caeai.2022.100114

- Carroll, J. M., &amp; Rosson, M. B. (1987). Paradox of the active user. In Interfacing thought: Cognitive aspects of human-computer interaction (pp. 80 -111). The MIT Press.
- Casal-Otero, L., Catala, A., Fern ´ andez-Morante, C., Taboada, M., Cebreiro, B., &amp; Barro, S. (2023). AI literacy in K-12: A systematic literature review. International Journal of STEM Education, 10 (1). - Cetindamar, D., Kitto, K., Wu, M., Zhang, Y., Abedin, B., &amp; Knight, S. (2022). Explicating AI literacy of employees at digital workplaces. IEEE Transactions on Engineering Management, 0 , 1 -14. - Charow, R., Jeyakumar, T., Younus, S., Dolatabadi, E., Salhia, M., Al-Mouaswas, D., Anderson, M., Balakumar, S., Clare, M., Dhalla, A., Gillan, C., Haghzare, S., Jackson, E., Lalani, N., Mattson, J., Peteanu, W., Tripp, T., Waldorf, J., Williams, S., … Wiljer, D. (2021). Artificial intelligence education programs for health care professionals: Scoping review. JMIR Med Educ, 7 (4), Article e31043. https://doi.org/ 10.2196/31043
- Chaudhury, R., Guo, P. J., &amp; Chilana, P. K. (2022). There ' s no way to keep up!. In Diverse Motivations and challenges Faced by informal Learners of ML 2022 IEEE symposium on visual languages and human-centric computing (VL/HCC) .
- Chen, C., &amp; Storey. (2012). Business intelligence and analytics: From big data to big impact. MIS Quarterly, 36 (4). - Cheney, P. H., Hale, D. P., &amp; Kasper, G. M. (1990). Knowledge, skills and abilities of information systems professionals: Past, present, and future. Information &amp; Management, 19 , 237 -247.
- Chiang, C.-W., &amp; Yin, M. (2022). Exploring the Effects of machine learning literacy Interventions on laypeople ' s Reliance on machine learning models 27th international conference on intelligent user interfaces . Helsinki: Finland.
- Colley, H., Hodkinson, P., &amp; Malcolm, J. (2002). Non-formal learning: Mapping the conceptual terrain (A consultation report, issue .
- Collins, C., Dennehy, D., Conboy, K., &amp; Mikalef, P. (2021). Artificial intelligence in information systems research: A systematic literature review and research agenda. International Journal of Information Management, 60 . https://doi.org/10.1016/j. ijinfomgt.2021.102383
- Cox, A. M., &amp; Mazumdar, S. (2022). Defining artificial intelligence for librarians. Journal of Librarianship and Information Science . https://doi.org/10.1177/ 09610006221142029
- Dai, Y., Chai, C.-S., Lin, P.-Y., Jong, M. S.-Y., Guo, Y., &amp; Qin, J. (2020). Promoting students ' well-being by developing their readiness for the artificial intelligence age. Sustainability, 12 (16). - Deuze, M., &amp; Beckett, C. (2022). Imagination, algorithms and news: Developing AI literacy for journalism. Digital Journalism, 10 (10), 1913 -1918. https://doi.org/ 10.1080/21670811.2022.2119152
- Druga, S. (2023). Creative AI Literacies for families University of Washington .
- Druga, S., Christoph, F. L., &amp; Ko, A. J. (2022). Family as a third Space for AI literacies: How do children and parents learn about AI together? CHI conference on human factors in computing systems .
- Druga, S., &amp; Ko, A. J. (2021). How do children ' s perceptions of machine intelligence change when training and coding smart programs? Interaction Design and Children . - Druga, S., Vu, S. T., Likhith, E., &amp; Qiu, T. (2019). Inclusive AI literacy for kids around the world Proceedings of FabLearn 2019, New York City, USA .
- Duan, Y., Edwards, J. S., &amp; Dwivedi, Y. K. (2019). Artificial intelligence for decision making in the era of Big Data -evolution, challenges and research agenda. International Journal of Information Management, 48 , 63 -71. https://doi.org/ 10.1016/j.ijinfomgt.2019.01.021
- Eguchi, A., Okada, H., &amp; Muto, Y. (2021). Contextualizing AI education for K-12 students to enhance their learning of AI literacy through culturally responsive approaches. Kunstliche Intell (Oldenbourg), 35 (2), 153 -161. - Eraut, M. (2000). Non-formal learning and tacit knowledge in professional work. British Journal of Educational Psychology, 70 (Pt 1), 113 -136. https://doi.org/10.1348/ 000709900158001
- Eshet-Alkalai, Y. (2004). Digital literacy. Journal of Educational Multimedia and Hypermedia, 13 (1), 93 -106.
- Evans, J. A., &amp; Foster, J. G. (2011). Metaknowledge. Science, 331 (6018), 721 -725. https:// doi.org/10.1126/science.1201765
- Feerrar, J. (2019). Development of a framework for digital literacy. Reference Services Review, 47 (2), 91 -105. - Fernandez Domingos, E., Terrucha, I., Suchon, R., Grujic, J., Burguillo, J. C., Santos, F. C., &amp; Lenaerts, T. (2022). Delegation to artificial agents fosters prosocial behaviors in the collective risk dilemma. Scientific Reports, 12 (1), 8492. https://doi. org/10.1038/s41598-022-11518-9
- Folkestad, G. (2006). Formal and informal learning situations or practices vs formal and informal ways of learning. British Journal of Music Education, 23 (2), 135 -145. - Fügener, A., Grahl, J., Gupta, A., &amp; Ketter, W. (2021). Cognitive challenges in human -artificial intelligence collaboration: Investigating the path toward productive delegation. Information Systems Research, 33 (2), 678 -696. https://doi. org/10.1287/isre.2021.1079
- Fujiwara, T., Müller, K., &amp; Schwarz, C. (2021). The effect of social media on elections: Evidence from the United States .
- Gilster, P. (1997). Digital literacy . Wiley.
- Hendler, J. (2008). Avoiding another AI winter. IEEE Intelligent Systems, 23 (2), 2 -4. - Hermann, E. (2021). Artificial intelligence and mass personalization of communication content -an ethical and literacy perspective. New Media &amp; Society, 24 (5), 1258 -1277. - Heyder, T., &amp; Posegga, O. (2021). Extending the foundations of AI literacy international conference on information systems, Austin, USA .
- Hughes, A. (2023). ChatGPT: Everything you need to know aboutOpenAI ' s GPT-4 tool. BBC science focus . Retrieved https://www.sciencefocus.com/future-technology/gpt-3. (Accessed 8 August 2023).
- Isaak, J., &amp; Hanna, M. J. (2018). User data privacy: Facebook, cambridge Analytica, and privacy protection. Computer, 51 (8), 56 -59. https://doi.org/10.1109/ mc.2018.3191268
- Jain, H., Padmanabhan, B., Pavlou, P. A., &amp; Raghu, T. S. (2021). Editorial for the special section on humans, algorithms, and augmented intelligence: The future of work, organizations, and society. Information Systems Research, 32 (3), 675 -687. https:// doi.org/10.1287/isre.2021.1046
- Janiesch, C., Zschech, P., &amp; Heinrich, K. (2021). Machine learning and deep learning. Electronic Markets, 31 (3), 685 -695. - Jorzik, P., Yigit, A., Kanbach, D. K., Kraus, S., &amp; Dabi ´ c, M. (2023). Artificial intelligenceenabled business model innovation: Competencies and roles of top management. IEEE Transactions on Engineering Management , 1 -13. https://doi.org/10.1109/ tem.2023.3275643
- Jussupow, E., Spohrer, K., Heinzl, A., &amp; Gawlitza, J. (2021). Augmenting medical diagnosis decisions? An investigation into physicians ' decision-making process with artificial intelligence. Information Systems Research, 32 (3), 713 -735. https://doi.org/ 10.1287/isre.2020.0980
- Kandlhofer, M., Steinbauer, G., Hirschmugl-Gaisch, S., &amp; Huber, P. (2016). Artificial Intelligence and computer Science in education: From Kindergarten to university 2016 IEEE frontiers in education conference, erie, USA .
- Kaplan, A. D., Kessler, T. T., Brill, J. C., &amp; Hancock, P. A. (2023). Trust in artificial intelligence: Meta-analytic findings. Human Factors and Ergonomics Society, 65 (2), 337 -359. - Kerpedzhiev, G. D., K ¨ onig, U. M., R ¨ oglinger, M., &amp; Rosemann, M. (2020). An exploration into future business process management capabilities in view of digitalization. Business &amp; Information Systems Engineering, 63 (2), 83 -96. https://doi.org/10.1007/ s12599-020-00637-0
- Khalid, K., Iivari, N., Kinnula, M., &amp; Sharma, S. (2022). Familiarizing Children with artificial intelligence proceedings of the 25th international academic mindtrek conference .
- Kim, K., &amp; Kwon, K. (2023). Exploring the AI competencies of elementary school teachers in South Korea. Computers &amp; Education: Artificial Intelligence, 4 . https://doi.org/ 10.1016/j.caeai.2023.100137
- Kitchenham, B., &amp; Charters, S. (2007). Guidelines for performing systematic literature Reviews in software engineering EBSE technical report EBSE-2007-01, issue .
- Kong, S.-C., Man-Yin Cheung, W., &amp; Zhang, G. (2021). Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds. Computers &amp; Education: Artificial Intelligence, 2 . https://doi.org/10.1016/j. caeai.2021.100026
- Kraiger, K., Ford, J. K., &amp; Salas, E. (1993). Application of cognitive, skill-based, and affective theories of learning outcomes to new methods of training evaluation. Journal of Applied Psychology, 78 (2), 311 -328. - Krath, J., Schürmann, L., &amp; von Korflesch, H. F. O. (2021). Revealing the theoretical basis of gamification: A systematic review and analysis of theory in research on gamification, serious games and game-based learning. Computers in Human Behavior, 125 . - Kruger, J., &amp; Dunning, D. (1999). Unskilled and unaware of it: How difficulties in recognizing one ' s own incompetence lead to inflated self-assessments. Journal of Personality and Social Psychology, 77 (6), 1121 -1134.
- Kusuma, M., Mohanty, V., Wang, M., &amp; Luther, K. (2022). Civil war twin proceedings of the 2022 AAAI/ACM conference on AI, ethics, and society .
- Laupichler, M. C., Aster, A., Haverkamp, N., &amp; Raupach, T. (2023). Development of the ' Scale for the assessment of non-experts ' AI literacy ' -an exploratory factor analysis. Computers in Human Behavior Reports, 12 . https://doi.org/10.1016/j. chbr.2023.100338
- Laupichler, M. C., Aster, A., &amp; Raupach, T. (2023). Delphi study for the development and preliminary validation of an item set for the assessment of non-experts ' AI literacy. Computers &amp; Education: Artificial Intelligence, 4 . https://doi.org/10.1016/j. caeai.2023.100126
- Laupichler, M. C., Aster, A., Schirch, J., &amp; Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers &amp; Education: Artificial Intelligence, 3 . - Lee, I., Ali, S., Zhang, H., DiPaola, D., &amp; Breazeal, C. (2021). Developing middle school students ' AI literacy proceedings of the 52nd ACM technical symposium on computer science education, virtual .
- Lee, I., &amp; Shin, Y. J. (2018). Fintech: Ecosystem, business models, investment decisions, and challenges. Business Horizons, 61 (1), 35 -46. https://doi.org/10.1016/j. bushor.2017.09.003
- Lee, I., Zhang, H., Moore, K., Zhou, X., Perret, B., Cheng, Y., Zheng, R., &amp; Pu, G. (2022). AI book club proceedings of the 53rd ACM technical symposium on computer science education .
- Leichtmann, B., Humer, C., Hinterreiter, A., Streit, M., &amp; Mara, M. (2023). Effects of Explainable Artificial Intelligence on trust and human behavior in a high-risk decision task. Computers in Human Behavior, 139 . https://doi.org/10.1016/j. chb.2022.107539
- Leidig, P., &amp; Salmela, H. (2020). A competency Model for Undergraduate programs in information systems. The joint ACM/AIS IS2020 task force . https://doi.org/10.1145/ 3460863
- Leu, D. J., Kinzer, C. K., Coiro, J. L., &amp; Cammack, D. W. (2004). Toward a theory of new literacies emerging from the Internet and other information and communication technologies. Theoretical models and processes of reading, 5 (1), 1570 -1613.
- Leu, D. J., Kinzer, C. K., Coiro, J., Castek, J., &amp; Henry, L. A. (2013). New literacies: A dual-level theory of the changing nature of literacy, instruction, and assessment. Journal of Education, 197 (2), 1 -18. - Liu, S., &amp; Xie, X. (2021). AI quality Cultivation and application ability Training for normal university students 2021 7th annual international conference on network and

- information systems for computers (ICNISC), Livingstone, S. (2004). Media literacy and the challenge of new information and communication technologies. The Communication Review, 7 (1), 3 -14. - Long, D. (2023). Conducting remote design Research on embodied, collaborative museum exhibits. In Extended abstracts of the 2023 CHI conference on human factors in computing systems .
- Long, D., Blunt, T., &amp; Magerko, B. (2021). Co-designing AI literacy exhibits for informal learning spaces. Proceedings of the ACM on Human-Computer Interaction, 5 , 1 -35. - Long, D., Jacob, M., &amp; Magerko, B. (2019). Designing Co-creative AI for public spaces proceedings of the 2019 on creativity and cognition .
- Long, D., &amp; Magerko, B. (2020). What is AI literacy? Competencies and design considerations 2020 CHI conference on human factors in computing systems, Honolulu, USA . https:// doi.org/10.1145/3313831.3376727
- Long, D., Padiyath, A., Teachey, A., &amp; Magerko, B. (2021). The Role of collaboration, creativity, and Embodiment in AI learning experiences creativity and cognition . https:// doi.org/10.1145/3450741.3465264
- Long, D., Teachey, A., &amp; Magerko, B. (2022). Family learning Talk in AI literacy learning activities. In CHI conference on human factors in computing systems .
- Maitz, K., Fessl, A., Pammer-Schindler, V., Kaiser, R., &amp; Lindstaedt, S. (2022). What do construction workers know about artificial intelligence?. In An Exploratory Case Study in an Austrian SME Mensch und Computer 2022 . https://doi.org/10.1145/ 3543758.3547545
- Manuti, A., Pastore, S., Scardigno, A. F., Giancaspro, M. L., &amp; Morciano, D. (2015). Formal and informal learning in the workplace: A research review. International Journal of Training and Development, 19 (1), 1 -17. https://doi.org/10.1111/ ijtd.12044
- Marcolin, B. L., Compeau, D. R., Munro, M. C., &amp; Huff, S. L. (2000). Assessing user competence: Conceptualization and measurement. Information Systems Research, 11 (1), 37 -60. - Markauskaite, L., Marrone, R., Poquet, O., Knight, S., Martinez-Maldonado, R., Howard, S., Tondeur, J., De Laat, M., Buckingham Shum, S., Ga ˇ sevi ´ c, D., &amp; Siemens, G. (2022). Rethinking the entwinement between artificial intelligence and human learning: What capabilities do learners need for a world with AI? Computers &amp; Education: Artificial Intelligence, 3 . - Markus, M. L. (2017). Datification, organizational strategy, and IS research: What ' s the score? The Journal of Strategic Information Systems, 26 (3), 233 -241. https://doi.org/ 10.1016/j.jsis.2017.08.003
- Marsick, V. J., &amp; Watkins, K. E. (2001). Informal and incidental learning. New Directions for Adult and Continuing Education, 2001 (89). - McCarthy, J. L., Minsky, M. L., Rochester, N., &amp; Shannon, C. E. (1955). A proposal for the dartmouth summer research project on artificial intelligence. August 31 . http://jmc.st anford.edu/articles/dartmouth/dartmouth.pdf.
- Melsi ´ on, G. I., Torre, I., Vidal, E., &amp; Leite, I. (2021). Using Explainability to help children UnderstandGender Bias in AI interaction design and children, merriam-webster. (2023). Awareness. Merriam-Webster.com dictionary . Retrieved https://www.merriam-webst er.com/dictionary/awareness. (Accessed 9 August 2023).
- Meske, C., Bunde, E., Schneider, J., &amp; Gersch, M. (2020). Explainable artificial intelligence: Objectives, stakeholders, and future research opportunities. Information Systems Management, 39 (1), 53 -63. https://doi.org/10.1080/ 10580530.2020.1849465
- Mikalef, P., Conboy, K., Lundstr ¨ om, J. E., &amp; Popovi ˇ c, A. (2022). Thinking responsibly about responsible AI and 'the dark side ' of AI. European Journal of Information Systems, 31 (3), 257 -268. - Milmo, D. (2023). ChatGPT reaches 100 million users two months after launch . The Guardian. Retrieved https://www.theguardian.com/technology/2023/feb/02/chat gpt-100-million-users-open-ai-fastest-growing-app. (Accessed 25 July 2023).
- Murray, A., Rhymer, J., &amp; Sirmon, D. G. (2021). Humans and technology: Forms of conjoined agency in organizations. Academy of Management Review, 46 (3), 552 -571. - NAICS. (2023). North American Industry classification system (NAICS) . U.S. Census Bureau. Retrieved https://www.census.gov/naics/. (Accessed 31 July 2023).
- Neumann, M. M., Finger, G., &amp; Neumann, D. L. (2016). A conceptual framework for emergent digital literacy. Early Childhood Education Journal, 45 (4), 471 -479. https:// doi.org/10.1007/s10643-016-0792-z
- Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., &amp; Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers &amp; Education: Artificial Intelligence, 2 . - Ng, D. T. K., Luo, W., Chan, H. M. Y., &amp; Chu, S. K. W. (2022). Using digital story writing as a pedagogy to develop AI literacy among primary students. Computers &amp; Education: Artificial Intelligence, 3 . - Nguyen, Q. N., Sidorova, A., &amp; Torres, R. (2022). Artificial intelligence in business: A literature review and research agenda. Communications of the Association for Information Systems, 50 , 175 -207. - Njenga, J. K. (2018). Digital literacy: The quest of an inclusive definition. Reading and Writing, 9 (1). - OECD. (2019). The survey of adult skills: Reader ' s companion .
- Olari, V., &amp; Romeike, R. (2021). Addressing AI and data Literacy in teacher education: A Review of existing educational frameworks the 16th workshop in primary and secondary computing education .
- Ortiz, S. (2023). ChatGPT ' s hallucination just got OpenAIsued. Here ' s what happened. ZDNET . Retrieved 25.07.2023 from https://www.zdnet.com/article/chatgpts-halluc ination-just-got-openai-sued-heres-what-happened/.
- Papert, S. (1993). Mindstorms: Children, computers, and powerful ideas (2nd ed.). Basic Books.
- Par ´ e, G., Trudel, M.-C., Jaana, M., &amp; Kitsiou, S. (2015). Synthesizing information systems knowledge: A typology of literature reviews. Information &amp; Management, 52 (2), 183 -199. - Peng, B., Galley, M., He, P., Cheng, H., Xie, Y., Hu, Y., Huang, Q., Liden, L., Yu, Z., &amp; Chen, W. (2023). Check your facts and try again: Improving large language models with external knowledge and automated feedback . arXiv preprint arXiv:2302.12813 .
- Pillay, N., Maharaj, B. T., &amp; van Eeden, G. (2018). AI in engineering and computer science education in preparation for the 4th industrial revolution: A South African perspective. 2018 world engineering education forum - global engineering deans council (Weef-Gedc) . - Pinski, M., Adam, M., &amp; Benlian, A. (2023). AI knowledge: Improving AI Delegation through human enablement 2023 CHI conference on human factors in computing systems (CHI ' 23), hamburg, Germany . - Pinski, M., &amp; Benlian, A. (2023). AI literacy - towards measuring human Competency in artificial intelligence 56th Hawaii international conference on system sciences . Lahaina, USA.
- Pinski, M., Haas, M., &amp; Benlian, A. (2024). Building Metaknowledge in AI literacy -the Effect of Gamified vs. text-based Learning on AI literacy metaknowledge 57th Hawaii international conference on system sciences, Honolulu, USA .
- Pinski, M., Haas, M., &amp; Franz, A. (2023). AiLingo -a design science Approach to advancing non-expert adults ' AI literacy forty-fourth international conference on information systems . India: Hyderabad.
- Pinski, M., Hofmann, T., &amp; Benlian, A. (2023). Executive AI literacy: A text-mining Approach to understand Existing and demanded AI Skills of Leaders in unicorn firms WI23 - 18th international conference on wirtschaftsinformatik, paderborn, Germany .
- Pinski, M., Hofmann, T., &amp; Benlian, A. (2024b). AI literacy for the top management: An upper echelons perspective on corporate AI orientation and implementation ability . Electronic Markets.
- Potter, W. (2004). Theory of media literacy: A cognitive approach . https://doi.org/ 10.4135/9781483328881
- Potter, W. J. (2013). Review of literature on media literacy. Sociology Compass, 7 (6), 417 -435. - Rai, A., Constantinides, P., &amp; Sarker, S. (2019). Next-generation digital platforms: Toward human -AI hybrids. MIS Quarterly, 43 (1).
- Register, Y., &amp; Ko, A. J. (2020). Learning machine Learning with personal data helps stakeholders ground advocacy Arguments in model mechanics. In Proceedings of the 2020 ACM conference on international computing education research .
- Salazar-Gomez, A. F., Bagiati, A., Minicucci, N., Kennedy, K. D., Du, X., &amp; Breazeal, C. (2022). In Designing and implementing an AI education program for learners with diverse background at scale 2022 IEEE Frontiers in Education Conference (FIE) .
- Sarker, S., Chatterjee, S., Xiao, X., &amp; Elbanna, A. (2019). The sociotechnical Axis of cohesion for the IS discipline: Its historical legacy and its continued relevance. MIS Quarterly, 43 (3), 695 -719. - Schepman, A., &amp; Rodway, P. (2022). The general attitudes towards artificial intelligence scale (GAAIS): Confirmatory validation and associations with personality, corporate distrust, and general trust. International Journal of Human-Computer Interaction , 1 -18. - Schneider, J., Meske, C., &amp; Bikic, A. (2023). How individuals can shape AI through data - an AI literacy and morality perspective European Conference on Information Systems, Kristiansand, Norway .
- Schryen, G., Wagner, G., Benlian, A., &amp; Par ´ e, G. (2021). A knowledge development perspective on literature reviews: Validation of a new typology in the IS field. Communications of the Association for Information Systems, 49 (1), 134 -186. https:// doi.org/10.17705/1cais.04607
- Schuetz, S., &amp; Venkatesh, V. (2020). Research perspectives: The rise of human machines: How cognitive computing systems challenge assumptions of user-system interaction. Journal of the Association for Information Systems, 21 (2), 460 -482. https://doi.org/ 10.17705/1jais.00608
- Someh, I., Davern, M., Breidbach, C. F., &amp; Shanks, G. (2019). Ethical issues in big data analytics: A stakeholder perspective. Communications of the Association for Information Systems, 44 (1), 718 -747. - Steinbauer, G., Kandlhofer, M., Chklovski, T., Heintz, F., &amp; Koenig, S. (2021). A differentiated discussion about AI education K-12. Kunstliche Intell (Oldenbourg), 35 (2), 131 -137. - Su, J., Ng, D. T. K., &amp; Chu, S. K. W. (2023). Artificial intelligence (AI) literacy in early childhood education: The challenges and opportunities. Computers &amp; Education: Artificial Intelligence, 4 . - Torkzadeh, G., &amp; Koufteros, X. (1993). Computer user training and attitudes: A study of business undergraduates. Behaviour &amp; Information Technology, 12 (5), 284 -292. - Tschandl, P., Rinner, C., Apalla, Z., Argenziano, G., Codella, N., Halpern, A., Janda, M., Lallas, A., Longo, C., Malvehy, J., Paoli, J., Puig, S., Rosendahl, C., Soyer, H. P., Zalaudek, I., &amp; Kittler, H. (2020). Human-computer collaboration for skin cancer recognition. Nature Medicine, 26 (8), 1229 -1234. - Tully, S., Longoni, C., &amp; Appel, G. (2023). Knowledge of artificial intelligence predicts lower AI receptivity. PsyArXiv . - Turing, A. M. (1950). I. -computing machinery and intelligence. Mind, LIX (236), 433 -460. - Van Brummelen, J., Tabunshchyk, V., &amp; Heng, T. (2021). ' Alexa, can I program you? ' . In Student Perceptions of conversational artificial intelligence Before and after programming Alexa interaction design and children .
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł ., &amp; Polosukhin, I. (2017). In Attention is all you need. 31st conference on neural information processing systems .

- Vazhayil, A., Shetty, R., Bhavani, R. R., &amp; Akshay, N. (2019). In Focusing on teacher Education to introduce AI in schools: Perspectives and illustrative findings 2019 IEEE tenth international conference on technology for education (T4E) .
- Wang, B., Rau, P.-L. P., &amp; Yuan, T. (2022). Measuring user competence in using artificial intelligence: Validity and reliability of artificial intelligence literacy scale. In Behaviour &amp; information technology (pp. 1 -14). https://doi.org/10.1080/ 0144929x.2022.2072768
- Wang, D., Yang, Q., Abdul, A., &amp; Lim, B. Y. (2019). Designing theory-driven user-centric explainable AI 2019 CHI conference on human factors in computing systems .
- Weber, P., Pinski, M., &amp; Baum, L. (2023). Toward an objective Measurement of AI literacy pacific asia conference on information systems, nanchang, China .
- Webster, J., &amp; Watson, R. T. (2002). Analyzing the past to prepare for the future: Writing a literature review. MIS Quarterly, 26 (2), 1195 -1215. https://www.jstor.org/stable/ 4132319.
- Wiljer, D., &amp; Hakim, Z. (2019). Developing an artificial intelligence-enabled health care practice: Rewiring health care professions for better care. Journal of Medical Imaging and Radiation Sciences, 50 (4 Suppl 2), S8 -S14. https://doi.org/10.1016/j. jmir.2019.09.010
- Wilton, L., Ip, S., Sharma, M., &amp; Fan, F. (2022). Where is the AI? AI literacy for educators. In Artificial intelligence in education. Posters and late breaking results, workshops and tutorials, Industry and innovation tracks, practitioners ' and doctoral consortium (pp. 180 -188). - Wolff, A., Gooch, D., Cavero Montaner, J. J., Rashid, U., &amp; Kortuem, G. (2016). Special issue on data literacy: Articles creating an understanding of data literacy for a datadriven society. Journal of Community Informatics, 12 (3), 9 -26.
- Wong, G. K. W., Ma, X., Dillenbourg, P., &amp; Huan, J. (2020). Broadening artificial intelligence education in K-12. ACM Inroads, 11 (1), 20 -29. https://doi.org/10.1145/ 3381884
- World Economic Forum. (2018). The future of jobs report . http://www3.weforum.org/ docs/WEF\_Future\_of\_Jobs\_2018.pdf.
- World Economic Forum. (2020). Schools of the future. Defining new models of education for the fourth industrial revolution . http://www3.weforum.org/docs/WEF\_Schools\_of\_the\_ Future\_Report\_2019.pdf.
- World Economic Forum. (2022). Without universal AI literacy, AI will fail us . Retrieved htt ps://www.weforum.org/agenda/2022/03/without-universal-ai-literacy-ai-will-fail -us/. (Accessed 10 August 2022).
- Xu, J. J., &amp; Babaian, T. (2021). Artificial intelligence in business curriculum: The pedagogy and learning outcomes. International Journal of Management in Education, 19 (3). - Yang, W. (2022). Artificial Intelligence education for young children: Why, what, and how in curriculum design and implementation. Computers &amp; Education: Artificial Intelligence, 3 . - Yang, J., Blount, Y., &amp; Amrollahi, A. (2021). Factors that Influence the Adoption of artificial Intelligence by auditing firms international conference on information systems .