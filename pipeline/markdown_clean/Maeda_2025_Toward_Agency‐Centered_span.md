---
source_file: Maeda_2025_Toward_Agency‐Centered_span.pdf
conversion_date: 2026-02-03T09:10:10.880715
converter: docling
quality_score: 95
---

## Toward Agency-Centered AI Literacy: A Scoping Review

Maeda, Takuya Anderson, Hillary Quan-Haase, Anabel Willis, Katharine Gignac, Selena

Western University, Canada | tmaeda@uwo.ca Western University, Canada | hander33@uwo.ca Western University, Canada | aquan@uwo.ca University of Plymouth, UK | katharine.willis@plymouth.ac.uk Western University, Canada | sgignac3@uwo.ca

## ABSTRACT

Digital literacy is well-studied across disciplines, with established attention to core competencies and social inequalities. However, artificial intelligence (AI) literacy remains underexplored. To address this gap, we conducted a scoping review on AI literacy to: (1) consolidate current definitions and pinpoint conceptual gaps, (2) evaluate methodological approaches and their relevance in practice, and (3) examine how social inequalities are considered in AI literacy studies. Definitions of AI literacy are inconsistent across and within disciplines, and most studies do not consider social factors. Most definitions focus on knowledge and skill acquisition, framing AI literacy as a suite of acquired competencies. We argue that current understandings of AI literacy need to expand to include informed decision-making, critical engagement, and resistance to technological coercion by taking an agency-driven approach. These insights can guide researchers, educators, and policymakers in fostering an agency-centered AI literacy that empowers individuals in an increasingly AI-mediated world.

## KEYWORDS

AI literacy, digital literacy, social inequality, digital inclusion, scoping review, user agency, policy making.

## INTRODUCTION

As AI tools increasingly permeate everyday life, conceptual frameworks are being developed to study the public's understanding of and engagement with them (Long &amp; Magerko, 2020; Ng, Leung, Chu, &amp; Qiao, 2021; Carolus et al., 2023; Ng et al., 2024). Previous insights from algorithmic literacy have proven to be instructive, demonstrating that the lack of public awareness of algorithms makes it difficult to develop meaningful AI literacy (Gran et al. 2021). Moreover, algorithms tend to be highly opaque and black-box in nature, creating obstacles to grasping what they are doing and how they function (Burrell, 2016; Petrovčič, et al. 2024). Van Deursen and Mossberger (2018) highlight how this has potentially far-reaching implications for people with differing skill levels. However, the accelerated pace of AI proliferation has made it necessary to develop broader understandings of AI literacy (Long &amp; Magerko, 2020; Ng, Leung, Chu, &amp; Qiao, 2021), understood as a distinct form of algorithmic literacy. This area of research is still largely unstandardized and lacks comprehensive scope. Existing studies tend to focus on measuring AI literacy through the construction of assessment scales (Lintner, 2024). The risk of focusing too soon on measurement is that these assessment scales do not capture the nuance of lived experience, including how people use, understand, and integrate such tools into their everyday contexts. Indeed, scholars and practitioners are calling for the development of AI literacy as an integral part of digital equity, given a society that is increasingly reliant on AI integration (Cotter &amp; Reisdorf, 2020). Therefore, this scoping review explores research on AI literacy to: (1) consolidate current definitions and pinpoint conceptual gaps, (2) evaluate methodological approaches and their relevance in practice, and (3) examine how social inequalities are considered in AI literacy studies. Based on the scoping review findings, we suggest an agency-based framework that incorporates critical engagement, informed decision-making, and resistance to technological coercion as necessary responses to AI systems.

## METHODS

We conducted a scoping review to identify gaps in existing AI literacy studies. While systematic reviews address narrowly-defined research questions, scoping reviews allow for nimble exploration of emerging fields where theories and methods are still developing and not well understood or formulated (Arksey &amp; O'Malley, 2005; Levac et al., 2010). Using the search query '(``algorithm* literacy'' OR ``algorithm* awareness'' OR ``artificial intelligence literacy'' OR ``artificial intelligence awareness'') AND (study OR test OR interview* OR questionnaire OR experiment* OR qualitative OR quantitative)', we searched 11 databases from June 12 to June 30, 2024 - including ERIC , Science Direct , Scopus , Google Scholar , and Web of Science . We extensively tested various combinations of search terms for efficacy before arriving at the final search string. Given the recency of the topic, we extracted relevant sources published between 2015 and 2024. Three researchers independently checked each source to verify that it met the inclusion criteria, such as peer-reviewed journal or conference article. The exclusion criteria were: short/excessive length (e.g., extended abstracts and theses), non-academic writing (e.g., policy reports), irrelevant topics, and duplicates. We focused on papers written in English due to our language limitations. Using the above criteria, we removed 157 entries from 273 initial papers. This resulted in 129 studies which examined AI or

<!-- image -->

algorithmic literacy for non-specialist user groups. We then performed a thematic analysis (Braun &amp; Clarke, 2007) and developed a coding framework with six primary themes to classify the definitions of AI, algorithms, and literacy; methods; purposes and goals of the given studies; social contexts; the theoretical foundations; and findings/recommendations. The researchers established intercoder reliability by independently coding 15 papers, achieving more than 90% agreement after two rounds.

## FINDINGS

The scoping review indicates that terminology describing AI literacy is inconsistent. We found that 47% of studies ( n =61) use AI literacy as their primary definition, 24% ( n =31) focus on algorithmic awareness, and 13% ( n =17) use other terms. Most studies ( n =100) discuss AI or algorithms as generic umbrella terms, and only a few (n=17) explore specific applications of AI technology. This demonstrates that most current studies fail to capture the nuance of different AI tools, which can range from applications like customer service chatbots to technical processes such as machine learning and neural networks embedded within infrastructural systems. Results show that current AI literacy frameworks focus on knowledge and skill acquisition, framing AI literacy as a suite of acquired competencies. Of 129 papers, 68% ( n =87) discuss AI literacy as a type of competence, encompassing knowledge, skills, attitudes, and ethical considerations. Other papers construct literacy as either knowledge/awareness or an individual's capability to identify or effectively utilize AI systems. Even when literacy frameworks claim to include an individual's ability to critically evaluate AI tools, they do not examine whether users question power structures or implications/interventions. Most of the studies measure their constructs via interviews or questionnaires that solicit self-reports, rather than through in-context demonstrations. Around half (48%) of the studies use quantitative methods (n=62), with 39% of these examining knowledge and misconceptions of AI systems. Of the total 129 papers, 33% ( n =43) aim to cultivate an awareness and understanding of AI or algorithmic systems without addressing users' holistic decision -making concerning AI (what we regard as 'agency'). Of the papers that do address agency, they equate it with the maximization of one's ability to wield the tools, rather than with the capacity to resist or refuse them -treating non-participation as illiteracy, rather than informed choice.  Furthermore, we found that most studies overlook the critical impact of social factors during the acquisition of AI literacy. Almost half (46%) of the studies ( n =59) do not meaningfully examine factors of social inequality, and an additional 28% of studies ( n =36) collected information about the socio-economic status of their participants only for demographic statistics of their sample. A minority of studies examine how aspects of socio-economic status (16%, n=21) or digital inequality (10%, n=13) impacts parti cipants' AI literacy. This suggests that studies are capturing an incomplete picture of what shapes AI literacy in the public by overlooking social and other structural factors.

## DISCUSSION AND CONCLUSION

This study suggests that AI literacy is often conceptualized and measured in narrow ways, while studies on user understanding of algorithmic systems tend to take an overly broad approach. Our concern that studies are too superficial to fully understand the AI literacy of the general public is justified by current research, which warns that AI systems could create new forms of harm and inequality (Petrovčič et al., 2024; Wang et al., 2024). Foundational literature should aim to understand AI literacy in terms of the implications for new digital divides and critical engagement, promoting an agency-centred approach. Agency in this context refers to the capacity for informed personal action that requires the convergence of knowledge, power, and appropriate circumstances (Feenberg, 2017). The dimension of agency must also be included in studies to acknowledge how users make informed decisions to engage in, assess, or evaluate algorithmic environments. We propose that frameworks should acknowledge resistance, refusal, and opting out as legitimate responses to AI systems to reframe AI literacy from an activity of mandatory skill acquisition to one of critical decision-making. We identify significant gaps in understanding the role of demographic disparities within AI literacy, particularly regarding how marginalized groups develop and exercise agency when interacting with AI systems. These gaps are concerning given growing evidence that AI systems often perform differently across demographic groups (Van Deursen, et al., 2017). As AI literacy frameworks evolve, researchers must consider how social positioning influences both literacy development and the consequences of literacy gaps. Advancing this work will require research and consultation that bridges academic and community perspectives to fully capture the power dynamics, digital marginalization, and lived experiences that traditional scholarship often overlooks. Given the opacity of many AI tools, AI literacy should extend beyond merely measuring knowledge or competencies to include critical engagement and informed decisionmaking, highlighting social inequalities and power structures (Cotter &amp; Reisdorf, 2020). An agency-centred definition of AI literacy should include critical evaluation skills and informed refusal, moving beyond frameworks that prioritize participation over user autonomy and the right to technological self-determination.

## GENERATIVE AI USE

We confirm that we did not use generative AI tools/services to author this submission.

## AUTHOR ATTRIBUTION

Takuya Maeda: conceptualization, methodology, data curation, formal analysis, writing, review and editing; Hillary Anderson: conceptualization, methodology, data curation, formal analysis, writing, review and editing; Anabel Quan-Haase: conceptualization, methodology, writing, review and editing, supervision, funding acquisition; Katharine Willis: conceptualization, methodology, writing, review and editing, supervision, funding acquisition; Selena Gignac: formal analysis, writing, review and editing

## ACKNOWLEDGMENTS

This paper draws on research supported by the Social Sciences and Humanities Research Council of Canada and UKRI-ESRC.

## REFERENCES

- Arksey, H., &amp; O'Malley, L. (2005). Scoping studies: Towards a methodological framework. International Journal of Social Research Methodology, 8 (1), 19-32. https://doi-org/10.1080/1364557032000119616
- Braun, V., &amp; Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3 (2), 77 -101. - Burrell, J. (2016). How the machine 'thinks': Understanding opacity in machine learning algorithms. Big Data &amp; Society, 3 (1), 2053951715622512. - Carolus, A., Koch, M. J., Straka, S., Latoschik, M. E., &amp; Wienrich, C. (2023). MAILS-Meta AI literacy scale: Development and testing of an AI literacy questionnaire based on well-founded competency models and psychological change and metacompetencies. Computers in Human Behavior: Artificial Humans , 1 (2), 100014. https://doiorg.ca/10.48550/arXiv.2302.09319
- Cotter, K., &amp; Reisdorf, B. C. (2020). Algorithmic knowledge gaps: A new horizon of (digital) inequality. International Journal of Communication , 14 (2020), 745 765. https://ijoc.org/index.php/ijoc/article/view/12450
- Feenberg, A. (2017). Agency and citizenship in a technological society. In Spaces for the Future: A companion to philosophy of technology. (pp. 98-107). Routledge.
- Levac, D., Colquhoun, H., &amp; O'Brien, K. K. (2010). Scoping studies: Advancing the methodology. Implementation Science, 5 (69), 1-9. - Lintner, T. (2024). A systematic review of AI literacy scales. npj Science of Learning , 9 (1), 50. - Long, D., &amp; Magerko, B. (2020). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1 -16). ACM. - Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., &amp; Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence , 2( 1), 100041. - Ng, D. T. K., Wu, W., Leung, J. K. L., Chiu, T. K. F., &amp; Chu, S. K. W. (2024). Design and validation of the AI literacy questionnaire: The affective, behavioural, cognitive and ethical approach. British Journal of Educational Technology , 55 (3), 1082 -1104. - Petrovčič, A., Reisdorf, B. C., Vehovar, V., &amp; Bartol, J. (2024). Disentangling the role of algorithm awareness and knowledge in digital inequalities: An empirical validation of an explanatory model. Information, Communication &amp; Society , 28 (4), 557574. - Van Deursen, A. J., Helsper, E., Eynon, R., &amp; Van Dijk, J. A. (2017). The compoundness and sequentiality of digital inequality. International Journal of Communication , 11 (2017), 452 -473. https://ijoc.org/index.php/ijoc/article/view/5739/1911
- Van Deursen, A. J., &amp; Mossberger, K. (2018). Anything for anyone? A new digital divide in internet-of-things skills. Policy &amp; internet , 10 (2), 122-140. https://doi-org/10.1002/poi3.171
- Wang, C., Boerman, S. C., Kroon, A. C., M ö ller, J., &amp; H de Vreese, C. (2024). The artificial intelligence divide: Who is the most vulnerable? New Media &amp; Society , 14614448241232345. https://doi-org/10.1177/14614448241232345