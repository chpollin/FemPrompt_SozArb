---
source_file: Schneider_2018_Der_Einfluss_der_Algorithmen_Neue_Qualitäten.pdf
conversion_date: 2026-02-03T18:51:18.931654
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
## Der Einfluss der Algorithmen

Neue Qualitäten durch Big Data Analytics und Künstliche Intelligenz

Auch wenn es sie noch gibt, die Soziale Arbeit, die ohne den Einsatz von Computern auskommt, so ist doch die Nutzung von Software in der Planung, Dokumentation und Evaluation von Einzelfallhilfen mittlerweile selbstverständlich geworden und bei größeren Komplexträgern eigentlich alternativlos. Andere Branchen sind bei der Nutzung von Informationstechnologien seit jeher schon weiter vorangeschritten: im Finanzund Versicherungswesen oder der Medizin etablieren sich zunehmend Anwendungen auf der Basis von Big Data Analytics und Künstlicher Intelligenz. Ein Blick ins Ausland zeigt, dass aber auch in der Sozialen Arbeit vereinzelt schon mit diesen Technologien gearbeitet wird. Um deren Potentiale ausschöpfen zu können und Gefahren - etwa durch intransparente Entscheidungen solcher Systeme - erkennen und bannen zu können, ist eine frühzeitige Auseinandersetzung mit und aktive Gestaltung von solchen Systemen notwendig.

S oftware ist auch in der Sozialen Arbeit in den vergange nen Jahren immer leistungsfähiger geworden. Sie dient nicht nur dazu, Informationen digital zu speichern, und sie möglichst schnell und komfortabel, etwa mittels entsprechender Suchfunktionen, wieder zu finden. Vielmehr zeichnet sich Software auch dadurch aus, dass sie diese Informationen weiterverarbeitet und damit neue Informationen ge-

Diana Schneider *1988

<!-- image -->

<!-- image -->

M.A., Philosophin, Schwerpunkt Technikphilosopie, wissenschaftliche Mitarbeiterin an der FH Bielefeld, Fachbereich Sozialwesen, Promovendin des NRW-Graduiertenkollegs ,Digitale Gesellschaft' im Projekt ,Maschinelle Entscheidungsunterstützung in wohlfahrtsstaatlichen Institutionen' (MAEWIN)

diana.schneider@fh-bielefeld.de

Udo Seelmeyer *1971

Dr. phil., Diplom-Pädagoge, Prof. für Sozialarbeitswissenschaft an der FH Bielefeld, Fachbereich Sozialwesen, Stellvertretender Sprecher des NRW-Graduiertenkollegs ,Digitale Gesellschaft' und Leiter des Kompetenzzentrums Soziale Dienste (www.komsd.de) an der Universität Bielefeld udo.seelmeyer@fh-bielefeld.de

Abstract / Das Wichtigste in Kürze Digitalisierung prägt zunehmend auch Arbeitsvollzüge und Entscheidungsprozesse in der Sozialen Arbeit. Der Beitrag diskutiert, welche Veränderungen und Herausforderungen der Einsatz von Big Data und Künstlicher Intelligenz hervorbringt und welche neuen Anforderungen an Fachlichkeit sich für die Soziale Arbeit damit ergeben.

Keywords / Stichworte Digitalisierung; Informationstechnologien in der Sozialen Arbeit; Big Data; Künstliche Intelligenz; Formalisierung; Entscheidungsfindung neriert oder automatisiert bestimmte Aufgaben ausführt. Beispiele hierfür in Fachanwendungen in der Sozialen Arbeit wären etwa:

- Kategorisierungen und darauf bezogene Auswertungen (z.B. Erfassung von Aufnahmegründen)
- Quantifizierende Einschätzungen (z.B. Zielerreichungsgrade)
- Statistische Berechnungen (z.B. Risikoscores für Kindeswohlgefährdung)
- Prozesssteuerung durch Workflowsysteme (definierte Abfolgen von Bearbeitungsschritten; Auslösen von Aktionen abhängig von bestimmten Werten)

Bislang haben sich die eigenständigen Formen der Verarbeitung durch Software dabei auf die Bereiche beschränkt, in denen Inhalte und Prozesse formalisiert werden konnten dies war eine zwingende Voraussetzung für deren algorithmische Bearbeitung.

## Software als Ergebnis von Formalisierung

Denn Software ist - so der Informatiker Rolf - Ergebnis ei nes Prozesses der Transformation von sozialer Wirklichkeit in Code. Diese Transformation vollzieht sich in mehreren Schritten, nämlich

1.  der Semiotisierung als Versprachlichung von Wirklichkeit,
2.  deren Formalisierung, indem vom Kontext und von den Spezifika der einzelnen Situation abstrahiert wird und schließlich
3.  der Übersetzung dieser formalisierten Abbildung sozialer Phänomene in Algorithmen (vgl. Rolf 2008).

Je besser eine Software auf die spezifischen Arbeitsweisen einer Einrichtung angepasst werden soll, desto aufwendi-


<!-- PAGE 2 -->


## Durchblick Veränderte Fachlichkeit durch Digitalisierung?

ger ist der Prozess einer solchen Formalisierung - egal, ob für die Neuentwicklung von Software oder das ,Customi zing' von Standardsoftware, also die Anpassung auf der Ebene der Konfiguration. Viele Einrichtungen kennen das aus ei -gener Erfahrung.

Soziale Wirklichkeit ist allerdings nur begrenzt als Code abbildbar. Rolf spricht in diesem Zusammenhang von einer ,vorläufigen' und einer ,notwendigen Formalisierungslücke'. Bestimmte Dinge, wie etwa Kreativität, würden sich gar nicht formalisieren und in Software überführen lassen, andere Dinge wiederum prinzipiell schon, aber vorläufig noch nicht, weil uns hierzu bislang die technischen Möglichkei ten fehlen oder der Aufwand dafür zu groß ist und es somit ökonomisch inakzeptabel wäre. Vorläufige Formalisierungslücken zeichnen sich demnach dadurch aus, dass es sich um prinzipiell automatisierbare Handlungsroutinen handelt (Rolf 2008). Nun stellt sich die Frage, ob diese von Rolf be schriebene ,notwendige' Formalisierungslücke durch Künstliche Intelligenz nicht deutlich verkleinert wird oder sich sogar zu einer nur ,vorläufigen' Formalisierungslücke wandelt.

## Künstliche Intelligenz durch maschinelles Lernen

Das Neue an Technologien wie Big Data Analytics, maschinellem Lernen und Künstlicher Intelligenz (KI) besteht darin, dass nicht nur strukturierte Daten, sondern auch unstrukturierte Daten wie (Frei-) Texte, Audio- und Video daten maschinell verarbeitet werden können. Dies eröffnet die Möglichkeit, hieraus Ähnlichkeiten und Regelmäßigkei- ten zu analysieren sowie weitere Informationen mittels Mustererkennung zu extrahieren. Dafür bieten sich künstliche neuronale Netze (KNN) an, in die diese Daten eingespeist werden. Als lernendes System erarbeitet sich das künstliche neuronale Netz den Klassifikator, mittels dessen Daten kategorisiert werden, eigentätig bzw. verbessert ihn in seiner Genauigkeit. Auf diese Weise sind dank eines KNN nichtlineare Klassifikationen in praxisnahen Anwendungsfeldern möglich (vgl. Abb. 1).

In vielen Bereichen, in denen eine modell- und regelbasierte Formalisierung nur schwer zu realisieren ist - z.B. eine Definition von Regeln, nach denen ein Algorithmus eindeutig entscheiden kann, ob es sich bei einem Bild bzw. einer spezifischen Anordnung von Pixeln, um einen Baum handelt - bietet maschinelles Lernen auf der Basis neuronaler Netze nunmehr die Möglichkeit, genau eine solche Unterscheidung und Bilderkennung auf der Grundlage von klassifizierten Trainingsdaten (bei dem Beispiel: sehr viele Bilder, die dahingehend kategorisiert wurden, ob bzw. wo darauf ein Baum zu sehen ist) mit zunehmender Datenmenge immer sicherer vorzunehmen.

Eine explizite Regel, nach welchen Kriterien der Algorithmus die Daten klassifiziert (wie dies in klassischen Fachanwendungen der Sozialen Arbeit üblich ist), gibt es bei Anwendungen der künstlichen Intelligenz nicht. Vielmehr wird die Regelhaftigkeit der Klassifikation erst durch den Algorithmus erarbeitet und ist damit einerseits stark von den Trainingsdaten abhängig und andererseits nicht ohne wei-

Abb.1.: Nichtlineare Klassifikation (Stecker 1997, S. 4)

<!-- image -->


<!-- PAGE 3 -->


teres offenlegbar, weshalb diese Verfahren mittlerweile vermehrt in die Kritik geraten: so werden etwa Kreditvergaben auf der Basis von Scorings, die unterschiedlichste, im Netz verfügbare Daten zu einer Person, nutzen, wegen der Intransparenz ihrer Bewertungskriterien kritisiert.

Durch Big Data und KI schließt sich die von Rolf beschrie ben ,vorläufige Formalisierungslücke' in rasanter Weise, wie nicht zuletzt die Fortschritte etwa in den Bereichen der Spra -cherkennung und Sprachsteuerung oder des autonomen Fahrens zeigen. Welche ,notwendigen Formalisierungslücken' am Ende der Entwicklung von Künstlicher Intelligenz noch verbleiben werden, ist derzeit wohl kaum seriös einzuschätzen.

## Einfluss von Algorithmen auf die Arbeitspraxis Sozialer Arbeit

KI durchdringt bislang der algorithmischen Verarbeitung verschlossene Bereiche und macht immer mehr digital erfassbare ,Lebensäußerungen' von Menschen auswertbar. Entsprechend finden diese Informationen zunehmend Verwendung in Entscheidungen von Unternehmen und Organisationen, bis dahin, dass menschliche durch algorithmische Entscheidungen ersetzt werden. Dabei ist auch ohne KI schon ein deutlicher Einfluss von Software auf Entscheidungen auch in der Sozialen Arbeit festzustellen. Generell kann die Unterstützung durch Software sowohl zu einer Ermächtigung von Professionellen als auch zu einer De-Professionalisierung, etwa durch die Einschränkung von Ermessensspielräumen, führen (Ley/Seelmeyer 2004). Kategorisierungen und Typisierungen, die in der Software z.B. über Auswahlfelder oder standardisierte Diagnosemanuals erfasst werden, können den Blick auf Aspekte lenken, die sonst übersehen werden würden, aber auch den Blick verengen und damit eine ganzheitliche Betrachtung des Falls erschweren oder etikettierende Zuschreibungen befördern. Insbesondere wenn Kategorisierungen und Standardisierungen auf der Ebene der Adressat\_innen verbunden werden mit einer Standardisierung auf der Ebene der Hilfeangebote, wenn also aus bestimmten ,Diagnosen' automatisch Entscheidungen über die Auswahl und Ausgestaltung von Hilfen abgeleitet werden, führt dies zu besonders schwerwiegenden Einschränkungen der Ermessensspielräume (Høybye-Mortensen 2015).

Besondere Aufmerksamkeit erhielt das Verfahren zur Urteilsbildung bei Kindeswohlgefährdung, das mittlerweile in mehreren Bundesstaaten der USA Anwendung findet: das California Family Risk Assessment-Tool (CFRA). Obgleich dieses Verfahren noch nicht mit Anwendungen von künstlicher Intelligenz gleichgesetzt werden kann, verändert es dennoch die bisherige Urteilsbildung grundlegend, da es der Statistik einen - wenn nicht sogar den - wesentlichen Platz einräumt und die professionelle Urteilskompe- tenz der Fachkräfte mit computergestützten Prognosen in einen Wettstreit hinsichtlich der Treffsicherheit gerät. Anders als in diskursiven Verfahren zur Einschätzung spielen in diesem Verfahren weder mögliche Lösungsansätze noch ursächliche Problemstrukturen eine herausragende Rolle. Vielmehr werden 'die Items ausschließlich für den begrenzten Zweck der Risikoeinschätzung ausgewählt und hinsichtlich ihrer prognostischen Kraft empirisch getestet' (Schrödter et al. 2018). Die hohe Treffsicherheit von statistischen Prognosen hinsichtlich der Risikoanalyse wird dabei irrtümlicherweise oft mit einer Aussage über eine Interventionsentscheidung gleichgesetzt (vgl. Schrödter et al. 2018).

Die klassifikatorisch-statistischen Verfahren verdeutlichen bereits sehr gut, dass eine Formalisierung von sozialer Wirklichkeit zunehmend möglich ist - und diese Formalisierungsmöglichkeit wird in Anwendungsszenarien mit Hilfe von Big Data Analysen schon gar nicht mehr infrage gestellt. Die Analyse von großen, schnell generierten und transferierten, strukturierten und unstrukturierten Datenmengen mit sehr unterschiedlichen Datenformaten bildet hierbei die Grundlage einer Vorhersage. Mittels der Mustererkennung sollen Vorhersagekriterien bspw. für eine Kindeswohlgefährdung eigentätig und dynamisch durch den Algorithmus erkannt werden. Ziel ist es, die Aussagekraft solcher Vorhersagen nicht nur auf die Bevölkerungsebene zu beschränken, sondern unter Einbeziehung zusätzlicher Datenbanken auf die Individualebene zu erweitern (vgl. Schrödter et al. 2018).

## Neue Verfahren nur vermeintlich objektiv

So lohnenswert dieses Vorhaben klingt - wird mit einer verbesserten Prognosefähigkeit doch stets auch eine bessere Versorgung der Bedürftigen versprochen - so birgt es gleichsam nicht zu vernachlässigende Herausforderungen. Denn mit einer Formalisierung wird häufig eine vermeintliche Ob -jektivierung assoziiert. Dabei muss die Rede von Objektivität schon daran scheitern, dass sich innerhalb unstrukturierter Daten versteckte Verzerrungen finden lassen. Da ein Algorithmus die in ihm enthaltenden Daten nur kristallisieren und verschärfen kann, besteht stets die Gefahr, hier Vorurteile zu reproduzieren bzw. zu verstärken (u.a. Dat ta et al. 2015).

Zugleich machen Gillingham und Graham darauf aufmerksam, dass es nicht nur durch die Generierung der Daten zu einer subjektiven Einfärbung kommt, sondern auch durch Forscher\_innen und Entwickler\_innen: Im Rahmen der Datenextraktion müssen Daten in entsprechende Formate umgewandelt, gefiltert und gereinigt werden, um sie für statistische Analysen und algorithmische Berechnungen nutzbar zu machen. Hierbei wird entschieden, welche Variablen oder Merkmale die ein- und auszuschließenden Daten enthalten und wie mit unvollständigen Datensätzen umgegangen werden soll (Gillingham/Graham 2016).


<!-- PAGE 4 -->


## Durchblick Veränderte Fachlichkeit durch Digitalisierung?

Dieses Problem der vermeintlichen Objektivität verstärkt sich bei selbstlernenden Systemen im Falle ungewollter Mustererkennung. So können fehlerhafte Verknüpfungen oder falsche Fokus-Setzungen des Algorithmus durch unerwartete Korrelationen zu schwerwiegenden Fehlentschlüssen führen. Zugleich liegt der Teufel bei Big Data Anwendungen im Detail, denn die verwendeten Daten für die Prognose müssen noch nicht einmal vom Individuum selbst stammen, denn es wird auch mittels Daten von ähnlichen Personen auf das statistisch durchschnittliche Verhalten einer Person geschlossen. Dies kann Stigmatisierungen begünstigen; wird doch nicht das hinter den Ergebnissen der Da tenanalyse stehende Individuum betrachtet, sondern lediglich die Häufigkeitsverteilung innerhalb seines ,Milieus'. Es lohnt daher, sich die Methodologie der Wahrscheinlichkeits rechnung eines Algorithmus zu vergegenwärtigen, um mögliche falsch-negative und falsch-positive Ergebnisse zu erkennen und einordnen zu können.

## Neue Anforderungen an Fachlichkeit

Die neuen Herausforderungen, die im Zusammenhang mit Big Data und KI entstehen, verdeutlichen: Sowohl 'data literacy' als kompetenter Umgang mit komplexen Datenquellen und anspruchsvollen Verfahren zu deren Verarbeitung als auch ein konsequenter Persönlichkeitsschutz mit Blick auf die Nutzung vielfältiger Datenquellen bilden neue Anforderungen an die Professionalität von Fachkräften. Gleichsam wird deutlich, dass ein gelingender Umgang mit den genann ten Herausforderungen allein damit noch nicht gewährleistet ist. Denn die Effekte der neuen Technologien sind weder durch die Technik determiniert noch durch die Anwender\_ innen beliebig steuerbar. Vielmehr sind neue Technologien nach Finck und Janneck (2008) als soziotechnische Systeme mit sozio-technischer und technik-sozialer Wirkungsrichtung zu begreifen. Vor diesem Hintergrund gilt es, den eigenen Handlungsspielraum innerhalb dieses Arrangements zu begreifen und nicht zu verleugnen.

Um die Stellung der Fachkräfte gegenüber neuer Technologie formal zu stärken, könnte ein erster Schritt darin bestehen, nur Systeme algorithmischer Entscheidungsfindung zuzulassen, die menschliche Entscheidungen lediglich unterstützen und nicht ersetzen. Hierdurch könnte der oben beschriebene Fehlschluss - die Treffsicherheit des Algorithmus bezüglich einer Prognose mit der Aussage über eine mögliche Intervention zu verwechseln - umgangen werden, da Fra gen der Intervention klar in den Handlungsraum der Fachkräfte fielen. Allerdings ist diese formale Stärkung nur be dingt hilfreich, wenn durch das System darüber hinaus auch mögliche Interventionen vorgeschlagen und gewichtet werden und diese somit auf den Ermessensspielraum der Fachkräfte beeinflussend einwirken. Ob und inwiefern von den Vorschlägen des Algorithmus abgewichen werden kann, darf oder sogar muss, wird dann auch zu einer rechtlichen Fra ge. Das Projekt ,Maschinelle Entscheidungsunterstützung in wohlfahrtsstaatlichen Institutionen: Nutzungsoptionen, Implikationen und Regulierungsbedarfe' (MAEWIN), an dem die Autor\_innen beteiligt sind, will in den nächsten Jahren genau solchen Fragen nachgehen.

## Debatte erforderlich

Der Einsatz neuer Technologien wie Big Data Analytics, maschinellem Lernen und künstlicher Intelligenz im Anwendungsfeld Sozialer Dienste erfordert hinsichtlich der Generierung, Verarbeitung und Verwendung von Daten eine sehr weitreichende Sensibilisierung von Fachkräften. Gleichzeitig muss der Fokus über die Technik hinaus erweitert werden, um Fragen hinsichtlich der Etablierung stellen und der Herausforderung KI in der Sozialen Arbeit begegnen zu können. Soziale Arbeit braucht eine Debatte darüber, welche bis lang nicht verfügbaren Formen von Wissen die neuen Technologien erzeugen können, wo die Grenzen dieses Wissens liegen und wie es sinnvoll in fachliche Reflexions- und Entscheidungspraxen eingebunden werden kann. s

∑

<!-- image -->

<!-- image -->