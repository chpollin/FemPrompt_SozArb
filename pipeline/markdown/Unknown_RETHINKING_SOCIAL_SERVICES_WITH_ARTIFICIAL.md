---
source_file: Unknown_RETHINKING_SOCIAL_SERVICES_WITH_ARTIFICIAL.pdf
conversion_date: 2026-02-03T18:59:36.858346
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
International Studies in

## SOCIAL SCIENCES and HUMANITIES

EDITOR

PROF. DR. HAKAN ALTINTAŞ

<!-- image -->


<!-- PAGE 2 -->


Genel Yayın Yönetmeni / Editor in Chief · Eda Altunel

Kapak &amp; İç Tasarım / Cover &amp; Interior Design

Birinci Basım / First Edition

• © Haziran 2025

ISBN

•978-625-5897-43-5

## © copyright

Bu kitabın yayın hakkı Serüven Yayınevi'ne aittir. Kaynak gösterilmeden alıntı yapılamaz, izin almadan hiçbir yolla çoğaltılamaz. The right to publish this book belongs to Serüven Publishing. Citation can not be shown without the source, reproduced in any way without permission.

Serüven Yayınevi / Serüven Publishing

Türkiye Adres / Turkey Address:

Kızılay Mah. Fevzi Çakmak 1. Sokak

Ümit Apt No: 22/A Çankaya/ANKARA

Telefon / Phone:

05437675765

web:

www.seruvenyayinevi.com

e-mail:

seruvenyayinevi@gmail.com

## Baskı &amp; Cilt / Printing &amp; Volume

Sertifika / Certificate No: 42488

• Serüven Yayınevi


<!-- PAGE 3 -->


## INTERNATIONAL STUDIES in SOCIAL SCIENCES and HUMANITIES

## EDITOR PROF. DR. HAKAN ALTINTAŞ

<!-- image -->


<!-- PAGE 4 -->


<!-- image -->

,,

## Chapter 6

## RETHINKING SOCIAL SERVICES WITH ARTIFICIAL INTELLIGENCE: OPPORTUNITIES, RISKS, AND FUTURE PERSPECTIVES

Ferhat TOPER1

1 Associate Professor, Malatya Turgut Özal University Faculty of Health Sciences Department of Social Work, ORCID: 0000-0001-6398-5343, ferhat.toper@ozal.edu.tr


<!-- PAGE 5 -->


## Introduction

Arti fi cial intelligence (AI), de fi ned as computer technologies and machine  learning  capable  of  mimicking  human  intelligence,  encompasses technologies that learn using logic and solve complex problems (Kalota, 2024). AI has emerged as one of the most impressive technological developments in recent years due to its ability to predict future events based on past data. AI is designed to perform tasks that require human intelligence, such as learning from data, solving problems, and making accurate decisions in uncertain conditions (Ahn, Choi, Fowler, &amp; Song, 2025). Th is  technological advancement is shaping the way people learn, make decisions, communicate, and work by a ff ecting many aspects of daily life (Maslej &amp; Fattorini, 2024).

Recent  developments  in  AI  are  having  a  transformative  impact  on many industries, including healthcare worldwide (Shah, et al., 2019). AI applications, particularly those in the healthcare sector, are used in areas such as diagnosis, treatment, automating repetitive tasks, reducing dosage errors, managing medical records, analyzing patient scans, and providing customer service through chatbots (Rong, Mendez, Assi, Zhao, &amp; Sawan, 2020). AI tools used in critical areas such as mental health and risk prediction are employed in therapeutic settings to enhance individuals' well-being (Balan, Dobrean, &amp; Poetar, 2024).

## Arti fi cial Intelligence and Social Work

Social  workers,  who  play  critical  roles  in  addressing  complex  social issues, face various challenges due to limited resources, heavy workloads, and weak inter-agency collaboration (Li, Wang, &amp; Jian, 2025). AI is a new and  potentially  bene fi cial  technological  development  for  social  service professionals, who have played important roles in solving the problems brought about by social  change  and  transformation  for  over  a  century worldwide (Garkisch &amp; Goldkind, 2025). One of the basic functions of social services is to guide and analyze changes in individuals and communities. Th e challenges and conveniences brought about by digitalization and technological advancements are among the most signi fi cant changes for individuals and communities in today's societies (Dufva &amp; Dufva, 2019). In this context, digital change and transformation are increasingly gaining importance in social work practices (Goldkind, 2021).

Although studies on the use of AI in social service delivery are still in their infancy, AI has made positive contributions in the areas of mental health (Walsh, Ribeiro, &amp; Franklin, 2017), domestic violence (Hui, Constantino, &amp; Lee, 2023), and child protection (Field, et al., 2023). By analyzing large datasets, AI can predict risks associated with vulnerable individ-


<!-- PAGE 6 -->


uals, making it a highly useful tool for early intervention (Boetto, 2025).

Th e use of AI in the fi eld of social work is evident in supporting individuals' decision-making processes, conducting analyses related to needs assessment and resource allocation, and making predictions (Cresswell et  al.,  2020).  Reamer  (2023)  states  that  AI  has  the  potential  to  increase the e ff ectiveness and capacity of social workers in administrative, clinical, and policy contexts. Meilvang (2024) states that social workers who use AI in administrative tasks can devote more time to their core duties. In fact, the intersection of AI and social work lies in enhancing the e ff ectiveness  of  the  social  work  profession  and  improving  the  well-being  of individuals and communities through new methods and models that will be developed.

Th e use of AI and other technologies in social service applications enables the expansion of service delivery and provides support to individuals and communities that social service professionals have di ffi culty reaching through online platforms and video conferencing (Pascoe, 2023).

Victor and Goldkind (2025) state that ChatGPT, a large language model introduced by OpenAI in late 2022 and recognized globally, has begun to be used as a 'public therapist.' Similar AI tools are increasingly being used in the fi eld of mental health (Farhat, 2023). For example, the use of these platforms, which provide a non-judgmental environment for users in areas such as support for individuals in the grieving process and the development of social skills, is becoming more widespread every day (Giray, 2024). In another example, McNally et al. (2024) state that families with autistic children communicate with AI tools without having to go to the hospital, wait in line, or fear stigmatization.

## Th e  Application Potential of Arti fi cial Intelligence in the Field of Social Services: Opportunities and Contributions

Th e  integration  of  AI  into  social  work  applications  creates  various opportunities  for  both  social  workers  and  clients. Th is  technological transformation enables social workers to analyze case-related data more quickly and e ff ectively, reduce administrative burdens, allocate more time to professional practices, identify risk situations early, and plan services in a more comprehensive manner. Social workers can analyze large data sets, predict risks, and make more e ff ective assessments through AI (Toli &amp; Manasa, 2024). Th ey can also automate administrative tasks through virtual  assistants,  allowing  them  to  devote  more  time  to  professional practice. Alowais et al. (2023) have noted that AI cannot replace social workers but can optimize many processes to make them more e ff ective and e ffi cient.


<!-- PAGE 7 -->


Th e  use  of  AI  in  social  service  applications  can  provide  signi fi cant bene fi ts in areas such as developing personalized services (Bako &amp; Taylor, 2021), predictive thinking (Gillingham, 2011), and improving quality control (Kum, Stewart, Rose, &amp; Duncan, 2015).

Data analysis and predictive modeling are among the most powerful applications of AI in the social services fi eld. Th is is because AI can quickly scan large data sets that would take a long time for humans to scan and analyze, making it way easier for practitioners (Fernando &amp; Ranasinghe, 2023). For example, data from multiple sources, like police reports, health service databases, and school records, can be analyzed to identify kids at risk of neglect or abuse. Similarly, when used in the same way, community-level  data  can  be  examined  to  identify  areas  of  substance  use  and take proactive measures (resource allocation, risk mapping, etc.) for these areas (Vijayakumar, Seetharaman, &amp; Maddulety, 2023).

For social service professionals, administrative tasks in the fi eld consume a large  portion  of  their  time,  which  means  less  time  is  available to  work  with  clients.  At  this  point,  AI-supported  administrative  automation systems can take on routine but necessary tasks such as scheduling appointments, collecting preliminary information from clients, and answering frequently asked questions (Anda, 2001). Resource allocation in the social work fi eld is of critical importance, especially in countries and  regions  with  limited  resources.  AI  models  can  play  an  important role in e ff ective, goal-oriented planning in resource allocation (Fernando &amp; Ranasinghe, 2023). For example, by analyzing data sets related to the demographic  structure  of  the  community,  emerging  issues,  and  previously provided services, the areas where resources are most e ff ective can be identi fi ed (Tu ff ord &amp; Newman, 2010). Making data-driven decisions through AI can ensure that services reach the right people at the right time, which not only improves service quality but also increases cost-effectiveness (Dittakavi, 2022).

In addition, chatbots can play an important role as a fi rst line of support for cases requiring urgent intervention in the fi eld of mental health. Chatbots  that  provide  quick  and  algorithmic  responses  based  on  the symptoms  and  concerns  expressed  by  individuals  in  crisis  situations may not replace medical and clinical intervention, but they can serve as a bridge to professional support by providing emotional support in cases where experts are not immediately available (Fernando &amp; Ranasinghe, 2023). From the perspective of applicants, it creates opportunities in terms of overcoming geographical barriers to facilitate access to services, enabling applicants who are concerned about face-to-face meetings to access services, and reducing stigma. In this way, social service processes


<!-- PAGE 8 -->


can become faster and more e ff ective.

## Arti fi cial Intelligence and Social Services: Limitations and Ethical Questions

Th ere  are  various  challenges  associated  with  the  use  of  AI  in  social service applications. Chief among these is the concern that relationships may be automated, moving away from a case-speci fi c, individualized approach. Other concerns include the weakening of human relationships and empathy at the core of the service, biases embedded in algorithms, and discrimination against vulnerable groups. Th ere  are  also  concerns that surveillance conducted through AI during social service applications may violate  individuals'  privacy  rights  (Reamer  F.,  2023).  AI  tools  can play roles in many areas of social work practice, such as analyzing written records, comparing data sets, conducting risk assessments, and providing crisis prevention and assistance (Reamer F., 2023). However, despite their potential to bring about signi fi cant change in social work practice, AI tools also raise some concerns. Th ese concerns relate to the potential for excessive dependence (Dis, Bollen, Zuidema, Rooij, &amp; Bockting, 2023) and the erosion of the human skills and values that form the core of the social work profession (Oak, 2016).

Although developments in AI promise to revolutionize social service applications (Marquart &amp; Goldkind, 2023), the impact of using AI in social service delivery on the protection of human rights must be assessed (Garkisch &amp; Goldkind, 2025).

It is noted that AI fundamentally transforms social systems in terms of decision-making processes, access to resources, and in fl uence on policies (Ahn, Choi, Fowler, &amp; Song, 2025). However, it has been argued that while technologies such as AI o ff er signi fi cant opportunities, they also have the potential to further deepen existing inequalities when developed primarily by privileged and homogeneous groups (Farahani &amp; Ghasemi, 2024). Eubanks (2019) argues that AI tools can reinforce structural biases and negatively a ff ect vulnerable population groups, particularly low-income individuals (Eubanks, 2019, cited in Ahn et al., 2025). Th ese deepening inequalities are concerning for social workers, whose mission is to serve disadvantaged groups and advocate on their behalf. Coeckelberg (2022) notes that global inequalities have deepened due to the concentration of AI development activities in developed and wealthy countries, which has excluded disadvantaged communities from policy-making processes and weakened democratic representation (cited in Ahn et al., 2025).

Many AI models require large data sets to function, and this information o ft en includes personal data (Ferguson, 2005). Th is entails risks


<!-- PAGE 9 -->


such as the collection, storage, misuse, or unauthorized access of personal data. Although options such as encryption and two-factor authentication are available, the risk of data breaches and unauthorized use always exists (Gesi, Shen, Geng, Chen, &amp; Ahmed, 2023). Additionally, there is always the risk of serious problems, such as incorrect decisions being made based on these large data sets. Th is is because AI tools rely on analyzing existing data and making predictions. However, from the perspective of the social work profession, each case is unique, each individual is unique, and individuals must be evaluated within their context without being detached from it. Similarly, there is also a risk that AI algorithms may cause bias. An AI tool trained with biased data sets can perpetuate systematic discrimination and thus undermine the professional values of social work, which aims to promote social justice (Fernando &amp; Ranasinghe, 2023). For example, if an algorithm used for a speci fi c type of assistance is trained with data that predominantly represents a particular economic or racial group, that type of assistance may be allocated to similar economic and racial groups, inadvertently perpetuating existing inequalities.

Another concern that has been raised is the loss of the human touch with the integration of AI into social service applications. Th is aspect of the social service profession, which is based on human interaction, empathy, and unconditional positive regard, cannot be fully replicated by AI algorithms, no matter how advanced they become. Th is could erode the interpersonal relationships that form the core of social work, turning it into an automated system and creating a negative process for clients who already feel vulnerable and marginalized (Vijayakumar, 2023). E ff ective social work interventions o ft en rely on professionals' ability to understand complex emotional and social situations to reach a solution. Th e nuances of trust, empathetic listening, and understanding body language between the social worker and the client cannot be fully replicated by AI tools, no matter how advanced they may be (Fernando &amp; Ranasinghe, 2023).

## Ethical Concerns

Ethical  issues  are  among  the  most  fundamental concerns regarding the use of AI in social work practice. Th e use of AI raises notable ethical challenges such as client autonomy, privacy, con fi dentiality, transparency,  misdiagnosis,  misrepresentation,  bias,  injustice,  and  generalization (Fr ą ckiewicz, 2025; Rubeis, 2022).

Social  workers,  when  working  with  clients,  have  considered  it  their duty to explain both the bene fi ts and potential risks of the services they o ff er, viewing this as part of the informed consent process (Reamer, 2006). Similarly, when social workers use AI in practice, they must not only ex-


<!-- PAGE 10 -->


plain the bene fi ts and risks but also respect clients' decisions regarding whether or not to accept the use of AI (Reamer, 2023). Th e NASW Code of Ethics (2021) clearly states this: 'Social workers who use technology in the delivery of social work services must obtain informed consent from individuals using these services during the initial assessment or interview and before beginning the service.'

Social  workers who use AI during social work interventions are responsible for ensuring the con fi dentiality  of  the  data  they  collect  from clients. Th ey are obligated to ensure that the AI tool they use is properly encrypted and protected at the highest level (Reamer, 2023). Th is is clearly stated in the NASW Code of Ethics (2021) as follows: 'Social workers should take reasonable steps to protect the con fi dentiality of electronic communications,  including  information  provided  to  parties  and  third parties.'  Social  workers  should  apply  appropriate  protective  measures (encryption, fi rewalls, and passwords) when using electronic communications such as email, online sharing, online chat sessions, mobile communications, and text messages.'

Clinical social workers who use AI tools to assess behavioral disorders should take precautions to minimize the possibility of misdiagnosis. Misdiagnosis  can  lead  to  unnecessary  and  even  harmful  interventions (Reamer, 2023). Yan et al. (2023) recently stated that AI tools cannot replace clinicians in diagnosing mental disorders.

One of the most important ethical issues raised regarding the use of AI tools in social work practice is algorithmic bias and injustice. Th is is because AI is machine learning and learns from large data sets. Th is poses signi fi cant risks because it may not always re fl ect the characteristics of the client groups served by social workers. Th is risk may include serious biases toward vulnerable groups in terms of race, gender, ethnicity, and gender identity during client assessment and intervention planning (Lee, Resnick, &amp; Barton, 2019).

AI  technology  is  changing  and  developing  much  faster  than  other technological  developments. Th is  situation  highlights  the  fact  that  social  workers  have  certain  responsibilities  regarding  evidence-based  social work practices. Professionals who integrate AI tools into social work practices  have  ethical  responsibilities  to  follow  developments  based  on AI research and adapt their practices accordingly (Reamer, 2023). Th ese ethical  responsibilities  are  similar  to  those  involved  in  following  other evidence-based social work practices and integrating them into their own practices.


<!-- PAGE 11 -->


## Conclusion

Th e  use  of  AI  is  rapidly  increasing  in  many  areas,  including  social services.  As  in  other  areas,  there  are  ethical  challenges  and  risks  associated with the use of AI in social services, in addition to its bene fi ts. A number of bene fi ts can be mentioned, such as the planning of services, the  analysis  of  data  sets,  the  automation  of  administrative  tasks  to  allow more time for professional practice, easier access to social services for population groups that cannot access them due to geographical and cognitive barriers, the ability to perform risk analysis for sensitive population groups, and the facilitation of early diagnosis and warning. However, alongside these bene fi ts,  there  are  also  some challenges and risks. Th ese revolve around issues such as informed consent, client autonomy, privacy and con fi dentiality, the risk of misdiagnosis, surveillance, transparency-related  issues,  algorithmic  bias,  and  injustice.  Social  workers should be aware of the opportunities and risks that will arise from the integration of AI into social work practices and take proactive steps. Th ey should review ethical standards regarding the use of AI and adapt them to the institutions where they work. Institutions should design training programs to ensure that their employees can use AI tools appropriately and in accordance with ethical standards during practice. In addition, curriculum changes should be made in social service departments at universities regarding the use of AI so that future social service professionals can be taught how to use AI tools correctly and in accordance with ethical  standards during implementation. Finally, social service academics and practitioners should conduct comprehensive research on the use of AI in professional practice and establish standards regarding the impact, limitations, and algorithmic biases of this technology. Th is is because the integration of AI into social work is only possible through a multidisciplinary approach involving not only technologists but also social work professionals, academics, and policymakers (Khanna &amp; Srivastava, 2020). Th is  integration is very important as it o ff ers numerous advantages for both social work professionals and clients.


<!-- PAGE 12 -->


## REFERENCE

- Ahn, E., Choi, M., Fowler, P., &amp; Song, I. H. (2025). Artificial Intelligence (AI) Literacy for Social Work: Implications for Core Competencies. Journal of the Society for Social Work and Research,, 16 (1), 9-26. doi: 10.1086/735187
- Alowais, S. A., Alghamdi, S. S., Alsuhebany, N., Alqahtani, T., Alshaya, A. I., Almohareb, S. N., . . . Albekairy, A. (2023). Revolutionizing healthcare: the role of artificial intelligence in clinical practice. BMC Medical Education, 23 (1). https://doi.org/10.1186/s12909-023-04698-z
- Anda, D. d. (2001). A qualitative evaluation of a mentor program for at-risk youth: The participants' perspective,. Child &amp; Adolescent Social Work Journal, 18 (2), 97-117. https://doi.org/10.1023/A:1007646711937
- Bako,  A.  T.,  &amp;  Taylor,  H.  L.  (2021).  Using  Natural  Language  Processing  to Classify Social Work Interventions .  The American Journal of Managed Care, 27 (1), 24-31 . doi: 10.37765/ajmc.2021.88580.
- Balan, R., Dobrean, A., &amp; Poetar, C. R. (2024). Use of automated conversational agents in improving young population mental health: a scoping review. Dijital Medicine, 7 (75). https://doi.org/10.1038/s41746-024-01072-1
- Boetto,  H.  (2025).  Artificial  Intelligence  in  Social  Work:  An  EPIC  Model  for Practice. Australian Social Work .
- Cresswell,  K.,  Callaghan,  M.,  Khan,  S.,  Sheikh,  Z.,  Mozaffar,  H.,  &amp;  Sheikh, A.  (2020).  Investigating  the  use  of  data-driven  artificial  intelligence in  computerised decision support systems for health and social care: A systematic  review. Health  Informatics  Journal,  26 (3),  2138-2147.  doi: 10.1177/1460458219900452.
- Dis,  E.  A.,  Bollen,  J.,  Zuidema,  W.,  Rooij,  R.  v.,  &amp;  Bockting,  C.  L.  (2023). ChatGPT: five priorities for research. Nature (614), 224-226. DOI: 10.1038/ d41586-023-00288-7
- Dittakavi, R. S. (2022). Evaluating the Efficiency and Limitations of Configuration Strategies  in  Hybrid  Cloud  Environments. International  Journal  of Intelligent Automation and Computing, 5 (2), 29-45.
- Dufva, T., &amp; Dufva, M. (2019). Grasping the future of the digital society. Futures, 107 , 17-28. https://doi.org/10.1016/j.futures.2018.11.001
- Farahani, M. S., &amp; Ghasemi, G. (2024). Artificial Intelligence and Inequality: Challenges and Opportunities. Qeios ,  1-14.    DOI:  10.32388/7HWUZ2
- Farhat,  F.  (2023).  ChatGPT  as  a  Complementary  Mental  Health  Resource:  A Boon or a Bane. Annals of Biomedical Engineering, 52 (5), 1111-1114. DOI: 10.1007/s10439-023-03326-7
- Ferguson, K. M. (2005). Beyond indigenization and reconceptualization: Towards a  global,  multidirectional  model  of  technology  transfer. International Social Work , 48 (5), 519-535. DOI: 10.1177/0020872805055315
- Fernando, N., &amp; Ranasinghe, P. (2023). Integration of Artificial Intelligence in Social Work: Opportunities, Challenges, and Considerations. Journal of Computational Social Dynamics, 8 , 13-24. Retrieved from https://vectoral.


<!-- PAGE 13 -->


org/index.php/JCSD/article/view/35

- Field,  A.,  Coston,  A.,  Gandhi,  N.,  Chouldechova,  A.,  Putnam-Hornstein,  E., Steier,  D.,  &amp;  Tsvetkov,  Y.  (2023).  Examining  risks  of  racial  biases  in NLP tools  for  child  protective  services. Proceedings  of  the  2023  ACM Conference  on  Fairness,  Accountability,  and  Transparency ,  1479-1492. https://doi.org/10.48550/arXiv.2305.19409
- Frąckiewicz, M. (2025, April 10). Inside DeepSeek AI: The Chinese Foundation Model  Powerhouse  Revolutionizing  Open-Source  AI  in  2025 .  TS2. Retrieved  from  https://ts2.tech/en/comprehensive-overview-of-deepseekai/
- Garkisch, M., &amp; Goldkind, L. (2025). Considering a Unified Model of Artificial Intelligence  Enhanced  Social  Work:  A  Systematic  Review. Journal  of Human Rights and Social Work, 10 , 23-42. https://doi.org/10.1007/s41134024-00326-y
- Gesi, J., Shen, X., Geng, Y., Chen, Q., &amp; Ahmed, I. (2023). Leveraging Feature Bias for Scalable Misprediction  Explanation  of  Machine  Learning Models. International Conference on Software Engineering (ICSE). DOI: 10.1109/ICSE48619.2023.00135
- Gillingham, P. (2011). Computer-based information systems and human service organisations: Emerging problems and future possibilities. Australian  Social  Work,  64 (3),  299-312.  https://doi.org/10.1080/031240 7X.2010.524705
- Giray, L. (2024). Cases of Using ChatGPT as a Mental Health and Psychological Support Tool. Journal of Consumer Health on the Internet, 29 (1), 29-48. DOI: 10.1080/15398285.2024.2442374
- Goldkind, L. (2021). Social work and artificial intelligence: Into the matrix. Social Work, 66 (4), 372-374. https://doi.org/10.1093/sw/swab028
- Hui, V., Constantino, R. E., &amp; Lee, Y. J. (2023). Harnessing Machine Learning in  Tackling  Domestic  Violence-An  Integrative  Review. International Journal  of  Environmental  Research  and  Public  Health,  20 (6).  doi: 10.3390/ijerph20064984.
- Kalota,  F.  (2024).  A  Primer  on  Generative  Artificial  Intelligence. Education Sciences , 14 (2). https://doi.org/10.3390/educsci14020172
- Khanna, S.,  &amp;  Srivastava,  S.  (2020).  'Patient-Centric  Ethical  Frameworks  for Privacy,  Transparency,  and  Bias  Awareness  in  Deep  Learning-Based Medical Systems. Applied Research in Artificial Intelligence and Cloud Computing, 3 (1), 16-35. Erişim Linki: https://researchberg.com/index.php/ araic/article/view/165/154
- Kum, H.-C., Stewart, C. J., Rose, R. A., &amp; Duncan, D. F. (2015). Using big data for evidence based governance in child welfare. Children and Youth Services Review, 58 , 127-136. https://doi.org/10.1016/j.childyouth.2015.09.014
- Lee, N. T., Resnick, P., &amp; Barton, G. (2019, May 22). Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms .


<!-- PAGE 14 -->


- Brookings. Retrieved from https://www.brookings.edu/articles/ algorithmic-bias-detection-and-mitigation-best-practices-and-policies-toreduce-consumer-harms/
- Li,  L.,  Wang,  M.,  &amp;  Jian,  M.  (2025).  Artificial  Intelligence-Assisted  Case Management in Social Work Services: A Systematic Review. Research on Social Work Practice , 1-15. https://doi.org/10.1177/104973152513295
- Marquart,  M.  S.,  &amp;  Goldkind,  L.  (2023).  ChatGPT:  Implications  for  social work education and practice. Advance Online Pub- lication with: Virtual session for the 2023 NASW-NYC Social Work Month Series. https://doi. org/10.7916/axhj-x577
- Maslej,  N.,  &amp;  Fattorini,  L.  (2024). Artificial  Intelligence  Index  Report  2024. Stanford Institute for Human-Centered Artificial Intelligence.
- McNally, K., Wright, K., Goldkind, L., Kattari, S. K., &amp; Victor, B. G. (2024). Disability Expertise and Large Language Models: A Qualitative Study of Autistic TikTok Creators' Use of ChatGPT. Social Media + Society, 10 (3). https://doi.org/10.1177/20563051241279
- Meilvang,  M.  L.  (2024).  Working  the  Boundaries  of  Social  Work:  Artificial Intelligence  and  the  Profession  of  Social  Work. European  Journal  of Social Work, 27 (1), 30-42. DOI: 10.7577/pp.5108
- NASW. (2025, May 3). Code of Ethics . socialworkers.org. Retrieved from https:// www.socialworkers.org/About/Ethics/Code-of-Ethics
- Oak, E. (2016). A minority report for social work? The Predictive Risk Model (PRM) and the Tuituia Assessment Framework in addressing the needs of New Zealand's vulnerable children. The British Journal of Social Work , 46 (5), 1208-1223. DOI: 10.1093/bjsw/bcv028
- Pascoe, K. M. (2023). Considerations for integrating technology into social work practice: A content analysis of nine professional social work associations' Codes  of  Ethics. International  Social  Work,  66 (2),  298-312.  https://doi. org/10.1177/0020872820980833
- Reamer, F. (2023). Artificial Intelligence in Social Work: Emerging Ethical Issues. International Journal of Social Work Values and Ethics, 20 , 52-71. DOI: 10.55521/10-020-205
- Reamer, F. G. (2006). Ethical Standards in Social Work: A Review of the NASW Code of Ethics. NASW Press.
- Rong,  G.,  Mendez,  A.,  Assi,  E.  B.,  Zhao,  B.,  &amp;  Sawan,  M.  (2020).  Artificial Intelligence in Healthcare: Review and Prediction Case Studies. Engineering, 6 (3), 291-301. https://doi.org/10.1016/j.eng.2019.08.015
- Rubeis,  G.  (2022).  iHealth:  The  ethics  of  artificial  intelligence  and  big  data in mental  healthcare. Internet Interventions,  28 . DOI:  10.1016/j. invent.2022.100518
- Shah, P., Kendall, F., Khozin, S., Goosen, R., Hu, J., Laramie, J., . . . Schork, N. (2019). Artificial intelligence and machine  learning in clinical development: a translational perspective. Dijital Medicine , 2 (69). https://


<!-- PAGE 15 -->


doi.org/10.1038/s41746-019-0148-3

- Toli,  L.,  &amp;  Manasa,  G.  M.  (2024).  Artificial  Intelligence:  Opportunities  and Challenges  for  the  Social  Education  and  Profession. Scholars  Bulletin, 10 (4), 143-147. DOI: 10.36348/sb.2024.v10i04.005
- Tufford,  L.,  &amp;  Newman,  P.  A.  (2010).  'Bracketing  in  qualitative  research,' Qualitative  social  work,. Qualitative  Social  Work,  11 (1),  80-96.  DOI: 10.1177/1473325010368316
- Victor, B. G., &amp; Goldkind, L. (2025). The Therapist in the Machine: Confronting AI's Challenge to Clinical Social Work. Journal of Technology in Human Services, 43 (2), 73-81. https://doi.org/10.1080/15228835.2025.2500827
- Vijayakumar, H. (2023). Business Value Impact of AI-Powered Service Operations (AIServiceOps). Conference: 13th International Conference on Computer Science, Engineering and Applications (CCSEA 2023). DOI: 10.5121/ csit.2023.130502
- Vijayakumar, H., Seetharaman, A., &amp;  Maddulety, K. (2023). Impact of AIServiceOps on Organizational Resilience. 15th International Conference  on  Computer  and  Automation  Engineering. DOI:  10.1109/ ICCAE56788.2023.10111409
- Walsh, C. G., Ribeiro, J. D., &amp; Franklin, J. C. (2017). Predicting risk of suicide attempts  over  time  through  machine  learning. Clinical  Psychological Science, 5 (3), 457-469. https://doi.org/10.1177/2167702617691560
- Yan, W.-J., Ruan, Q.-N., &amp; Jiang, K. (2023). Challenges for Artificial Intelligence in  Recognizing  Mental  Disorders. Diagnostics,  13 (2).  DOI:  10.3390/ diagnostics13010002