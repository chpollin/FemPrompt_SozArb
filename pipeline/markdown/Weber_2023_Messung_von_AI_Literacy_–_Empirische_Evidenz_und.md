---
source_file: Weber_2023_Messung_von_AI_Literacy_–_Empirische_Evidenz_und.pdf
conversion_date: 2026-02-03T09:31:03.013929
converter: docling
quality_score: 95
---

## Association for Information Systems

## AIS Electronic Library (AISeL)

Wirtschaftsinformatik 2023 Proceedings

10-9-2023

## Messung von AI Literacy - Empirische Evidenz und Implikationen

## Patrick Weber

Chair of Information Systems and Information Management, Goethe University Frankfurt, Germany, weber@wiwi.uni-frankfurt.de

## Lorenz Baum

Chair of Information Systems and Information Management, Goethe University Frankfurt, Germany, baum@wiwi.uni-frankfurt.de

## Marc Pinski

Technical University of Darmstadt, Germany, pinski@ise.tu-darmstadt.de

Follow this and additional works at: https://aisel.aisnet.org/wi2023

## Recommended Citation

Weber, Patrick; Baum, Lorenz; and Pinski, Marc, "Messung von AI Literacy - Empirische Evidenz und Implikationen" (2023). Wirtschaftsinformatik 2023 Proceedings. 3.

https://aisel.aisnet.org/wi2023/3

This material is brought to you by the Wirtschaftsinformatik at AIS Electronic Library (AISeL). It has been accepted for inclusion in Wirtschaftsinformatik 2023 Proceedings by an authorized administrator of AIS Electronic Library (AISeL). For more information, please contact elibrary@aisnet.org.

Wirtschaftsinformatik

## Messung von AI Literacy - Empirische Evidenz und Implikationen

## Research in Progress

Patrick Weber 1 , Lorenz Baum 1 , und Marc Pinski 2

1  Goethe University Frankfurt, Germany, {weber,baum}@wiwi.uni-frankfurt.de 2  Technical University of Darmstadt, Germany, {pinski}@ise.tu-darmstadt.de

Abstract. Während Künstliche Intelligenz (KI) jeden Aspekt der modernen Lebens- und Arbeitswelt durchdringt, gibt es noch kein objektives Messwerkzeug, um die sozio-technischen Kompetenzen, die Mensch-KI-Interaktionen beeinflussen, zu messen. Diese digitalen Individualkompetenzen fassen wir unter dem Begriff AI Literacy zusammen. Wir definieren und konzeptualisieren AI Literacy, entwickeln gemeinsam mit Experten objektive Messfragen und lassen Wissenschaftler Card-Sorting durchführen. Wir erarbeiten ein wissenschaftlich verankertes Messinstrument mit n = 25 Fragen zur Bestimmung dieser AI Literacy, das wir in drei verschiedenen Studien (n = 134) vorläufig evaluiert haben. Wir werden das Messinstrument in drei weiteren Studien (n = ~450) evaluieren und damit den etablierten Skalenentwicklungsprozess abschließen.

Keywords: AI  Literacy,  Objektive Messung, Subjektive Messung, Konstruktentwicklung

## 1 Einführung

Der Einsatz disruptiver Technologien wie Künstlicher Intelligenz (KI/AI) nimmt einen immer größer werdenden Bereich der modernen Lebens- und Arbeitswelt im digitalen Zeitalter ein. Daher sind digitale Individualkompetenzen, insbesondere die Fähigkeit zum Umgang mit KI essentiell, um am Arbeitsmarkt erfolgreich zu sein (World Economic Forum, 2022). Auch in der Bildungsvermittlung fand und findet KI Einzug und erfordert einen geübten Umgang mit KI durch Lehrpersonal (Chen et al., 2020; Roll &amp; Wylie, 2016). Daneben wird KI auch als eine der Schlüsseltechnologien des 21. Jahrhunderts (Jain et al., 2018) bezeichnet und ihre Nutzenden und Erschaffenden sowie diejenigen, die mit Hilfe von KI Entscheidungen treffen, werden in der Lage sein müssen, KI effizient zur Problemlösung einsetzen zu können. Diese Fähigkeit beschreiben wir als sozio-technische Kompetenzen, die relevante Typen von Mensch-KI-Interaktionen beeinflussen, und subsummieren sie unter dem Begriff AI Literacy (AIL).

Menschliches Wissen kann in objektiver und subjektiver Weise gemessen werden (Nguyen et al., 2017). Dabei bezeichnet objektives Wissen das tatsächlich vorhandene Wissen über ein konkretes Artefakt, während subjektives Wissen lediglich auf das empfundene Wissen darüber abzielt (Brucks, 1985). Diese beiden sind zwar miteinander

korreliert (Carlson et al., 2009), allerdings begehen Menschen systematische Fehler bei der Selbsteinschätzung (Unter- und Überschätzung) (Dunning, 2011; Moore &amp; Healy, 2008). Bisher wurde AIL mittels eines subjektiven Messinstruments gemessen (Pinski &amp; Benlian, 2023), welches lediglich für die Wahrnehmung des eigenen Wissens verwendet werden kann. Es erlaubt folglich keine verlässliche Abschätzung der objektiven AIL, die somit explizit gemessen werden muss. Dieses Phänomen ist aus der LiteracyForschung bekannt (Babiarz &amp; Robb, 2014; Kiechle et al., 2015; Nguyen et al., 2017). Zudem folgen wir mit unserer Studie wissenschaftlichen Aufrufen zur Entwicklung einer objektiven AIL-Messskala (Laupichler et al., 2022; Weber, 2023).

Wir  haben  gemeinsam  mit  n  =  10  Experteninterviews  und  zwei  Runden  CardSorting durch n = 12 Forschende der Wirtschaftsinformatik (WI) ein objektives Messinstrument mit n = 25 Fragen entwickelt. Das Messinstrument haben wir bereits in den drei Studien Onlinestichprobe , Zentralbank und Unikurs (n = 134) vorläufig innerhalb und außerhalb von Bildungseinrichtungen evaluiert. Abb. 1 visualisiert den Zusammenhang zwischen subjektiver (Pinski &amp; Benlian, 2023) und objektiver AIL (Weber et al., 2023) für zwei der drei Studien (Studie Onlinestichprobe und Unikurs). In dem Streudiagramm ist kein eindeutiger Zusammenhang zu erkennen, sodass nicht von der subjektiven  auf  die  objektive  AIL  geschlossen  werden  kann.  Dies  unterstreicht  die Notwendigkeit einer Messung von AIL auf objektive Weise.

Abbildung 1 . Scatterplot (schwarz) subjektiver und objektiver AIL der durchgeführten Studien Unikurs und Onlinestichprobe (n = 117) mit Trendlinie ( grau )

<!-- image -->

Mit diesen drei sowie mit drei weiteren Studien wollen wir dabei die Entwicklung des Messinstruments abschließen und AIL in weiteren Kontexten untersuchen. Dabei stellen wir uns folgende Forschungsfragen: Wie kann objektive AIL gemessen werden? Was sind  Antezedenzien,  Moderatoren,  Mediatoren,  Konsequenzen  objektiver  AIL?  Wie hoch ist die AIL in verschiedenen demographischen Gruppen? Schätzen Menschen ihre AIL richtig ein? Wie beeinflusst AIL die Einstellung (Trust in AI) sowie das Verhalten (Delegationsleistung) von Menschen bei der Zusammenarbeit mit KI-Agenten?

## 2 Theoretische Grundlagen

Die theoretischen Grundlagen unseres Messinstruments fußen auf den zwei Bereichen des sozio-technischen Kontinuums der WI sowie Blooms Taxonomie. Beide stellen jeweils eine Dimension der Mensch-KI-Interaktion dar (siehe Abb. 3).

Mit dem sozio-technischen Kontinuum beschreiben Sarker et al. (2019) die beiden Kernelemente der WI: den Menschen sowie das Artefakt, im vorliegenden Fall die KI. Diese  repräsentieren  die  zwei Teile der  Mensch-KI-Interaktion,  nämlich  die  soziale ( Socio ) sowie die technische Perspektive ( Technical ) auf die Disziplin der WI, die wir auch für unser objektives Messinstrument für AIL angenommen haben. Daneben bezieht sich Blooms Taxonomie auf verschiedene Interaktionsarten im Rahmen des Kompetenzerwerbs  und  Lernens  (Bloom  et  al.,  1956).  In  einer  überarbeiteten  Fassung werden die sechs Interaktionsarten Erinnern , Verstehen , Anwenden , Analysieren , Auswerten und Erschaffen mit in dieser Reihenfolge steigender Komplexität unterschieden (Krathwohl, 2002). Der Einfachheit halber und vorangegangener Forschung folgend (Ng et al., 2021) fassen wir die ersten drei Arten unter dem Begriff 'Verwenden' ( User ) sowie die letzten drei  unter  'Erschaffen/Auswerten' ( Creator/Evaluator )  zusammen und bilden daraus unsere beiden Arten der Mensch-KI-Interaktion.

## 3 Methodik

Abbildung 2 . Übersicht des Skalenentwicklungsprozesses nach MacKenzie et al. (2011).

<!-- image -->

Dem etablierten Skalenentwicklungsprozess nach MacKenzie et al. (2011) folgend haben wir ein Messinstrument entwickelt (siehe Abb. 2). Zunächst identifiierten wir mittels Literaturrecherche relevante Publikationen zum Thema AIL (e.g., Cetindamar et al., 2022; Chiu et al., 2021; Dai et al., 2020; Hermann, 2022; Kandlhofer &amp; Steinbauer, 2018; Long &amp; Magerko, 2020; Mikalef &amp; Gupta, 2021; Ng et al., 2021; Pinski &amp; Benlian, 2023; Wang et al., 2022) und basierend darauf eine Definition sowie Konzeptualisierung von AIL abgeleitet (siehe Abb. 3). Wir definieren AIL so: ' AI literacy is a set of socio-technical competencies of humans that shape relevant types of human-AI interaction .'  ('AI  Literacy  bezeichnet  eine  Menge  menschlicher,  sozio-technischer Kompetenzen, die relevante Typen von Mensch-KI-Interaktionen beeinflussen.').

Unser Konzept beinhaltet dabei die folgenden vier AIL-Arten, die sich aus der Kombination der im letzten Kapitel beschriebenen Teile und Arten der Mensch-KI-Interaktion ergeben: Socio User AI Literacy , Socio Creator/Evaluator AI Literacy , Technical

User AI Literacy , Technical Creator/Evaluator AI Literacy (siehe Abb. 3). Anschließend haben wir gemeinsam mit n = 10 Experten aus den Bereichen WI, IT und Management n = 56 Fragen entwickelt, die im Anschluss n = 12 Forschende der WI in zwei Runden in die vier AIL-Arten unseres Konzeptes einsortiert haben (Card-Sorting Methode). Wir haben den Fragenbogen zugunsten internationaler Vergleichbarkeit auf Englisch entwickelt und in drei Studien vorläufig evaluiert (siehe Abb. 3), wobei wir stets  den  vollen  Fragebogen  bestehend  aus  Fragen  aller  Quadranten  verwendeten. Schließlich haben wir eine Auswahl von n = 25 Fragen getroffen, die den Fragebogen bilden. 1 Abb. 3 visualisiert zusätzlich die geplanten Studien, die die einzelnen Quadranten  (fokussiert)  untersuchen,  wobei  der  Positionierung  der  Studien  innerhalb  der Quadranten keine Bedeutung beizumessen ist.

Abbildung 3 . Konzeptualisierung von AIL und Übersicht der durchgeführten (dunkelgrau) sowie geplanten (hellgrau) Studien

<!-- image -->

## 4 Ergebnisse der drei durchgeführten Studien

Wir haben unser Messinstrument in drei verschiedenen Kontexten evaluiert. Tabelle 1 liefert dazu einen passenden Überblick. In einem ersten Schritt haben wir eine repräsentative Stichprobe von Teilnehmenden auf einer Onlineumfrageplattform die Fragen zu AIL beantworten lassen. Dazu haben wir n = 88 Teilnehmende in zwei Gruppen eingeteilt,  wobei  wir  die  Stichprobengröße  mittels  GPower  ermittelt haben  um  eine Trennschärfe &gt; 0,8 zu erreichen. In der ersten Gruppe befanden sich 44 Teilnehmende mit IT-Hintergrund ('Computer Science', 'Computing (IT)') sowie mit einer hohen wöchentlichen Gerätenutzung (Handy, Tablet, Laptop, Desktop) von mindestens einer Nutzung am Tag (Gruppe 1). In der zweiten Gruppe waren die 44 Teilnehmenden mehrheitlich ohne IT-Hintergrund (Gruppe 2) sowie mit einer wöchentlichen Gerätenutzung von höchstens sechs Nutzungen pro Woche. Wir trafen hierbei die Annahme, dass Teil-

1 Aus Platzgründen bilden wir die n = 25 Fragen hier nicht ab. Auf Anfrage teilen wir den Fragebogen gerne. Ein Auszug von n = 16 Fragen findet sich in Weber et al. (2023).

nehmende mit technischem IT-Hintergrund sowie einer höheren, wöchentlichen Gerätenutzung eine höhere AIL haben, als solche ohne. Die Ergebnisse zeigen einen statistisch  signifikanten  Unterschied  (Mann-Whitney  U  =  757;  n1  =  n2  =  44;  p  =  0,076; beidseitig), d. h. unser Messinstrument diskriminiert erfolgreich zwischen den beiden Gruppen mit einer objektiven AIL von 31,3% (Gruppe 1) und 27,5% (Gruppe 2), gemessen als Durchschnitt der Anteile korrekt beantworteter Fragen.

Im Anschluss evaluierten wir in der zweiten Studie Zentralbank unser Messwerkzeug in einem Unternehmenskontext, insbesondere auf der Entscheidendenebene (Fokus auf Creator/Evaluator AI Literacy ). Dazu haben wir eine Stichprobe von n = 17 in Vollzeit tätigen Managern einer Zentralbank rekrutiert und diese im Anschluss an einen KI-Workshop Fragen zu AIL beantworten lassen. Mit dem Fokus auf Manager erzielen wir weitere Erkenntnisse zu personengruppenspezifischer AIL. Hier konnten wir mit 80,7% eine besonders hohe objektive AIL erkennen, was auf eine hohe Wirkung des Workshops sowie eine hohe objektive AIL in dieser Population hindeuten könnte. Aus Datenschutzgründen haben wir hier keine demographischen Daten erhoben.

Tabelle 1. Statistische Kennzahlen der drei Studien (n = 134)

| Stichprobenstatistiken    | Stichprobenstatistiken                      | Studie OST   | Studie OST   | Studie OST   | Studie   | Studie UK   |
|---------------------------|---------------------------------------------|--------------|--------------|--------------|----------|-------------|
|                           |                                             | G1           | G2           | T            | ZB       |             |
| Stichprobengröße          | n                                           | 44           | 44           | 88           | 17       | 29          |
| Geschlecht                | Weiblich                                    | 46%          | 48%          | 47%          |          | 52%         |
| Geschlecht                | Männlich                                    | 52%          | 52%          | 52%          |          | 41%         |
| Geschlecht                | Anderes                                     | 2%           | 0%           | 1%           |          | 7%          |
| Alter                     | Mittelwert (in Jahren)                      | 24,4         | 25,0         | 24,7         |          | 25,1        |
| Bildungsgrad *            | Realschulabschluss oder niedriger           | 8%           | 1%           | 9%           |          | -           |
| Bildungsgrad *            | Allgemeine Hochschulreife                   | 27%          | 23%          | 25%          |          | 93%         |
| Bildungsgrad *            | Hochschulabschluss                          | 36%          | 64%          | 50%          |          | 7%          |
| Ausbildungs- hintergrund  | Mit IT-Hintergrund                          | 100%         | 11%          | 56%          |          | 7%          |
| Ausbildungs- hintergrund  | Ohne IT-Hintergrund                         | -            | 89%          | 44%          |          | 93%         |
| Beschäftigungs- status    | Arbeitstätig (Vollzeit/Teilzeit)            | 34%          | 59%          | 47%          | 100%     | 7%          |
| Beschäftigungs- status    | Nicht arbeitstätig (arbeitslos/pensioniert) | 39%          | 32%          | 35%          | -        | -           |
| Beschäftigungs- status    | Studierende/r                               | -            | -            | -            | -        | 93%         |
| Beschäftigungs- status    | Anderes                                     | 27%          | 9%           | 18%          | -        | -           |
| Erfahrung mit KI          | Mittelwert **                               | 3,42         | 2,21         | 2,82         |          |             |
| Subjektive AIL            | Mittelwert (1 - niedrig; 7 - hoch)          | 4,37         | 3,89         | 4,13         |          | 3,16        |
| Objektive AIL (25 Fragen) | Mittelwert (Prozentsatz)                    | 31,3%        | 27,5%        | 29,4%        | 80,7%    | 56,4%       |

OST: Onlinestichprobe; ZB: Zentralbank; UK: Unikurs; G1: Gruppe 1; G2: Gruppe 2; T: Total * Ausschließlich der Option 'Andere'. ** Skala von 1 'Stimme überhaupt nicht zu' ('completely disagree') bis 7 'Stimme voll und ganz zu' ('completely agree').

Im weiteren Verlauf haben wir uns in der dritten  Studie Unikurs auf Teilnehmende ohne technischen Hintergrund aus einer Bildungseinrichtung konzentriert. Dazu haben wir die AIL von n = 29 Teilnehmenden eines KI-Schlüsselkompetenzkurses für nicht-technische Studierende gemessen und ermittelt, dass die Socio AI Literacy für diese Gruppe mit 63% über der Technical AI Literacy mit 51% liegt.

## 5 Fazit und nächste Forschungsschritte

Mit den bisher durchgeführten und ausgewerteten Studien konnten wir unser Messinstrument für AIL bereits in verschiedenen Populationen testen. Dabei zeigten sich erste, vorläufige Tendenzen (siehe letzte Zeile von Tab. 1). Anschließend werden wir die Forschung  zur  Konstruktentwicklung  mit  den  folgenden  drei  Studien  fortsetzen  (siehe Abb. 3) um Antezedenzien, Moderatoren, Mediatoren sowie Konsequenzen objektiver AIL zu identifizieren und die Beziehung zwischen objektiver AIL sowie verwandter Konstrukte wie Data Literacy und Digital Literacy zu erörtern.

1. Als Erweiterung der Studie Unikurs erheben wir im Sommersemester 2023 AIL bereits zu Beginn des KI-Schlüsselkompetenzkurses und dann erneut zum Kursende (jeweils n = ~70). Damit messen wir subjektspezifisch Fortschritte im Erwerb objektiver AIL.
2. Als weitere Studie planen wir eine Erhebung der objektiven AIL Studierender mit einem naturwissenschaftlich-technischen Studienhintergrund (n = ~50). Damit untersuchen wir explizit diese Gruppe hinsichtlich objektiver AIL, nachdem wir in der Studie Unikurs Studierende nicht-technischen Studienhintergrunds befragt haben.
3. Schließlich planen wir eine Erhebung, in der wir zahlreiche Untersuchungsgegenstände unterbringen wollen. Für eine repräsentative Stichprobe von n = ~330 Teilnehmenden werden wir subjektive AIL, objektive AIL sowie  weitere Konstrukte erheben (siehe Abb. 4). Zudem werden die Teilnehmenden ein KI-unterstütztes Bildsortierexperiment durchführen (vgl. Fügener et al., 2022).

Abbildung 4 . Nomologisches Netzwerk für die geplante Studie 3 (n = 330)

<!-- image -->

## Acknowledgements

Gefördert durch die Deutsche Forschungsgemeinschaft (DFG) im Rahmen des Sonderforschungsbereichs (SFB) 1053 MAKI.

## Referenzen

- Babiarz, P., &amp; Robb, C. A. (2014). Financial Literacy and Emergency Saving. Journal of Family and Economic Issues , 35 (1), 40-50. https://doi.org/10.1007/s10834-013-9369-9
- Bloom, B. S., Engelhart, M. D., Furst, E. J., Hill, W. H., &amp; Krathwohl, D. R. (1956). Taxonomy of  educational objectives: The classification of educational goals. New York: David McKay .
- Brucks, M. (1985). The effects of product class knowledge on information search behavior. Journal of Consumer Research , 12 (1), 1-16.
- Carlson, J. P., Vincent, L. H., Hardesty, D. M., &amp; Bearden, W. O. (2009). Objective and subjective knowledge relationships: A quantitative analysis of consumer research findings. Journal of Consumer Research , 35 (5), 864-876.
- Cetindamar, D., Kitto, K., Wu, M., Zhang, Y., Abedin, B., &amp; Knight, S. (2022). Explicating AI literacy of employees at digital workplaces. IEEE Transactions on Engineering Management .
- Chen, L., Chen, P., &amp; Lin, Z. (2020). Artificial Intelligence in Education: A Review. IEEE Access , 8 , 75264-75278. https://doi.org/10.1109/ACCESS.2020.2988510
- Chiu, Y.-T., Zhu, Y.-Q., &amp; Corbett, J. (2021). In the hearts and minds of employees: A model of pre-adoptive  appraisal  toward  artificial  intelligence  in  organizations. International Journal of Information Management , 60 , 102379.
- Dai, Y., Chai, C.-S., Lin, P.-Y., Jong, M. S.-Y., Guo, Y., &amp; Qin, J. (2020). Promoting Students' Well-Being by Developing Their Readiness for the Artificial Intelligence Age. Sustainability , 12 (16), Article 16.
- Dunning, D. (2011). The Dunning-Kruger effect: On being ignorant of one's own ignorance. In Advances  in  Experimental  Social  Psychology (Vol.  44,  pp.  247-296).  Elsevier. https://doi.org/10.1016/B978-0-12-385522-0.00005-6
- Fügener, A., Grahl, J., Gupta, A., &amp; Ketter, W. (2022). Cognitive challenges in Human-Artificial Intelligence Collaboration: Investigating the path toward productive delegation. Information Systems Research , 33 (2), 678-696.
- Gillath, O., Ai, T., Branicky, M. S., Keshmiri, S., Davison, R. B., &amp; Spaulding, R. (2021). Attachment  and  trust  in  artificial  intelligence. Computers  in  Human  Behavior , 115 , 106607.
- Hermann, E. (2022).  Artificial  intelligence  and  mass  personalization  of  communication  content-An ethical and literacy perspective. New Media &amp; Society , 24 (5), 1258-1277.
- Jain, H., Padmanabhan, B., Pavlou, P. A., &amp; Santanam, R. T. (2018). Call for Papers-Special Issue of Information Systems Research-Humans, Algorithms, and Augmented Intelligence:  The  Future  of  Work,  Organizations,  and Society. Information Systems  Research , 29 (1), Article 1. https://doi.org/10.1287/isre.2018.0784
- Kandlhofer, M., &amp; Steinbauer, G. (2018). A driving license for intelligent systems. Proceedings of the AAAI Conference on Artificial Intelligence , 32 (1).
- Karaca, O., Çalışkan, S. A., &amp; Demir, K. (2021). Medical artificial intelligence readiness scale for medical students (MAIRS-MS) - development, validity and reliability study. BMC Medical Education , 21 (1), 112. https://doi.org/10.1186/s12909-021-02546-6
- Kiechle, E. S., Bailey, S. C., Hedlund, L. A., Viera, A. J., &amp; Sheridan, S. L. (2015). Different Measures, Different Outcomes? A Systematic Review of Performance-Based versus Self-Reported Measures of Health Literacy and Numeracy. Journal of General Internal Medicine , 30 (10), 1538-1546. https://doi.org/10.1007/s11606-015-3288-4
- Krathwohl, D. R. (2002). A Revision of Bloom's Taxonomy: An Overview. Theory Into Practice , 41 (4), 212-218.
- Laupichler, M. C., Aster, A., Schirch, J., &amp; Raupach, T. (2022). Artificial intelligence literacy in higher and adult education: A scoping literature review. Computers and Education: Artificial Intelligence , 3 , 100101. https://doi.org/10.1016/j.caeai.2022.100101
- Long, D., &amp; Magerko, B. (2020). What is AI literacy? Competencies and design considerations. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems , 1-16. https://doi.org/10.1145/3313831.3376727
- MacKenzie, S. B., Podsakoff, P. M., &amp; Podsakoff, N. P. (2011). Construct measurement and validation procedures in MIS and behavioral research: Integrating new and existing techniques. MIS Quarterly , 293-334.
- Mikalef, P., &amp; Gupta, M. (2021). Artificial intelligence capability: Conceptualization, measurement calibration, and empirical study on its impact on organizational creativity and firm performance. Information &amp; Management , 58 (3), 103434.
- Moore, D. A., &amp; Healy, P. J. (2008). The trouble with overconfidence. Psychological Review , 115 (2), 502.
- Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., &amp; Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence , 2 , 100041.
- Nguyen, T. H., Paasche-Orlow, M. K., &amp; McCormack, L. A. (2017). The state of the science of health literacy measurement. Information Services &amp; Use , 37 (2), 189-203. https://doi.org/10.3233/ISU-170827
- Norman, C. D., &amp; Skinner, H. A. (2006). eHEALS: The eHealth Literacy Scale. Journal of Medical Internet Research , 8 (4), e507. https://doi.org/10.2196/jmir.8.4.e27
- Ongena, G. (2023). Data literacy for improving governmental performance: A competence-based approach  and  multidimensional  operationalization. Digital  Business , 3 (1),  100050. https://doi.org/10.1016/j.digbus.2022.100050
- Pinski, M., &amp; Benlian, A. (2023). AI Literacy-Towards Measuring Human Competency in Artificial Intelligence. Proceedings of the 56th Hawaii International Conference on System Sciences | 2023 .
- Roll, I., &amp; Wylie, R. (2016). Evolution and Revolution in Artificial Intelligence in Education. International Journal of Artificial Intelligence in Education , 26 (2), 582-599. https://doi.org/10.1007/s40593-016-0110-3
- Sarker, S., Chatterjee, S., Xiao, X., &amp; Elbanna, A. (2019). The Sociotechnical Axis of Cohesion for the IS Discipline: Its Historical Legacy and its Continued Relevance. Management Information Systems Quarterly , 43 (3), 695-719.
- Sindermann, C., Sha, P., Zhou, M., Wernicke, J., Schmitt, H. S., Li, M., Sariyska, R., Stavrou, M., Becker, B., &amp; Montag, C. (2021). Assessing the Attitude Towards Artificial Intelligence: Introduction of a Short Measure in German, Chinese, and English Language. KI  -  Künstliche  Intelligenz , 35 (1),  109-118.  https://doi.org/10.1007/s13218-02000689-0
- Soto, C. J., &amp; John, O. P. (2017). Short and extra-short forms of the Big Five Inventory-2: The BFI-2-S and BFI-2-XS. Journal of Research in Personality , 68 , 69-81. https://doi.org/10.1016/j.jrp.2017.02.004
- Wang, B., Rau, P.-L. P., &amp; Yuan, T. (2022). Measuring user competence in using artificial intelligence: Validity and reliability of artificial intelligence literacy scale. Behaviour &amp; Information Technology , 1-14.
- Weber, P. (2023). Unrealistic Optimism Regarding Artificial Intelligence Opportunities in Human  Resource  Management. International  Journal  of  Knowledge  Management (IJKM) , 19 (1), 1-19. https://doi.org/10.4018/IJKM.317217
- Weber, P., Pinski, M., &amp; Baum, L. (2023). Towards an Objective Measurement of AI Literacy. PACIS  2023  Proceedings .  Pacific  Asia  Conference  on  Information  Systems  2023, Nanchang, China.
- World  Economic  Forum:  Firth-Butterfield,  K.,  Toplic,  L.,  Anthony,  A.,  and  Reid,  E.  (2022, March  17). Artificial  Intelligence.  Without  universal  AI  literacy,  AI  will  fail  us . https://www.weforum.org/agenda/2022/03/without-universal-ai-literacy-ai-will-failus/