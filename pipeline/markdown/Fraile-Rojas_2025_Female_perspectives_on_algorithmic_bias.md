---
source_file: Fraile-Rojas_2025_Female_perspectives_on_algorithmic_bias.pdf
conversion_date: 2026-02-03T18:27:00.796197
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
MD 63,9

## 3042

Received 20 April 2024 Revised 12 August 2024 20 October 2024

Accepted 30 November 2024

<!-- image -->

Management Decision Vol. 63 No. 9, 2025 pp. 3042-3065

© Emerald Publishing Limited

e-ISSN:

1758-6070

p-ISSN:

0025-1747

DOI

10.1108/MD-04-2024-0884

## Female perspectives on algorithmic bias: implications for AI researchers and practitioners

## Belen Fraile-Rojas

Escuela Internacional de Doctorado, Universidad Rey Juan Carlos, Madrid, Spain and

Department of Market Research and Quantitative Methods, ESIC University, Madrid, Spain

## Carmen De-Pablos-Heredero

Departamento de Econom � ıa de la Empresa (Administraci � on, Direcci � on, y Organizaci � on), Econom � ıa Aplicada II y Fundamentos de An � alisis Econ � omico, Universidad Rey Juan Carlos, Madrid, Spain, and

Mariano Mendez-Suarez

ESIC University -ESIC Business &amp; Marketing School, Madrid, Spain

## Abstract

Purpose -This article explores the use of natural language processing (NLP) techniques and machine learning (ML) models to discover underlying concepts of gender inequality applied to artificial intelligence (AI) technologies in female social media conversations. The first purpose is to characterize female users who use this platform to share content around this area. The second is to identify the most prominent themes among female users' digital production of gender inequality concepts, applied to AI technologies.

Design/methodology/approach -Social opinion mining has been applied to historical Twitter data. Data were gathered using a combination of analytical methods such as word clouds, sentiment analyses and clustering. It examines 172,041 tweets worldwide over a limited period of 359 days.

Findings -Empirical data gathered from interactions of female users in digital dialogues highlight that the most prominent topics of interest are the future of AI technologies and the active role of women to guarantee gender balanced systems. Algorithmic bias impacts female user behaviours in response to injustice and inequality in algorithmic outcomes. They share topics of interest and lead constructive conversations with profiles affiliated with gender or race empowerment associations. Women challenged by stereotypes and prejudices are likely to fund entrepreneurial solutions to create opportunities for change.

Research limitations/implications -This study does have its limitations, however. First, different keywords are likely to result in a different pool of related research. Moreover, due to the nature of our sample, the largest proportion of posts are from native English speakers, predominantly (88%) from the US, UK, Australia and Canada. This demographic concentration reflects specific social structures and practices that influence gender equity priorities within the sample. These cultural contexts, which often emphasize inclusivity and equity, play a significant role in shaping the discourse around gender issues. These cultural norms, preferences and practices are critical in understanding the individual behaviours, perspectives and priorities expressed in the posts; in other words, it is vital to consider cultural context and economic determinants in an analysis of gender equity discussions. The US, UK, Australia and Canada share a cultural and legal heritage, a common language, values, democracy and the rule of law. Bennett (2007) emphasizes the potential for enhanced cooperation in areas like technology, trade and security, suggesting that the anglosphere's cultural and institutional commonalities create a natural foundation for a cohesive, influential global network. These shared characteristics further influence the common approaches and perspectives on gender equity in public discourse. Yet findings from Western nations should not be assumed to apply easily to the contexts of other countries.

Practical implications -From a practical perspective, the results help us understand the role of female influencers and scrutinize public conversations. From a theoretical one, this research upholds the argument that feminist critical thought is indispensable in the development of balanced AI systems.

Social implications -The results also help us understand the role of female influencers: ordinary individuals often challenged by gender and race discrimination. They request an intersectional, collaborative and pluralistic understanding of gender and race in AI. They act alone and endure the consequences of stigmatized products and services. AI curators should strongly consider advocating for responsible, impartial technologies, recognizing the indispensable role of women. This must consider all stakeholders, including representatives from industry, small and medium-sized enterprises (SMEs), civil society and academia.


<!-- PAGE 2 -->


Originality/value -This study aims to fill critical research gaps by addressing the lack of a socio-technical perspective on AI-based decision-making systems, the shortage of empirical studies in the field and the need for a critical analysis using feminist theories. The study offers valuable insights that can guide managerial decisionmaking for AI researchers and practitioners, providing a comprehensive understanding of the topic through a critical lens.

Keywords Intersectional feminism, AI gender bias, AI ethics, Societal biases, Social opinion mining Paper type Research paper

## 1. Introduction

The intersection of gender and artificial intelligence (AI) has garnered significant attention in recent feminist scholarship, highlighting the need for critical analysis to ensure social justice. Feminist researchers play a key role in critically examining AI systems within this context (Browne et al. , 2023; D'Ignazio and Klein, 2023; McInerney and Drage, 2024). The literature shows that gender bias in state-of-the-art AI models is a fast-growing research area: which started to expand in 2017, then increased quite considerably in 2020 (Hall and Ellis, 2023). Distinguished scholars critically examined structural inequalities, contributing significantly to a deeper understanding of how gender dynamics are embedded in technological products and services (Haraway, 1987; Harding, 1991).

Cockburn and Ormrod explore 'the curious relationship between gender and technology' (1993, p. 1), arguing that technology is not neutral but instead shaped by and reinforces gender norms and inequalities. This both challenges the common perception of technology as inherently masculine and investigates how gender biases influence its development and use. Technology's design both mirrors and perpetuates existing gender roles and stereotypes and is strongly influenced by masculine values and priorities (Wajcman, 2010; Crawford, 2016; West et al. , 2019).

AI algorithms, defined as a sequence of instructions which primarily learn from observing data, are considered a powerful force (Floridi et al. , 2021). They have a substantial impact on individuals, society and business innovation (Cano-Marin, 2024). The increasing influence of AI brings with it significant concerns regarding potential human rights violations (Ntoutsi et al. , 2020; Curto et al. , 2024). Additionally, some argue that the practical application of AI computational techniques faces substantial challenges in real-world scenarios (Veale and Binns, 2017), particularly when deployed in sensitive contexts where critical, life-altering decisions are made (Mehrabi et al. , 2019). Hansson acknowledges technology as a cause of social injustice that creates 'permanent advantages for a privileged minority' or 'permanent disadvantages for underprivileged groups' (2017, pp. 53-54).

However, research to date tends to focus on the design and implementation of AI systems and has discarded contextual and social factors (Foffano et al. , 2023; Moorosi et al. , 2023), as well as ethical issues (Holmes et al. , 2019; Trotta et al. , 2023): fundamental concepts when discussing the benefits and risks of adaptive AI. There is also a lack of empirical research shedding light on its behavioural, economic and social impacts (Draude et al. , 2020). Most published studies are conceptual in nature (Nadeem et al. , 2022). Table 1 presents critical arguments from feminist perspectives, emphasizing how addressing these overlooked dimensions, such as the relationship between gender and technology, has been inspired by the pioneering contributions of Donna Haraway and Sandra Harding.

Some scholars have highlighted high-stakes AI scenarios: such as unequal word embedding in search algorithms (Bolukbasi et al. , 2016), stereotyped virtual assistants (Ahn et al. , 2022), biased facial recognition systems (Buolamwini and Gebru, 2018), unfair criminal justice artefacts (Hamilton, 2019), digital advertisements and personalized product recommendations (Rathee et al. , 2023), or algorithmically-induced inequities in recruitment processes (Hoover et al. , 2019), which owe to prejudice, gender and social stereotypes. Given that AI algorithms reflect the values inherent in our society and their creators, there is a substantial risk of these systems perpetuating strong gender stereotypes (Crawford, 2017; West et al. , 2019). Although Daugherty et al. (2018) argue that AI can help address biases instead of perpetuating them, it has been compellingly argued that AI systems amplify and reproduce existing and historic biases embedded in the data (Charlesworth et al. , 2021; Bianchi et al. , 2023).

Management Decision

3043


<!-- PAGE 3 -->


## 3044

In this context, we advocate for the importance of exploring public awareness around gendered AI technologies. Our particular focus is on the digital conversations of female users surrounding this. Social media platforms foster the broad sharing of ideas and encourage open public discussions. Users' posts can serve as a valuable source of information, as these conversations mirror social perspectives across domains (Cano-Marin et al. , 2023).

Kaplan and Haenlein define social media as 'a group of Internet-based applications that build on the ideological and technological foundations of Web 2.0, and that allow the creation and exchange of user generated content' (2010, p. 61). This study focuses on one social networking site, formerly known as Twitter. It analyses 172,041 tweets worldwide over a limited period of one year.

The article explores the use of natural language processing (NLP) techniques and machine learning (ML) models to discover underlying concepts of gender inequality applied to AI technologies in female social media conversations. To reach this objective, it will answer these research questions: RQ1) Are there underlying unique user profile attributes? RQ2) What is the nature of digital conversations among female users? Consequently, the objectives are twofold: Objective 1: We aim to reveal underlying user profiles and behaviours, based on their characteristics; Objective 2: Based on NLP techniques and ML models, we aim to discover the most prominent topics of interest among female users' digital production around concepts of gender bias, as applied to AI technologies.

From a practical perspective, the results help us understand the role of female influencers and scrutinize public conversations. From a theoretical one, this research upholds the argument that feminist critical thought is indispensable in the development of balanced AI systems. The article will unfold as follows: first, a gender and technology intersected theoretical framework will be provided, focussing on their significance and positioning this study in the field of inclusive AI. The research questions addressing algorithmic bias phenomena are formulated. Finally, we conclude with a reflection on how a feminist framework enables a much more profound, complex, in-depth analysis of gender-neutral technologies: which account for the nuances of gender as a narrow social construct.

## 2. Theoretical background and hypotheses

Haraway's manifesto is one of the most influential pieces in this area, profoundly shaping discussions around the intersection of technology, gender and identity in contemporary society within feminist theory. The feminist socio-technical approaches to technology of Haraway (1987) and Faulkner (2001) share similarities, particularly in challenging simplistic views of it. Both confront the arguments of those who perceive technology over-optimistically or solely as an agent of liberation; or those who are too pessimistic and view it only as a mechanism of oppression. They emphasize a more refined understanding of technology's role in feminism, highlighting its complexity and multifaceted nature regarding gender.

Wajcman (2010) evaluates the impact of the over-representation of dominant androcentric groups which share common attributes: Christian-Jewish, American, white, heterosexual, non-disabled, intellectually gifted men, thought of as responsible for the design, development and deployment of these technologies. Feminist AI scholars contend that this existing Bro Culture in large technology companies (Mittelstadt et al. , 2016; West et al. , 2019) fosters a competitive environment which disadvantages women and other outsiders.

These exclusionary, hypermasculine practices affect women in information technology (IT) firms and female entrepreneurs (Carbone et al. , 2019). Clark refers to this imbalance as a 'sea of dudes problem', whereby males predominantly occupy positions of influence, development and research in AI (2016). This concentration of power fosters masculinity and exclusivity and discriminates systematically against non-dominant groups (Broussard, 2018). Wajcman and Young (2023) identify the masculine culture of the workplace as a significant barrier to the career advancement of women in AI. For all the above reasons, it is important to explore gender balance and pinpoint how crucial it is to prevent algorithms from perpetuating a vicious cycle of gender ideologies that disadvantage women (Criado-Perez, 2021).


<!-- PAGE 4 -->


Gender bias in AI-based decision-making systems is a socio-technical problem that requires a combination of technological, organizational and societal approaches. The contextual and socio-demographic factors observed are traditional societal prejudices: based on gender (Hamilton, 2019; Cirillo et al. , 2020), race (Benjamin, 2019; Huq, 2019), nationality (Landabur Ayala and Wilson Alcalde, 2022), disability (Shew, 2020), and age (Chu et al. , 2023). Jaume-Palasi (2021) notes that perception of bias differs among all individuals: where data scientists tend to consider it as a mathematical concept, and AI ethics experts view it as a complex term linked to humanistic ideals, Jaume-Palasi considers biological and sociocultural differences, as well as background and experience, to be key factors.

In our research, AI is used to refer to a heterogeneous network of technologies built from data and algorithms, which share the functional automation of the human brain (European

Table 1. Critical arguments from feminist perspectives

| Theoretical frameworks                                    | Key arguments                                                                                                                        | Authors                                                                                                    |
|-----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| Critical theory                                           | Social systems of oppression; seeking social justice                                                                                 | Browne et al. (2023) Crenshaw (2017) Haslanger (2018) O'Neil (2016)                                        |
| Social theory                                             | Interconnection of science, technology and gender                                                                                    | Gobo and Marcheselli (2023) Faulkner (2001) Haraway (1987) Harding (1991) Wajcman (2007)                   |
| Feminist critical thought to AI                           | Feminist perspectives to challenge inequalities and relations of power in AI                                                         | Browne et al. (2023) McInerney and Drage (2024) D'Ignazio and Klein (2023)                                 |
| AI gender and race                                        | AI systems and intersectionality Societal race and gender and bias in AI systems Amplification of racial biases and inequities in AI | Benjamin (2019) Buolamwini and Gebru (2018) Gebru (2020) Huq (2019)                                        |
| Gender bias and sustainable development                   | Economic, social, and environmental dimensions                                                                                       | O'Neil (2016) Crawford (2021) Hall and Ellis (2023) Haslanger (2018) Luccioni et al. (2024) Treanor (2022) |
| Role congruity theory of prejudice towards female leaders | Gender leadership management Challenge gendered assumptions in the workplace                                                         | Bailyn (2011) Eagly and Karau (2002) Eagly and Koenig (2021)                                               |
| Matrix of domination and black women's standpoint         | Black women shaping feminist theory Axes of social division                                                                          | Collins (1990, 2022)                                                                                       |
| Media psychology theories Think manager-think male model  | Social media engagement and behaviour Leader stereotypes and preferences Revisiting the role of alpha males                          | Rutledge (2024) Wiezel et al. (2024)                                                                       |
| Women entrepreneurs in STEM                               | Research field underexplored Structural gender inequalities                                                                          | Treanor (2022)                                                                                             |
| Gender gap in AI entrepreneurship                         | Women entrepreneurs and venture capital allocation                                                                                   | Balachandra et al. (2019, 2020)                                                                            |
| Source(s): Own elaboration                                |                                                                                                                                      |                                                                                                            |

Management

Decision

3045


<!-- PAGE 5 -->


## MD 63,9

## 3046

Commission, 2022). When academics use the term AI, they tend not to refer to a single technology, but rather a general term that describes a wide range of applications and methods, such as ML, NLP, data mining, neural networks or a variety of algorithms to assist human decision-making (Pedr � o, 2020; Segura Mojica, 2024).

The term 'algorithmic bias' has its roots in social phenomena such as discrimination, unfairness and social injustice (Williams et al ., 2018). Discriminatory behaviours such as this bias arise when a ML model is systematically erroneous; human selection of training data can easily yield a skewed distribution (Omrani et al. , 2022). 'Algorithmic bias phenomenon' is 'a systematic deviation from equality that emerges in the outputs of an algorithm' (Kordzadeh and Ghasemaghaei, 2022, p. 8). In the context of decision-making, algorithmic bias is the presence of any prejudice or favouritism towards an individual or group based on their inherent or acquired characteristics (Mehrabi et al. , 2019).

Leavy discusses how women potentially affected by bias are more likely to recognize, understand and seek to mitigate this (2018): which aligns in the social realm with Chu et al. (2023). Social media usage is mainly motivated by social factors such as the desire to form new relationships, sustain current ones, seek support and foster a sense of belonging within a community. Yet the literature features little theoretical insight into AI bias and its behavioural consequences (Khalil et al. , 2020). O'Neil (2016) found that the models employed to date have been opaque, unregulated and incontestable (Noto La Diega, 2018; Kazim et al. , 2021; Dalcher, 2022). They were even referred to as 'black box' algorithms (Zarsky, 2016; Kordzadeh and Ghasemaghaei, 2022). Little progress has been made in mitigating unfair bias, discrimination, explaining how algorithms work or data quality.

Building on these arguments, we propose a social opinion mining analysis to provide further insights. The first hypothesis is as follows:

- H1. Algorithmic bias impacts female user behaviours in response to injustice and inequality in algorithmic outcomes.

In recent years, amid the commercialization of these systems, female thinkers have become more aware of the algorithmic inequalities these applications can contain and are attempting to address bias in AI. Schiebinger coined the concept of gendered innovation, suggesting how gender considerations can lead to innovative research findings and foster creativity (2008). Wang pointed towards a lack of awareness of certain sensitive features among AI curators, which might be corrected by education and training (2020). Others have considered creating a wider range of consultative multi-stakeholder expertise groups, which can help generate fairer AI and reduce gender iniquities (Crawford, 2017; Hagendorff, 2020). Burrell (2016) proposes involving user populations and the broader public to highlight exclusions and forms of discrimination which might be overlooked by domain experts.

The concept of design justice developed by Costanza-Chock (2020) seeks to challenge the ways in which design practices contribute to social inequality. Although it does not specifically focus on AI design, the principles and ideas are applicable to it. Costanza-Chock advocates redistributing power and resources in the design process, ensuring that historically underrepresented groups have greater control and influence over design outcomes. Others have set out clear guidelines to proactively and thoroughly mitigate algorithmic biases (Collett et al. , 2019; Guevara-G � omez et al. , 2021; Pinney et al. , 2023).

Researchers, then, are diligently developing techniques to remove bias, from input data through careful training of AI models. Nonetheless, much work remains, such as on lack of a standardized method for assessing data quality (Balahur et al. , 2022). This is the main reason behind alternative proposals, such as well-grounded legal frameworks to ensure social good (Cheng et al. , 2021; Mendez-Suarez et al. , 2024). M � endez-Su � arez et al. (2023) stress the need for more regulation and audits to prevent AI from being used for unlawful or unethical purposes.

Expanding upon legal frameworks, the European Parliament recently launched the AI Act which establishes obligations for providers and users, depending on the level of risk (European


<!-- PAGE 6 -->


Parliamentary Research Service, 2023). Leufer and Hidvegi (2023) argue that the Act's riskbased approach faces challenges, particularly because its narrow focus on specific risk categories may leave certain issues unaddressed, creating gaps in effectiveness (2023). L € utz notes the European digital strategy's attempts to ensure effective gender equality and avoid algorithmic discrimination -but argues that it should have more explicitly addressed underlying issues around gender and non-discrimination (2022).

As a highly influential article at the turn of the century put it, 'entrepreneurship matters' (Wennekers and Thurik, 1999, p. 51). Entrepreneurship is a critical factor in the development of the modern economy. Yet Valian (1998) highlights how gendered expectations influence women's advancement in science, technology, engineering and mathematics (STEM); and how these biases and structural obstacles hinder innovation and diversity in technological fields. Treanor (2022) suggests that the topic of women entrepreneurs in STEM is a growing research area; but it remains under-explored.

Organizational framework theory holds that individuals with proactive personalities take the initiative, foresee opportunities and challenges, and proactively influence the situation and others to create a different future. Experiencing frustration and anger can encourage proactive behaviour, partly as a means of alleviating it (Parker et al. , 2010). The literature also consistently suggests that it is more difficult for women to become leaders and achieve success in leadership roles (Eagly and Karau, 2002; Bailyn, 2011).

The second hypothesis is as follows:

- H2. Women challenged by cultural bias and social discrimination are more likely to fund entrepreneurial solutions to address algorithmic bias.

Elkington's 'triple bottom line' posits the idea of sustainability: encompassing economic, social and environmental dimensions (1997). It has been framed as a multi-dimensional concept including environmental integrity, economic health and social equity (Hawken et al. , 2000; Stern, 2006). Jacobson (1992) explores the relationship between gender bias and sustainable development. She argues that gender bias is a significant barrier to achieving Sustainable Development Goals (SDGs). Her critical examination of this intersection was novel; others went on to note more optimistically that as organizations move away from traditional perspectives on leadership and adopt a more democratic, participatory approach, women are likely to face less prejudice and achieve greater representation and acceptance in leadership positions (Eagly and Karau, 2002). It is also important to consider gender differences when seeking to achieve equitable sustainable development outcomes (MeinzenDick et al. , 2014).

In alignment with this, United Nations SDGs 5: Gender equality and the empowerment of all women and girls ; and 12: Responsible consumption and production are both of great import (UN, 2024). Western governments allocate substantial financial resources to support STEM research and commercialization efforts, driven by expected socioeconomic benefits such as wealth generation, job creation, economic and social development (Treanor, 2022).

There is also growing research on the environmental impact of AI systems on energy consumption, carbon footprints and resource utilization (Gallego G � omez and Vaquero Fr � ıas, 2022; Luccioni et al. , 2024), in other words, of 'the planetary costs of Artificial Intelligence' (Crawford, 2021). Therefore, the third hypothesis is:

- H3. The term 'sustainability' is strongly linked to gender inequity conversations.

The standpoint theory coined by Sandra Harding (1986) suggests that individuals in marginalized positions, whether by gender or other categories such as race and class, form a distinctive perspective due to their experiences of oppression. These individuals have a unique standpoint, enabling them to understand their own marginalized experiences and the perspectives of dominant groups, and survive within oppressive social systems. Building on Harding's work, Hill Collins explores the perspectives of Black women who navigate both racial and gender-based oppression (Collins, 1990, 2022).

Management Decision

3047


<!-- PAGE 7 -->


## MD 63,9

## 3048

H4. Gender and race affiliations tend to converge in digital collective conversations.

Race and gender are key factors in how biases and social perceptions are formed and maintained, influencing social thought processes. Gebru (2020) illuminates how biases disproportionately harm marginalized groups, particularly women and people of colour. She emphasizes the importance of intersecting identities and makes recommendations regarding AI. Rutledge (2024), meanwhile, analyses major theories in media psychology, shedding light on how individuals engage with digital platforms and the effects of these interactions on their behaviour. These connections, which shape individuals' self-perception and identity, have been referred to as latent ties (Haythornthwaite, 2005).

There is a very real diversity crisis in the AI sector across gender and race (Bolukbasi et al. , 2016; Buolamwini and Gebru, 2018). As Wellner and Rothman (2019) argue, users and developers need to be conscious of potential gender and racial biases; and should strive to prevent, circumvent or eliminate these. Social media platforms provide unrestricted access to a vast array of information, enabling individuals to share a wide range of beliefs and values (Olan et al. , 2024). Additionally, the nature of Twitter increases benefits for affiliated groups as the platform evolves (Burgess and Baym, 2022). This allows us to address the gap in previous empirical studies.

## 3. Methodology

Social media platforms promote the wide sharing of ideas and encourage public group discussions with open views. Social media provides a more effective means to obtain quick responses and feedback on different global issues via textual posts, news, images and videos (Birjali et al. , 2021). Twitter (also known as X) is one of the largest social media platforms (Kumar et al. , 2020). Twitter's multimodal capabilities are used for communication and dissemination of information among its users. The ease of communication, content sharing, networking opportunities and advocacy on specific topics across a global digital community are some of its most valuable aspects (Burgess and Baym, 2022).

Since 2019, micro-influencers have emerged: regular users with modest numbers of followers -between 1,000 and 100,000 -who focus on one specific area of interest. They are often reflective of their audience and enjoy a great deal of trust, authority and authenticity which might be considered the perfect formula for powerful influence (Alampi, 2019).

Most human-provided data generated through social media is unstructured (Gandomi and Haider, 2015); Twitter offers a large volume of this. Twitter data analysis is of great importance for understanding public opinion, so has become one of the most popular sources of information in academic research (Li et al. , 2022). Processing textual data can yield valuable insights, enabling researchers to employ Twitter analytics as a tool for prediction.

Textual data can be broadly categorized into two main types: facts and opinions. Factual data comprise objective assertions about entities, occurrences and their properties, whereas opinions typically embody subjective expressions illustrating individuals' sentiments, evaluations or emotional responses to entities, events and their properties (Liu, 2010). Here, we use the term 'opinion' to refer to expressions generated and spread by female digital users in English through this platform.

Conducting internet-mediated research can present unique, often subtle challenges in upholding established ethical principles (Hewson and Buchanan, 2013). These issues include differentiating between public and private domains online, confidentiality and security of online data, participant anonymity, procedures for obtaining valid consent, ensuring withdrawal rights, levels of researcher control, implications for scientific value and potential harm to participants and researchers. This is especially pertinent to the privacy consent agreements which Twitter users accept when posting on the platform, as these delineate how their data may be collected, stored and analysed (Twitter, 2022). With these considerations in mind, we have ensured the implementation of ethical guidelines which


<!-- PAGE 8 -->


include maintaining data confidentiality, minimizing potential harm to participants and maximizing the scientific value of our findings.

Discussions were extracted from Twitter for the following reasons: (1) social networks help us understand human society, nature and technology together (Grover et al. , 2018); (2) a large number of users are available on Twitter; (3) the discussion on Twitter contains different metadata information such as user profile, geotag, timestamp and network information; (4) cost-effectiveness.

Opinion mining algorithms help detect, extract and classify opinions, sentiments and attitudes concerning different topics and themes, as expressed in textual input (Birjali et al. , 2021). Opinion mining is largely used in technology-oriented studies (Cortis and Davis, 2021): delving into textual analysis to comprehend the underlying factors of public sentiment (Birjali et al. , 2021). Sentiment analysis assesses positive or negative feelings. Digital consumption is expanding human boundaries and offering unprecedented opportunities, while simultaneously generating AI risks (Kanungo et al. , 2022).

Media platforms have been identified as a useful tool for researching public opinion (Yang et al. , 2022). Analysing user-generated content provides a great opportunity to automatically detect opinions and trends on topics of interest (Chatziadam et al. , 2020). However, because of its nature, user-generated data should be analysed through text mining and NLP techniques, including opinion mining (Meesala and Subramanian, 2022).

In this research, social opinion mining has been applied to historical Twitter data from 2022. Data were gathered using a combination of analytical methods such as word clouds, sentiment analyses and clustering. Through social opinion mining, natural language can be understood in terms of different opinion dimensions expressed by humans (Cortis and Davis, 2021). The appropriate technique selection is key to success here.

ML revolves around the problem of prediction (Mullainathan and Spiess, 2017) and facilitates confronting a vast amount of user-generated data and extracting useful information effectively (Ballestar et al. , 2022). These techniques integrate NLP, text analysis and computational linguistics to perform intense data analyses from our primary data. This framework allows us to test the dynamics behind current social media discussion, focussing on algorithmic AI gender bias.

Data were extracted from our research team's former academic account on Twitter, where historical public data are available. Considering the vast volume of data which users share daily on social media platforms, it is vital for researchers to pinpoint the developing latent topics and societal viewpoints, and extract relevant insights. First, we searched under a combination of Twitter hashtags #ai #gender #female #feminine #woman, posted over a limited period of 359 days from January 1 to December 25, 2022. A download was carried out, making use of the former Academic Twitter R package, and a data cleaning process performed to remove off-topic data. 172,041 tweets worldwide were identified. These conversations were analysed (Burgess and Baym, 2022) following three specific features of Twitter: @ reply, # hashtag and retweets (RT). However, we considered adding the number of 'likes' to be examined, from which we collected 172,041 posts written in English.

Then we classified users by gender, taking into account that some might be institutions. As the Twitter API does not provide information about the user's gender, we used the dictionary-based method included in the Python gender-guesser library after obtaining the first name of each unique user from their username or nickname, where possible. The cleaning process was a difficult task, as Twitter names include a lot of symbols, emojis, unnecessary spaces, links or hashtags, so we used some of the functions available in the Text Clean R package to remove all unnecessary characters.

After the first classification, a second one made use of the 'she/her' and 'he/him' keywords if available on the user description: overriding the result of the previous classification. A relative engagement index was then created, calculated with an average of 'likes', RT and followers. Users were listed from higher to lower engagement; only those classified as women were left. Based on this ranking, we extracted the 100 most influential global female accounts

Management Decision

3049


<!-- PAGE 9 -->


## MD 63,9

## 3050

and carefully analysed them manually, using all available information to ensure Python genderguesser was correct. We focused on the activity and engagement of 25 of those accounts to name the most relevant influential users. We then observed the overall hashtags used in 2022.

There were two main outcomes of this study of using Twitter analytics as a predictive tool to understand AI gender bias from a female socio-technical perspective. First, understanding and characterization of female users. Second, identification of underlying topics of discussion amid public female conversation.

## 4. Results and discussion

## 4.1 Influencers' profiles and behaviour

The top 100 most recognized female influencers possess 55,197 followers on average, and an average of 5,041 overall posts. Despite their modest number of followers and interaction, they are considered as key players in the collective digital conversation. Most of them are native English speakers who obtain followers' attention by communicating about the future of technology: conversations which lead threads around digital trends. The RT button is frequently used to give credits or expose non-ethical actions.

Figure 1 shows 100 accounts associated with influencer users. The word cloud graphic displays a large, heterogeneous number of parties involved in the conversation. MIT Technology Review magazine features prominently, along with the University of Washington and Stanford University. This demonstrates the active role of female journalists and university professors in this study.

From our cluster (Figures 2 and 3), we observe that most users are female entrepreneurs with businesses linked to gender equality causes. As company heads, they use this platform to self-promote and communicate their point of view and experiences. This correlates with the use of some popular hashtags: #womenentrepreneurs; #womeninventure; #womenintech; #femalefounders; #womeninbusiness; #womeninscience; #womeninvestors, mentioned on a total of 540 occasions.

As depicted in Figure 2, almost half the most influential influencers are company founders. This is an expected outcome: there have been gender biases reported in decisions allocating venture capital (VC) investments in companies founded by women (Malmstrom et al. , 2018;

Figure 1. Word cloud of associated accounts of the 100 most influential users where 'AI' and 'gender' are mentioned

<!-- image -->


<!-- PAGE 10 -->


Figure 2. Bar chart of types of accounts of the 100 most influential users, where 'AI' and 'gender' are mentioned

<!-- image -->

Balachandra et al. , 2019; Balachandra, 2020). According to the most recent Global Gender Gap report (World Economic Forum, 2024), only 2% of new companies targeted by VC in 2023 were founded by women. Our findings support Hypothesis 2, demonstrating that female founders provide creative and prosocial solutions to address gender equality causes.

Another label used by female influencers to define themselves is that of activists . Data feminists contend that feminism inherently involves activist efforts to transform feminist ideals into real-world actions (D'Ignazio and Klein, 2023). They share common interests with minorities such as feminism or anti-racism, some of them affiliate to gender or race empowerment associations. The two most influential users fight for race and gender issues: @ShanaVWhite and @jojobickley are both coloured women, which supports Hypothesis 4. Independent female authors use social media to promote their books, while female journalists and correspondents raise awareness of social issues for magazines and newspapers, or by themselves.

A considerable number of female university professors linked to prestigious academic institutions cover AI-related topics and address gender prejudices and stereotypes. Their role is vital in addressing this male-dominated industry and promoting diversity among AI researchers, encompassing both gender and racial perspectives. This transition aims to ensure the development of technologies that are balanced and inclusive.

Finally, there are a few female managers linked to some of the most influential technological corporations worldwide. @jojobickley, working for Uber Technologies, and @criticalneuro, working for Microsoft Research, are considered the third and fourth most influential leaders.


<!-- PAGE 11 -->


Figure 3. Word cloud of Twitter description of the 100 most influential users, where 'AI' and 'gender' are mentioned

<!-- image -->

Recently, the United States has surpassed China, the European Union and the United Kingdom as the primary source of leading AI models. In 2023, US-based institutions produced 61 notable AI models, significantly exceeding the EU's 21 and China's 15 (Perrault and Clark, 2024). Indeed, most contributors are presently based in the US, highlighting the amount of funding allocated to AI initiatives and indicating that discussions on feminism and technology are particularly prevalent there (McInerney and Drage, 2024). Building upon these facts, Figure 4 shows that the largest proportion of our sample posts are from native English speakers, mostly from the US, UK, Australia and Canada (88%).

## 4.2 Topics of discussion

As we have noted, RT are vital in conveying Twitter users' messages around gender. Hashtags, meanwhile, help organize the discourse and create a community around it. The hashtag #sustainability represented a substantial portion of the picture and was used 2,573 times. This demonstrates how a term linked to gender inequity was at the core of many conversations; and emanated most often from @katiepatrick. Another directly related hashtag is that of #PeggySmedley, the nineteenth most influential female (frequency value: 1,489), an American tech journalist and sustainability influencer, she hosts her own podcast called The Peggy Smedley Show discussing big trends and digital transformation. The relevance of this hashtag reflects the important role of journalists in this community. These two analyses confirm Hypothesis 3, demonstrating that economic, social and environmental sustainability dimensions and algorithmic gender bias are strongly linked to each other.

We also tested whether the conversation among these women was proactive or reactive. In other words, did the user frequently generate content through fairness-related terms, such as equity, balance, equality, justice, integrity, right or diverse; or discriminatory-related terms,


<!-- PAGE 12 -->


Figure 4. Spatial distribution of the 100 most influential users where 'AI' and 'gender' are mentioned

<!-- image -->

<!-- image -->

such as unequal, inequality, minority, disparity, invisible, gap, discrimination, underrepresented, misrepresented or bias? Of all 172,041 tweets:

- (1) 7,909 contain some of the words related to fairness.
- (2) 8,383 (6% more) contain some of the words related to discrimination. Of those, 1,419 tweets contain both proactive and reactive terms, those related to equity and those related to discrimination, therefore:
- (3) There are 6,490 'fair' tweets which do not contain any discriminatory terms.
- (4) There are 6,964 'discriminatory' tweets (7.3% more) which do not contain any fair terms.

These analyses suggest a similar distribution among polarized tweets, both proactive and reactive speech, although the latter was slightly higher in absolute terms. An additional sentiment analysis was also executed to understand users' sentiments and emotions expressed in text (Liu, 2010).

We classified our primary data here by adopting Ekman's six basic emotions (Ekman et al. , 1999): anger, disgust, fear, joy, sadness and surprise. As we utilized the Syuzhet sentiment analysis algorithm and the R programming language, we obtained two additional sentiments: anticipation and trust (Jockers, 2023). As depicted in Figure 5, four pleasant and four unpleasant emotions were observed, with surprise being categorized as either positive or negative, depending on the context. The result shows that digital conversations by women users have a significantly positive sentiment, which validates Butler's groundbreaking research on feminist discourse around solidarity and hope (2024). Both analyses confirm Hypothesis 1: Algorithmic bias impacts female user behaviours in response to injustice and equality in algorithmic outcomes.

Finally, we sought to understand gender and race association. We applied the chi-square test to evaluate whether there is a significant relationship between the variables of gender and race. The hypotheses proposed were:


<!-- PAGE 13 -->


Figure 5. Bar chart by emotion of all 172,041 tweets

<!-- image -->

- (1) Null hypothesis (H ₀ ): There is no relationship between gender and race, meaning they are independent.
- (2) Alternative hypothesis (H ₁ ): There is a relationship between gender and race, meaning they are not independent.

The values observed in the contingency table are as follows (see Table 2):

The expected values for each cell were calculated under the hypothesis of independence. The chi-square statistic obtained was 4365.85, with 1 degree of freedom, and an extremely low p -value (0.0), which allows us to reject the null hypothesis. This means there is a significant association between the variables, 'gender' and 'race'.

These results support black feminist scholar Patricia Hill Collins' matrix of domination conceptual model: which holds that differing axes of social division such as race, gender, class, sexual orientation, age and ability do not exist independently of each other. Instead, they intersect and form a matrix, creating a complex system of oppression and privilege (Collins, 1990).

Table 2. Number of tweets with gender and race in the tweet body

| Absolutes                  | Race No   | Yes   |
|----------------------------|-----------|-------|
| Gender                     | 143,555   | 919   |
|                            | 25,987    | 1,580 |
| Source(s): Own elaboration |           |       |


<!-- PAGE 14 -->


Building on Black feminist thought, Crenshaw (2017) developed the concept of 'intersectionality'. She coined this term to address the intersecting social forces, identities and ideological frameworks through which systems of power and inequality are articulated and legitimized. Costanza-Chock (2018) suggests that gender, race and class are interlocking systems, often experienced together by individuals who exist at their intersections. The analyses here confirm Hypothesis 4: Gender and race affiliations tend to converge in collective conversations.

## 4.3 Theories linked to study results

The analysis here supports Treanor's (2022) findings, emphasizing that the obstacles faced by female STEM professionals highlight the persistent, widespread nature of structural gender inequalities. In accordance with Balachandra et al. (2019, 2020), financially supporting AI projects led by women must be a priority to address gender gap entrepreneurship friction (Howell and Nanda, 2023) and overcome a complex, iteratively transformative process (Gobo and Marcheselli, 2023). Our findings also align with those of Eagly and Koenig (2021) which underscore the importance of changing the roles typically occupied by group members, rather than simply attempting to eliminate the stereotypes from individual minds.

Entrepreneurship, dominated by men, may be the most effective approach through which women can avoid some of the barriers in the work environment. Women engage their audience through gender-neutral digital conversations expressing optimistic, powerful viewpoints and providing potential solutions to address AI gender-biased technologies. Parker et al. (2010) suggest that proactive women actively shape their actions or environment to create a different outcome in the future.

Building on gender leadership management, Bailyn (2011) recognized the critical need to identify and challenge gendered assumptions within workplace structures. Yet despite this awareness, decades later, these gendered paradigms continue to persist as significant issues. Our findings agree with those of Wiezel et al. (2024): it is time to revise the think manager-think male model and our understanding of sex, dominance and leadership models.

## 5. Conclusions

Intersectional feminist approaches are paramount in the design, development and deployment of AI systems. Yet the consequences of their persistent inequality for both individuals and wider society have become a growing topic of controversy, evidenced by conversations in the social media space.

This research has contributed to the feminist perspective of gender-neutral technologies by identifying societal approaches in the digital conversation and female users' reactions to technological change. Through social opinion mining and a combination of analytical methods such as word cloud analysis, clustering and sentiment analysis, some insights about AI in the collective debate have been obtained. Empirical data gathered from interactions of female users in digital dialogues highlight that the most prominent topics of interest are the future of AI technologies and the active role of women in guaranteeing gender-balanced systems. These insights may be useful for future lines of research.

Female leaders who struggle from cultural and social discrimination lead constructive conversations and create opportunities for change. Feminist thinkers in this incipient field are considered an independent, reliable source of information by their followers. From a practical perspective, this suggests that AI bias impacts female user behaviours in response to injustice and inequality in algorithmic outcomes. Additionally, they share common attributes and topics of interest, with profiles affiliated to gender or race empowerment associations: which confirms that, in practice, gender and race affiliations tend to converge in collective digital conversations.

Management Decision

3055


<!-- PAGE 15 -->


## 3056

Others among them are feminist activists, independent authors, tech journalists and university professors who engage the audience: raising awareness of social issues and technological threads, and confirming that the term 'sustainability' is strongly linked to conversations around gender inequity. Furthermore, women challenged by cultural bias and social discrimination are more likely to fund entrepreneurial solutions which address AI and ML bias. Most of the women highlighted in our study are entrepreneurs who use Twitter to communicate their point of view and experiences, and promote their prosocial companies.

Building on Wajcman (2007), this study contributes to evidence that feminine theory, knowledge and methods are critical if algorithm development teams are to ensure that what they create is sensitive to gender considerations. Analytical social opinion mining may be an effective methodology in obtaining actionable insights and mitigating biased effects, and highly useful for decision-makers.

The results also help us understand the role of female influencers: ordinary individuals often challenged by gender and race discrimination. They request an intersectional, collaborative and pluralistic understanding of gender and race in AI. They act alone and endure the consequences of stigmatized products and services. AI curators should strongly consider advocating for responsible, impartial technologies, recognizing the indispensable role of women. This must consider all stakeholders, including representatives from industry, small and medium-sized enterprises (SMEs), civil society and academia.

This study does have its limitations, however. First, different keywords are likely to result in a different pool of related research. Moreover, due to the nature of our sample, the largest proportion of posts are from native English speakers, predominantly (88%) from the US, UK, Australia and Canada. This demographic concentration reflects specific social structures and practices that influence gender equity priorities within the sample. These cultural contexts, which often emphasize inclusivity and equity, play a significant role in shaping the discourse around gender issues. These cultural norms, preferences and practices are critical in understanding the individual behaviours, perspectives and priorities expressed in the posts; in other words, it is vital to consider cultural context and economic determinants in an analysis of gender equity discussions.

The US, UK, Australia and Canada share a cultural and legal heritage, a common language, values, democracy and the rule of law. Bennett (2007) emphasizes the potential for enhanced cooperation in areas like technology, trade and security, suggesting that the anglosphere's cultural and institutional commonalities create a natural foundation for a cohesive, influential global network. These shared characteristics further influence the common approaches and perspectives on gender equity in public discourse. Yet findings from Western nations should not be assumed to apply easily to the contexts of other countries.

That said, despite the limitations acknowledged above, this research has provided valuable insights which can serve as a guide for AI researchers and practitioners seeking a comprehensive understanding of the topic within a critical feminist lens. Women who endure the consequences of stigmatized products and services are more likely to share their opinions and experiences in social media. They demand responsible, unbiased AI applications for all parties involved. They are considered an independent, reliable source of information by their followers. The term sustainability enjoys greatest frequency, while gender and race variables display a frequent association around equitable, inclusive digital conversations about AI.

Further research is needed to identify and assess the various impacts of AI bias (Varsha, 2023). We have shown that female narratives are useful in highlighting discriminatory actions against gendered and racial minorities and reducing stereotypes and prejudices. To avoid algorithmic discrimination and improve fairness, we propose three recommendations for concrete actions.

First , advanced technologies should continue to be approached from a socio-technical viewpoint with a multifaced development team, ensuring that robust legal frameworks and ethical considerations are followed. Lawmakers, regulators and company policymakers should prioritize both direct and indirect approaches when addressing gender equality.


<!-- PAGE 16 -->


However, as Karanicolas (2024) points out, as regulatory AI frameworks evolve into transnational global standards, it is essential to assess whether they truly address the needs and concerns of those most impacted by technological disruption -particularly in the US, EU and China -or if these global standards merely perpetuate existing domestic inequalities on a global scale. Addressing these broader systemic issues is critical before ensuring that specific concerns, like gender equality, are adequately integrated into these frameworks.

Corporations and academic institutions should adopt a more committed plan and strengthen legal frameworks which mandate a certain level of parity in algorithm development and researcher teams. It is vital to include a diverse range of actors in democratic discussions around the future development of AI (Hedlund and Persson, 2024). Haslanger (2018) argues that achieving justice goes beyond merely changing laws and policies; it also involves a cultural shift that challenges, disrupts and reshapes social meanings.

Second , female participation in STEM should be fostered, thereby helping facilitate the active role of women in AI teams. This can be especially challenging, because most AI research resources are controlled by Big Tech companies dominated by advantaged groups. Most women in STEM academia believe that opportunities and success are influenced more by non-meritocratic factors, such as social connections or systemic biases, rather than meritbased factors like hard work and talent (Bird and Rhoton, 2021).

Third , it should be remembered that women face unique challenges beyond entrenched biases (O'Connell and McKinnon, 2021) and increased stereotypes (Kovaleva et al. , 2023), including negative experiences of bullying or harassment (Freedman et al. , 2023). Women in STEM also often suffer microaggressions such as gaslighting and mansplaining (Johnson et al. , 2021), which further undermines their confidence and participation in professional settings.

Female-founded companies received just 2% of all VC funding invested in Europe and the US in 2023 (World Economic Forum, 2024). Narrowing this alarming gap is extremely urgent: so providing financial support for AI initiatives led by women should be a priority. This can help women overcome the gender gap in entrepreneurship and address systemic structural and gender-based inequalities.

## References

- Ahn, J., Kim, J. and Sung, Y. (2022), 'The effect of gender stereotypes on artificial intelligence recommendations', Journal of Business Research , Vol. 141, pp. 50-59, doi: 10.1016/ J.JBUSRES.2021.12.007.
- Alampi, A. (2019), 'The future is micro: how to build an effective micro-influencer programme', Journal of Digital and Social Media Marketing , Vol. 7 No. 3, p. 203, doi: 10.1126/ science.ade2420.
- Bailyn, L. (2011), 'Redesigning work for gender equity and work-personal life integration', Community, Work and Family , Vol. 14 No. 1, pp. 97-112, doi: 10.1080/13668803.2010.532660.
- Balachandra, L. (2020), 'How gender biases drive venture capital decision-making: exploring the gender funding gap', Gender in Management , Vol. 35 No. 3, pp. 261-273, doi: 10.1108/GM-112019-0222.
- Balachandra, L., Briggs, T., Eddleston, K. and Brush, C. (2019), 'Don't pitch like a girl! How gender stereotypes influence investor decisions', Entrepreneurship: Theory and Practice , Vol. 43 No. 1, pp. 116-137, doi: 10.1177/1042258717728028.
- Balahur, A., Jenet, A. and Hupont Torres, I. (2022), Data Quality Requirements for Inclusive, NonBiased and Trustworthy AI: Putting Science into Standards . doi: 10.2760/365479.
- Ballestar, M.T., Mart � ın-Llaguno, M. and Sainz, J. (2022), 'An artificial intelligence analysis of climatechange influencers' marketing on Twitter', Psychology and Marketing , Vol. 39 No. 12, pp. 2273-2283, doi: 10.1002/mar.21735.

Management Decision

3057


<!-- PAGE 17 -->


## MD 63,9

## 3058

- Benjamin, R. (2019), Race after Technology: Abolitionist Tools for the New Jim Code , Polity Press, Cambridge, Medford.
- Bennett, J.C. (2007), The Anglosphere Challenge: Why the English-Speaking Nations Will Lead the Way in the Twenty-First Century , Rowman &amp; Littlefield, Lanham, MA.
- Bianchi, F., Kalluri, P., Durmus, E., Ladhak, F., Cheng, M., Nozza, D., Hashimoto, T., Jurafsky, D., Zou, J. and Caliskan, A. (2023), 'Easily accessible text-to-image generation amplifies demographic stereotypes at a large scale', Conference on Fairness, Accountability, and Transparency , pp. 1493-1504.
- Bird, S.R. and Rhoton, L.A. (2021), 'Seeing isn't always believing: gender, academic STEM, and women scientists' perceptions of career opportunities', Gender and Society , Vol. 35 No. 3, pp. 422-448, doi: 10.1177/08912432211008814.
- Birjali, M., Kasri, M. and Beni-Hssane, A. (2021), 'A comprehensive survey on sentiment analysis: approaches, challenges and trends', Knowledge-Based Systems , Vol. 226, 107134, doi: 10.1016/ J.KNOSYS.2021.107134.
- Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V. and Kalal, A. (2016), 'Man is to computer programmer as woman is to homemaker? Debiasing word embeddings', 30th Conference on Neural Information Processing Systems .
- Broussard, M. (2018), Artificial Unintelligence: How Computers Misunderstand the World , MIT Press, Cambridge, MA.
- Browne, J., Cave, S., Drage, E., McInerney, K. and Feminist, A.I., (Eds) (2023), Critical Perspectives on Algorithms, Data, and Intelligent Machines , Oxford University Press, Oxford, doi: 10.1093/ oso/9780192889898.001.0001.
- Buolamwini, J. and Gebru, T. (2018), 'Gender shades: intersectional accuracy disparities in commercial gender classification', Conference on Fairness, Accountability, and Transparency , pp. 1-15.
- Burgess, J. and Baym, N.K. (2022), Twitter: A Biography , NYU Press, New York City, NY.
- Burrell, J. (2016), 'How the machine 'thinks': understanding opacity in machine learning algorithms', Big Data and Society , Vol. 3 No. 1, doi: 10.1177/2053951715622512.
- Butler, J. (2024), Who Is Afraid of Gender? , Knopf Canada, Toronto.
- Cano-Marin, E. (2024), 'The transformative potential of generative artificial intelligence (GenAI) in business: a text mining analysis on innovation data sources', ESIC Market , Vol. 55 No. 2, e333, doi: 10.7200/esicm.55.333.
- Cano-Marin, E., Mora-Cantallops, M. and Sanchez-Alonso, S. (2023), 'The power of big data analytics over fake news: a scientometric review of Twitter as a predictive system in healthcare', Technological Forecasting and Social Change , Vol. 190, 122386, doi: 10.1016/ J.TECHFORE.2023.122386.
- Carbone, J., Cahn, N. and Levit, N. (2019), 'Women, rule-breaking, and the triple bind', George Washington Law Review , Vol. 87, pp. 1105-1162.
- Charlesworth, T.E.S., Yang, V., Mann, T.C., Kurdi, B. and Banaji, M.R. (2021), 'Gender stereotypes in natural language: word embeddings show robust consistency across child and adult language corpora of more than 65 million words', Psychological Science , Vol. 32 No. 2, pp. 218-240, doi: 10.1177/0956797620963619.
- Chatziadam, P., Dimitriadis, A., Gikas, S., Logothetis, I., Michalodimitrakis, M., Neratzoulakis, M., Papadakis, A., Kontouslis, V., Siganos, N., Theodoropoulos, D., Vougioukalos, G., Hatzakis, I., Gerakis, G., Papadakis, N. and Kondylakis, H. (2020), 'TwiFly: a data analysis framework for Twitter', Information 2020 , Vol. 11 No. 5, 247, doi: 10.3390/INFO11050247.
- Cheng, L., Varshney, K.R. and Liu, H. (2021), 'Socially responsible AI algorithms: issues, purposes, and challenges', Arxiv , Vol. 71, pp. 1137-1181, doi: 10.1613/jair.1.12814, available at: http:// arxiv.org/abs/2101.02032
- Chu, C.H., Donato-Woodger, S., Khan, S.S., Nyrup, R., Leslie, K., Lyn, A., Shi, T., Bianchi, A., Abbasgholizadeh Rahimi, S. and Grenier, A. (2023), 'Age-related bias and artificial intelligence:


<!-- PAGE 18 -->


- a scoping review', Humanities and Social Sciences Communications , Vol. 10 No. 1, pp. 1-17, doi: 10.1057/s41599-023-01999-y.
- Cirillo, D., Catuara-Solarz, S., Morey, C., Guney, E., Subirats, L., Mellino, S., Gigante, A., Valencia, A., Rementeria, M.J., Chadha, A.S. and Mavridis, N. (2020), 'Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare', NPJ Digital Medicine , Vol. 3 No. 1, pp. 1-11, doi: 10.1038/s41746-020-0288-5.
- Clark, J. (2016), 'Artificial intelligence has a 'sea of dudes' problem', Bloomberg Professional Services , available at: https://www.bloomberg.com/professional/blog/artificial-intelligence-seadudes-problem/
- Cockburn, C. and Ormrod, S. (1993), Gender and Technology in the Making , SAGE Publications, Thousand Oaks, CA.
- Collett, C., Dillon, S., Neff, G., Patel, R., Browne, J., Wilcox, L., Cave, S., Rankin, J., Keyes, O. and Robinson, D. (2019), AI and Gender: Four Proposals for Future Research , The Leverhulme Centre for the Future of Intelligence, Cambridge.
- Collins, P.H. (1990), 'Black feminist thought in the matrix of domination', Black Feminist Thought: Knowledge, Consciousness, and the Politics of Empowerment , Vol. 138, pp. 221-238.
- Cortis, K. and Davis, B. (2021), 'Over a decade of social opinion mining: a systematic review', Artificial Intelligence Review , Vol. 54 No. 7, pp. 4873-4965, doi: 10.1007/S10462-021-10030-2.
- Costanza-Chock, S. (2018), 'Design justice: towards an intersectional feminist framework for design theory and practice', Proceedings of the Design Research Society , Vol. 2, doi: 10.21606/ drs.2018.679.
- Costanza-Chock, S. (2020), Design Justice: Community-Led Practices to Build the Worlds We Need , The MIT Press, Cambridge, MA.
- Crawford, K. (2016), 'Artificial intelligence's white guy problem', The New York Times .
- Crawford, K. (2017), 'The trouble with bias', NIPS , available at: https://www.youtube.com/watch? v 5 fMym\_BKWQzk
- Crawford, K. (2021), The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence , Yale University Press, available at: http://ebookcentral.proquest.com/lib/cam/ detail.action?docID 5 6478659
- Crenshaw, K. (2017), On Intersectionality. Essential Writings , The New Press, New York City, NY.
- Criado-Perez, C. (2021), Invisible Women: Data Bias in a World Designed for Men , Harry N. Abrams, New York City, NY.
- Curto, G., Jojoa Acosta, M.F., Comim, F. and Garcia-Zapirain, B. (2024), 'Are AI systems biased against the poor? A machine learning analysis using Word2Vec and GloVe embeddings', AI and Society , Vol. 39 No. 2, pp. 617-632, doi: 10.1007/s00146-022-01494-z.
- Dalcher, D. (2022), 'The quest for artificial intelligence in projects 2', Advances in Project Management Series , Vol. XI, pp. 2330-4480, available at: www.pmworldlibrary.net
- Daugherty, P.R., Wilson, H.J. and Chowdhury, R. (2018), 'Using artificial intelligence to promote diversity', MIT Sloan Management Review , available at: https://sloanreview.mit.edu/article/ using-artificial-intelligence-to-promote-diversity/
- Draude, C., Klumbyte, J., L € ucking, P. and Treusch, P. (2020), 'Situated algorithms: a sociotechnical systemic approach to bias', Online Information Review , Vol. 44 No. 2, pp. 325-342, doi: 10.1108/OIR-10-2018-0332.
- D'Ignazio, C. and Klein, L.F. (2023), Data Feminism , MIT Press, Cambridge, MA: doi: 10.7551/ mitpress/11805.001.0001.
- Eagly, A.H. and Karau, S.J. (2002), 'Role congruity theory of prejudice toward female leaders', Psychological Review , Vol. 109 No. 3, pp. 573-598, doi: 10.1037/0033-295X.109.3.573.
- Eagly, A.H. and Koenig, A.M. (2021), 'The vicious cycle linking stereotypes and social roles', Current Directions in Psychological Science , Vol. 30 No. 4, pp. 343-350, doi: 10.1177/ 09637214211013775.

## Management Decision


<!-- PAGE 19 -->


## MD 63,9

## 3060

- Ekman, P., Dalgleish, T. and Power, M. (1999), Handbook of Cognition and Emotion , Wiley, Chichester.
- Elkington, J. (1997), 'The triple bottom line for 21st century business', Environmental Management: Readings and Cases , Vol. 2, pp. 49-66.
- European Commission (2022), 'A European approach to artificial intelligence', available at: https:// digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence
- European Parliamentary Research Service (2023), 'Artificial intelligence act', available at: https:// www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-firstregulation-on-artificial-intelligence
- Faulkner, W. (2001), 'The technology question in feminism: a view from feminist technology studies', Women's Studies International Forum , Vol. 24 No. 1, pp. 79-95, doi: 10.1016/S0277-5395(00) 00166-7.
- Floridi, L., Cowls, J., King, T.C., Taddeo, M., Chazerand, P., Dignum, V., Luetge, C., Madelin, R., Pagallo, U., Rossi, F., Schafer, B., Valcke, P. and Vayena, E. (2021), 'An ethical framework for a good AI society: opportunities, risks, principles, and recommendations', Philosophical Studies Series , Vol. 144, pp. 19-39, doi: 10.1007/978-3-030-81907-1\_3/COVER.
- Foffano, F., Scantamburlo, T. and Cort � es, A. (2023), 'Investing in AI for social good: an analysis of European national strategies', AI and Society , Vol. 38 No. 2, pp. 479-500, doi: 10.1007/s00146022-01445-8.
- Freedman, G., Green, M.C., Kussman, M., Drusano, M. and Moore, M.M. (2023), ''Dear future woman of STEM': letters of advice from women in STEM', International Journal of STEM Education , Vol. 10 No. 1, 20, doi: 10.1186/s40594-023-00411-0.
- Gallego G � omez, C. and Vaquero Fr � ıas, L. (2022), 'Inteligencia artificial y desarrollo sostenible del turismo: el valor de los acuerdos de colaboraci � on', ESIC Market , Vol. 53 No. 3, e281, doi: 10.7200/esicm.53.281.
- Gandomi, A. and Haider, M. (2015), 'Beyond the hype: big data concepts, methods, and analytics', International Journal of Information Management , Vol. 35 No. 2, pp. 137-144, doi: 10.1016/ j.ijinfomgt.2014.10.007.
- Gebru, T. (2020), 'Race and gender', in Dirk Dubber, M., Pascale, F. and Das, S. (Eds), The Oxford Handbook of Ethics of AI , Oxford University Press, pp. 252-269, doi: 10.1093/oxfordhb/ 9780190067397.013.16.
- Gobo, G. and Marcheselli, V. (2023), 'Science, technology and gender', in Science, Technology and Society , Springer International Publishing, pp. 201-215, doi: 10.1007/978-3-031-08306-8\_10.
- Grover, P., Kar, A.K. and Davies, G. (2018), ''Technology enabled health' -insights from twitter analytics with a socio-technical perspective', International Journal of Information Management , Vol. 43, pp. 85-97, doi: 10.1016/J.IJINFOMGT.2018.07.003.
- Guevara-G � omez, A., de Z � arate-Alcarazo, L. and Criado, J.I. (2021), 'Feminist perspectives to artificial intelligence: comparing the policy frames of the European Union and Spain', Information Polity , Vol. 26 No. 2, pp. 173-192, doi: 10.3233/ip-200299.
- Hagendorff, T. (2020), 'The ethics of AI ethics: an evaluation of guidelines', Minds and Machines , Vol. 30 No. 1, pp. 99-120, doi: 10.1007/S11023-020-09517-8/TABLES/1.
- Hall, P. and Ellis, D. (2023), 'A systematic review of socio-technical gender bias in AI algorithms', Online Information Review , Vol. 47 No. 7, pp. 1264-1279, doi: 10.1108/OIR.
- Hamilton, M. (2019), 'The sexist algorithm', Behavioral Sciences and the Law , Vol. 37 No. 2, pp. 145-157, doi: 10.1002/BSL.2406.
- Hansson, S.O. (2017), The Ethics of Technology: Methods and Approaches , Rowman &amp; Littlefield, Lanham, MA.
- Haraway, D. (1987), 'A manifesto for cyborgs: science, technology, and socialist feminism in the 1980s', Australian Feminist Studies , Vol. 2 No. 4, pp. 1-42, doi: 10.1080/ 08164649.1987.9961538.


<!-- PAGE 20 -->


- Harding, S. (1986), From Feminist Empiricism to Feminist Standpoint Epistemologies, The Science Question in Feminism , available at: https://books.google.com/books/about/The\_Science\_ Question\_in\_Feminism.html?hl 5 es&amp;id 5 27TrCuk4LRgC
- Harding, S. (1991), Whose Science? Whose Knowledge? Thinking from Women's Lives , Cornell University Press, Ithaca, NY.
- Haslanger, S. (2018), 'What is a social practice?', Royal Institute of Philosophy Supplement , Vol. 82, pp. 231-247, doi: 10.1017/s1358246118000085.
- Hawken, P., Lovins, A.B. and Lovins, L.H. (2000), Natural Capitalism: The Next Industrial Revolution , Routledge, Abingdon.
- Haythornthwaite, C. (2005), 'Social networks and internet connectivity effects', Information, Community and Society , Vol. 8 No. 2, pp. 125-147, doi: 10.1080/13691180500146185.
- Hedlund, M. and Persson, E. (2024), 'Expert responsibility in AI development', AI and Society , Vol. 39 No. 2, pp. 453-464, doi: 10.1007/s00146-022-01498-9.
- Hewson, C. and Buchanan, T. (2013), 'Ethics guidelines for internet-mediated research', The British Psychological Society.
- Hill Collins, P. (2022), Black Feminist Thought , 30th Anniversary Edition, Routledge, New York.
- Holmes, W., Bektik, D., Di Gennaro, M., Woolf, B.P. and Luckin, R. (2019), 'Ethics in AIED: who cares?', 20th International Conference on Artificial Intelligence in Education .
- Hoover, A.E., Hack, T., Garcia, A.L., Goodfriend, W. and Habashi, M.M. (2019), 'Powerless men and agentic women: gender bias in hiring decisions', Sex Roles , Vol. 80 Nos 11-12, pp. 667-680, doi: 10.1007/S11199-018-0964-Y/METRICS.
- Howell, S.T. and Nanda, R. (2023), 'Networking frictions in venture capital, and the gender gap in entrepreneurship', Journal of Financial and Quantitative Analysis , Vol. 59 No. 6, pp. 2733-2761, doi: 10.1017/S0022109023000819.
- Huq, A.Z. (2019), 'Racial equity in algorithmic criminal justice', Duke Law Journal , Vol. 68, p. 1043.
- Jacobson, J. (1992), Gender Bias: Roadblock to Sustainable Development , Spring, Berlin.
- Jaume-Palasi, L. (2021), ' � Etica relacional e inteligencia artificial', The Ethical Tech Society , available at: https://www.youtube.com/watch?v 5 mcWsUwt7IY8
- Jockers, M.M. (2023), 'Syuzhet', available at: https://github.com/mjockers/syuzhet
- Johnson, V.E., Nadal, K.L., Sissoko, G.D.R. and King, R. (2021), ''It's not in your head': gaslighting, 'splaining, victim blaming, and other harmful reactions to microaggressions', Perspectives on Psychological Science , Vol. 16 No. 5, pp. 1024-1036, doi: 10.1177/17456916211011963.
- Kanungo, R.P., Gupta, S., Patel, P., Prikshat, V. and Liu, R. (2022), 'Digital consumption and socionormative vulnerability', Technological Forecasting and Social Change , Vol. 182, 121808, doi: 10.1016/J.TECHFORE.2022.121808.
- Kaplan, A.M. and Haenlein, M. (2010), 'Users of the world, unite! The challenges and opportunities of social media', Business Horizons , Vol. 53 No. 1, pp. 59-68, doi: 10.1016/ J.BUSHOR.2009.09.003.
- Karanicolas, M. (2024), 'Challenging minority rule: developing Al standards that serve the majority world', UCLA Law Review Discourse , Vol. 71, pp. 196-213, available at: https://ssrn.com/ abstract 5 4450707
- Kazim, E., Mendes, D., Denny, T. and Koshiyama, A. (2021), 'AI auditing and impact assessment: according to the UK information commissioner's office', AI and Ethics , Vol. 1 No. 3, pp. 301-310, doi: 10.1007/S43681-021-00039-2.
- Khalil, A., Ahmed, S.G., Khattak, A.M. and Al-Qirim, N. (2020), 'Investigating bias in facial analysis systems: a systematic review', IEEE Access , Vol. 8, pp. 130751-130761, doi: 10.1109/ ACCESS.2020.3006051.
- Kordzadeh, N. and Ghasemaghaei, M. (2022), 'Algorithmic bias: review, synthesis, and future research directions', European Journal of Information Systems , Vol. 31 No. 3, pp. 388-409, doi: 10.1080/ 0960085X.2021.1927212.

## Management Decision


<!-- PAGE 21 -->


## MD 63,9

## 3062

- Kovaleva, Y., Hyrynsalmi, S., Saltan, A., Happonen, A. and Kassurinen, J. (2023), 'Becoming an entrepreneur: a study of factors with women from the tech sector', Information and Software Technology , Vol. 155, 107110, doi: 10.1016/j.infsof.2022.107110.
- Kumar, A., Sangwan, S.R. and Nayyar, A. (2020), 'Multimedia social big data: mining', Intelligent Systems Reference Library , Vol. 163, pp. 289-321, doi: 10.1007/978-981-13-8759-3\_ 11/COVER.
- Landabur Ayala, R. and Wilson Alcalde, J.E. (2022), 'Better attitudes toward foreigners: effects of dual-identity, identity fusion with the country and humanity', Psykhe , doi: 10.7764/ psykhe.2021.38527.
- Leavy, S. (2018), 'Gender bias in artificial intelligence: the need for diversity and gender theory in machine learning', Proceedings -International Conference on Software Engineering , pp. 14-16, doi: 10.1145/3195570.3195580.
- Leufer, D. and Hidvegi, F. (2023), 'The pitfalls of the European Union's risk-based approach to digital rulemaking', UCLA Law Review Discourse , Vol. 71, available at: https://datamatters
- Li, X., Wen, J., Jiang, J., Daim, T. and Huang, L. (2022), 'Identifying potential breakthrough research: a machine learning method using scientific papers and Twitter data', Technological Forecasting and Social Change , Vol. 184, 122042, doi: 10.1016/J.TECHFORE.2022.122042.
- Liu, B. (2010), 'Sentiment analysis and subjectivity', in Handbook of Natural Language Processing , [Preprint].
- Luccioni, S., Jernite, Y. and Strubell, E. (2024), 'Power hungry processing: watts driving the cost of AI deployment?', in Association for Computing Machinery (ACM) , pp. 85-99, doi: 10.1145/ 3630106.3658542.
- L € utz, F. (2022), 'Gender equality and artificial intelligence in Europe. Addressing direct and indirect impacts of algorithms on gender-based discrimination', ERA Forum , Vol. 23 No. 1, pp. 33-52, doi: 10.1007/S12027-022-00709-6/METRICS.
- Malmstrom, M., Voitkane, A., Johansson, J. and Wincent, J. (2018), 'VC stereotypes about men and women aren't supported by performance data', Harvard Business Review .
- McInerney, K. and Drage, E. (2024), The Good Robot: Why Technology Needs Feminism , Bloomsbury Publishing, London.
- Meesala, S.R. and Subramanian, S. (2022), 'Feature based opinion analysis on social media tweets with association rule mining and multi-objective evolutionary algorithms', Concurrency and Computation: Practice and Experience , Vol. 34 No. 3, e6586, doi: 10.1002/CPE.6586.
- Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K. and Galstyan, A. (2019), 'A survey on bias and fairness in machine learning', ACM Computing Surveys , Vol. 54 No. 6, pp. 1-35, doi: 10.1145/ 3457607.
- Meinzen-Dick, R., Kovarik, C. and Quisumbing, A.R. (2014), 'Gender and sustainability', Annual Review of Environment and Resources , Vol. 39 No. 1, pp. 29-55, doi: 10.1146/ANNUREVENVIRON-101813-013240.
- Mendez-Suarez, M., De las Mercedes de Obesso, M., Marquez, O.C. and Palacios, C.M. (2024), 'Why do companies employ prohibited unethical artificial intelligence practices?', IEEE Transactions on Engineering Management , Vol. 71, pp. 12218-12227, doi: 10.1109/tem.2023.3258686.
- M � endez-Su � arez, M., Sim � on-Moya, V. and Mu ~ noz-De Prat, J. (2023), 'Do current regulations prevent unethical AI practices?', Journal of Competitiveness , Vol. 15 No. 3, pp. 207-222, doi: 10.7441/ joc.2023.03.11.
- Mittelstadt, B.D., Allo, P., Taddeo, M., Wachter, S. and Floridi, L. (2016), 'The ethics of algorithms: mapping the debate', Big Data and Society , Vol. 3 No. 2, doi: 10.1177/2053951716679679/ ASSET/IMAGES/LARGE/10.1177\_2053951716679679-FIG1.JPEG.
- Moorosi, N., Sefala, R. and Luccioni, A.S. (2023), 'AI for whom? Shedding critical light on AI for social good', NeurIPS 2023 Computational Sustainability: Promises and Pitfalls from Theory to Deployment , available at: https://sdgs.un.org/goals


<!-- PAGE 22 -->


- Mullainathan, S. and Spiess, J. (2017), 'Machine learning: an applied econometric approach', The Journal of Economic Perspectives , Vol. 31 No. 2, pp. 87-106, doi: 10.1257/JEP.31.2.87.
- Nadeem, A., Marjanovic, O. and Abedin, B. (2022), 'Gender bias in AI-based decision-making systems: a systematic literature review', Australasian Journal of Information Systems , Vol. 26, doi: 10.3127/ajis.v26i0.3835.
- Noto La Diega, G. (2018), 'Against the dehumanisation of decision-making -algorithmic decisions at the crossroads of intellectual property, data protection, and freedom of information', SSRN , Vol. 9 JIPITEC 3 para 1, available at: https://ssrn.com/abstract 5 3188080
- Ntoutsi, E., Fafalios, P., Gadiraju, U., Nejdl, W., Vidal, M.E., Ruggieri, S., Turini, F., Papadopoulos, S., Krasanakis, E., Kompatsiaris, I., Kinder-Kurlanda, K., Wagner, C., Karimi, F., Fernandez, M., Alani, H., Berendt, B., Kruegel, T., Heinze, C., Broelemann, K., Kasneci, G., Tiropanis, T. and Staab, S. (2020), 'Bias in data-driven artificial intelligence systems -an introductory survey', Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery , Vol. 10 No. 3, e1356, doi: 10.1002/WIDM.1356.
- Olan, F., Jayawickrama, U., Arakpogun, E.O., Suklan, J. and Liu, S. (2024), 'Fake news on social media: the impact on society', Information Systems Frontiers , Vol. 26 No. 2, pp. 443-458, doi: 10.1007/s10796-022-10242-z.
- Omrani, N., Rivieccio, G., Fiore, U., Schiavone, F. and Garcia Agreda, S. (2022), 'To trust or not to trust? An assessment of trust in AI-based systems: concerns, ethics and contexts', Technological Forecasting and Social Change , Vol. 181, 121763, doi: 10.1016/J.TECHFORE.2022.121763.
- O'Connell, C. and McKinnon, M. (2021), 'Perceptions of barriers to career progression for academic women in stem', Societies , Vol. 11 No. 2, p. 27, doi: 10.3390/soc11020027.
- O'Neil, C. (2016), 'Weapons of math destruction: how big data increases inequality and threatens democracy', Scientific American , Vol. 44 No. 2, pp. 97-98, doi: 10.1177/0256090919853933.
- Parker, S.K., Bindl, U.K. and Strauss, K. (2010), 'Making things happen: a model of proactive motivation', Journal of Management , Vol. 36 No. 4, pp. 827-856, doi: 10.1177/ 0149206310363732.
- Pedr � o, F. (2020), 'The conditions and results of innovation in educational models: applications of artificial intelligence to higher education: possibilities, evidence, and challenges', available at: www.iuline.it
- Perrault, R. and Clark, J. (2024), 'Artificial intelligence index report 2024'.
- Pinney, C., Raj, A., Hanna, A. and Ekstrand, M.D. (2023), 'Much ado about gender: current practices and future recommendations for appropriate gender-aware information access', CHIIR 2023 -Proceedings of the 2023 Conference on Human Information Interaction and Retrieval , pp. 269-279, doi: 10.1145/3576840.3578316.
- Rathee, S., Banker, S., Mishra, A. and Mishra, H. (2023), 'Algorithms propagate gender bias in the marketplace -with consumers' cooperation', Journal of Consumer Psychology , Vol. 33 No. 4, pp. 621-631, doi: 10.1002/JCPY.1351.
- Rutledge, P. (2024), 'Major theories and constructs in media psychology', in Rich, G.J., Kumar, V.K. and Farley, F.H. (Eds), Handbook of Media Psychology , Springer.
- Schiebinger, L. (2008), Gendered Innovations in Science and Engineering , Stanford University Press, Stanford, CA.
- Segura Mojica, F.J. (2024), 'Medici � on y comparaci � on del rendimiento de cuatro algoritmos de aprendizaje supervisado para formular modelos predictivos sobre la rotaci � on temprana de personal', ESIC Market , Vol. 54 No. 2, e318, doi: 10.7200/esicm.54.318.
- Shew, A. (2020), 'Ableism, technoableism, and future AI', IEEE Technology and Society Magazine , Vol. 39 No. 1, pp. 40-50 þ 85, doi: 10.1109/MTS.2020.2967492.
- Stern, N. (2006), 'Stern review on the economics of climate change', The National Archives , available at: https://webarchive.nationalarchives.gov.uk/ukgwa/ þ /http:/www.hm-treasury.gov.uk/ sternreview\_index.htm

## Management Decision


<!-- PAGE 23 -->


## MD 63,9

## 3064

- Treanor, L. (2022), 'Gender, STEM women and entrepreneurship: a review and future research directions', International Journal of Gender and Entrepreneurship , Vol. 14 No. 4, pp. 499-520, doi: 10.1108/IJGE-06-2022-0094.
- Trotta, A., Ziosi, M. and Lomonaco, V. (2023), 'The future of ethics in AI: challenges and opportunities', AI and Society , Vol. 38 No. 2, pp. 439-441, doi: 10.1007/s00146-023-01644-x.
- Twitter (2022), 'Twitter privacy policy', available at: https://x.com/en/privacy
- United Nations (2024), 'Transforming our world: the 2030 agenda for sustainable development', available at: https://sdgs.un.org/2030agenda
- Valian, V. (1998), Why So Slow? The Advancement of Women, Contemporary Sociology , SAGE Publications, Thousand Oaks, CA, doi: 10.2307/2653855.
- Varsha, P.S. (2023), 'How can we manage biases in artificial intelligence systems -a systematic literature review', International Journal of Information Management Data Insights , Vol. 3 No. 1, 100165, doi: 10.1016/j.jjimei.2023.100165.
- Veale, M. and Binns, R. (2017), 'Fairer machine learning in the real world: mitigating discrimination without collecting sensitive data', Big Data and Society , Vol. 4 No. 2, doi: 10.1177/ 2053951717743530/ASSET/IMAGES/LARGE/10.1177\_2053951717743530-FIG1.JPEG.
- Wajcman, J. (2007), 'From women and technology to gendered technoscience', Information, Community and Society , Vol. 10 No. 3, pp. 287-298, doi: 10.1080/13691180701409770.
- Wajcman, J. (2010), 'Feminist theories of technology', Cambridge Journal of Economics , Vol. 34 No. 1, pp. 143-152, oi: 10.1093/CJE/BEN057.
- Wajcman, J. and Young, E. (2023), 'Feminist confronts AI: the gender relations of digitalisation', in Browne, J., Cave, S., Drage, E. and McInerney, K. (Eds), Feminist AI: Critical Perspectives on Algorithms, Data, and Intelligent Machines , Oxford University Press, doi: 10.1093/oso/ 9780192889898.001.0001.
- Wang, L. (2020), 'The three harms of gendered technology', Australasian Journal of Information Systems , Vol. 24, pp. 1-9, doi: 10.3127/AJIS.V24I0.2799.
- Wellner, G. and Rothman, T. (2019), 'Feminist AI: can we expect our AI systems to become feminist?', Philosophy and Technology , Vol. 33 No. 2, pp. 191-205, doi: 10.1007/s13347-01900352-z.
- Wennekers, S. and Thurik, R. (1999), 'Linking entrepreneurship and economic growth', Small Business Economics , Vol. 13 No. 1, pp. 27-56, doi: 10.1023/A:1008063200484.
- West, S., Whittaker, M. and Crawford, K. (2019), 'Discriminating systems: gender, race, and power in AI', in AI Now , New York University, pp. 1-33, available at: https://ainowinstitute.org/ discriminatingsystems.html
- Wiezel, A., Barlev, M., Martos, C.R. and Kenrick, D.T. (2024), 'Stereotypes versus preferences: revisiting the role of alpha males in leadership', Evolution and Human Behavior , Vol. 45 No. 3, pp. 292-308, doi: 10.1016/j.evolhumbehav.2024.01.001.
- Williams, B.A., Brooks, C.F. and Shmargad, Y. (2018), 'Challenges, solutions, and policy implications', Journal of Information Policy , Vol. 8, pp. 78-115, doi: 10.5325/ jinfopoli.8.2018.0078.
- World Economic Forum (2024), Global Gender Gap Report 2024 , Geneva, available at: https:// www.weforum.org/publications/global-gender-gap-report-2024/
- Yang, Z., Wu, Q., Venkatachalam, K., Li, Y., Xu, B. and Trojovsky, P. (2022), 'Topic identification and sentiment trends in Weibo and WeChat content related to intellectual property in China', Technological Forecasting and Social Change , Vol. 184, 121980, doi: 10.1016/ J.TECHFORE.2022.121980.
- Zarsky, T. (2016), 'The trouble with algorithmic decisions', Science, Technology and Human Values , Vol. 41 No. 1, pp. 118-132, doi: 10.1177/0162243915605575.


<!-- PAGE 24 -->


## About the authors

Belen Fraile-Rojas is lecturer at ESIC University, Spain, and a PhD candidate in Social Sciences at Universidad Rey Juan Carlos, Spain. She is currently a visiting student at the Leverhulme Centre for the Future of Intelligence at the University of Cambridge. Bel � en's robust educational foundation is underscored by her acquisition of three master's degrees, each enriching her interdisciplinary approach: Marketing and Sales Management, ESIC Business &amp; Marketing School; International Art's Management and Social Innovation, Universidad Complutense de Madrid; and Neuromarketing at Universidad Internacional de la Rioja. She holds a degree in Modern Languages from Universidad Complutense de Madrid. She has extensive experience in marketing management and education, bringing a multidisciplinary approach to her work cultivated over the past 25 years. She has worked for large multinational corporations and embarked on entrepreneurial ventures. Her current research focuses on the intersection of gender and technology. She is passionate about social justice and gender equality. Her research employs computational methods to examine how AI narratives influence social outcomes. Belen Fraile-Rojas is the corresponding author and can be contacted at: belen.fraile@esic.university

Carmen De-Pablos-Heredero, PhD, is Full Professor in the Business Administration Area at the Rey Juan Carlos University in Madrid (URJC), Spain, since 1994. She is a visiting scholar at Norwich University (USA), Queensland University of Technology, QUT (Australia), Durban University of Technology, DUT (South Africa), UTEQ (Ecuador), U. Desarrollo (Chile), U. Nacional de Tarapac � a (Chile). She is the coordinator of the High-Performance Research Group OpenInnnova and belongs to Strategic Research Group (High-Performance Group) and AGRI 257 Research Group. She has chaired 42 doctoral dissertations and projects on the impact of information and communication technologies on organizational performance (5 of them with international mention). She has presented communications in different international venues. She has published more than 170 articles in specialized and indexed journals (JCR and SCOPUS) and 12 books and participated. She has presented communications in different international venues, published more than 170 articles in specialized and indexed journals (JCR and Scopus) and 12 books, and participated in 28 competitive projects. She has been awarded in the Campus of Excellence in Energy CEI in 2015, 2017 and 2018, ASEDIE 2022 Research Award in the category promoting the knowledge of the data for the report about data reuse in Spain III. She has also worked as a consultant in IS management at Prima Consulting. She is the academic director for the master's degree and doctoral program in Business Administration and Entrepreneurship at the Rey Juan Carlos University and the co-director of the master's degree in project management, SAP (awarded with Gold Mention in 2015), WIDS Ambassador from 2020 and former editor of the Academic Review ESIC Market from July 2016 to July 2024.

Mariano Mendez-Suarez is currently the Director of Research at ESIC University, Former Director of the Department of Market Research and Quantitative Methods at ESIC Business and Marketing School, combining both management tasks with research and teaching. He has a doctorate from the Autonomous University of Madrid and an MBA from the University of Houston. He has authored or coauthored many research articles and books in peer-reviewed scientific journals, and a reviewer for many international journals. His research interests include the ethical behaviour of firms in artificial intelligence, the growth of artificial intelligence and the impact of business communication.

Management Decision

3065