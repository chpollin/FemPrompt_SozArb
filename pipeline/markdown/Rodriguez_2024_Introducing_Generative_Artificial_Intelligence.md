---
source_file: Rodriguez_2024_Introducing_Generative_Artificial_Intelligence.pdf
conversion_date: 2026-02-03T09:17:25.697214
converter: docling
quality_score: 95
---

<!-- image -->

## Journal of Social Work Education

ISSN: 1043-7797 (Print) 2163-5811 (Online) Journal homepage: www.tandfonline.com/journals/uswe20

## Introducing Generative Artificial Intelligence Into the MSW Curriculum: A Proposal for the 2029 Educational Policy and Accreditation Standards

Maria Y. Rodriguez, Lauri Goldkind, Bryan G. Victor, Barbara Hiltz &amp; Brian E. Perron

To cite this article: Maria Y. Rodriguez, Lauri Goldkind, Bryan G. Victor, Barbara Hiltz &amp; Brian E. Perron (2024) Introducing Generative Artificial Intelligence Into the MSW Curriculum: A Proposal for the 2029 Educational Policy and Accreditation Standards, Journal of Social Work Education, 60:2, 174-182, DOI: 10.1080/10437797.2024.2340931

To link to this article:

https://doi.org/10.1080/10437797.2024.2340931

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

Published online: 30 May 2024.

Submit your article to this journal

Article views: 1261

View related articles

View Crossmark data

Citing articles: 19 View citing articles

曲

CrossMark

<!-- image -->

<!-- image -->

<!-- image -->

## Introducing Generative Artificial Intelligence Into the MSW Curriculum: A Proposal for the 2029 Educational Policy and Accreditation Standards

<!-- image -->

Recent  developments  in  artificial  intelligence  (AI),  including  large  language  models  (LLMs)  (e.g., ChatGPT,  Claude,  and  Bard)  and  image-creating  models  (e.g.,  Midjourney,  DALL·E,  and  Stable Diffusion), are producing new opportunities and challenges for social work education and practice. Much  of  the  popular  discussion  about  these  generative  artificial  intelligence  (GenAI)  systems  in academia has focused on challenges, especially regarding the implications of AI-generated text and images for academic integrity (see, e.g., Bearman &amp; Ajjawi, 2023). At the same time, social workers are now practicing in a world transformed by GenAI, and must be prepared to engage with these tools effectively  and  ethically.  The  Council  on  Social  Work  Education  (CSWE)  currently  charges  social workers to develop competence in the ethical deployment of technology, but there is less clarity on how  to  do  so  in  such  a  rapidly  changing  landscape,  to  say  nothing  of  the  general  challenges  of implementing broadly stated curricular goals at a scale recognizing the disruptive and evolving nature of GenAI (Danneels, 2004; Felten et al., 2023).

Building on Singer et al.'s (2023) work detailing how GenAI could support Master of Social Work (MSW)  instruction,  this  article  recommends  the  establishment  of  a  new  Educational  Policy  and Accreditation  Standard  (EPAS)  competency  indicator: Social  workers  demonstrate  the  knowledge, skills, and understanding to responsibly use generative artificial intelligence tools .  We also detail four skills to be developed in the social work curricula to achieve this new competency. Below is a version of the proposed competency, which we hope will serve as a starting point for discussions on the role of social work educators in preparing students for practice in an AI-informed world (see Figure 1).

<!-- image -->

<!-- image -->

-ompet ency- W Social W Workers W dem onst rat eW the W know ledgeN W skill sW andW understanding W toW responsibly W useW generat i veW artif i ci al W i nt ellige nceW 6'I 8 W toolsJW I n.a.dat a.s at urated .and.dig i t al ly. enhanced.human .enviro nmen t :.social .worker s.ar e.cr i tic al .tra nsl at or s .of .human .need.and.soc i al. jus t iceT .Social .worker s.ar e.knowledgeabl e.about .t he.soc i oJcultural .contex t .of .generati ve.9 I .use. and.its .impact .acr oss.societie sT .Social .worker s.c an.competent l y.and.et hica l l y.deploy.generative. 9 I .too l s .across .pr actice .set tingsT .Soci al .workers .can.crit i cally .eval uat e.outpu t s .of.g ener ative .9 I . too l s .f or .uni ntend ed.consequ ences .and.potenti al .har m T .Social .worker s.under st and.the .log i c.of . the .underlying .auto m ation: .as.well .as.t he.potent i al .f or .bi as .i n.auto m ated .deci s ion .makingT .Social. worker s.develop .and.maintain .di gi t al .and.algo r i t hm i c.litera cy.t o.ens ur e.t hei r .contin ued.ethic al . use.o f .these .t echnologie sT .

Ski l ls.indic at i ve.of .t hi s .compe t ency.include Q .

- 0T Demons t rat i ng.pr act i cal .under s t andi ng.of .how .Gen 9 I .mode l s .are .train ed.and.how .t hey. fun ction:.a nd.the. t ypes.of .t ask s .they.can .performD.
- FT Underst anding.ho w .to.wr i te.model .pr om pts.effe ct i vel yD
- 1T 9ssessing .outpu t .f r om .9 I .mode l s.for .eth i cal: .s ocio Jemotio nal .and.pr act i ce.i m pl icationsD
- 5T I m pl em ent i ng.an.iterative .literacy .f r am ew or k.for .st aying .cur r ent .with .emergi ng.G en9I. t echnologies

Figure 1. Competency.

The structure of this article comprises four distinct sections. The first provides a general overview of AI, differentiating between older, narrow technologies and the new class of GenAI tools. The second highlights the value and potential of GenAI in the context of social work education and practice. The third section tempers our optimism with critical considerations that acknowledge potential harms and challenges of GenAI in education and practice. We conclude with a description of the four skills we argue would promote effective engagement with GenAI tools in social work practice.

## Artificial intelligence

Broadly, AI refers to computer systems or models capable of mimicking tasks commonly requiring human intelligence. These include, but are not limited to, interpreting/generating language, recognizing patterns, solving problems, and making recommendations. More traditional AI systems, referred to with terms like general/weak or narrow AI (Andrason, 2020), are rule-based methods that perform specific actions using predefined algorithms and explicit programming, such as if-then rules used in decision-making systems. Narrow  AI systems have been  deployed in  social work  practice  for  over a decade, including predictive analytics to assist in clinical decision making (Cariceo et al., 2018) and simulation-based training for workers and clients (Asakura et al., 2020; Goldkind, 2021).

AI  has  evolved  significantly  with  the  introduction  of  machine  learning,  where  algorithms  learn from data rather than following preset rules. This evolution has led to more adaptable and effective AI applications across various fields. In social work, for instance, machine learning models have been applied to analyze and organize large volumes of unstructured text documents (Perron et al., 2019; Victor et al., 2021).

In contrast, GenAI systems use vast amounts of training data to create images, texts, music, video, and other  forms  of  design  with  results  that  are  often  similar  or  sometimes  indistinguishable  from human content creators. Literally speaking, GenAI is proliferate in nature: its purpose is to produce a new artifact or object and it does so by learning the underlying pattern of art, text, or whatever media is in question. That is, although GenAI creates new artifacts, it does so by classifying or predicting the next 'logical' thing based on the patterns it has learned from the media it has already consumed.

LLMs fall within this broader umbrella of GenAI and are arguably the most relevant to social work among the various types of GenAI models. LLMs are AI systems trained on extensive amounts of text data. They can perform a wide range of text-related tasks, including (but not limited to) classification, summarization, generation, and question-answer based on patterns they learned from their underlying  training  data.  Social  work  students  and  practitioners  can  use  plain  language  to  interact  with

<!-- image -->

<!-- image -->

GenAI systems.  Yet  GenAI  systems  like  ChatGPT  are  built  on  computer  programming-meaning humans made decisions about the data used to train the model, the features to be emphasized in the data, and the ways output would be generated.

## Opportunities of GenAI in social work practice

Like its influence in other disciplines and professions, GenAI holds some promise for improving social work  practice, primarily  through  its  ability  to  ease  resource  constraints  for  writing-oriented  tasks . Practice  at  the  individual  level  often  includes  case  management  and  therapeutic  interventions. GenAI has the potential to enhance individual practice as a tool for documentation and reflection (Flemotomos et al., 2021), as well as a clinical enhancement similar to worksheets one might use in cognitive behavioral therapy. LLMs might be able to help draft treatment plans and case notes, provide materials for both individual and group sessions, assist with translations, and aid in developing other writing-based skills.

Many social work organizations face resource constraints and uncertainties (Golensky &amp; Mulder, 2006). GenAI tools offer mezzolevel practitioners and organizations new ways for automating routine, writing-intensive tasks. For example, LLMs can be used to create customized training materials and resources  for  ongoing  professional  development,  ensuring  that  staff  are  up  to  date  with  the  latest practices and organizational policies. Social workers at this level might also use GenAI tools to assist in drafting grant proposals, fundraising letters, and other materials needed for resource development, potentially enhancing the quality and efficiency of these critical tasks.

Finally, macro social work is broadly focused on policy-level practice and systems change efforts. As other social work scholars have noted (e.g., McBeath, 2016), AI technologies can be useful to social work practitioners engaged at this level. For instance, policy analysis and subsequent advocacy efforts rely  heavily  on  the  review  and  production  of  written  materials.  LLMs  could  offer  time  savings  by summarizing long policy documents and drafting advocacy materials tailored to different audiences. GenAI models can also be used to help organizations work more effectively with their own documents, helping organizations better use their existing resources, quickly retrieve and synthesize information from  their  own  documents  to  answer  queries,  make  decisions,  or  develop  strategies.  This  can  be particularly  helpful  in  large  organizations  where  valuable  information  may  be  scattered  across numerous sources.

These  practice  application  examples  are  not  exhaustive;  rather,  are  meant  to  demonstrate  the flexibility  and  ubiquity  of  AI,  and  especially  GenAI  applications,  for  social  work  practice  settings. Social work students have an opportunity to be well-positioned for both implementing these tools and shaping policy around their use. The current higher education environment is unclear about whether and  how  to  use  GenAI,  resulting  in  much  fear  and  aversion  throughout  academia.  Yet,  without exposure,  understanding,  and  reflection,  students  may  leave  graduate  MSW  programs  without  the necessary knowledge and competence to successfully engage with the GenAI ecosystem.

## Challenges and potential harms of GenAI

Beyond concerns about plagiarism and academic integrity (Wang, Akins, et al., 2023), GenAI poses real threats to human and environmental well-being in new and accelerated ways. There is currently a heated debate about regulating GenAI in the United States, as well as globally (Chakravorti, 2023; Matthews,  2023).  The  Biden  administration  has  issued  an  executive  order  on  'safe,  secure,  and trustworthy AI' (Klare, 2023), which summarily calls for AI companies to make public their safety testing results with the U.S. government, gives the National Institute for Standards and Technology regulating  leverage  over  AI  model  safety  testing  by  commercial  red  teams, 1 and sets  standards  for

1 Red teams work to 'break' systems in an attempt to anticipate the actions of adversarial users who would look to exploit a system weakness, as in the case of hackers.

<!-- image -->

detecting and labeling AI-generated content (charged to the Department of Commerce), among other noteworthy national-level standards. The same administration has also set forth the 'Blueprint for an AI Bill of Rights,' 2 which attempts to lay out the rights citizens have in a marketplace now driven by automated systems and decisions. These two documents help illustrate the well-known harms that can result from AI applied in nonjudicious ways.

Additionally, the output of GenAI models are reflective of the data on which it is trained (Patton et al., 2023). Thus, bias in GenAI systems is often geared toward women, people of color, gender and sexually  minortized  individuals  and  communities,  and  those at  the  intersections  of  these  identities (Dhingra et al., 2023; Whittaker et al., 2019). For example, a recent study of images generated by Stable Diffusion and DALL·E demonstrated gender bias. When prompted for the terms 'CEO' or 'director,' 97% of the returned images were White men (Heikkilä, 2023). Omiye et al. (2023) also found that LLMs often generate outputs aligned with race-based rather than personalized medicine, a practice that could cause great harm and lead to improper care.

Social work students and practitioners must be wary of the potential for data harms when engaging with GenAI tools. To use LLMs and other GenAI utilities, all users must first agree to a Terms of Service agreement. Terms of Service have become a ubiquitous part of obtaining any service or content online  (Goldkind  &amp;  Wolf,  2020).  Infamous  for  their  impenetrable  language  and  legalese,  these contracts offer their users terms that may be unfair or even abusive (De Rosnay, 2016). In the case of prompt- or question-driven GenAI tools, any data that the user enters into a system can potentially be accessed by the model developer for subsequent training and model development. For example, if a student wishes to summarize a client's case note using ChatGPT, the data could later be accessed and used by OpenAI, the model's developer.

Understanding how LLMs are trained and operated is crucial to mitigate the risks of 'hallucinations,'  a  term  used  in  computer  science  and  communications  to  describe  errors,  mismatches,  and omissions by GenAI models (Beutel et al., 2023). In GenAI image literature, hallucination occurs when models generate inconsistent or absent objects in descriptions or captions of images (Li et al., 2023). LLMs  are  similarly  susceptible  to  such  errors,  often  confidently  presenting  false  information.  For instance, LLMs might create plausible-sounding academic literature titles based on their training data, even though these articles do not exist (Wu &amp; Dang, 2023). A strong foundational knowledge in LLMs' training and functionality can help in identifying and reducing the occurrence of these inaccuracies.

## Four skills needed to develop GenAI competency

Social work education in the United States is governed by the CSWE. CSWE creates and monitors the EPAS, which dictate the competencies and broad skills that all social work students should be able to demonstrate upon graduation from an accredited school of social work.

Technology features prominently in the first of the nine EPAS competencies put forward by CSWE in  2022.  According  to  CSWE  (2022),  the  ability  to demonstrate  ethical  and  professional  behavior (Competency 1) requires that 'social workers understand digital technology and the ethical use of technology in social work practice' (p. 8). The EPAS goes on to note that competency is evidenced by the ability to 'use technology ethically and appropriately to facilitate practice outcomes' (p. 9). Based on this guidance, both technology-related knowledge and skill are required for competent practice. AI knowledge and skills are centrally critical to achieving the goals for competence articulated in the 2022 EPAS. One mechanism for accomplishing this goal is the introduction of AI content into the MSW curricula (Goldkind, 2021).

We argue there are four foundational skills necessary for competent and effective use of GenAI and LLMs  in  social  work  practice,  which  comprise  in  turn  the  assessment  basis  for  our  proposed competency. These skills are:

2 https://www.whitehouse.gov/ostp/ai-bill-of-rights/.

<!-- image -->

- (1) demonstrating conceptual understanding of the ways in which AI models are trained, and the types of tasks they can perform;
- (2) becoming knowledgeable users of GenAI by understanding how to write prompts effectively;
- (3) assessing  output  from  GenAI  models  for  ethical,  socioemotional,  and  practice  implications; and
- (4) cultivating intellectual curiosity by continuously engaging in active learning about the benefits and harms of using GenAI tools at the individual, community, organizational, and national level.

## Conceptual understanding of AI models

Using GenAI effectively requires a broad knowledge of what constitutes GenAI and its applications as well as whether, when, and how to use them in practice.

## Definitions and terms

Establishing conceptual grounding includes clarifying crucial definitions. This not only demystifies these  technologies  but  also  allows  for  informed  and  critical  engagement  in  their  applications. Programs should take care to provide consistent definitions of key concepts, such as AI, GenAI, and LLMs, with a focus on what distinguishes generative technologies from other forms of AI.

## Model training

Before deployment of GenAI tools, students should understand how these models were developed and what  it  means  to  'train'  a  model.  Training  GenAI  models,  such  as  LLMs,  involves  feeding  vast amounts of data, including text, images, and sometimes sound, into the model so it can learn patterns, language  structures,  or  relationships  among  the  data  elements  (e.g.,  words,  images).  This  training process is facilitated through use of machine learning algorithms that gradually fine-tune the model's settings to improve predictions and generate more accurate and contextually relevant responses or content.  For  instance,  in  the  context  of  social  work  we  might  look  to  develop  a  GenAI  model  to support  clinical  practice  that  was  trained  on  a  corpus  of  text  data  that  includes  case  studies,  legal regulations,  ethical  guidelines,  diagnostic  criteria,  and  textbooks,  enabling  it  to  provide  informed suggestions that account for the context of individual situations. However, it is crucial for students to understand  that  the  quality  and  diversity  of  the  training  data  significantly  influence  the  model's outputs,  and  they  should  be  aware  of  potential  biases  or  limitations  inherent  in  the  data  used  for training.

## Data security and confidentiality

In addition, social workers regularly engage with sensitive and often confidential information about individuals and communities. Practitioners must ensure that data submitted into third-party GenAI systems like ChatGPT do not include identifying or protected medical information, or that the use of such data is covered by informed consent agreements.

## Computational thinking

Wing (2006) noted that 'computational thinking involves solving problems, designing systems, and understanding  human  behavior,  by  drawing  on  the  concepts  fundamental  to  computer  science' (p.  33).  That  is,  computational  thinking  involves  approaching  problems  in  a  way  that  leverages computational concepts. For social work students, this includes the ability to break complex issues into manageable pieces that can be addressed systematically, creating representations of real-world situations that can be analyzed, and identifying patterns and trends within data, which can lead to evidence-informed  decision  making.  Developing  curricular  resources  to  enhance  MSW  students' computational  thinking  skills  can  help  to  ensure  that  students  gain  an  understanding  of  the

<!-- image -->

capabilities and limitations of GenAI. For example, case studies or scenarios can highlight situations where GenAI technologies could be applied in social work contexts, and used to evaluate whether using a GenAI solution aligns with ethical standards or promotes social justice.

## Prompting skills

Prompt engineering is the central skill for interacting with GenAI models and getting desired outputs for a given task (Wang, Shi, et al., 2023). Prompting GenAI models is a wholly different skill than performing web searches with a range of strategies for securing desired outputs. Techniques in prompt engineering  are  rapidly  evolving,  with  considerable  research  showing  that  slightly  reformulated prompts  can  significantly  affect  and  improve  results.  For  example,  chain  of  thought  prompting instructs the LLM to explain its reasoning when answering a prompt, which can lead to significant gains in accuracy (Wei et al., 2022). White et al. (2023) have introduced a catalog detailing various methods for designing prompts. This catalog features  techniques like  personas,  game  play,  flipped interactions, and context managers. These methods can be customized to address challenges in diverse areas and for the variety of professional tasks that social workers complete across practice levels.

## Assessing model outputs

While GenAI tools can be an integral tool for practitioners, their utility will only be as high as the quality of their output. As noted previously, GenAI outputs can often include hallucinations (i.e., inaccuracies) for which users must assess and correct prior to using any text or code produced by these tools. This process of assessing the quality and accuracy of model outputs is often referred to as output validation (Bandi  et  al.,  2023).  The  tasks  of  prompting  and  validating  are  often  iterative,  as  the  detection  of inaccuracies, or an appraisal that the output was not of sufficient quality for the task at hand, leads to a new round of prompting with necessary adjustments. Additionally, as noted previously, GenAI models are known to reflect the bias that is present in the training data. Social work courses should investigate how outputs generated by these systems could perpetuate this bias and what mitigation is possible.

## Cultivating intellectual curiosity

It  is  incumbent  on  MSW  programs  to  safeguard  the  ethical  value  of  competence  by  providing mechanisms for MSW students to be lifelong learners of new technologies (Silva et al., 2022). This is also part of Competency 1 in the current EPAS: 'Social workers recognize the importance of lifelong learning  and  are  committed  to  continually  updating  their  skills  to  ensure  relevant  and  effective practice.' 3 Lifelong  learning  is  also  a  value  found  in  the  National  Association  of  Social  Workers (2021) Code of Ethics , under the competence principle, 'Social workers continually strive to increase their professional knowledge and skills and to apply them in practice. Social workers should aspire to contribute to the knowledge base of the profession.'

The pace of GenAI technology's evolution is outstripping the current capacity for adaptation in social  work  curricula.  For  instance,  various  applications  now  enable  the  installation  of  small-scale LLMs  that  operate  locally  and  offline.  This  development  presents  new  opportunities  to  address security  concerns  related  to  handling  sensitive  data.  Retrieval-augmented  generation  (RAG), a  recent  development  in  GenAI  technologies  (Gao  et  al.,  2023;  Lewis  et  al.,  2020),  is  particularly applicable  to  social  work.  RAG  improves  the  responses  of  LLMs  by  incorporating  data  from  an external  document  database,  allowing  organizations  and  individuals  to  interact  with  their  local knowledge.  This  method  reduces  inaccuracies  and  ensures  responses  are  contextually  appropriate. Although the most sophisticated RAG methods require programming skills, increasingly available no-

3 https://www.cswe.org/accreditation/standards/2022/.

code tools like Azure Machine Learning (Microsoft, 2023) are making this technology accessible to individuals without technical expertise.

Accordingly, social work programs need support to know what to teach and how, so they can develop the expertise needed within their schools and departments to support students in achieving  this  competency  prior  to  graduation.  Continuing  education  opportunities  will  also  be  paramount for social work practitioners to maintain and further develop their competence with GenAI tools  as  these  technologies  continue  to  evolve.  Collaborations  with  other  departments  in  the university  or  private  sector  practitioners  might  prove  particularly  useful  in  ensuring  ongoing training  opportunities  for  alumni.

## Conclusion

Incorporating content on GenAI technologies into the MSW curriculum is not merely a response to technological  trends;  it  is  a  proactive  step  toward  empowering  social  workers  with  the  tools  and insights required to excel in this new landscape. By cultivating a strong foundation in fundamental knowledge, practical  applications,  and  ethical  awareness,  social  workers  will  be  able  to  confidently navigate  the  integration  of  GenAI  into  practice,  ultimately  enhancing  their  ability  to  support  the individuals and communities they serve.

There are two primary strategies for introducing new content into postsecondary curricular offerings: infusion of  content  across existing  areas or block insertions of  specialized  courses (De Jong &amp; Naranjo, 2019). Block insertions are the siloing of new content on populations, practice areas, or innovations into one course, whereby the remaining curricula remains unchanged. Infusing new content is the notion of including  a  specific  key  conceptual  area,  such  as  GenAI,  across  relevant  courses.  The  infusion  model ensures  that  all  students  have  multiple  touchpoints  with  new  content.  An  infusion  approach  is  often attractive, as it tends to work within existing curricular structures and hence may be easier and more costeffective to implement than the insertion of an additional course or courses (De Jong &amp; Naranjo, 2019; Jin et al.,  2011). We are also mindful that an infusion approach is not without its challenges, as it requires training or hiring faculty with the requisite skills and additional oversight on the part of administrators to ensure effective implementation.

While we believe that the integration of this knowledge is critical to future social workers, we are not naive to the multitude of challenges presented by the task of integrating new content into a curriculum. Integrating new content necessitates the allocation of resources-both in terms of time and funding. The dynamic  nature  of  technology  requires  careful  consideration  of  how  faculty  will  stay  abreast  of  the changing landscape. Balancing the inclusion of new curricular content demands thoughtful planning to ensure  cohesion  and  consistency,  while  avoiding  unnecessary  duplication.  Furthermore,  variations  in teaching styles and approaches might inadvertently result in fragmented learning experiences for students.

Addressing these complexities will involve collaborative efforts among faculty, administrators, and stakeholders. It will require a strategic approach that considers curriculum design, faculty development,  resource  allocation,  and  ongoing  program  evaluation.  Such  a  comprehensive  approach  will allow social work programs to harness the opportunities of GenAI to enhance knowledge and skills while upholding the core values of the social work profession.

## Disclosure statement

No potential conflict of interest was reported by the author(s).

## Notes on contributors

Maria  Y.  Rodriguez is  Assistant  Professor  in  the  School  of  Social  Work  and  Adjunct  Assistant  Professor  in  the Department of Computer Science and Engineering at the University at Buffalo. Lauri Goldkind is Assistant Professor in the Graduate School of Social Service at Fordham University. Bryan G. Victor is Assistant Professor in the School of

<!-- image -->

<!-- image -->

<!-- image -->

Social Work at Wayne State University. Barbara Hiltz is Clinical Associate Professor in the School of Social Work at University of Michigan-Ann Arbor. Brian E. Perron is Professor in the School of Social Work at University of MichiganAnn Arbor.

## ORCID

Maria Y. Rodriguez http://orcid.org/0000-0003-1401-2099

Lauri Goldkind http://orcid.org/0000-0002-0967-3960

Bryan G. Victor http://orcid.org/0000-0002-2092-912X

## References

- Andrason,  S.  P.  (2020). Performance  of  an  AGI-aspiring  system  &amp;  narrow-AI  approaches:  A  systematic  comparison [Doctoral dissertation]. Reykjavík Univeristy.
- Asakura, K., Occhiuto, K., Todd, S., Leithead, C., &amp; Clapperton, R. (2020). A call to action on artificial intelligence and social  work  education:  Lessons  learned  from  a  simulation  project  using  natural  language  processing. Journal  of Teaching in Social Work , 40 (5), 501-518. https://doi.org/10.1080/08841233.2020.1813234
- Bandi, A., Adapa, P. V. S. R., &amp; Kuchi, Y. E. V. P. K. (2023). The power of generative AI: A review of requirements, models,  input-output  formats,  evaluation  metrics,  and  challenges. Future  Internet , 15 (8),  260.  https://doi.org/10. 3390/fi15080260
- Bearman, M., &amp; Ajjawi, R. (2023). Learning to work with the black box: Pedagogy for a world with artificial intelligence. British Journal of Educational Technology , 54 (5), 1160-1173. https://doi.org/10.1111/bjet.13337
- Beutel, G., Geerits, E., &amp; Kielstein, J. T. (2023). Artificial hallucination: GPT on LSD? Jornal of Critical Care , 27 (1), 148. https://doi.org/10.1186/s13054-023-04425-6
- Cariceo, O., Nair, M., &amp; Lytton, J. (2018). Data science for social work practice. Methodological Innovations , 11 (3), 1-8. https://doi.org/10.1177/2059799118814392
- Chakravorti, B. (2023, August 4). The AI regulation paradox . Foreign Policy. https://foreignpolicy.com/2023/08/04/airegulation-artificial-intelligence-democracy-elections/
- Council on Social Work Education. (2022). 2022 educational policy and accreditation standards for baccalaureate and master's social work programs . https://www.cswe.org/getmedia/bb5d8afe-7680-42dc-a332-a6e6103f4998/2022-EPAS. pdf
- Danneels, E. (2004). Disruptive technology reconsidered: A critique and research agenda. Journal of Product Innovation Management , 21 (4), 246-258. https://doi.org/10.1111/j.0737-6782.2004.00076.x
- de Jong, E., &amp; Naranjo, C. (2019). General education teacher educators and English language learner teacher preparation: Infusion as curricular change. The New Educator , 15 (4), 331-354. https://doi.org/10.1080/1547688X.2019.1663331
- de Rosnay, M. D. (2016). Alternative policies for alternative internets. Journal of Peer Production . https://halshs.archivesouvertes.fr/halshs-01362482/document  .
- Dhingra, H., Jayashanker, P., Moghe, S., &amp; Strubell, E. (2023). Queer people are people first: Deconstructing sexual identity stereotypes in large language models . arXiv. https://arxiv.org/abs/2307.00101
- Felten, E., Raj, M., &amp; Seamans, R. (2023). How will language modelers like ChatGPT affect occupations and industries? [Working paper]. https://arxiv.org/abs/2303.01157
- Flemotomos, N., Martinez, V. R., Chen, Z., Singla, K., Ardulov, V., Peri, R., Caperton, D. D., Gibson, J., Tanana, M. J., Georgiou, P., Epps, J. V., Lord, S. P., Hirsch, T., Imel, Z. E., Atkins, D. C., &amp; Narayanan, S. (2021). Am I a good therapist? Automated evaluation of psychotherapy skills using speech and language technologies. CoRR, Abs , 2102 (10.3758). https://doi.org/10.3758/s13428-021-01623-4
- Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J., Wang, M., &amp; Wang, H. (2023). Retrieval-augmented generation for large language models: A survey . arXiv preprint arXiv:2312.10997.
- Goldkind, L. (2021). Social work and artificial intelligence: Into the matrix. Social Work , 66 (4), 372-374. https://doi.org/ 10.1093/sw/swab028
- Goldkind, L., &amp; Wolf, L. (2020). Selling your soul on the information superhighway: Consenting to services in direct-toconsumer tele-mental health. Families in Society , 101 (1), 6-20. https://doi.org/10.1177/1044389419872125
- Golensky, M., &amp; Mulder, C. A. (2006). Coping in a constrained economy: Survival strategies of nonprofit human service organizations. Administration in Social Work , 30 (3), 5-24. https://doi.org/10.1300/J147v30n03\_02
- Heikkilä, M. (2023, March 23). These new tools let you see for yourself how biased AI image models are. MIT Technology Review .  https://www.technologyreview.com/2023/03/22/1070167/these-news-tool-let-you-see-for-yourself-howbiased-ai-image-models-are/

<!-- image -->

- Jin,  B.,  Swinney,  J.,  Cao,  H.,  Muske,  G.,  Nam,  J.,  &amp;  Kang,  J.  (2011).  Doing  business  with  China:  Curriculum  internationalisation through an infusion method. Innovations in Education and Teaching International , 48 (2), 171-181. https://doi.org/10.1080/14703297.2011.564012
- Klare, M. T. (2023). Biden issues executive order on AI safety. Arms Control Today , 53 (10), 36-37.
- Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., &amp; Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems , 33 , 9459-9474.
- Li,  Y.,  Du,  Y.,  Zhou,  K.,  Wang,  J.,  Zhao,  W.  X.,  &amp;  Wen,  J.  R.  (2023). Evaluating  object  hallucination  in  large vision-language models . arXiv preprint arXiv:2305.10355.
- Matthews, D. (2023, August 1). The AI rules that US policymakers are considering, explained. Vox .  https://www.vox. com/future-perfect/23775650/ai-regulation-openai-gpt-anthropic-midjourney-stable
- McBeath, B. (2016). Re-envisioning macro social work practice. Families in Society , 97 (1), 5-14. https://doi.org/10.1606/ 1044-3894.2016.97.9
- Microsoft.  (2023,  September  30).  Use  Azure  machine  learning  pipelines  with  no  code  to  construct  RAG  pipelines. Microsoft  Learn .  https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-pipelines-prompt-flow? view=azureml-api-2
- National Association of Social Workers. (2021). Code of ethics .  https://www.socialworkers.org/About/Ethics/Code-ofEthics/Code-of-Ethics-English
- Omiye, J. A., Lester, J. C., Spichak, S., Rotemberg, V., &amp; Daneshjou, R. (2023). Large language models propagate racebased medicine. NPJ Digital Medicine , 6 , 195. https://doi.org/10.1038/s41746-023-00939-z
- Patton,  D.  U.,  Landau,  A.  Y.,  &amp;  Mathiyazhagan,  S.  (2023).  ChatGPT  for  social  work  science:  Ethical  challenges  and opportunities. Journal of the Society for Social Work and Research , 14 (3), 553-562. https://doi.org/10.1086/726042
- Perron,  B.  E.,  Victor,  B.  G.,  Bushman,  G.,  Moore,  A.,  Ryan,  J.  P.,  Lu,  A.  J.,  &amp;  Piellusch,  E.  K.  (2019).  Detecting substance-related problems in narrative investigation summaries of child abuse and neglect using text mining and machine learning. Child Abuse and Neglect , 98 , 104180. https://doi.org/10.1016/j.chiabu.2019.104180
- Silva, D. E., Chen, C., &amp; Zhu, Y. (2022). Facets of algorithmic literacy: Information, experience, and individual factors predict  attitudes  toward  algorithmic  systems. New Media &amp; Society ,  14614448221098042. https://doi.org/10.1177/ 14614448221098042
- Singer, J. B., Báez, J. C., &amp; Rios, J. A. (2023). AI creates the message: Integrating AI language learning models into social work education and practice. Journal of Social Work Education , 59 (2), 294-302. https://doi.org/10.1080/10437797. 2023.2189878
- Victor, B. G., Perron, B. E., Sokol, R. L., Fedina, L., &amp; Ryan, J. P. (2021). Automated identification of domestic violence in written child welfare records:  Leveraging text mining and machine learning to enhance social work research and evaluation. Journal of the Society for Social Work and Research , 12 (4), 631-655. https://doi.org/10.1086/712734
- Wang, J., Shi, E., Yu, S., Wu, Z., Ma, C., Dai, H., Yang, Q., Kang, Y., Wu, J., Hu, H., Yue, C., Zhang, H., Liu, Y., Pan, Y., Liu, Z., Sun, L., Li, X., Ge, B., Jiang, X., &amp; Zhang, S. (2023). Prompt engineering for healthcare: Methodologies and applications . arXiv preprint arXiv:2304.14670.
- Wang, K., Akins, S., Mohammed, A., &amp; Lawrence, R. (2023). Student mastery or AI deception? Analyzing ChatGPT's assessment proficiency and evaluating detection strategies . arXiv preprint arXiv:2311.16292.
- Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E. H., Xia, F., Le, Q., &amp; Zhou, D. (2022). Chain of thought prompting elicits reasoning in large language models . ArXiv, abs/2201.11903.
- White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., &amp; Schmidt, D. C. (2023). A prompt pattern catalog to enhance prompt engineering with ChatGPT . ArXiv, abs/2302.11382.
- Whittaker, M., Alper, M., Bennett, C. L., Hendren, S., Kaziunas, L., Mills, M., Morris, M. R., Rankin, J., Emily Rogers, N., Salas, M., &amp; West, S. M. (2019). Disability, bias, and AI. AI Now Institute , 8 .
- Wing,  J.  M.  (2006).  Computational  thinking. Communications  of  the  ACM , 49 (3),  33-35.  https://doi.org/10.1145/ 1118178.1118215
- Wu, R. T., &amp; Dang, R. R. (2023). ChatGPT in head and neck scientific writing: A precautionary anecdote. American Journal of Otolaryngology , 44 (6), 103980. https://doi.org/10.1016/j.amjoto.2023.103980