---
source_file: Kong_2021_Evaluation_of_an_artificial_intelligence_literacy.pdf
conversion_date: 2026-02-03T09:04:04.375929
converter: docling
quality_score: 95
---

<!-- image -->

GLYPH&lt;0&gt;,GLYPH&lt;0&gt;QGLYPH&lt;0&gt;WGLYPH&lt;0&gt;HGLYPH&lt;0&gt;OGLYPH&lt;0&gt;OGLYPH&lt;0&gt;LGLYPH&lt;0&gt;JGLYPH&lt;0&gt;HGLYPH&lt;0&gt;QGLYPH&lt;0&gt;FGLYPH&lt;0&gt;H

## Contents lists available at ScienceDirect

## Computers and Education: Artificial Intelligence

journal homepage: www.sciencedirect.com/journal/computers-and-education-artificial-intelligence

GLYPH&lt;0&gt;GLYPH&lt;21&gt;

GLYPH&lt;0&gt;GLYPH&lt;11&gt;GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;20&gt;GLYPH&lt;0&gt;GLYPH&lt;12&gt;

<!-- image -->

## Evaluation of an artificial intelligence literacy course for university students with diverse study backgrounds

<!-- image -->

Siu-Cheung Kong a,* , William Man-Yin Cheung b , Guo Zhang b

a

<!-- image -->

- Department of Mathematics and Information Technology, Director of Centre for Learning, Teaching and Technology, The Education University of Hong Kong, 10 Lo Ping

Road, Tai Po, New Territories, Hong Kong

b Centre for Learning, Teaching and Technology, The Education University of Hong Kong, 10 Lo Ping Road, Tai Po, New Territories, Hong Kong

## A R T I C L E  I N F O

Keywords: Artificial intelligence Concepts Evaluation Literacy University students

## 1. Introduction

In  the  digital  era,  as  the  application  of  artificial  intelligence  (AI) increasingly permeates every corner of the world, the cultivation of AI literacy  for  all  citizens  has  become  increasingly  important  (Long &amp; Magerko, 2020; Sabouret, 2020). This article describes an initiative to provide  AI  knowledge  to  university  students  in  Hong  Kong  through conducting an AI course with a flipped classroom learning approach (Bye, 2018). The course served as a pilot initiative to promote AI literacy to the public. This article reports the process of designing, implementing and evaluating this AI literacy course, which is named 'Understanding Artificial Intelligence ' .

## 2. Background

Currently, the role of AI applications in our daily lives and workplace is a hot topic of discussion. This intense interest is not surprising, given that AI might lead to radical and unprecedented changes in the ways people live and work (Pan, 2016; Stone et al., 2016). However, along

* Corresponding author. E-mail addresses:

## A B S T R A C T

A few limited efforts have been made to promote artificial intelligence (AI) literacy for citizens. The objective of this study was to design, implement and evaluate an AI literacy course for university students. One of the study ' s research questions was whether university students from a variety of disciplines could develop a conceptual understanding of AI through a literacy course. We promoted this course to 4000 students and recruited 120 volunteer participants to attend and complete the 7-h course. The results of our pre-course and post-course surveys indicated that  the  participants  made  significant  progress  in  understanding  AI  concepts,  felt  empowered to work with AI. These findings indicated that the participants of diverse study backgrounds, and of both genders,  could  understand  the  concepts  of  machine  learning,  supervised  learning,  regression,  classification, unsupervised  learning,  and  clustering.  Prior  knowledge  of  programming  was  not  necessary  for  AI  concepts development, and the flipped classroom learning approach enabled more flexible learning by the participants. In the future, this AI literacy course could be extended to include AI application projects and discussions of related ethical issues regarding the wider use of AI in society. We are planning to introduce this literacy course to senior secondary school students.

with the new benefits and options that AI can offer, these new technologies also raise public concerns over issues such as bias, digital privacy and security (Anderson &amp; Anderson, 2006; Brendel et al., 2021; Floridi et al., 2018; Wang &amp; Siau, 2019). To enable people to use AI appropriately while successfully protecting their benefits and privacy, training should be provided to every citizen. People need to acquire certain kinds of knowledge, skills and values regarding AI. Such basic AI literacy  is  increasingly  necessary  for  effective  collaboration  between humans and machines in life, learning and work (Ali et al., 2019).

The AI revolution is no longer in its infancy, but its most important effects on the economy are yet to come. Some countries and regions have already  realised  the  great  economic  potential  of  AI,  and  they  are developing  frameworks  to  capitalise  on  the  opportunities  it  offers (Legislative Council Commission, 2019; Ministry of Economic Affairs and Employment, 2017). For many business and government leaders, it is evident that fostering AI literacy is vital for the personal success of every citizen and for enabling regional prosperity in general. AI-related technology is increasingly pervasive throughout society, especially in the more developed countries and regions. Therefore, it is time for our siucheungkong@gmail.com (S.-C. Kong), williamcheung@eduhk.hk (W. Man-Yin Cheung), gzhang@eduhk.hk (G. Zhang).

Received 13 May 2021; Received in revised form 29 May 2021; Accepted 1 June 2021

GLYPH&lt;0&gt;GLYPH&lt;20&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;

GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;25&gt;GLYPH&lt;0&gt;GLYPH&lt;25&gt;GLYPH&lt;0&gt;GLYPH&lt;25&gt;GLYPH&lt;0&gt;GLYPH&lt;16&gt;GLYPH&lt;0&gt;GLYPH&lt;28&gt;GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;;GLYPH&lt;0&gt;GLYPH&lt;18&gt;GLYPH&lt;0&gt;â€¹

GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;20&gt;

GLYPH&lt;0&gt;-GLYPH&lt;0&gt;XGLYPH&lt;0&gt;QGLYPH&lt;0&gt;H

GLYPH&lt;0&gt;7GLYPH&lt;0&gt;KGLYPH&lt;0&gt;H

GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;GLYPH&lt;21&gt;GLYPH&lt;0&gt;GLYPH&lt;20&gt;

<!-- image -->

GLYPH&lt;0&gt;3GLYPH&lt;0&gt;XGLYPH&lt;0&gt;EGLYPH&lt;0&gt;OGLYPH&lt;0&gt;LGLYPH&lt;0&gt;VGLYPH&lt;0&gt;KGLYPH&lt;0&gt;HGLYPH&lt;0&gt;G

GLYPH&lt;0&gt;EGLYPH&lt;0&gt;\

GLYPH&lt;0&gt;(GLYPH&lt;0&gt;OGLYPH&lt;0&gt;VGLYPH&lt;0&gt;HGLYPH&lt;0&gt;YGLYPH&lt;0&gt;LGLYPH&lt;0&gt;HGLYPH&lt;0&gt;U

GLYPH&lt;0&gt;/GLYPH&lt;0&gt;WGLYPH&lt;0&gt;GGLYPH&lt;0&gt;GLYPH&lt;17&gt;

GLYPH&lt;0&gt;GLYPH&lt;20&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;GLYPH&lt;0&gt;GLYPH&lt;19&gt;

GLYPH&lt;0&gt;RGLYPH&lt;0&gt;SGLYPH&lt;0&gt;HGLYPH&lt;0&gt;Q

society to educate their citizens regarding AI.

## 2.1. Teaching AI concepts

Researchers have already conducted empirical studies on the best ways to teach AI. However, at the current stage, few efforts have been made to start the teaching with the key concepts of AI to university students with diverse study backgrounds. Most of the approaches have focused on algorithms and programming for teaching AI (Bye, 2018; Chesani et al., 2017; de Freitas &amp; Weingart, 2021; Estevez et al., 2019; Pouly &amp; Arnold, 2019). Accordingly, most of these computer science-centric  approaches  (Mishra  and  Siy,  2020)  targets  university students  with  computer  science-related  disciplines.  Though  attempts have  been  started  on  developing  middle  school  students ' conceptual understanding of AI (Lee et al., 2021), efforts on teaching AI concepts to university students with diverse study backgrounds and public are rare. Our initiative seeks to fill the gap to offer an AI literacy course to university students of diverse study backgrounds with emphasis on teaching AI concepts.

## 2.2. AI literacy

The term 'literacy ' originally referred to the ability to read and write. In  today ' s  digital  era,  the  notion  of  'functional  literacy ' has  been extended to include a range of 'new ' or 'multiple ' literacies (Buckingham, 1993) such as visual, media, computer, digital information, and AI literacy (Emwanta et al., 2013; Hattwig et al., 2013; Jeffrey et al., 2011; Kong, 2008, 2014; Potter, 2018).

All efforts on AI literacy education have had to address the question of what AI literacy comprises. We propose that AI literacy includes three components: AI concepts, using AI concepts for evaluation, and using AI concepts  for  understanding  the  real  world  through  problem  solving. Understanding AI concepts is essential for learners developing AI literacy. Basic AI concepts are clearly emphasised in the OECD guidelines (2018b) and curriculum guidelines suggested by Touretzky et al. (2019). Some examples of AI concepts named are machine learning, classifiers, decision trees, reasoning and prediction, patterns in data, and statistical inferences.

Once learners have acquired the basic concepts, they may apply the knowledge to make judgement concerning AI independently, which is using AI concepts for evaluation. This falls in line with the definition of AI literacy suggested by Long and Magerko (2020), in which the competency to evaluate AI technology is an important component. In addition to understanding AI concepts and using AI concepts for evaluation, an AI-literate person should be able to use AI concepts for understanding the real world through problem solving. Long and Magerko (2020) hold this idea that the ability to use AI as a tool for problem-solving at home and in the workplace is an integral component of AI literacy. Learners use the AI concepts acquired to solve problems in their private lives and their  daily  work.  With  related  problem-solving  experiences,  learners know more about the impact of AI for individuals and the society at large and have a deeper understanding of the AI-permeated digital world.

As mentioned earlier, there is an increasingly urgent need for society to educate their citizens regarding AI. Therefore, our experiment of how to foster AI literacy serves the purpose of equipping educated citizens to succeed in the modern digital society. As noted in the Report of the Royal Commission on Education (Sullivan, 1988), the term 'educated citizens ' can have multiple meanings, but one key feature of such citizens is that they are skilled and able to make contributions, both to their professions and to society in general. In accordance with this description of 'educated citizens ' , we propose that cultivating AI literacy is a way to equip  educated  citizens  with  the  skills  to  advance  their  interests  as members of society and to use AI to serve their communities.

## 2.3. Empowerment through AI

Another important aim of the proposed literacy course is to empower participants by enabling them to understand, interact and communicate with AI applications in this digital era. According to Makinen (2006), the phrase 'empowerment of individuals ' refers to giving people the tools they need to better control their lives and expand their coping skills. When viewed from this angle, the purpose of AI literacy is to give people new abilities and ways to participate in the digital society. This understanding points to a goal of empowerment through AI, or an aim to enhance  the  learners ' confidence  through  engaging  with  AI.  Several similar concepts have been proposed, such as 'digital empowerment ' (Makinen, 2006) and 'programming empowerment ' (Kong, 2019; Kong et al., 2018). All of these terms describe the means of empowering individuals  in  various  contexts.  Kong  et  al.  (2018)  proposed  that  programming  empowerment  has  four  main  components:  programming self-efficacy,  meaningfulness,  impact  and  creative  self-efficacy.  In borrowing this framework for understanding programming empowerment, we propose that the concept of AI empowerment incorporates the components  of  AI  self-efficacy,  meaningfulness,  impact  and  creative self-efficacy.

AI self-efficacy is the primary focus of the proposed programme. As the  psychologist  Bandura  (1982)  explained,  self-efficacy  involves  a person ' s own evaluation of his or her ability to carry out a course of action needed to deal with a future challenge. In the context of AI literacy  education,  self-efficacy  refers  to  how  well  participants  believe they are doing when they engage with AI. If participants have a higher degree of self-efficacy, they feel more self-assured about their ability to achieve  an  AI-related  task,  and  they  are  more  likely  to  begin  or  to continue working on that task.

The  second  component,  meaningfulness,  concerns  the  perceived value and significance that AI has for learners in their everyday lives. The value of AI literacy is widely recognised, as it is beneficial for lifelong learning and can be used in many daily circumstances (Martin, 2006). Furthermore, participants who see AI as meaningful are more likely to make more efforts to excel and to feel empowered (Frymier et al., 1996).

Impact  refers  to  the  degree  to  which  accomplishing  a  task  is perceived as making a difference in the scheme of things (Frymier et al., 1996). Our interest in impact concerns the learners ' perceptions of AI literacy and its societal effects. An individual who feels that interacting with AI creates a greater impact tends to have more internal drive for learning the relevant skills (Frymier et al., 1996). In other words, participants  can  become  motivated  to  learn  AI  skills  once  they  become aware of their societal impact.

Finally, creative self-efficacy refers to a student ' s conviction that he or she can come up with new ideas and solutions (Brennan &amp; Resnick, 2012; Kong et al., 2018). When confronted with a challenging task, an individual with a higher degree of creative self-efficacy is more likely to try various ideas and methods to complete the task, and thus that individual is more likely to succeed (Kong et al., 2018; Paulus &amp; Brown, 2003). Therefore, by empowering the public, AI literacy education has the potential to inspire future producers of technology, and not just to enable consumption of existing technology (Resnick et al., 1996; Touretzky et al., 2019).

## 2.4. Course design for participants with diverse study backgrounds

As mentioned earlier, this article reports a study in designing and evaluating an AI literacy course. This is the first course of an AI literacy programme and it concentrates on concepts related to machine learning. The second course is about AI concepts related to deep learning. These two courses build up the foundation for participants to take the last course of the programme. The last course supports participants to solve problems by developing AI applications. These three courses would be developed  to  generate  a  diverse  population  of  AI  literates.  Machine

GLYPH&lt;0&gt;,

learning was the focus of this first course, due to its widespread use and huge impact on today ' s society. However, the course did not cover the details of mathematical formulae and programming, as most individuals who interact with AI in their daily lives do not need to know the underlying mathematical models or how to do the programming (Long &amp; Magerko, 2020). In evaluating our trial of  this course,  we  sought  to compare the gains in learning AI concepts for the participants with and without programming knowledge.

The course targeted university students from all study backgrounds and both genders. We felt it was critical that participants from different backgrounds and of both genders have equal opportunities to gain the skills they need to operate in an AI-integrated society. Various governments have also launched initiatives to promote AI literacy for participants from differing backgrounds. For instance, the UK government has provided AI and data science conversion courses, with scholarships for participants from underrepresented backgrounds. These courses have helped to tackle skills gaps and to expand the range of choices and opportunities for all participants.

In  addition  to  overcoming  the  disparities  among  participants  of different educational backgrounds, we were concerned about closing the gender gap in tech-related learning. AI literacy might help to narrow the commonly observed digital gender gap. According to the OECD (2018a), gender  disparities  in  AI  knowledge  and  experience  lead  to  unequal engagement in learning programmes and increased potential for unintended bias in the design of various applications. Greater inclusion of women in the digital economy and increased diversity bring increased value, both social and economic. Thus, with all of these considerations in mind, we intended our AI literacy course to be suitable for all participants, regardless of their backgrounds or genders.

To meet these goals, we conducted our course design and evaluation efforts to investigate the following research questions: (1) Can the proposed AI literacy course address AI concepts and literacy in relation to the latest developments such as machine learning? (2) Can this AI literacy course help to empower the participants to use AI? (3) Can this AI literacy course narrow the gaps in learning about AI between the genders and people of different study backgrounds? (4) Can the proposed flipped classroom learning approach to teach AI literacy appropriately fit the needs of the participants?

## 3. Methodology

## 3.1. Participants in the course

Among the 120 course participants, 82 were women and 38 were men. Approximately 75% of them were taking Bachelor ' s degree programmes, and they were spread among years one, two, three and four. The rest of the participants were learners who came from postgraduate programmes or higher diploma programmes. As illustrated in Fig. 1, the participants came from a variety of study backgrounds, such as Chinese language studies, mathematics, general studies, or fields such as information  and  communication  technology,  sciences,  English  language studies or psychology.

## 3.2. Course content

The course covered the following major concepts: artificial intelligence, machine learning, supervised learning and unsupervised learning.

Artificial  Intelligence. The  participants  were  first  given  a  brief introduction to AI with a discussion of strong and weak AI. During the course ' s  workshops,  they  were  invited  to  share  their  views  on  the application and impact of AI.

Machine Learning. The  participants  were  introduced  to  the  five steps for applying machine learning to problem solving, namely 'problem defining ' , 'data collection ' , 'data processing ' , 'model training ' and 'reasoning and prediction ' . Then they received guidance on performing image recognition via online platforms.

Supervised Learning. The participants were introduced to the two main  ideas  involved  in  supervised  learning,  namely  'regression ' and 'classification ' . They learnt to distinguish these two ideas by considering examples and gaining hands-on experience. For example, to learn about 'classification ' ,  the participants received a guided introduction to the subjects of algorithms, k-nearest neighbours (KNN) and decision trees. The examples provided helped the participants to understand how these

Fig. 1. Distribution of study backgrounds of the course participants.

<!-- image -->

GLYPH&lt;0&gt;,

models served to classify items among multiple categories.

Unsupervised Learning. The participants were introduced to the concept of unsupervised learning and then received guidance on the application of k-means clustering in a series of case studies. These case studies helped the participants to understand the working principles of unsupervised learning.

## 3.3. An example of how AI concepts were taught in the course

In  seeking  to  cultivate  AI  literacy  in  the  general  population  of educated citizens, this course focused on conveying relevant AI concepts rather  than  technical  details.  Therefore,  the  course  materials  were designed to help the participants grasp the relevant concepts but did not cover mathematical formulae or the codes used to implement AI algorithms. The way that the KNN algorithm was explained can serve as an example of the approach used.

The KNN is a classic algorithm used in machine learning, and it is widely applied for classification tasks. In this course, the KNN algorithm was first introduced by discussing a practical task, namely assigning a new student to one of two classes according to that student ' s performance in English and maths tests. Fig. 2 provides a visualisation of the scenario. We started by considering the scores of the other students by plotting them on a coordination system chart, where the vertical axis represented  their  English  scores  and  the  horizontal  axis  represented their maths scores. The students in Classes A and B were represented by the symbols of a diamond ( ) or a cross ( ), respectively.

Under this setting, the task involved plotting the scores of a new student, represented by a star ( ), and choosing the most appropriate class  for  that  student.  Instead  of  trying  to  learn  the  complex  mathematical formulae, the participants were introduced to the concept of KNN. In other words, they needed to identify the students on the graph whose performance was closest to that of the new student. In this way, we attempted to illustrate the meaning of the technical term

'neighbours ' . Examining this kind of 'closeness ' required some form of distance measure. With this presented visualisation of the problem, it was intuitive to use the Euclidean distance on the graph to calculate the distance, although the axes represented test scores. The distances between the new student ' s scores and those of all of the other students were calculated. With these distances defined and available, we could select the k nearest students to determine the new student ' s class. We told the participants that the value of k determined the number of the neighbourhood and could influence the class assignment. For instance, when k = 3, the majority of the class memberships of the three nearest neighbours to the new student determined which class the new student should go to. In this case, the majority of the three nearest neighbours (two  out  of  three)  were  in  Class  A,  and  thus  the  new  student  was assigned to Class A.

Based on this example, we generalised the process by using an abstract example to facilitate the course participants ' understanding. We told them that the students in the previous example were represented by data points. The English scores and maths scores were features of the data points, and Classes A and B were labels for the data points. The participants  were  reminded  that  the  number  of  features  and  labels varied  under  differing  scenarios.  A  general  image  of  this  example  is shown in Fig. 3. In this figure, the objects in Categories A and B are represented  by  the  symbols  of  the  diamond  ( )  and  the  cross  ( ), respectively. Features 1 and 2 represent the two dimensions (the English and maths scores) of the data. When a new observation, represented by the star ( ), is to be labelled, the distances from the new data observation to the existing data points is calculated. Next, we pick the knearest data points. The label for the new observation is determined by the majority of the labels of the k nearest data points. For instance, in Fig. 3, when k = 3, the new observation is labelled according to the majority of the labels among its three nearest neighbours. In Fig. 3, the new point is labelled as a cross ( ),  because two of its three nearest neighbours are labelled with crosses ( ).

## Maths&amp;EnglishScores

Fig. 2. An example to illustrate the operation of the KNN algorithm in the context of classifying a student into one of two classes, according to the student ' s English and maths test scores.

<!-- image -->

GLYPH&lt;0&gt;,

Fig. 3. An example to illustrate the operation of the KNN algorithm in the context of classifying a new object into one of two categories according to the majority of the labels of the k nearest data points in relation to the two features.

<!-- image -->

As mentioned earlier, the KNN parameters, including the number of features, the number of categories and the k values, can vary in different cases.  To  help  the  course  participants  better  understand,  an  online animated  demonstration  was  provided  to  help  them  visualise  the changes to the results when different parameters were set (http://vision. stanford.edu/teaching/cs231n-demos/knn/). By changing the number of classes (categories), the number of neighbours (k) and the number of labelled data points, the participants had the opportunity to observe the corresponding changes in the classifications and to reflect on how the k values influence the results of the classifications.

In addition to this two-feature-based demonstration, the participants were given examples of how to apply KNN for higher dimensional data. They were reminded that although the data features could include more than two dimensions, the rationale would remain the same, with an assumption that similar things existed in proximity. The fundamental principle  of  the  KNN  algorithm  is  that  new  objects  are  classified  by examining their neighbours. In this way, we consolidated conceptual learning by helping the participants grasp the concept of the KNN algorithm. We helped them understand the relevant AI concepts rather than focusing on the mathematical formulae or the program codes to implement the algorithm. We considered that using real-life scenarios and hands-on exercises would help the participants to strengthen their understanding of the major AI concepts. At the same time, the example of a task for assigning a new student to Class A or Class B (as illustrated in  Fig.  2)  gave  the  participants  more  ideas  that  were  transferable  to concepts they used in their private lives and their daily work. These ideas could substantially enhance their levels of creative self-efficacy.

## 3.4. Procedures for administering the course and evaluation

We conducted pre-course surveys and tests, post-course surveys, tests on the course materials and focus group interviews to assess the effectiveness of the course. We divided the 120 participants into three classes. The course for each class took three weeks ' time. At the beginning of the course, the participants were invited to do a pre-course concepts test and a pre-course survey, which included assessments of their AI literacy and AI  empowerment.  This  took  half  an  hour.  The  course  included  two workshops, with each workshop lasting one and a half hours. Before attending each workshop, the participants were required to study the self-directed reading materials for one and a half hours. Before the first workshop, they were required to read the first two chapters of a book ' AI for Everyone ' (AI4kids, 2020). The two chapters were ' Into the world of artificial  intelligence ' and ' Can  build  machine  learning ' .  Before  the second workshop, they were required to read another two chapters of the  book.  They  were ' Hands-on supervised learning ' and ' Hands-on unsupervised learning ' . The readings enabled participants to have an initial understanding of the concepts such as machine learning, supervised  learning,  and  unsupervised  learning.  The  workshops  allowed participants to have hands-on experiences with the concepts such as an online  exploration  in  learning  the  KNN  concept  as  illustrated  above. Teachers could help participants to visualise the changes when different parameters were set. Teachers provided opportunities for participants to discuss the AI concepts in the workshops. Finally, after attending both workshops, the participants were invited to do the same set of surveys and tests again. This took another half an hour. The whole course took 7 h.

After the course, we held sessions involving focus group interviews to solicit the students ' in-depth thoughts and feedback. The participants in these  interviews  included  13  students  who  were  selected  from  the course ' s  three  classes,  and  they  did  five  group  interviews.  These  interviews focused on two topics, namely the participants ' feedback after attending  the  AI  literacy  course  and  their  responses  to  the  flipped classroom learning approach used in the course. For instance, regarding AI literacy, one question was 'What have you learnt from this course about  AI? ' Concerning the flipped  classroom  learning  approach,  one question was 'Do you think the flipped classroom learning approach was effective for learning about AI? '

## 3.5. Instruments

To evaluate the course participants ' progress in developing AI literacy, we designed and administered an AI Concepts Test, an AI Literacy Survey and an AI Empowerment Survey. In accordance with Suskie ' s proposal (2018), we considered that an effective assessment of learning by  students  should  provide  direct  evidence  of  learning.  Thus,  we composed the AI Concepts Test as a way to directly measure the participants ' learning. The AI Literacy Survey and the AI Empowerment Survey further helped us to understand and evaluate the course participants ' self-reported improvements in AI literacy and AI empowerment.

We  design  the  instruments  in  four  steps.  Firstly,  we  conduct

GLYPH&lt;0&gt;,

literature  review to generate initial ideas of the tests and surveys. A systematic review of the related literature provided ideas on the major concepts for the AI Concepts Test as well as the major components of the AI Literacy Survey. We refer to guides on how to incorporate AI into K12  curricula  (Touretzky  et  al.,  2019)  and  competencies  and  design considerations of AI literacy (Long &amp; Magerko, 2020), together with the major contents covered by the textbook (AI4kids, 2020). They served as the major guidelines in developing the two instruments. Concerning the AI empowerment survey, we initiated the constructs of AI empowerment by  referring  to  the  constructs  of  programming  empowerment  (Kong et  al.,  2018),  which  has  been  elaborated  in  the  background  section. Secondly, we composed items for these three instruments and produced initial drafts of the tests and surveys based on the concepts, components and constructs identified. Thirdly, the instruments were refined collaboratively by the research team, which comprised of a professor in the field of computer science, teaching staff of the AI literacy course and a researcher of the project. Fourthly, after conducting the tests and surveys, we analysed the reliability of the instruments and further refine the instruments based on the statistical results.

In the pre-/post-course AI Concepts Test, the participants were asked to answer 14 multiple choice questions (with four choices per question). These questions concerned the AI concepts covered in the course and were designed to measure the participants ' progress in understanding these  concepts.  We  used  the  revised  version  of  Bloom ' s  Taxonomy (Anderson et al., 2001) as our guide for writing the AI Concepts Test. The 14 questions were designed to measure the participants ' mastery of the key concepts. The questions concerned four types of skills, including the ability 'to understand ' , 'to apply ' , 'to analyse ' and 'to evaluate ' . Some questions covered more than one skill.

On this 14-item AI Concepts Test, 11 questions focused on the participants ' understanding of basic AI concepts. Four questions assessed the  participants ' ability  'to  apply ' the  concepts,  four  questions  concerned their ability 'to analyse ' their applications, and three questions concerned their ability 'to evaluate ' the issues and solutions concerned. For example, one question was 'Which algorithm for supervised learning involves  the  concept  of ' birds  of  a  feather  flocking  together ' ? ' This question was introduced to assess the participants ' understanding of the important KNN concept, as discussed previously.

The second instrument, the AI Literacy Survey, concerned the participants ' perceptions of their own levels of AI literacy in the areas of AI concepts, using AI concepts for evaluation, and using AI concepts for understanding the real world through problem solving. This self-report survey  included  10  items.  The  participants  were  asked  to  indicate their level of agreement with each item by choosing answers on a 5point  Likert  scale  (1 = strongly  disagree;  5 = strongly  agree).  For instance, one of the items was 'I understand various applications of AI in everyday life ' . The participants ' responses to this survey reflected their self-perceived levels of AI literacy.

The third instrument, the AI Empowerment Survey, concerned the participants ' sense of empowerment to deal with AI, and it included 17 items. The participants were asked to indicate their level of agreement with each item on a 5-point Likert scale (1 = strongly disagree; 5 = strongly agree). This was a self-report survey with questions about the participants ' perceptions of their own levels of empowerment in relation to AI. The survey ' s four components were 'AI self-efficacy ' , 'meaningfulness ' ,  'impact ' and  'creative  self-efficacy ' .  These  four  components were measured with five, five, four and three questions, respectively. For instance, regarding 'AI self-efficacy ' , one item was 'I think of myself as someone who can learn well in an AI literacy course ' . On 'meaningfulness ' , one item was 'Knowing AI is useful to me ' . Concerning 'impact ' , the  participants  were  asked  to  rate  their  level  of  approval  for  four statements, such as 'I want to apply my AI knowledge and skills to make people ' s  lives  better ' .  Regarding the last component of 'creative selfefficacy ' , one item was 'I like to express my ideas through AI ' . The answers to this survey gave an overall indication of the participants ' perceptions of their own AI empowerment. Regarding the reliability of the instruments, the Cronbach ' s alpha coefficients for the post-tests of AI concepts, AI literacy and AI empowerment were 0.66, 0.89 and 0.93 respectively.

## 4. Results and discussion

This section presents the results of comparing the participants ' responses  on  the  AI  Concepts  Test,  the  AI  Literacy  Survey  and  the  AI Empowerment Survey, both before and after attending the course. This section  also  reports  key  findings  from  the  focus  group  interviews. Furthermore, the results are compared based on the participants ' genders and study backgrounds.

## 4.1. Gains in understanding AI concepts

Regarding the participants ' progress in understanding AI concepts, Table 1 summarises the mean scores and standard deviations of the AI Concepts Tests taken before and after the course. This table also gives the paired t -test scores of all participants who completed these tests.

Table 1 indicates that the participants made significant progress in grasping concepts related to AI, as shown by the statistically significant increase in the mean score, from 6.31 to 9.71. In addition, the corresponding ttest results showed that the test scores of the participants from computer science-related disciplines and the scores of the participants from other study backgrounds showed no statistically significant difference, either before or after the course. In this study, information and communication technology, mathematics, general studies and science were regarded as computer science-related disciplines. The beforeand after-course performance of the participants from computer sciencerelated disciplines and that of the participants from other disciplines are compared in Fig. 4.

Similarly, the performances of the female and male participants are shown in Fig. 5. The test scores of the female participants in the AI Concepts Test were not significantly different from those of their male counterparts, either before or after the course. These findings indicated that the course was similarly beneficial in promoting understanding of AI for participants of all disciplines and of both genders.

## 4.2. Gains in AI literacy

Concerning changes in the course participants ' self-perceived levels of AI literacy, Table 2 shows the mean scores and standard deviations of our AI literacy Survey before and after the course, along with the paired t -test scores for all participants. Table 2 indicates that the course participants made significant gains in terms of their self-perceived AI literacy, as the average score increased from 2.93 before the course to 3.98 after the course.

## 4.3. Gains in AI empowerment

Regarding how learning about AI helped our course participants to feel empowered, Table 3 summarises the results from our AI Empowerment Survey taken before and after the course. The results showed a statistically significant increase in the mean score, from 3.93 to 4.06, which indicates  that  the  course  helped  the  participants  to  feel  more empowered.

Table 1 Means, standard deviations and t -test  scores  on  the  AI  Concepts  Tests  taken

before and after the course.

| AI Concepts Test   | Pre-test (max. mark = 14)   | Pre-test (max. mark = 14)   | Post-test (max. mark = 14)   | Post-test (max. mark = 14)   | Paired t- test   |         |
|--------------------|-----------------------------|-----------------------------|------------------------------|------------------------------|------------------|---------|
|                    | M                           | SD                          | M                            | SD                           |                  |         |
|                    | 6.31                        | 2.06                        | 9.71                         | 2.60                         | 13.90***         | t (119) |

N = 120; * p &lt; .05; ** p &lt; .01; *** p &lt; .001.

GLYPH&lt;0&gt;,

Fig. 4. Comparison of performance on the AI Concepts Test before and after the course, by participants from computer science-related disciplines and participants from other disciplines.

<!-- image -->

Fig. 5. Comparison of performance on the AI Concepts Tests by male and female participants before and after the course.

<!-- image -->

Table 2 Means, standard deviations and t -test scores on the AI Literacy Survey before and after the course.

| AI Literacy   | Pre-survey (max. mark = 5)   | Pre-survey (max. mark = 5)   | Post-survey (max. mark = 5)   | Post-survey (max. mark = 5)   | Paired t- test   |
|---------------|------------------------------|------------------------------|-------------------------------|-------------------------------|------------------|
|               | M                            | SD                           | M                             | SD                            |                  |
|               | 2.93                         | 0.65                         | 3.98                          | 0.46 16.02***                 | t (119)          |

N = 120; * p &lt; .05; ** p &lt; .01; *** p &lt; .001.

Table 3 Means, standard deviations and t -test scores for the AI Empowerment Survey before and after the course.

| AI Empowerment   | Pre-survey (max. mark = 5)   | Pre-survey (max. mark = 5)   | Post-survey (max. mark = 5)   | Post-survey (max. mark = 5)   | Paired t- test   |
|------------------|------------------------------|------------------------------|-------------------------------|-------------------------------|------------------|
|                  | M 3.93                       | SD 0.46                      | M 4.06                        | SD 0.45                       | 2.96** t (119)   |

N = 120; * p &lt; .05; ** p &lt; .01; *** p &lt; .001.

Like the survey results, the results of the participant interviews also indicated  a  significant  improvement  in  the  participants ' sense  of  AI empowerment. This improvement was especially evident in the domain of the perceived meaningfulness of AI empowerment. Table 4 shows the participants ' perceptions of their own gains in learning after taking the course. They showed strong recognition for the usefulness of this course in their studies, jobs and daily lives. Most of the participants said that the course broadened their ideas on teaching strategies using AI tools. Some of the participants said that the course inspired them to brainstorm AIrelated projects, that it gave them ideas for using AI tools to assess and monitor the performance of their students, or that it enhanced their efficiency  in  teaching  and  learning.  Concerning  the  benefits  to  their daily lives, the course participants stated that the course made them think more deeply about AI-related applications, the underlying rationale for these applications and their reliability for use in everyday life. Such  reflection  and  evaluation  indicated  that  the  participants  were willing and able to apply their knowledge of AI to real-life situations. These statements revealed that the course helped them to develop their creative self-efficacy, which is another vital component of AI empowerment.

## 4.4. Bridging the gender gap

Regarding  gender  differences  in  the  participants ' level  of  understanding of AI concepts and related self-perceptions, our findings of the AI Concepts Test and the AI Literacy Survey showed that there were no statistically  significant  differences  in  scores  between  genders,  either

GLYPH&lt;0&gt;,

Key  points  that  the  participants  made  during  their  interviews  about  their

Table 4 perceived gains in knowledge from the course.

| Question themes                                                  | Descriptions                                                                                                                | Course participants ' responses                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Usefulness for study Usefulness for work Benefits to daily lives | Project idea; Further study; Enhanced teaching; Enhanced teaching resources; Reflection on and evaluation of AI technology. | The course inspired me to brainstorm several projects related to AI (S4). I will further my studies with a major related to computer science. I will have the advantage of having a better understanding of AI (S2). As a teacher, I see that AI can be used in teaching. For example, using some AI tools may arouse the students ' interest in learning. Another application is AI tools for English learning (S7). I feel that the Information and Communications Technology course helped me in my work by giving me a lot of resources for organising AI activities (S13). After taking the course, when I use a certain software in daily life, I think about whether it involves AI technology, how AI is applied and whether its results are reliable. I think deeper than before (S3). |

before  or  after  the  course.  The  results  of  AI  empowerment  Surveys showed that the course effectively helped to overcome gender disparity. Concerning  gender  differences  in  self-perceived  AI  empowerment, Table 5 shows that our female participants felt less empowered before the course, but this difference no longer existed after the course. Gender stereotypes may account for the fact that female participants feel less empowered before the course even though they have similar performance as that of their male counterparts in AI Concepts Test and AI Literacy Survey. It was reported that female students were more critical of their abilities in STEM than male students even if they had the same grades (Ertl et al., 2017). Such a gender stereotypes can lead to different levels of self-motivation and create structural barriers that perpetuate workplace gender inequality (International Labour Organization, 2017; OECD, 2018a). Fig. 6 illustrates the changes in AI empowerment between before and after the course. Although the female and male participants  reported  that  they  felt  more  empowered  through  learning about  AI,  the  female  participants  showed  a  greater  increase  in  their sense of empowerment. This finding highlighted that the course helped to bridge the difference in AI empowerment between genders.

## 4.5. Bridging the gaps between participants with diverse study backgrounds

In this section, we consider the performance of the participants from different disciplines and compare the performance of the participants with or without prior knowledge of programming. Our tests and surveys showed that the course reduced the disparities in AI-related knowledge between the participants from different study backgrounds. In addition,

Table 5 Means, standard deviations and t -test scores on the AI Empowerment Survey before and after the course for female and male participants.

| Pre-survey (max. mark = 5)   | Female Participants ( N = 82)   | Female Participants ( N = 82)   | Male Participants ( N = 38)   | Male Participants ( N = 38)   | Independent- samples t- test   | Independent- samples t- test   |
|------------------------------|---------------------------------|---------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|
|                              | M                               | SD                              | M                             | SD                            |                                |                                |
|                              | 3.84                            | 0.41                            | 4.12                          | 0.52                          | 3.21**                         | t (118)                        |
| Post-survey (max. mark = 5)  | 4.03                            | 0.45                            | 4.13                          | 0.43                          | 1.17                           | t (118)                        |

* p &lt; .05; ** p &lt; .01; *** p &lt; .001.

the  participants  without  programming  knowledge  made  significant gains in knowledge and confidence by attending the course.

Our tests did show statistically significant differences in AI literacy between the participants from computer science-related disciplines and those from other disciplines, both before and after our course. However, there  were  no  significant  statistical  differences  in  scores  on  the  AI Concepts  Test  or  the  AI  Empowerment  Survey.  Table  6  reports  the means, standard deviations and the corresponding ttest  scores  in  AI literacy for these two groups of participants. Although the participants from computer science-related disciplines tended to show higher levels of AI literacy before attending the course, this difference was reduced after  the course, as shown in Fig. 7. Therefore, the course helped to narrow the gap in AI literacy between the participants from computer science-related disciplines and those from other disciplines.

## 4.6. Narrowing disparities between participants with prior programming knowledge and those without programming knowledge

To evaluate the influence of prior programming knowledge on the development of AI concepts, we collected data on the participants ' prior programming knowledge. There were 101 responses from participants reporting on their prior programming knowledge. We then divided the participants into two groups, one with prior programming knowledge and  the  other  without  prior  programming  knowledge.  We  then compared the performance of both groups on the AI Concepts Test and their self-reported levels of AI literacy and AI empowerment. The results showed that our course helped both groups of participants to effectively develop their understanding of AI concepts and to improve their selfperceived  levels  of  AI  literacy  and  AI  empowerment.  This  evidence supported our hypothesis that programming knowledge is not a prerequisite for understanding AI concepts. The course effectively enhanced AI  literacy  for  all  participants  regardless  of  their  prior  educational backgrounds. Concerning the participants ' performance on the AI Concepts Test, we found no statistically significant differences between the participants  with  programming  experience  and  those  without  such experience, either before or after the course.

Table 7 shows the mean scores and standard deviations of our AI literacy Survey, taken before and after the course. The table also shows the paired t -test scores for both groups of participants. These scores show that before the course, the participants with prior knowledge of programming perceived themselves to have higher levels of AI literacy than were reported by their counterparts without prior knowledge of programming. After the course, the gap in AI literacy between these groups was narrower, as shown in Fig. 8.

Regarding the differences in self-reported AI empowerment between the  participants  with  prior  knowledge  of  programming  and  those without  such  prior  knowledge,  Table  8  shows  the  mean  scores  and standard deviations of our AI Empowerment Survey before and after the course, and the paired t -test scores for both groups of participants. The results  showed  that  there  were  significant  differences  in  the  participants ' self-perceived levels of AI empowerment before the course, but after  the  course,  there  were  no  statically  significant  differences.  The performance of these two groups of participants is illustrated in Fig. 9.

In  summary,  the  study  results  showed  that  the  course  effectively improved the participants ' AI literacy in terms of developing their understanding of AI concepts and enhancing their self-perceived levels of AI literacy and AI empowerment. In addition, this course was found suitable for participants of different study backgrounds and both genders. The results verified our assumption that programming knowledge is not a prerequisite for acquiring AI concepts.

## 4.7. Flipped classroom learning approach

The  course  focused  on  conceptual  learning  and  was  delivered through a flipped classroom learning approach. As the focus group interviews showed, the participants were able to effectively acquire key AI

GLYPH&lt;0&gt;,

Table 6

Means, standard deviations and t -test scores on the AI Literacy Survey before and after the course for participants from computer science-related disciplines and those from other disciplines.

| Pre-survey (max. mark = 5)   | Computer Science- related disciplines ( N = 51)   | Computer Science- related disciplines ( N = 51)   | Other disciplines ( N = 69)   | Other disciplines ( N = 69)   | Independent- samples t- test   | Independent- samples t- test   |
|------------------------------|---------------------------------------------------|---------------------------------------------------|-------------------------------|-------------------------------|--------------------------------|--------------------------------|
|                              | M                                                 | SD                                                | M                             | SD                            |                                |                                |
|                              | 3.14                                              | 0.63                                              | 2.78                          | 0.64                          | 3.05**                         | t (118)                        |
| Post-survey (max. mark = 5)  | 4.09                                              | 0.44                                              | 3.90                          | 0.46                          | 2.30*                          | t (118)                        |

* p &lt; .05; ** p &lt; .01; *** p &lt; .001.

concepts in a flipped classroom setting, and they preferred the flipped classroom learning approach. Our major findings regarding the effects and pedagogical value of the flipped classroom setting are presented in Table  9.  The  participants  stated  that  the  flipped  classroom  learning approach was effective in teaching key AI concepts. Some of the participants  mentioned  that  because  AI  is  a  complex  and  fast-changing subject, it was difficult to teach all the content within the limits of the class  time,  and  the  flipped  classroom  learning  approach  successfully addressed this issue. Other participants pointed out additional strengths of  the  flipped  classroom  learning  approach,  including  its  ability  to facilitate self-regulated learning, cater to learners ' differences, increase

Fig. 6. Results of the AI Empowerment Survey before and after the course for female and male participants.

<!-- image -->

in-class interaction and cultivate habits of preparing before class.

## 5. Conclusion and implications

This article reports on the design and implementation of an AI literacy course to improve university students ' understanding of AI and empower them to confidently engage in the digital world. We developed a 7-h course on AI and tested it with 120 university students in Hong Kong. The lessons were presented using a flipped classroom learning approach. Our surveys and tests showed that the course enabled the participants to achieve statistically significant improvements in

## Table 7

Means, standard deviations and t -test scores on the AI Literacy Survey before and after  the  course  for  participants  without  prior  programming  knowledge  and those with prior programming knowledge.

| Pre-survey (max. mark = 5)   | Without programming knowledge ( N = 61)   | Without programming knowledge ( N = 61)   | With programming knowledge ( N = 40)   | With programming knowledge ( N = 40)   | Independent- samples t- test   | Independent- samples t- test   |
|------------------------------|-------------------------------------------|-------------------------------------------|----------------------------------------|----------------------------------------|--------------------------------|--------------------------------|
|                              | M                                         | SD                                        | M                                      | SD                                     |                                |                                |
|                              | 2.72                                      | 0.64                                      | 3.25                                   | 0.61                                   | 4.14***                        | t (99)                         |
| Post-survey (max. mark = 5)  | 3.92                                      | 0.49                                      | 4.15                                   | 0.41                                   | 2.46*                          | t (99)                         |

* p &lt; .05; ** p &lt; .01; *** p &lt; .001.

Fig. 7. Results of the AI Literacy Survey before and after the course by participants from computer science-related disciplines and those from other disciplines.

<!-- image -->

GLYPH&lt;0&gt;,

Fig.  8. Results  of  the  AI  Literacy  Survey  before  and  after  the  course  by  participants  without  prior  programming  knowledge  and  those  with  prior  programming knowledge.

<!-- image -->

Table 8 Means, standard deviations and t -test scores on the AI Empowerment Surveys before and after the course for participants without prior programming knowledge and those with prior programming knowledge.

| Pre-survey (max. mark = 5)   | Without programming knowledge ( N = 61)   | Without programming knowledge ( N = 61)   | With programming knowledge ( N = 40)   | With programming knowledge ( N = 40)   | Independent- samples t- test   | Independent- samples t- test   |
|------------------------------|-------------------------------------------|-------------------------------------------|----------------------------------------|----------------------------------------|--------------------------------|--------------------------------|
|                              | M                                         | SD                                        | M                                      | SD                                     |                                |                                |
|                              | 3.88                                      | 0.45                                      | 4.09                                   | 0.46                                   | 2.28*                          | t (99)                         |
| Post-survey (max. mark = 5)  | 4.01                                      | 0.38                                      | 4.18                                   | 0.52                                   | 2.02                           | t (65)                         |

*p &lt; .05; **p &lt; .01; ***p &lt; .001.

understanding  AI  concepts,  in  self-perceived  AI  literacy  and  in  AI empowerment. In addition, the course successfully reduced the gender gap regarding AI literacy and AI empowerment. Our tests showed that prior knowledge of programming was not a prerequisite for fostering AI literacy. The participants reported positive perceptions of the process and its outcomes in terms strengthening their AI literacy. The participants  also  considered  the  flipped  classroom  learning  approach  to  be appropriate for developing AI literacy.

These results have several important implications. First, this kind of basic course on AI can be successfully taught to university students of all genders and study backgrounds. The course helps to reduce the gender digital divide in the field of AI. The results of the study showed that the 7-h course can help both male and female participants to significantly improve their understanding of AI concepts and AI literacy. Indeed, the male and female participants showed no statistically significant differences in terms of their scores on the AI Concepts Test or the AI Literacy Test. Furthermore, the gender gap in self-perceived AI empowerment was reduced after the course. These successful results from the AI literacy  course  might  help  to  change  the  traditional  image  of  AI  as  a subject most suited for male participants. Our findings may be important in overcoming traditional beliefs regarding gender stereotypes (Makarova et al., 2019), increasing the motivation of female participants and broadening educational options for students of both genders (Thomas, 2017).

Second, this course helped eliminate the skill gaps among participants  with  different  educational  backgrounds.  As  the  study  results illustrated,  all  of  the  participants  significantly  improved  their  understanding of AI concepts due to the 7-h course. No significant differences were found in the participants ' performance on the AI Concepts Test or the AI Empowerment Test, regardless of whether they had computer science-related  backgrounds  or  other  educational  backgrounds.  In addition, the disparity in AI literacy between these groups of students

Fig.  9. Performance on the AI Empowerment Survey before and after the course by participants without prior programming knowledge and those with prior programming knowledge.

<!-- image -->

GLYPH&lt;0&gt;,

## Table 9

Key points that the participants made during the interviews about the use of a flipped classroom learning approach to teach AI literacy.

| Question themes                                                                                                      | Descriptions                                                                                                                                                                                                                              | Course participants ' responses                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|----------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Effect of using the flipped classroom learning approach Pedagogical value of the flipped classroom learning approach | Effectiveness in teaching concepts and developing understanding; Self-regulated learning involved; Self-autonomy of the participants and catering for learners ' diversity; More interaction involved; Habits of pre-learning cultivated; | It was effective when learning the basic concepts. It was effective because AI is a complex and fast- changing topic, and it is difficult to teach all the content in the limited class time (S13). Today, self-regulated learning is important. This flipped classroom learning approach facilitated self- regulated learning. I could control the pace of learning myself, which facilitated self-regulated study (S3). There was more autonomy for the participants, and this approach catered to the differences among learners (S6). It increased the interaction among participants (S12). It cultivated our habits of pre-learning (S10). |

was reduced after the course. We can therefore recommend that universities make such courses on AI literacy accessible to participants of all study backgrounds.

Admittedly, this study is subject to limitations. First, the sample only included participants from one university. Although participants from different majors and levels were involved in the study, this sample is not representative of participants from Hong Kong, much less of participants from other countries and regions. Future research could examine participants from more universities in Hong Kong and from other countries and regions, to investigate the effects of such a course on more representative samples. Second, concerning the reliability of the AI Concepts Test,  the  Cronbach ' s  alpha  reliability  coefficient  of  the  post-test  was 0.66. Some researchers have argued that the acceptable limit for alpha values should be between 0.6 and 0.7 (Hair et al., 2010), especially for newly developed instruments (Taber, 2018). Even so, efforts should be made to increase the reliability of the 14-item instrument used in the AI Concepts Test.

Concerning the improvement of samples and instruments for future studies,  the  encouraging  results  of  this  study  reveal  a  potential  for promoting this course to different groups of participants. To validate the success of the design and implementation of this AI literary course, the course  should  be  offered  to  members  of  the  public,  including  senior secondary school students and citizens from various walks of life who have  senior  secondary  school  education  backgrounds  or  above.  The course should also be extended to include classes on the application of AI technologies, which can prepare participants to better apply AI in their workplaces and at home. Such courses can enable a broader population of educated citizens to advance their own interests and use AI to better serve their communities.

## Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

## Acknowledgements

The authors would like to acknowledge the funding support of the ' Designing and Evaluating an Artificial Intelligence Literacy Programme for University and Secondary School Students ' project from the Li Ka Shing Foundation.

## References

- AI4kids. (2020). AI for everyone . Cup Magazine Publishing. Ali, S., Payne, B. H., Williams, R., Park, H. W., &amp; Breazeal, C. (2019). Constructionism, ethics, and creativity: Developing primary and middle school artificial intelligence education. In International workshop on education in artificial intelligence K-12 (EDUAI ' 19) (pp. 1 -4).
- Anderson, M., &amp; Anderson, S. L. (2006). Guest editors ' introduction: Machine ethics. IEEE Intelligent Systems, 21 (4), 10 -11. https://doi.org/10.1109/MIS.2006.70.

Anderson, L. W., &amp; Bloom, B. S. (2001). A taxonomy for learning, teaching, and assessing: A revision of Bloom ' s taxonomy of educational objectives . Longman.

- Bandura, A. (1982). Self-efficacy mechanism in human agency. American Psychologist, 37 (2), 122. https://doi.org/10.1037/0003-066X.37.2.122.
- Brendel, A. B., Mirbabaie, M., Lembcke, T. B., &amp; Hofeditz, L. (2021). Ethical management of artificial intelligence. Sustainability, 13 (4), 1 -18. https://doi.org/10.3390/ su13041974.
- Brennan, K., &amp; Resnick, M. (2012). New frameworks for studying and assessing the development of computational thinking. In A. F. Ball, &amp; C. A. Tyson (Eds.), Proceedings of the 2012 annual meeting of the American educational research association (pp. 1 -25). Vancouver: American Educational Research Association.
- Buckingham, D. (1993). Children talking television: The making of television literacy . Falmer Press.
- Bye, R. T. (2018). A flipped classroom approach for teaching a Master ' s course on artificial intelligence. In P. Escudeiro, G. Costagliola, S. Zvacek, J. Uhomoibhi, &amp; B. M. McLaren (Eds.), Computer supported education: CSEDU 2017 -revised selected best papers, communications in computer and information science (CCIS) (Vol. 865, pp. 246 -276). Springer International Publishing. https://doi.org/10.1007/978-3-31994640-5\_13.
- Chesani, F., Galassi, A., Mello, P., &amp; Trisolini, G. (2017). A game-based competition as instrument for teaching artificial intelligence. November. In Conference of the Italian association for artificial intelligence (pp. 72 -84). Cham: Springer.
- Emwanta, M. G., &amp; Nwalo, K. I. N. (2013). Influence of computer literacy and subject background on use of electronic resources by undergraduate students in universities in south-western Nigeria. International Journal of Library and Information Science, 5 (2), 29 -42.
- Ertl, B., Luttenberger, S., &amp; Paechter, M. (2017). The impact of gender stereotypes on the self-concept of female students in STEM subjects with an under-representation of females. Frontiers in Psychology, 8 , 1 -11. https://doi.org/10.3389/ fpsyg.2017.00703.
- Estevez, J., Garate, G., Guede, J. M., &amp; Grana, M. (2019). Using Scratch to teach undergraduate students ' skills on artificial intelligence . arXiv preprint arXiv: 1904.00296.
- Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P., Dignum, V., et al. (2018). AI4People -an ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. Minds and Machines, 28 (4), 689 -707.
- de Freitas, A. A., &amp; Weingart, T. B. (2021). I ' m going to learn what?!? Teaching artificial intelligence to freshmen in an introductory computer science course. March. In Proceedings of the 52nd ACM technical symposium on computer science education (pp. 198 -204). New York, United States.
- Frymier, A. B., Shulman, G. M., &amp; Houser, M. (1996). The development of a learner empowerment measure. Communication Education, 45 (3), 181 -199. https://doi.org/ 10.1080/03634529609379048.
- Hair, J. F., Back, W. C., Basin, B. J., &amp; Anderson, R. E. (2010). Multivariate data analysis (7th ed.). Prentice Hall.
- Hattwig, D., Bussert, K., Medaille, A., &amp; Burgess, J. (2013). Visual literacy standards in higher education: New opportunities for libraries and student learning. Portal: Libraries and the Academy, 13 (1), 61 -89.
- International Labour Organization. (2017). Breaking barriers: Unconscious gender bias in the workplace . International Labour Organization. https://www.ilo.org/actemp/publ ications/WCMS\_601276/lang-en/index.htm.
- Jeffrey, L., Hegarty, B., Kelly, O., Penman, M., Coburn, D., &amp; McDonald, J. (2011). Developing digital information literacy in higher education: Obstacles and supports. Journal of Information Technology Education: Research, 10 (1), 383 -413. http://www. learntechlib.org/p/111528/.
- Kong, S. C. (2008). A curriculum framework for implementing information technology in school education for fostering information literacy. Computers &amp; Education, 51 (1), 129 -141. https://doi.org/10.1016/j.compedu.2007.04.005.
- Kong, S. C. (2014). Developing information literacy and critical thinking skills through domain knowledge learning in digital classrooms: An experience of practicing flipped classroom strategy. Computers &amp; Education, 78 , 160 -173. https://doi.org/ 10.1016/j.compedu.2014.05.009.
- Kong, S. C. (2019). Components and methods of evaluating computational thinking for fostering creative problem-solvers in senior primary school education. In S. C. Kong, &amp; H. Abelson (Eds.), Computational thinking education (pp. 119 -141). SpringerOpen.
- Kong, S. C., Chiu, M. M., &amp; Lai, M. (2018). A study of primary school students ' interest, collaboration attitude, and programming empowerment in computational thinking

GLYPH&lt;0&gt;,

education. Computers &amp; Education, 127 , 178 -189. https://doi.org/10.1016/j. compedu.2018.08.026.

- Lee, I., Ali, S., Zhang, H., DiPaola, D., &amp; Breazeal, C. (2021). Developing middle school students ' AI literacy. March. In Proceedings of the 52nd ACM technical symposium on computer science education (pp. 191 -197). New York, United States.
- Legislative Council Commission. (2019). Study of development blueprints and growth drivers of artificial intelligence in selected places. Research Office of the Legislative Council of Hong Kong . https://www.legco.gov.hk/research-publications/english /1920in01-study-of-development-blueprints-and-growth-drivers-of-artificial-intelli gence-in-selected-places-20191023-e.pdf.
- Long, D., &amp; Magerko, B. (2020). What is AI literacy? Competencies and design considerations. April. In Proceedings of the 2020 CHI conference on human factors in computing systems (pp. 1 -16). Honolulu, USA https://dl.acm.org/doi/fullHtml/10.11 45/3313831.3376727.
- Makarova, E., Aeschlimann, B., &amp; Herzog, W. (2019). The gender gap in STEM fields: The impact of the gender stereotype of math and science on secondary students ' career aspirations. Frontiers in Education, 4 , 1 -11. https://doi.org/10.3389/ feduc.2019.00060.
- Makinen, M. (2006). Digital empowerment as a process for enhancing citizens ' participation. E-learning, 3 (3), 381 -395. https://doi.org/10.2304/ elea.2006.3.3.381.
- Martin, A. (2006). A European framework for digital literacy. Nordic Journal of Digital Literacy, 2 (1), 151 -161. https://www.idunn.no/file/pdf/33191479/a\_europe an\_framework\_for\_digital\_literacy.pdf.
- Ministry of Economic Affairs and Employment. (2017). Finland ' s age of artificial intelligence . Ministry of Economic Affairs and Employment.
- Mishra, A., &amp; Siy, H. (2020, October). An interdisciplinary approach for teaching artificial intelligence to computer science students. In Proceedings of the 21st annual conference on information technology education (p. 344). New York, United States.
- Organisation for Economic Co-operation and Development (OECD). (2018a). Bridging the digital gender divide: Include, upskill, innovate . OECD. http://www.oecd.org/digital/ bridging-the-digital-gender-divide.pdf.
- Organisation for Economic Co-operation and Development (OECD). (2018b). Future of education and skills 2030: Conceptual learning framework . OECD. https://www.oecd.or
- g/education/2030/Education-and-AI-preparing-for-the-future-AI-Attitudes-and-Va lues.pdf.
- Pan, Y. (2016). Heading toward artificial intelligence 2.0. Engineering, 2 (4), 409 -413. https://doi.org/10.1016/J.ENG.2016.04.018.
- Paulus, P. B., &amp; Brown, V. R. (2003). Enhancing ideational creativity in groups: Lessons from research on brainstorming. In P. B. Paulus, &amp; B. A. Nijstad (Eds.), Group creativity: Innovation through collaboration (pp. 110 -136). Oxford University Press.

https://doi.org/10.1093/acprof:oso/9780195147308.003.0006.

- Potter, W. J. (2018). Media literacy . Sage Publications.
- Pouly, M., Koller, T., &amp; Arnold, R. (2019). A game-centric approach to teaching artificial intelligence, 1. In CSEDU (pp. 398 -404).
- Resnick, M., Bruckman, A., &amp; Martin, F. (1996). Pianos not stereos: Creating computational construction kits. Interactions, 3 (5), 40 -50 (Crete, Greece). Sabouret, N. (2020). Understanding artificial intelligence . CRC Press LLC.
- Stone, P., Brooks, R., Brynjolfsson, E., Calo, R., Etzioni, O., Hager, G., &amp; Teller, A. (2016). Artificial intelligence and life in 2030 - one hundred year study on artificial intelligence: Report of the 2015-2016 study panel . Stanford University.
- Sullivan, B. M. (1988). A legacy for learners: The report of the Royal Commission on Education . Royal Commission on Education.
- Suskie, L. (2018). Assessing student learning: A common sense guide . John Wiley &amp; Sons. Taber, K. S. (2018). The use of Cronbach ' s alpha when developing and reporting research instruments in science education. Research in Science Education, 48 (6), 1273 -1296.
- Thomas, A. E. (2017). Gender differences in students ' physical science motivation: Are teachers ' implicit cognitions another piece of the puzzle? American Educational Research Journal, 54 , 35 -58. https://doi.org/10.3102/0002831216682223.
- Touretzky, D., Gardner-McCune, C., Martin, F., &amp; Seehorn, D. (2019). Envisioning AI for k-12: What should every child know about AI?. In Proceedings of the AAAI conference on artificial intelligence, 33(1), 9795 -9799, palo alto, California, USA . https://doi.org/ 10.1609/aaai.v33i01.33019795.
- Wang, W., &amp; Siau, K. (2019). Artificial intelligence, machine learning, automation, robotics, future of work and future of humanity: A review and research agenda. Journal of Database Management, 30 (1), 61 -79.

GLYPH&lt;0&gt;,