---
source_file: Mosene_2023_Feministische_Netzpolitik_und_Künstliche.pdf
conversion_date: 2026-02-03T18:42:10.211465
converter: docling
quality_score: 90
---

<!-- PAGE 1 -->
<!-- image -->

## UNSERE SCHWERPUNKTEDEBATTESERVICE

Politische Medienkompetenz / Debatte / KI und Intersektionalität

## KI UND INTERSEKTIONALITÄT

## FEMINISTISCHE NETZPOLITIK UND KÜNSTLICHE INTELLIGENZ IN DER POLITISCHEN BILDUNG

<!-- image -->

Bild: iStock / acilo

Netzpolitik Feminismus, Künstliche Intelligenz

<!-- image -->


<!-- PAGE 2 -->


Autor\_in:

<!-- image -->

## UNSERE SCHWERPUNKTEDEBATTESERVICE

## HINTERGRUND FÜR DIE POLITISCHE BILDUNGSARBEIT

feministische übt Kritik an bestehenden Ungleichheitsverhältnissen im digitalen Raum, der stets eng verschränkt ist mit der analogen Lebenswelt. Es gilt, tradierte Ausschlusssysteme sowie damit einhergehende diskriminierende Strukturen aufzudecken und durch neue progressive und gleichberechtigte Systeme zu ersetzen. Auch der Blick auf in digitalen Innovationen verborgene koloniale Strukturen und auf die in intelligente Systeme eingeschriebenen diskriminierenden Strukturen - die in diesem Artikel behandelt werden - bietet mannigfaltige, spannende und gut nachvollziehbare Möglichkeiten, sich dem Thema anzunähern. Intersektionale  Netzpolitik 

Zudem rückt gerade das Thema tradierter Rassismen, die grundlegender Teil einer intersektionalen feministischen Kritik sind, zunehmend in den Mittelpunkt der politischen Debatte. Es scheint, als gebe es als Reaktion auf die #blacklivesmatter-Demonstrationen ein Umdenken bei Technologiekonzernen, was das Thema Gesichtserkennung im Rahmen der Strafverfolgung (Stichwort: ) angeht[1] - Google will überdies rassistische Begriffe aus seinem Code streichen.[2] Auch hier bieten sich vielfältige, spannende Ansatzpunkte für die politische Bildungsarbeit. Racial Profiling 

## FEMINISTISCHE NETZPOLITIK UND INNOVATIONEN

Unsere Alltagsbegleiter heißen heute Siri und Alexa: eine Frau in der Hosentasche oder im Haushalt, die uns stets gefügig zur Seite steht.


<!-- PAGE 3 -->


Sprachassistenten sind uns als Künstliche Intelligenzen bekannt; doch die meisten hinterfragen nicht, warum es gerade weibliche Stimmen sind, die

##  MENÜ

uns durch den Alltag navigieren sollen. Dahinter verbergen sich

<!-- image -->

## stereotype weibliche Rollenvorstellungen: die Frau als Sekretärin, UNSERE SCHWERPUNKTEDEBATTESERVICE

Hausfrau und Mutter. Ob eine öffentliche Einrichtung so gebaut wird, dass Rollstuhlfahrer\_innen sie problemlos betreten können, oder ob digitale Infrastruktur barrierefrei gestaltet wird - all das sind normative Entscheidungen. Kranzbergs 'First Law of Technology' aus den 1980er Jahren hat deswegen heute wie damals gleichermaßen Bedeutung: 'Technology is neither good nor is it bad, nor is it neutral.'[3]

## INTERSEKTIONALE PERSPEKTIVEN FEMINISTISCHER NETZPOLITIK

Technik und Geschlecht stehen seit jeher in einem Wechselverhältnis: Technik kann bestehende Rollen festschreiben, aber ebenso Räume bieten, aus diesen auszubrechen. Das potenzielle Aufbrechen von Geschlechterzuschreibungen hat Donna Haraway schon 1985 in ihrem 'Cyborg Manifesto'[4] beschrieben. Dennoch lässt sich fragen: Bricht das Internet hegemoniale[5] Grenzen tatsächlich auf oder verstärkt es diese nicht zusätzlich, normiert geradezu tradierte Systeme?

Denn auch wenn es oberflächlich so aussieht, als erlaube uns die Digitalisierung zunehmend, unsere sozialen Rollen zu de- und neu zu konstruieren, lässt eine intersektionale feministische Perspektive daran zweifeln. Intersektionale Perspektiven nehmen ineinandergreifende, sich teils verstärkende Strukturen von Ungleichheit, Macht und Herrschaft in den Blick, und ein besonderer Fokus liegt dabei auf der wechselseitigen Konstitution von Rassismus und Sexismus in ihren gesellschaftsstrukturierenden Formen. Es geht also klassisch um das Sichtbarmachen und Anerkennen von mehrfach diskriminierten Gruppen. Als (Ausschluss-)Kategorien gelten race, class und gender, die in


<!-- PAGE 4 -->


Personen und Gruppen nicht selten als Mehrfachidentitäten zusammenfallen und in der Addition strukturelle

Diskriminierungserfahrungen noch potenzieren (oft zusätzlich erweitert

<!-- image -->

## um Antisemitismus, Homo- und Transfeindlichkeit oder Ableismus).[6] UNSERE SCHWERPUNKTEDEBATTESERVICE

'Nehmen wir als Beispiel eine Straßenkreuzung, an der der Verkehr aus allen vier Richtungen kommt. Wie dieser Verkehr kann auch Diskriminierung in mehreren Richtungen verlaufen. Wenn es an einer Kreuzung zu einem Unfall kommt, kann dieser von Verkehr aus jeder Richtung verursacht worden sein - manchmal gar von Verkehr aus allen Richtungen gleichzeitig. Ähnliches gilt für eine schwarze Frau, die an einer ,Kreuzung' verletzt wird; die Ursache könnte sowohl sexistische als auch rassistische Diskriminierung sein.'[7]

## KÜNSTLICHE INTELLIGENZ: DISKRIMINIERUNG DURCH CODE UND KAPITAL

Digitale Assistenzsysteme, Smart-Home-Anwendungen und automatisierte Entscheidungssysteme basieren häufig auf Algorithmen der künstlichen Intelligenz. Wenn von Künstlicher Intelligenz (KI) gesprochen wird, ist meistens maschinelles Lernen (machine learning) gemeint; hierbei geht es um das 'Lernen' von Mustern aus vorgegebenen Datensamples, die auf neue, unbekannte Daten angewendet werden.

Beispielsweise kann ein Algorithmus des maschinellen Lernens aus den als 'Spam' markierten E-Mails Muster zu erkennen lernen, um beim


<!-- PAGE 5 -->


nächsten Mal Spam-Mails direkt in den dazu passenden Ordner einzuordnen. Oder er kann 'lernen', zwischen Hunden- und Katzenfotos

##  MENÜ

zu unterscheiden. Auch hier erlernt der Algorithmus Muster - und zwar in

<!-- image -->

## der Pixelanordnung -, die er dann auf alle weiteren Tierfotos anwendet. UNSERE SCHWERPUNKTEDEBATTESERVICE

Künstliche Intelligenzen denken also nicht wie Menschen. Sie erkennen Hunde und Katzen nicht einfach, sondern lernen, dass beispielsweise Hundefotos statistisch häufiger mit einem Copyrightzeichen versehen sind als Katzenfotos.

Künstliche Intelligenz, das wird hier deutlich, ist damit stark von Trainingsdaten abhängig. Sie erkennt weniger einen Sinn als vielmehr eine Korrelation.

Algorithmen des maschinellen Lernens werden in unterschiedlichen Bereichen eingesetzt: Sie sortieren Googles Web- und Bildersuche, den Facebook-Newsfeed, das, was uns Amazon als Nächstes anzeigt. Sie werden aber auch außerhalb des 'Consumer-Bereichs' für staatliche Entscheidungen eingesetzt: z. B. in Österreich mit dem (derzeit pausierten) Arbeitsmarkt-Chancen-Modell, um darüber zu entscheiden, welche Person welche Sozialleistungen erhalten sollte[8]. In Deutschland wird an personenbezogenem Predictive Policing gearbeitet[9], um Straftaten vorherzusagen; und das BAMF verwendet ein SprachanalyseTool, das postuliert, durch die Analyse eines 'Dialektes' einer Person die Staatsangehörigkeit zuordnen zu können[10]. Am Fernbahnhof Berlin Südkreuz wurden von der Bundespolizei überdies Gesichtserkennungsprogramme für eine mögliche Verbrechensbekämpfung getestet, die vielfach kritisiert wurden - an den europäischen Außengrenzen werden diese trotzdem längst eingesetzt. [11]

Im Komplex Künstliche Intelligenz ist aber schon länger klar, dass diskriminierende Stereotype sich im Code manifestieren,[12] also mit in


<!-- PAGE 6 -->


den Bausatz von innovativen Technologien eingeschrieben werden. Es ist hinlänglich bekannt, dass biometrische Gesichtserkennung, die

##  MENÜ

vorwiegend in einem männlich dominierten Raum im weißen globalen

<!-- image -->

## Norden entwickelt wird, lange nicht in der Lage war, Schwarze Menschen UNSERE SCHWERPUNKTEDEBATTESERVICE

und People of Colour zu identifizieren, da sie sich überwiegend auf Trainingsdatensätze weißer Personen stützte. Noch Ende letzten Jahres hat das National Institute of Standards and Technology darauf hingewiesen, dass People of Colour überdurchschnittlich häufig falsch zugeordnet werden, also z. B. im Rahmen der Strafverfolgung oftmals fälschlicherweise für eine gesuchte Person auf einem Bild gehalten werden.[13]

'Machtstrukturen sind schon in der technischen Infrastruktur fest angelegt. Sie führen die Geschichte des Kolonialismus auch in der virtuellen Sphäre fort: in Gestalt des ,digitalen' oder ,elektronischen Kolonialismus'.'[14]

Gebündelt als Big Data werden tradierte Ausschlusssysteme so implizit in den Code übersetzt. Ähnlich verhält es sich mit KI-Trainingsdatensätzen für autonome Fahrzeuge, die Trainingsdaten von nicht-normierten Körpern, etwa von Rollstuhlfahrer\_innen, nicht berücksichtigen.[15]


<!-- PAGE 7 -->


O-Ton Nushin Yazdani - AI Researcherin &amp; Chris Köver -

Mitbegründerin des Missy Magazine und Journalistin bei

Netzpolitik.org

<!-- image -->

## UNSERE SCHWERPUNKTEDEBATTESERVICE

Hinzu kommen die Warenkreisläufe, die entlang der alten kolonialen Hierarchien verlaufen; die Rohstoffe des Südens, teils unter menschenunwürdigen Bedingungen gewonnen, gelangen für die TechIndustrie billig in den Norden. Politik und Konzerne sind nicht selten stark vernetzt; fast monopolisiert erscheint das Internet durch die großen proprietären Player aus Silicon Valley, die selbstverständlich ihre ganz eigenen Interessen mit ihren Technologien auch in den globalen Süden tragen, statt lokale Initiativen, ausgerichtet nach lokalen Bedarfen, zu stärken.

'Die Routen (der Glasfaserkabel) folgen denen der Telegraphenkabel, die wiederum den Routen der Sklavenschiffe folgen. Die digitale Kommunikation der Gegenwart folgt den Kartierungen kolonialer Geografien. Obwohl das Internet als Raum der sozialen Mobilität vermarktet wird, verläuft es entlang historischer und politischer Linien, die Ungleichheiten in seine DNA einbringen.'[16]

## EMANZIPATIONSPERSPEKTIVEN

Auch in diesem Kontext aber formen sich Bewegungen und Allianzen, die den oben beschriebenen Entwicklungen entgegenwirken: Caroline

##  MENÜ


<!-- PAGE 8 -->


Sinders beschreibt mit ihrem 'Feminist Data Set'[17] die Utopie eines non-biased[18] Internet auf der Grundlage feministischer Datensätze.

Feministische Netzpolitik besteht deshalb auch darin, KI-Forscher\_innen

<!-- image -->

## und Aktivist\_innen zu unterstützen, die im Techniksektor die UNSERE SCHWERPUNKTEDEBATTESERVICE

Bias



sowohl auf der Produzent\_innen- als auch auf der Outcome-Seite aufzuheben suchen. Dazu kann auch politische Bildung beitragen; es ist deshalb nicht nur wichtig, den Nutzer\_innen von Technologien zu vermitteln, wie diese funktionieren, sondern vor allem wie sie entstanden sind, welche gesellschaftlichen Ideen und Realitäten sie widerspiegeln, welche soziopolitischen Potenziale sich in ihnen verbergen, aber auch, wo die Fallstricke liegen und es einen starken kritischen Diskurs braucht.

## NEUGIERIG AUF MEHR?

Weiterführende Literaturhinweise zu diesem Thema finden Sie im Service-Bereich.

- LITERATURLISTE ÖFFNEN 

## QUELLEN

[1] Mehr dazu bei . Gierlinger, Marisa: Warum Tech-Konzerne der Gesic htserkennung abschören, in: sueddeutsche.de, 12.06.2020 [eingesehen a m 16.10.2020] 


<!-- PAGE 9 -->


[2] Siehe auch

Gierlinger, Marisa: Wenn die Blacklist zur Blocklist wird,



in: sueddeutsche.de, 18.06.2020 [eingesehen am 16.10.2020]

.

##  MENÜ

<!-- image -->

## [3] Melvin Kranzberg war ein US-amerikanischer Technikhistoriker. UNSERE SCHWERPUNKTEDEBATTESERVICE

Bekannt ist Kranzberg neben seiner Arbeit als Wissenschaftler für seine Technologiegesetze, die einerseits einen ernsthaften wissenschaftlichen Kern besitzen, andererseits jedoch auch mit einem gewissen

Augenzwinkern verstanden werden müssen. Vgl. Kranzberg, Melvin: T echnology and History: Kranzberg's Laws', in: Technology and Culture, Jg. 27 (1986), H. 3, S. 544-560 [eingesehen am 27.10.2020]. 

- [4] . Haraway, Donna: Manifesto for Cyborgs: Science, Technology, and Socialist Feminism in the 1980's, in: Socialist Review, Jg. 80 (1985), S. 65 -108 [PDF, eingesehen am 27.10.2020] 
- [5] Hegemonie = die zugerechnete oder eingenommene Führungsrolle einer gesellschaftlichen Institution.
- [6] Mehr zum Thema Intersektionalität [eingesehen am 16.10.2020]. 
- [7] Crenshaw, Kimberlé: Demarginalizing the Intersection of Race and Sex: A Black Feminist Critique of Antidiscrimination Doctrine, in: University of Chicago Legal Forum, H. 1/1989, S. 149
- [8] Die österreichische Datenschutzbehörde stoppte das Projekt im August 2020 und fordert eine gesetzliche Grundlage; . mehr dazu lesen [eingesehen am 27.10.2020] 
- [9] Zum Beispiel im Projekt hessenData, . mehr Informationen dazu [ein gesehen am 27.10.2020] 
- [10] . Mehr Informationen zur Dialektanalyse [eingesehen am 27.10.202 0] 


<!-- PAGE 10 -->


[11] Mehr Informationen über den Einsatz von Gesichtserkennung



nem Beitrag über eine Erprobung am Bahnhof BErlin-Südkreuz

<!-- image -->



und in

[eingesehen am einem Beitrag über das 'EasyPASS'-System

## 27.10.2020]. Die Europäische Kommission entwickelt darüber hinaus ein UNSERE SCHWERPUNKTEDEBATTESERVICE

Verfahren zur Identifikation von Personen anhand ihres gesprochenen Wortes. . Die Plattform 'Roxanne' soll große Datenmengen verarbeiten und kombiniert dafür Audiodateien mit anderen Informationen, die Person en hinterlassen [abgerufen am 27.10.2020] 

[12] Vgl. z.B. . Shepard, Nicole: Was hat Überwachung mit Sex und Gen der zu tun?, in: Denknetz. Jahrbuch 2017 - Technisierte Gesellschaft, Züric h, 2017, S. 108-116 [PDF, eingesehen am 16.10.2020] 

[13] Siehe dazu ; dort findet sich auch die o.g. Studie. o.V.: NIST Study Evaluates Effects of Race, Age, Sex o n Face Recognition Software, 2019 [eingesehen am 16.10.2020] 

[14] . Holev, Ina: 2020: Digitaler Kolonialismus [eingesehen am 16.10.2 020] 

[15] Nachzulesen bei . Shephard, Nicole: 5 reasons why surveillance is a feminist issue, 02.06.2016 [eingesehen am 16.10.2020] 

[16] . Köppert, Katrin: 'Internet is not in the Cloud.' Digitaler Kolonialism us, 10.04.2019 [eingesehen am 16.10.2020] 

[17] Mehr zum Feminist Dataset [eingesehen am 27.10.2020]. 

<!-- image -->


<!-- PAGE 11 -->


<!-- image -->

##  MENÜ

## UNSERE SCHWERPUNKTEDEBATTESERVICE

KONTAKT

Niedersächsische Landeszentrale für politische Bildung Georgsplatz 18/19

30159 Hannover

0511 120 - 7500 

## SEITENINFO

Sitemap

Suche

Impressum

Erklärung zur Barrierefreiheit

Datenschutz

Lizenzhinweise