---
source_file: Engelhardt_2025_Voll_(dia)logisch_Ein_Werkstattbericht_über_den.pdf
conversion_date: 2026-02-03T08:54:53.791625
converter: docling
quality_score: 95
---

<!-- image -->

## Engelhardt, Emily; Ley, Thomas

Wunder,  Maik  [Hrsg.];  Giercke-Ungermann,  Annett  [Hrsg.]:  Digitalisierung  in  der  Hochschulbildung  für Soziale Arbeit. Bad Heilbrunn : Verlag Julius Klinkhardt 2025, S. 251-264

<!-- image -->

Voll (dia)logisch? Ein Werkstattbericht über den Einsatz von generativer KI in der Hochschulbildung für Soziale Arbeit. Curriculare Überlegungen und veränderte Akteurskonstellationen

<!-- image -->

## Quellenangabe/ Reference:

Engelhardt, Emily; Ley, Thomas: Voll (dia)logisch? Ein Werkstattbericht über den Einsatz von generativer KI in der Hochschulbildung für Soziale Arbeit. Curriculare Überlegungen und veränderte Akteurskonstellationen - In: Wunder, Maik [Hrsg.]; Giercke-Ungermann, Annett [Hrsg.]: Digitalisierung in der Hochschulbildung für Soziale Arbeit. Bad Heilbrunn : Verlag Julius Klinkhardt 2025, S. 251-264 URN: urn:nbn:de:0111-pedocs-331330 - DOI: 10.25656/01:33133; 10.35468/6166-16

https://nbn-resolving.org/urn:nbn:de:0111-pedocs-331330 https://doi.org/10.25656/01:33133

in Kooperation mit / in cooperation with:

<!-- image -->

http://www.klinkhardt.de

## Nutzungsbedingungen

## Terms of use

Dieses Dokument steht unter folgender Creative Commons-Lizenz: http://creativecommons.org/licenses/by/4.0/deed.de  -  Sie  dürfen  das  Werk bzw.  den  Inhalt  vervielfältigen,  verbreiten  und  öffentlich  zugänglich  machen sowie Abwandlungen und Bearbeitungen des Werkes bzw. Inhaltes anfertigen, solange Sie den Namen des Autors/Rechteinhabers in der von ihm festgelegten Weise nennen.

This  document  is  published  under  following  Creative  Commons-License: http://creativecommons.org/licenses/by/4.0/deed.en - You may copy, distribute and  render  this  document  accessible,  make  adaptations  of  this  work  or  its contents  accessible  to  the  public  as  long  as  you  attribute  the  work  in  the manner specified by the author or licensor.

Mit der Verwendung dieses Dokuments erkennen Sie die Nutzungsbedingungen an.

By using this particular document, you accept the above-stated conditions of use.

<!-- image -->

## Kontakt / Contact:

## peDOCS

DIPF | Leibniz-Institut für Bildungsforschung und Bildungsinformation Informationszentrum (IZ) Bildung

Internet: www.pedocs.de

<!-- image -->

## Emily Engelhardt und Thomas Ley

Voll (dia)logisch? Ein Werkstattbericht über den Einsatz von generativer KI in der Hochschulbildung für Soziale Arbeit. Curriculare Überlegungen und veränderte Akteurskonstellationen

Der vorliegende Artikel beleuchtet den Einsatz generativer KI in der Hochschulbildung für Soziale Arbeit und diskutiert damit verbundene curriculare Überlegungen sowie die veränderten Rollen von Lehrenden und Lernenden. Hierzu werden drei verschiedene  Anwendungsszenarien  vorgestellt:  akademische  Schreibassistenz,  methodischer Übungspartner und Chatbots als Produktivumgebung. Der Werkstattbericht betont die Potenziale generativer KI zur Bereicherung und Diversifizierung von Lehr-/Lernprozessen, zeigt jedoch auch mögliche Schwierigkeiten beim Einsatz von KI auf. Zudem wird auf die Notwendigkeit einer ausgewogenen Nutzung hingewiesen, die die akademische Redlichkeit sicherstellt und die kritische Denk- und Analysefähigkeit fördert. Der Beitrag zielt darauf ab, über eine verkürzte Chancen-Risiken-Diskussion hinauszugehen und die transformative Rolle von KI in der Hochschulbildung zu beleuchten.

## 1  Einleitung

Die rasante Entwicklung von Künstlicher Intelligenz (KI) hat weitreichende Auswirkungen auf zahlreiche Wissenschafts- und Praxisfelder. Der vorliegende Aufsatz beleuchtet mögliche Einsatzszenarien generativer KI in der Hochschulbildung Sozialer Arbeit und stellt einige curriculare Überlegungen dar; er versteht sich als Werkstattbericht. Nicht nur, weil sich die technischen Entwicklungen förmlich überschlagen, sondern weil auch wir als lernende Lehrende - mit Blick auf die eigene wie auch die didaktische Nutzung - im Modus des Ausprobierens sind. Im November 2022 wurde das Large-Language-Modell (LLM) GPT-3.5 des amerikanischen Konzerns OpenAI veröffentlicht. Innerhalb weniger Monate fand die Anwendung ChatGPT weite Verbreitung, sowohl unter Hochschulmitarbeiter:innen (Hochschulforum Digitalisierung 2023) als auch unter Studierenden (v. Garrel u. a. 2023, für die Soziale Arbeit: Witter u. a. 2024). Durch die öffentlichkeitswirksa-

me Verbreitung von ChatGPT 1 drängte sich auch das Thema KI im Studium der Sozialen Arbeit auf eigentümliche Art und Weise auf. So scheinen sich zwei Pole rund  um  das  Thema  aufzustellen:  Auf  der  einen  Seite  bestehen  Bedenken,  dass Studierende Tools wie ChatGPT zur Erstellung wissenschaftlicher Arbeiten nutzen könnten und somit das Kerngeschäft der Hochschule unterminieren. Dies wirft die Frage nach der Zukunft der wissenschaftlichen Hausarbeit sowie anderer schriftlicher Prüfungsformen auf und führte etwa an der Wirtschaftsuniversität Prag schon zur Abschaffung schriftlicher Bachelor-Arbeiten (vgl. Bager 2023). Die Nutzung einer  KI,  die  komplexe  Schriftstücke  erzeugen  kann,  führt  zu  einer  zunehmend verschwommenen Trennlinie  zwischen  der  studentischen  Eigenleistung  und  der technologisch unterstützten Produktion. Auf der anderen Seite sehen Lehrende das Potenzial von KI-Tools wie ChatGPT als Ergänzung im Lehr-/Lernprozess und der Eröffnung neuer Lehr-/Lern- Arrangements und Ansätzen forschenden Lernens. Sinnvoll eingesetzt können die Technologien die Auseinandersetzung mit wissenschaftlichen Inhalten vertiefen. Die zentrale Herausforderung liegt in der ausgewogenen Anwendung, die die Vorteile der Technik zu nutzen vermag und gleichzeitig die akademische Redlichkeit sicherstellt. Es gilt die Förderung einer eigenständigen kritischen  Denk-  und  Analysefähigkeit  der  Studierenden  in  den  Mittelpunkt  zu stellen und eine zukunftsorientierte Hochschuldbildung zu ermöglichen.

Der vorliegende Beitrag zielt  darauf  ab,  über  den  verkürzten  Chancen-Risiken Diskurs hinauszugehen und mögliche Einsatzszenarien von generativer KI zu diskutieren. Die aktuellen - auch kapitalistisch geprägten - Entwicklungen scheinen unumkehrbar und es ist ratsam, sich diesen auch im Sinne einer kritisch-progressiven, aber nicht affirmativen, Sozialen Arbeit zu widmen. Der Fokus liegt auf den veränderten Akteurskonstellationen in der Hochschulbildung, den neuen Rollen von Lehrenden und Lernenden und den damit verbundenen Lernprozessen sowie der Formierung neuer Aufgaben und Kompetenzen in Studium und Gesellschaft. Zunächst werden die Potenziale und Herausforderungen generativer KI-Systeme im Studium skizziert. Anschließend wird erörtert, welche Rollen generative KI im Studium der Sozialen Arbeit einnehmen kann - etwa als unterstützende Rechenmaschine, dialogische Informationsquelle, akademische Schreibassistenz, methodischem Übungspartner oder Produktivumgebung forschenden Lernens. In einem nächsten Schritt wird verdeutlicht das KI-Tools nicht nur als Werkzeug verstanden werden sollten, sondern sich in ihrer transformativen Funktion als kooperative Agenten bzw. nicht-menschliche Akteure in die Hochschulbildung einschreiben. Darauf folgt eine Diskussion über Prompting, betrachtet als metakognitiver Prozess

1  Aufgrund seiner starken Verbreitung wird in diesem Artikel der Fokus auf ChatGPT gelegt. 2023 entwickelte  zudem  die  HAWK  ein  webbasiertes,  frei  zugängliches  Interface  zur  Nutzung  von ChatGPT, das auch von anderen Hochschulen genutzt werden kann. Eine erste Übersicht unterschiedlicher KI Tools Schreiben bietet das virtuelle Kompetenzzentrum - Schreiben lehren und lernen mit Künstlicher Intelligenz: https://www.vkkiwa.de/ki-ressourcen/.

und grundlegende Fähigkeit, die im Studium entwickelt werden kann. Den Abschluss bildet eine Reflexion über die sich verändernden Rollen von Lehrenden und Lernenden sowie curricularen Konsequenzen für das Studium der Sozialen Arbeit in einer zunehmend digitalisierten und KI-unterstützten Bildungsumgebung.

## 2  Potenziale und Herausforderungen von generativer KI im Studium

Generative KI-Technologien besitzen das Potenzial, Lehr-/Lernprozesse zu bereichern und zu diversifizieren. Ihre Integration in das Hochschulstudium erfordert daher  eine  sorgfältige  Abwägung.  Der  Einsatz  von  KI-Technologien  kann  den Zugang der Lernenden zu Informationen erleichtern und hegt damit auch den Anspruch das Lernen zu personalisieren. Gleichzeitig stellen sich jedoch auch diverse  kritische  Fragen,  die  im  Rahmen  des  hochschulischen  Einsatzes  thematisiert werden müssen. Die Qualität des Lernsystems, der (ethische) Umgang mit KI-generierten Daten bzw. Daten, die der KI zur Verfügung gestellt werden und nicht zuletzt Fragen digitaler Teilhabe müssen hinterfragt werden. So benötigen Lernende neben dem Zugang zu den Systemen, den bislang nur wenige deutsche Hochschulen ihren Studierenden und Mitarbeitenden zur Verfügung stellen, auch die Möglichkeit Anwendungskompetenzen zu erwerben (SWK 2023). Darüber hinaus wären fachwissenschaftliche Fragen zur Nutzung von KI in der beruflichen Sozialen Arbeit ein gesondertes Thema (siehe etwa Steiner &amp; Tschopp 2022; Linnemann u. a. 2023).

Es würde den Rahmen dieses Artikels sprengen, in die Grundlagen der generativen KI einzuführen 2 , dennoch mag hier zumindest eine kursorische Einordnung hilfreich sein: ChatGPT ist eine generative KI, die auf der Architektur von großen Sprachmodellen ( Large Language Modells, kurz LLM) basiert. Diese Modelle werden mit enormen Mengen an Textdaten trainiert, um Muster und Zusammenhänge in der Sprache zu erkennen. LLM funktionieren, indem sie natürliche Sprache in kleine Einheiten, sogenannte Tokens, zerlegen. Jedes Token kann ein Wort, eine Silbe, ein Satzzeichen oder ein Teil davon darstellen. Auf der Basis des Gelernten trifft ChatGPT Vorhersagen und generiert passende Texte, indem es das wahrscheinlichste nächste Token wählt. So entstehen kohärente und sprachlich  saubere  Antworten  auf  verschiedenartigste  Anfragen,  die  die  Nutzer:innen eingeben (sog. prompts ).  ChatGPT ist also entwickelt worden, um einen menschenähnlichen Dialog zu erschaffen und simuliert folglich eine formelle Sprachkompetenz, die jedoch nicht mit Sinnverstehen gleichzusetzen ist. Es besitzt keine echten Verständnisfähigkeiten, liefert daher nicht immer korrekte Antworten (sog.

2 Neben vielen anderen bietet der KI Campus des Stifterverbandes für die Deutsche Wissenschaft hier einige Einführungskurse: https://www.ki-campus.org/.

Halluzinieren ) und bildet aus der Datenbasis Kategorien und Abstraktionen, die häufig als sehr schlüssig wahrgenommen werden. Die Auswahl der Trainingsdaten kann zu einer systematischen Verzerrung und der Reproduktion von Vorurteilen (sog. bias ) führen. Allein die rapide Veröffentlichung von neuen Versionen von ChatGPT (dieser Artikel entstand in der Zeit, in der die Version GPT-4o verfügbar war), deutet daraufhin das hier erhebliches Entwicklungspotenzial ist, welches wiederum auch Konsequenzen für die untenstehenden Szenarien haben wird.

## 3  Prompting zwischen metakognitivem Prozess und grundlegender Fähigkeit

Mit jeder neuen technologischen Innovation steht auch immer wieder die Frage im Raum, ob das Erlernen einer neuen Kulturtechnik erfolgen müsste - was aktuell unter der Chiffre Prompting-Kompetenz diskutiert wird. Dies soll und kann hier nicht diskutiert werden und doch wird deutlich, dass das Prompting in der Generativen KI gelernt sein will und es auch im Studium darum geht, eine Informations- und Datenkompetenz zu erwerben und anwenden zu können.

Prompting-Kompetenz kann man demnach als eine metakognitive Fähigkeit beschreiben, die sich auf die effektive Formulierung von Fragen und Anweisungen bezieht,  um  spezifische,  informative  und  relevante  Antworten  oder  Ergebnisse zu generieren. Die Lernenden müssen also über die Fähigkeit zur Steuerung der eigenen Recherche- und Arbeitsprozesse und damit eine selbst- und medienreflexive Kompetenz entwickeln. Neben der Fähigkeit sich selbst beim Nachdenken zuzuschauen, geht es dann aber auch darum, entsprechende prompts zu verschriftlichen und ggf. zu modfizieren. Hierbei können unterschiedliche Strategien ausprobiert  werden.  Larsen  und  Weßels  (2022)  beschreiben  beispielsweise  das Chain-of-Thought (CoT)-Prompting als nützliche Vorgehensweise, denn 'durch das CoT-Prompting finden wir vermeintlich den Weg in die Gedankenwelt (sic!) der KI, indem sie uns ihre gedanklichen Schritte zur Lösung einer Aufgabe der Reihe nach offenbart.' (ebd. o. S.)

In der Interaktion zwischen Menschen und KI ist die menschliche Denkleistung für die Initiierung und Steuerung des Prozesses weiterhin unerlässlich. Die Übersetzung der eigenen Denkprozesse in entsprechende prompts bildet die Brücke zur KI, während der Output von ChatGPT die menschlichen Überlegungen ergänzen oder auch irritieren kann.

Bei der Nutzung von Suchmaschinen musste auch zunächst gelernt werden, dass die Ergebnisse, die etwa bei Google auf der ersten Seite ganz oben stehen, nicht immer die besten und vor allem nicht zwingend die wissenschaftlich relevantesten sind, sondern dass die Anordnung aufgrund von Algorithmen und kommerziellen Inter-

essen sowie Werbestrategien beeinflusst wird. 3 Bei der Nutzung von ChatGPT muss den Nutzer:innen bewusst sein, dass die KI über kein menschliches Verständnis und Sinnverstehen verfügt, auch wenn sie mit den Nutzer:innen in einen menschenähnlichen Dialog eintritt. Gerade durch diesen Dialog entstehen häufig Anthropomorphisierungen, innerhalb derer der KI menschliche Eigenschaften, Emotionen oder Absichten zugeschrieben werden. Dies kann unter anderem dazu führen, dass die Antworten von ChatGPT als Ausdruck menschlicher Intelligenz, Empathie oder Verständnis missinterpretiert und unreflektiert übernommen werden.

## 4  Vom Werkzeug zum kooperativen Agenten KI als neuer Akteur in der Hochschulbildung?

In  gegenwärtigen  Debatten  wird  ChatGPT  nicht  nur  als  avancierte  Technik, sondern auch als ein umfassendes Werkzeug beschrieben und eingeordnet. Um im Bild des Werkzeuges zu bleiben: Es gleicht einem Schweizer Messer - einem Multitool für unterschiedliche Anwendungsszenarien, das an unterschiedlichen Orten diverse Handlungsanforderungen zu erfüllen vermag. Diese Einschätzung eines Werkzeuges mag auf einer individuellen (Handlungs-)Ebene durchaus richtig  sein,  verkennt  aber  die  interaktionistische  und  gesellschaftliche  Einbettung dieser umfassenden Technologie. Gerade mit Perspektive der Wissenschafts- und Technikforschung (Rammert 2007) möchten wir die reduktionistische Perspektive auf ein ,Werkzeug' kritisieren und vor allem die Handlungsträgerschaft dieser Technik verdeutlichen (ebd., 91ff.). Der verengte Blick auf KI offenbart demnach eine verdinglichende Perspektive, die Technik im Wesentlichen als Maschinen also Sachtechnik - betrachtet und demnach das Schweizer Messer nur mit Blick auf  seine  Situationsangemessenheit  bewertet. 4 Generative  KI  ist  aber  mehr  als nur  ein  Arbeitsmittel.  Es  ist  eine  komplexe informationstechnische  Infrastruktur (Ley &amp; Seelmeyer 2020) , ein symbolischer Träger von (westlichen) Wissensstrukturen und ein spezifischer Motor für technisch-soziale Innovationen. Es bringt durch neue technische Funktionen nicht nur andersartige Kommunikationsfor-

3  Es ist davon auszugehen, dass sich die klassische Suchmaschinennutzung stark verändern wird. Mit Microsoft Copilot wurde bereits der Anfang gemacht: Statt der Eingabe eines Suchbegriffs, sind die Nutzer:innen dazu angehalten eine Frage zu stellen, auf die der Textbot dann eine Antwort ausgibt und auf weiterführende Ressourcen (Weblinks) verweist. Gleichzeitig lädt Copilot zu einem Dialog ein, der entweder durch das Eingeben einer weiteren selbst geschriebenen Frage fortgeführt werden kann oder durch die Auswahl einer von Copilot vorgegebenen Fragestellung durch einen Klick initiiert werden kann.

4  Dies  zeigt  sich  auch  am  üblichen  -  und  verengten  -  Chancen/Risiken  Diskurs  in  der  Sozialen Arbeit. Dabei verbleibt der Mehrwert der digitalen Medien häufig diffus. Er fußt auf einem unreflektierten Verständnis von Medienintegration, reduziert IT in naiver Weise auf bloße Werkzeuge und Arbeitsmittel, verstärkt deterministische Perspektiven und ist fest in der analogen (verbalen) Kultur verhaftet.

men hervor, sondern stellt in pragmatistischer Diktion ein bewusst geschaffenes und soziales (!) Arrangement dar.

ChatGPT kann in diesem Sinne eben auch als ein nicht-menschlicher Akteur (Agent) verstanden werden, der auf Aufforderungen reagiert, sich auf vergangene Konversationsstränge bezieht, auf Konfrontationen in eigentümlicher Weise reagiert und ,eigene' Perspektiven in den Diskurs mit einbringt. Dies zeigt sich zum einen in diversen Zuschreibungen von menschlichen Qualitäten (Anthropomorphisierungen: 'Er [sic!] hat mir ganz freundlich gesagt, dass…'), der Anerkennung von Leistungen ('Darauf wäre ich jetzt so schnell nicht gekommen') und der Annahme einer gleichwertigen (wenn auch nicht gleichberechtigen) Rolle des Akteurs ChatGPT in sozialen Situationen ('Ich habe mal ChatGPT gefragt…'). Diese beschreibt zum einen die ,Sozialität der Technik' und zum anderen aber auch wie sich Handeln auf technisches Wirken und menschliches Verhalten verteilt, in dem wir der KI den Status als pro-aktiven, kontext-sensiblen und kooperativen Agenten zuerkennen müssen (vgl. Rammert 2007).

Daran anschließend führen Linnemann, Löhe und Rottkemper den Begriff der quasi-sozialen Beziehung ein, welcher definiert werden kann, als 'die Beziehung zwischen einem Menschen und einem künstlichen Agenten, bei der die Merkmale zwischenmenschlicher Beziehungsbildung (1) Soziale Präsenz, (2) Vertrauen, (3) emotionale Bindung und (4) gegenseitige Beeinflussung gleichzeitig vorhanden sind. Quasisoziale Beziehungen weisen soziale Elemente auf, sind aber dennoch von echten zwischenmenschlichen Beziehungen zu unterscheiden.' (2024, 11). Demzufolge  kann  der  KI-Chatbot  wiederum  verschiedene  Rollen  -  etwa  die einer:s  Beraters:in,  Begleiters:in  oder  Unterstützers:in  -  einnehmen  (ebd.  und weiter unten) und sie wird ihm gleichermaßen eingeräumt.

Neben dieser  (vergleichsweise)  hohen  Handlungsträgerschaft  des  Agenten  und der teilweise stattfindenden Zuschreibung von Verantwortung und Beziehungsqualitäten  ist  es  daher  gerade  im  Hochschulkontext  sinnvoll,  ChatGPT  nicht nur  situativ  in  bestimmten  Handlungssituationen  zu  verorten,  sondern  seinen Beitrag kritisch zu prüfen und mit Blick auf das eigene Handeln zu reflektieren. Gerade für eine Fachwissenschaft Soziale Arbeit ist es von enormer Bedeutung den Beitrag von KI in seinen institutionellen und gesellschaftlichen Gefügen zu betrachten (siehe Kapitel 6). So verweisen Reinmann und Watanabe darauf, dass KI das schon vorher existierende Spannungsfeld akademischer Lehre von (1) Wissenschaft (Wie verändert KI Disziplinen und deren Forschung?), (2) Person (Wie verändert KI Menschen und das Menschsein?) und (3) Praxis (Wie verändert KI das Handeln außerhalb von Hochschule?) noch weiter verstärken wird und damit der Anspruch an eine wertebasierte Diskussion wie auch die didaktische Gestaltung steigt (2023, 35f.).

## 5  Potenzielle Rollen generativer KI im Studium Sozialer Arbeit

Im Studium der Sozialen Arbeit gibt es vielfältige Nutzungsformen für ChatGPT. So  unterscheiden Witter  u.  a.  (2024,  10f.)  in  ihrer  quantitativen  Befragung  von Studierenden Sozialer Arbeit zwölf Anwendungskontexte die von Recherche und Textanalyseverarbeitung  über  Programmierung (ohne dabei selbst eine Programmiersprache beherrschen zu müssen) und Übersetzungen hin zur Erklärung von fachspezifischen Konzepten, der Konzeptentwicklung und Problemlösung reichen. Der folgende  Abschnitt  beleuchtet  daran  anschließend  drei  exemplarische  Anwendungsszenarien, die über die alltäglichen Nutzungsformen (etwa der Unterstützung von planerischen und administrativen Aufgaben oder der dialogischen Informationsbeschaffung  und  -herstellung)  hinausgehen  und  diskutiert  sowohl ihre Möglichkeiten als auch Grenzen. Diese Szenarien unterscheiden sich dabei in der Tiefe der Anwendung, der Rolle der generativen KI sowie in den veränderten Rollen der Lernenden sowie der didaktischen Begleitung.

## 5.1  Generative KI als akademische Schreibassistenz

Generative KI ermöglicht es, beliebige Textgenres künstlich zu produzieren - in einer Geschwindigkeit und künftig vermutlich auch in einer Qualität, die für den Menschen unerreichbar ist. Dies wirft fundamentale Fragen nach der Bedeutung des  wissenschaftlichen  Schreibens  auf.  Eine  tiefgreifende  Auseinandersetzung in  (urheber-  und  prüfungs-)rechtlicher,  inhaltlicher,  curricularer,  method(olog) ischer und ethischer Hinsicht steht im Wissenschaftssystem noch an (siehe grundlegend Schreiber &amp; Ohly 2024). 5

Und doch mag die Kompetenz, eigenständig wissenschaftlich schreiben zu können, für einen akademisch gebildeten Menschen auch in Zeiten von KI wertvoll sein (vgl. Reinmann &amp; Watanabe 2023, 39) und damit das Schreiben als Lernund Denkwerkzeug nutzen zu können. Oder wie Niklas Luhmann (1981, 222) es prägnant formuliert hat: 'Ohne zu schreiben, kann man nicht denken; jedenfalls nicht in anspruchsvoller, anschlussfähiger Weise'.

Szenario 1: Der virtuelle Schreibassistent und -trainer

Anna ist im letzten Semester ihres Studiums der Sozialen Arbeit und schreibt ihre Bachelorarbeit zum Thema ' Potenziale und Herausforderungen des Einsatzes von digitalen Technologien  in  der  Jugendsozialarbeit ' .  Da  sie  wenig  Erfahrung  im  wissenschaftlichen Schreiben hat, nutzt sie verschiedene KI-Tools für die verschiedenen Phasen wissenschaftlichen Schreibens. (1) Themenfindung und Literaturrecherche: Anna beginnt mit ChatGPT, um sich einen Überblick zu verschaffen. Sie fragt nach aktuellen Entwicklungen  und  Forschungslücken  im  Bereich  der  digitalen T echnologien  in  der  Jugendsozialarbeit. ChatGPT liefert ihr prägnante Argumente und verweist auf wichtige

5  Eine Übersicht zu aktuellen Entwicklungen und Leitfäden im Kontext von KI und Bildung bietet die Webseite https://www.unidigital.news/.

Konzepte und Schlüsselbegriffe. Darüber hinaus wird eine erste Gliederung generiert. (2)  Forschungsstand  und  Quellenanalyse:  Anna  verwendet  perplexity.ai  um  sich  den Forschungsstand aufbereiten zu lassen. Das Tool schlägt relevante Studien vor und hilft bei der Analyse der gefundenen Literatur. (3) Datenanalyse: Für die Analyse ihrer Interviews mit Fachkräften der Jugendsozialarbeit nutzt Anna NVivo. Die Software transkribiert die Interviews und identifiziert Schlüsselthemen und Muster, was Anna eine systematische Darstellung ihrer Ergebnisse ermöglicht. (4) T extgenerierung und -überarbeitung: ChatGPT unterstützt Anna bei der Strukturierung und Formulierung ihrer Texte. Sie gibt Gliederungspunkte und Stichworte ein und erhält Rohentwürfe für ihre Kapitel. Das Tool verbessert auch den Stil und korrigiert Grammatikfehler. (5) Plagiatsprüfung: Vor der Abgabe überprüft Anna ihre Arbeit mit Turnitin. Das Tool scannt die Arbeit und vergleicht sie mit einer umfangreichen Datenbank, um unbeabsichtigte Plagiate zu vermeiden.

Im Hinblick auf wissenschaftliches Arbeiten kann generative KI in nahezu allen Phasen der Recherche, Informationsverarbeitung, Datenanalyse, Textproduktion, -überarbeitung und Endredaktion genutzt werden; dennoch ist eine gründliche Überprüfung des Ergebnisses notwendiger denn je. Die Ergebnisse können jedoch als Ausgangspunkt für weitere Überlegungen bzw. als Feedback dienen. Die eigentliche Erarbeitung eines Themas muss weiterhin mit Bezug auf wissenschaftliche Quellen und aktuelle Forschungsliteratur erfolgen. KI-Systeme können den Zugang zu aktuellen Forschungsdaten erleichtern und es ist davon auszugehen, dass zahlreiche spezifische KI-Modelle mit wissenschaftlichem Hintergrund entstehen werden. 6 Gleichwohl spiegeln KI-Tools nicht zwingend die Fachkultur wider - es kann somit auch zu deutlichen Verzerrungen von Problemwahrnehmung und -diskussion kommen, die dem wissenschaftlichen Stand nicht entsprechen. Darüber hinaus bleibt der Anspruch der Eigenständigkeit an die eigene Arbeit bestehen. Die Arbeit mit generativer KI lässt sich faktisch nicht als Plagiat darstellen, weil die Produkte der KI selbst Unikate sind. Und dennoch ist das Thema wissenschaftlicher Redlichkeit damit nicht vom Tisch. Für die Bewertung schriftlicher Studien- und Abschlussarbeiten werden sich neue Ansätze etablieren müssen, die die nicht nur das Endergebnis, sondern auch explizit den Prozess der Entstehung des Dokumentes berücksichtigen. Für diesen prozessualen Aspekt könnten mindestens zwei Kriterien in die Bewertung einfließen: (1) Der inhaltlich/methodische Aufbau im Sinne eines KI-basierten Forschungsdesigns und die Qualität der Forschungsfrage sowie (2) das dazu ausgewählte technische Tool-Design: Wann habe ich was zur Unterstützung meiner Fragestellung genutzt - inklusive einem deklarierten Prompting-Verzeichnis im Anhang, dass den Lern- und Forschungsprozess transparent macht (vgl. Weßels 2022).

6  So entwickelt beispielsweise das Forschungszentrum Jülich mit Partnereinrichtungen der Helmholtz-Gemeinschaft eine neue Generation von KI-Grundlagenmodellen für die Wissenschaft.

## 5.2  Generative KI als methodischer Übungspartner

Wie bereits ausgeführt kann mit ChatGPT ein Dialog geführt werden, der von einem menschlichen Gespräch - zumindest bei einfachen Anforderungen - kaum mehr unterscheidbar ist. Da ChatGPT in der Lage ist, verschiedenste Tonalitäten und Schreibstile einzunehmen, kann die KI als Partner beim Einüben von Beratungskompetenzen und Gesprächsführungstechniken genutzt werden (Engelhardt 2024a). Hierbei kann ein schriftlicher Dialog simuliert werden, wie er zum Beispiel im Rahmen professioneller Onlineberatung (Mail- oder Chatberatung) stattfinden könnte. Ebenso kann in der Version GPT-4o auch via Sprachein- und ausgabe kommuniziert werden (hierbei auch in unterschiedlichen Sprachen). Das gesprochene  Gespräch  wird  zudem  von  der  KI  als T ranskript  ausgegeben  und kann im Nachgang analysiert werden.

Szenario 2: Rollenspiele zum Einüben von Beratungstechniken

Studierende der Sozialen Arbeit üben die Methoden der Chatberatung durch ein Rollenspiel, bei dem ChatGPT als interaktiver Übungspartner eingesetzt wird. In spezifischen Beratungsszenarien simuliert ChatGPT eine ratsuchende Person, die verschiedene Herausforderungen oder Lebenssituationen präsentiert, während die Studierenden in der Rolle der Beratenden agieren (Es sind auch umgekehrte Szenarien denkbar, in denen Studierende sich in die Rolle von Adressat*innen begeben). Die Übung ermöglicht es den Studierenden in einem künstlichen, aber geschützten, Umfeld ihre kommunikativen Fähigkeiten, empathisches Verstehen und die Anwendung von Beratungstechniken und -methoden zu entwickeln. Durch das direkte Feedback von ChatGPT können  die  Lernenden  ihr  Handeln  in  Echtzeit  reflektieren  und  ggf.  anpassen. Diese Art des Rollenspiels bietet die Möglichkeit, praktische Onlineberatungs-erfahrungen zu sammeln und gleichzeitig die Grenzen und Möglichkeiten von KI in diesem Kontext zu erkunden. Wichtig ist hierbei vor allem, dass die Studierenden, angeleitet durch die Lehrenden, die simulierten Interaktionen kritisch auswerten und mit Erfahrungen in realen Beratungssituationen abgleichen.

Zu  den  Kernkompetenzen  sozialarbeiterischen  Handelns  gehören  Empathie, ethische Urteilsfähigkeit und Kommunikationsfähigkeit. Es muss daher kritisch hinterfragt werden, inwieweit eine KI in der Lage ist, solche tief im menschlichen Erleben und im Interaktionsprozess verwurzelten Erfahrungen realistisch darstellen zu können. So wirken die Antworten von ChatGPT in der Ratsuchendenrolle beispielsweise stets sehr selbstreflektiert und kooperativ, was zu einer sehr eindimensionalen Lernerfahrung führen kann. Außerdem neigt die KI dazu Aussagen der  Beratenden  immer  wieder  zu  paraphrasieren  oder  selbst  in  eine  beratende Rolle zu schlüpfen. Eine Möglichkeit diese Verzerrungen zu verringern, zeichnet sich durch die Gestaltung eigener GPTs ab, denen spezifisches Verhalten antrainiert werden kann und die durch eigene Trainingsdaten (wie z. B. Chatprotokolle

von menschlichen Interaktionspartner:innen einer bestimmten Zielgruppe) den Bedürfnissen bestimmter Übungen angepasst werden können.

Aktuell ist noch davon auszugehen, dass die Interaktion mit KI-Systemen nicht die komplexen, oft unvorhersehbaren menschlichen Interaktionen vollständig replizieren kann, die für die Praxis der Sozialen Arbeit entscheidend sind.

## 5.3  Chatbots als Produktivumgebung für neuartige Hilfearrangements

Anschließend an die oben erwähnten Ideen der Gestaltung eigener GPTs ist es möglich - etwa im Rahmen von Projektarbeiten - ohne Programmierkenntnisse und mit geringem Zeitaufwand eigene Chatbots für Anwendungsszenarien innerhalb der Sozialen Arbeiten zu entwickeln (Engelhardt 2024b). Damit wird generative KI zu einer Simulations- und Produktivumgebung, in der man spezifische Adressat:innengruppen, ihre Problem- und Bedarfslagen und ihre Nutzungsweisen analysieren, simulieren, modellieren und bewerten kann.

## Szenario 3: Entwicklung eines eigenen Chatbots

Zunächst erstellen die Studierenden ein detailliertes Konzept für den Bot und fertigen darauf basierend Trainingsmaterialien an, die sie in die selbst erstellten GPTs von OpenAI einspeisen. Hierbei sollen die Studierenden selbst recherchieren, formulieren und die Daten sorgfältig vorbereiten. Im nächsten Schritt konfigurieren sie den Bot und führen erste T estläufe durch, um Feedback zu sammeln und den Bot entsprechend zu überarbeiten. Dieses Vorgehen verfolgt mehrere Ziele: Die Studierenden sollen die Grundprinzipien generativer KI kennenlernen und deren Anwendungsmöglichkeiten und -grenzen reflektieren. Sie untersuchen, basierend auf ihrem Wissen über Hilfearrangements, deren Inanspruchnahme und Barrieren sowie eigenen Praxiserfahrungen, inwieweit eine KI wie ChatGPT Unterstützung anbieten kann. Dabei lernen sie, den Output fachlich zu bewerten und die ethischen Aspekte der Bot-Nutzung zu berücksichtigen. Im Rahmen dieses Projekts vertiefen die Studierenden zentrale Aspekte wissenschaftlichen und methodischen Arbeitens. Sie lernen, relevante wissenschaftliche Quellen zu identifizieren, kritisch zu bewerten und in geeigneter Form für ihr Projekt aufzubereiten. Dieser Prozess schult ihre Fähigkeit, komplexe Informationen zu strukturieren und in einen neuen Kontext zu überführen. Zudem fördert die iterative Verbesserung des Bots durch Nutzer*innenfeedback  ihre  Reflexionsfähigkeit  und  den  konstruktiven  Umgang  mit Rückmeldungen. So entwickeln sie ein tiefgehendes Verständnis für die technischen und ethischen Herausforderungen beim Einsatz von KI in der Sozialen Arbeit.

Dieses  projektbasierte  Lernen  ermöglicht  es  den  Studierenden,  einen  virtuellen Prototypen zu entwickeln und umzusetzen. Darüber hinaus lernen Sie durch den gestalterischen Aspekt nicht nur die Chancen und Grenzen generativer KI in der Umsetzung neu kennen, sondern können diesen Entwicklungsprozess auch auf Methoden, Spezifika und Eigenheiten Sozialer Arbeit übertragen (Wie stelle ich Niedrigschwelligkeit her? Mit welchen Voraussetzungen und Bedarfslagen kommen die

Adressat:innen zu meinem Angebot? Wie kann ich den Hilfeprozess koproduktiv denken? etc.) Somit lässt sich auch der Wert von digitalen Zugängen für die Soziale Arbeit diskutieren, die über klassische Beratungssettings hinausgehen und unterschiedliche Hilfesettings und -arrangements in den Blick nehmen können (etwa spezifische Formen der Psychoedukation, der Vor- oder Nachsorge etc.).

Diese drei Szenarien deuten nicht nur unterschiedlich gelagerte Anwendungskontexte an, sondern zeigen auch diverse (idealtypische) Funktions- und Akteurszuschreibungen: Während in der anfangs genannten Metapher des Werkzeuges noch auf die (vermeintliche) Instrumentalität der KI rekurriert wird, bedarf der dialogische Umgang in den o. g. Beispielen schon einer weitreichenderen selbst- und medienreflexiven Einordnung der gelieferten Ergebnisse der KI. Hier gilt es nicht nur die eigenen prompts kritisch zu prüfen, für bessere Ergebnisse anzupassen, sondern auch den Anteil des kooperativen Agenten zu betrachten. So zeigt sich etwa bei der akademischen Schreibassistenz schon ein erheblicher Anteil der KI am Arbeitsergebnis an. Die KI hat mitgeschrieben, korrigiert, inhaltliche Flanken gesetzt. Nicht nur mit Blick auf die Eigenständigkeit in der wissenschaftlichen Bearbeitung stellt sich  hier  die  Frage  nach  der  jeweiligen  Handlungs-  und  Verantwortungsträgerschaft von Mensch und Technik (Rammert 2007). Im Szenario des methodischen Übungspartners wird der KI eine gleichberechtigte (wenn auch nicht gleichwertige) Rolle und damit ein quasi-sozialer Agentenstatus in der Mensch-Technik Interkation zugeschrieben. Bei der Erstellung eigener Chatbots schließlich begeben sich die Studierenden in eine Simulationsumgebung, in der sie konzeptionell und kreativ lernen und durch die Modellierung nicht nur das interaktive Verhältnis von Mensch und Technik neu entdecken, sondern auch die Grenzen der 'sozialarbeitertischen Problembearbeitung' durch die KI identifizieren können.

## 6  Hochschuldidaktische und curriculare Konsequenzen für das wissenschaftliche Studium Sozialer Arbeit

Welche Konsequenzen ergeben sich in hochschuldidaktischer Hinsicht, wenn generative KI immer weiter in Wissenschaft, Studium und Beruf hineinragt? Doris Weßels (2022) fasst dies prägnant zusammen: 'Wir Lehrenden werden zu Architektinnen und Gestaltern des virtuellen […] und analogen Lernraums, wobei die Rolle der Lernbegleitung mit der Navigationsfunktion für die Lernenden und die Gestaltung des sozialen Raums von besonderer Relevanz sein werden' (o. S.). Durch die (Omni)Präsenz von generativer KI wird deutlich, dass die Rolle und auch der Anteil dieser Agenten in der Hochschulbildung nicht nur expliziter aufgegriffen werden muss, sondern dass es für Lehrenden wie Lernende gleichermaßen eines selbst- und medienreflexiven Umgangs bedarf. Auch als Lehrenden kommen wir nicht umhin

mit generativer KI arbeiten, um im Sinne unserer Wissenschaftsdisziplin eine Qualitätsabschätzung der generierten Antworten vornehmen zu können.

Was für curricularen Konsequenzen ergeben sich für ein wissenschaftliches Studium Sozialer Arbeit? Es wäre eine eigene Arbeit wert, das Kerncurriculum Sozialer Arbeit (DGSA 2016) mit Blick auf die Herausforderungen durch generative KI durchzudeklinieren. Wir wollen uns hier mit einem kursorischen Blick auf die Studienbereiche (1) ,Fachwissenschaftliche Grundlagen der Sozialen Arbeit', (2) ,Allgemeine Handlungstheorie und spezielle Handlungstheorien/Methoden Sozialer Arbeit' und (3) ,Gesellschaftliche und institutionelle Rahmenbedingungen Sozialer Arbeit' beschränken.

- 1) Letztlich geht es darum, eine grundlegende Data Literacy zu erwerben (Rennstich 2019). Diese grundlegende Informations- und Datenkompetenz soll insbesondere durch die fachwissenschaftlichen Grundlagen der Sozialen Arbeit vermittelt  werden.  Insofern  bedeutet  dies,  generative  KI  auch  schon  in  den Einführungen in das wissenschaftliche Arbeiten bis hin zum Schreiben von Abschlussarbeiten zu thematisieren und aufzugreifen. Neben einem grundlegenden Orientierungswissen geht es hier vor allem um das Einüben aber auch das kritische Bewerten von wissenschaftlichen und beruflichen Schreibpraktiken, die sich in Gemeinschaftsproduktion von Mensch und Maschine vollziehen.
- 2) Mit Blick auf die Methoden Sozialer Arbeit bieten nicht nur neue didaktische Ansätze zur Einübung methodischer Kompetenzen (vgl. Szenario 2), sondern auch deren explorative Nutzung (vgl. Szenario 3) Potenzial, um projekt- und forschungsorientiertes  Lernen  zu  fördern  und  die  Mensch-Maschine-Kollaboration progressiv in das Studium zu integrieren. Wenn dabei die Rolle der prozessorientierten Lernbegleitung und die Gestaltung des sozialen Raums von besonderer Relevanz sind (vgl. Wessels 2022), kann dies möglicherweise auch eine neue Qualität des Präsenzstudiums mit sich bringen.
- 3) in allen genannten Einsatzbereichen wie auch in den gesellschaftlichen Rahmenbedingungen Sozialer Arbeit im Besonderen ist es wichtig, die Intransparenz generativer KI kritisch zu beleuchten. Dies umfasst sowohl ihre opake Datengrundlage als auch die nicht transparenten generativen Regeln. Zudem müssen das normierende und diskriminierende Potenzial, das zur datengetriebenen  Reproduktion  und  Verschärfung  sozialer  Ungleichheit  führen  kann, hervorgehoben werden. Folglich müssen die ethischen, sozialen und rechtlich problematischen Implikationen der Nutzung von KI in die Hochschuldidaktik und Soziale Arbeit eingebettet werden, um einer isolierten und affirmativen Nutzung entgegenzuwirken.

Verantwortungsvoll mit der KI lernen heißt daher, (a) ihre materielle, ökonomische und rechentechnische Basis zu verstehen, (b) die heterogenen Vorausetzungen und Zugänge Lernender (und Lehrender) didaktisch zu beachten und (c) die Implikationen der Nutzung von generativer KI stetig zu vermitteln.

## Literatur

- Bager, Jo (2023): ChatGPT &amp;Co.: Uni in Prag schafft Bachelorarbeiten ab. Online unter: https:// www.heise.de/news/ChatGPT-Co-Uni-schafft-Bachelorarbeiten-ab-9546851.html (Abrufdatum: 13.07.2024).
- Engelhardt, Emily (2024a): Einsatz generativer KI in der Beratungsausbildung: Lehrmethoden und Praxisbeispiele  aus  dem  Hochschulkontext.  In:  Neumaier,  Stefanie/Dörr,  Madeleine/Botzum, Edeltraud (Hrsg.): Digitale Projekte in der Sozialen Arbeit. Weinheim: Beltz, 63-79.
- Engelhardt, Emily (2024b): Den KI-Spieß umdrehen - Lehrprojekt im Sommersemester 2024. Online unter: https://www.der-dreh.net/2024/03/04/den-ki-spiess-umdrehen-lehrprojekt-im-sommersemester-2024/ (Abrufdatum: 05.07.2024).
- Hochschulforum Digitalisierung (2023): Trotz fehlender Lizenzen - ChatGPT an Hochschulen längst Alltag.  Online:  https://hochschulforumdigitalisierung.de/news/trotz-fehlender-lizenzen-chatgptan-hochschulen-laengst-alltag/ (Abrufdatum: 05.07.2024).
- Garrel, Jörg von/Mayer, Jana/Mühlfeld, Markus (2023): Künstliche Intelligenz im Studium Eine quantitative Befragung von Studierenden zur Nutzung von ChatGPT &amp; Co. Online unter: https://doi.org/10.48444/h\_docs-pub-395.
- Larsen,  Moritz/Weßels,  Doris  (2022):  Chain  of  Thought  Prompting  -  KI-T ransfer  Hub  SH.  Online unter: https://kuenstliche-intelligenz.sh/de/chain-of-thought-prompting (Abrufdatum: 05.07.2024).
- Linnemann, Gesa/Löhe, Julian/Rottkemper, Beate (2023): Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit. In: Soziale Passagen 15 (1), 197-211.
- Linnemann, Gesa/Löhe, Julian/Rottkemper, Beate (2024): Bedeutung von Selbstoffenbarungseffekten in quasisozialen Beziehungen mit auf generativer KI basierten Systemen in Settings von Onlineberatung und -therapie. In: e-beratungsjournal.net 20 (1), 1-21.
- Ley, Thomas/Seelmeyer, Udo (2020): Digitale Technologien als Informationsinfrastrukturen. In: Kutscher, Nadia/Ley, Thomas/Seelmeyer, Udo/Siller, Friederike/Tillmann Angela/Zorn, Isabel (Hrsg.). Handbuch Soziale Arbeit und Digitalisierung. Weinheim/Basel: Beltz Juvenat, 376-389.
- Luhmann, Niklas (1981): Kommunikation mit Zettelkästen. Ein Erfahrungsbericht. In: Baier, Horst/ Kepplinger, Hans Mathias/Reumann, Kurt (Hrsg.), Öffentliche Meinung und sozialer Wandel. Opladen: Westdeutscher, 222-228.
- Rammert, Werner (2007): Technik - Handeln - Wissen. Zu einer pragmatistischen Technik- und Sozialtheorie. Wiesbaden: VS.
- Reinmann, Gabi/Watanabe, Alice (2024): KI in der universitären Lehre: Vom Spannungs- zum Gestaltungsfeld. In Schreiber, Gerhard/Ohly, Lukas (Hrsg.), KI:Text: Diskurse über KI-Textgeneratoren. Berlin: De Gruyter, 29-46.
- Schreiber, Gerhard/Ohly, Lukas (2024): KI:Text. Diskurse über KI-Textgeneratoren. Berlin: De Gruyter. Ständige  Wissenschaftliche  Kommission  der  Kultusministerkonferenz  (SWK)  (2023):  Large  Language  Models  und  ihre  Potenziale  im  Bildungssystem.  Impulspapier  der  Ständigen  Wissenschaftlichen  Kommission  (SWK)  der  Kultusministerkonferenz.  Online  unter:  http://dx.doi. org/10.25656/01:28303.
- Steiner, Olivier/Tschopp, Dominik (2022): Künstliche Intelligenz in der Sozialen Arbeit. In: Sozial Extra 46 (4), 466-471.
- Mollick, Ethan R./Mollick, Lilach (2023): Using AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including prompts. The Wharton School Research Paper. Online unter: http://dx.doi.org/10.2139/ssrn.4391243.
- Weßels, Doris (2022): ChatGPT - ein Meilenstein der KI-Entwicklung. Online unter: https://www. forschung-und-lehre.de/lehre/chatgpt-ein-meilenstein-der-ki-entwicklung-5271 (Abrufdatum: 05.07.2024).
- Witter, Stefanie/Meinhardt-Injac, Bozana/Siemer, Lutz/Späte, Julius (2024): ChatGPT im Studium der Sozialen Arbeit. Eine quantitative Studie zur Nutzung, Bewertung und Thematisierung in der Hochschule aus Studierendensicht. Potsdam: Fachhochschule Potsdam. Online unter: https://doi. org/10.34678/opus4-3382.

## Autor:innen

## Engelhardt, Emily, Prof. in

Orcid: 0009-0006-4395-2943

Professorin an der Fakultät für angewandte Sozialwissenschaften der Hochschule München.

Arbeitsschwerpunkte : Digitale T ransformation in Sozialen Handlungsfeldern und Gesellschaft.

## Ley, Thomas, Prof. Dr.

Professor für Soziale Arbeit an der Fakultät für Wirtschafts- und Sozialwissenschaften an der Hochschule Osnabrück Arbeitsschwerpunkte : Mediatisierte Lebenswelten und Arbeitsformen.