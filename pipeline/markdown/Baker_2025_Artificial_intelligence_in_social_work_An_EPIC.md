---
source_file: Baker_2025_Artificial_intelligence_in_social_work_An_EPIC.pdf
conversion_date: 2026-02-03T18:21:18.916927
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
<!-- image -->

## Australian Social Work

ISSN: 0312-407X (Print) 1447-0748 (Online) Journal homepage: www.tandfonline.com/journals/rasw20

## Artificial Intelligence in Social Work: An EPIC Model for Practice

## Heather Boetto

To cite this article: Heather Boetto (27 Apr 2025): Artificial Intelligence in Social Work: An EPIC Model for Practice, Australian Social Work, DOI: 10.1080/0312407X.2025.2488345

To link to this article:

https://doi.org/10.1080/0312407X.2025.2488345

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

© 2025 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group

Published online: 27 Apr 2025.

Submit your article to this journal

Article views: 9531

View related articles

View Crossmark data

- [x] Citing articles: 2 View citing articles

曲

CrossMark

<!-- image -->


<!-- PAGE 2 -->


<!-- image -->

<!-- image -->

## Artificial Intelligence in Social Work: An EPIC Model for Practice

<!-- image -->

Heather Boetto

School of Social Work and Arts, Charles Sturt University, Wagga Wagga, New South Wales, Australia

## ABSTRACT

As artificial intelligence (AI) permeates the workplace environments of social workers, there is a need to understand the risks and benefits posed  to  the  mission  and  values  of  the  profession.  This  article examines  the  influence  of  artificial  intelligence  on  the  profession, including  opportunities  to  advance  socially  just  outcomes  and challenges  that  risk  ethical  practice.  A  comprehensive  review  of literature  was  conducted  to  examine  existing  research  on  the intersection  of  AI  and  social  work.  Drawing  on  insights  from  this review,  an  EPIC  model  for  integrating  artificial  intelligence  into  the profession  is  presented,  consisting  of  four  components:  (E)  ethics and  justice;  (P)  policy  development  and  advocacy;  (I)  intersectoral collaboration; and (C) community engagement and empowerment. The  author  contends  that  augmenting  the  benefits  of  artificial intelligence in social work requires a proactive and ethical approach towards a more secure, safe, transparent, and socially just future.

## IMPLICATIONS

- . A  structured,  ethical  approach  to  integrating  AI  emphasises  the importance of addressing biases and promoting justice.
- . Advocating a dual human-technology approach supports social work  methods  and  enhances  effective  decision  making  and efficiency.
- . The inclusion of AI guidelines in professional standards will ensure its ethical application for empowering marginalised communities.

The recent acceleration of artificial intelligence (AI) is reshaping the roles and responsibilities of social workers, including the relationships formed between service users and practitioners. AI provides opportunities to address social problems and advance socially just outcomes. For example, AI can enable accessibility and foster inclusivity for people with disabilities (Kumar et al., 2023), enhance the efficiency of humanitarian aid efforts (Taouktsis  &amp;  Zikopoulos,  2024),  and  improve  diagnostics  and  treatment  in  health (Alowais et al., 2023). However, the most recent Global Risks Report (World Economic Forum, WEF, 2024) identified AI-generated misinformation and disinformation as the number one risk factor to global stability over the next two years, involving the persistent

CONTACT

Heather Boetto hboetto@csu.edu.au

<!-- image -->

© 2025 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group This  is  an  Open  Access  article  distributed  under  the  terms  of  the  Creative  Commons  Attribution-NonCommercial-NoDerivatives License (http://creativecommons.org/licenses/by-nc-nd/4.0/),  which  permits  non-commercial  re-use,  distribution,  and  reproduction  in  any medium,  provided  the  original  work  is  properly  cited,  and  is  not  altered,  transformed,  or  built  upon  in  any  way.  The  terms  on  which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent.

## ARTICLE HISTORY

Received 22 September 2024 Accepted 30 March 2025

## KEYWORDS

Artificial  Intelligence; AI; Generative AI, Ethics; Technology; Social Work; Ethics; Social Justice; Community Engagement; Empowerment; Policy Development; Advocacy; Collaboration; First Nations; Australia; Safety; Future; Structural Bias


<!-- PAGE 3 -->


<!-- image -->

spread of false, manipulated, and fabricated information through online media networks. Further, the United Nations (UN, 2024) adopted a landmark resolution to promote the development  of  secure  and  trustworthy  AI  systems,  referring  to  the  need  to  address associated racial discrimination, bias, and human rights issues. This evidence highlights the paradoxical and complex nature of AI, requiring an articulated and collective global social work approach.

## Defining AI

The term AI refers to computer technologies that have the capacity to mimic or simulate human  intelligence  (Kalota,  2024;  Sheikh  et  al.,  2023).  Often  referred  to  in  popular culture  as  'smart'  or  'intelligent',  AI  encompasses  a  wide  scope  of  technologies  that can solve complex problems using mathematical logic to learn, reason and self-correct (Dung Le et al., 2023). A subcategory of AI is machine learning applications. According to  Janiesch  et  al.  (2021),  there  are  three  foundations  of  machine  learning  architecture involving machine learning algorithms; artificial neural networks; and deep neural networks. While these terms often are used interchangeably, machine learning algorithms and artificial neural networks adopt 'shallow' machine learning processes involving relatively simple models that consist of a small number of processing stages (Janiesch et al., 2021, p. 687). Typically, they have a limited capacity to learn complex patterns (e.g., a decision tree used to classify medical symptoms). Deep neural networks adopt 'deep' machine  learning  processes,  which  consist  of  a  multilayered  neural  network  system that  is  not  traceable  or  interpretable  by  humans  (Janiesch  et  al.,  2021,  p.  688),  and which typically  involve  more  advanced  tasks  (e.g.,  convolutional  neural  network  used for  image  recognition).  The  type  of  deep  learning  machines  garnering  much  public debate is  generative AI,  which  has  the  capacity  to  autonomously  augment, synthesise, and  innovate  new  data  inspired  from  an  original  dataset  (Gignac  &amp;  Szodorai,  2024; Kalota,  2024).  A  significant  issue  with  deep  learning  machines,  especially  generative AI, is that their operations are often likened to a 'black box', meaning their decisionmaking  processes  are  opaque,  even  to  the  developers  who  create  them  (Wadden, 2021). This rise of generative AI represents an acceleration in technological advancement and presents complex challenges regarding the ethical use of AI.

## AI Developments in Healthcare

The development of AI in healthcare has grown rapidly with applications available in a range of areas, including early disease detection, medical imaging, drug development, personalised care, and administration (Alowais et al., 2023). A particularly relevant area for social  work  is  AI's  application  in  mental  health  and  predictive  risk  assessment.  AIpowered chatbots, for example, are increasingly used in clinical and therapeutic settings to improve individual mental health and wellbeing (Balan et al., 2024; Xue et al., 2023). These  chatbots,  designed  to  simulate  human  conversation,  allow  users  to  interact  with digital  devices,  offering  support  for  mental  health,  physical  activity,  and  behaviour change (Coghlan et al., 2023; Xue et al., 2023). In addition, AI plays a significant role in predictive risk modelling for suicide (e.g., Nordin et al., 2022; Walsh et al., 2017), domestic violence (Hui et al., 2023; Petering et al., 2018), and child protection (Field et al., 2023).


<!-- PAGE 4 -->


By  analysing  large  datasets,  AI  systems  are  used  to  predict  individuals  at  higher  risk, enabling the implementation of early interventions to reduce the likelihood of harm.

Research outcomes on the use of AI in healthcare are mixed. On the one hand, some research on the effectiveness and diagnostic accuracy of AI is promising. For example, a review of research using AI-learning machines to predict domestic violence using online social  media  data  found  exceptional  potential  for  identifying  at-risk  individuals  (Hui et  al.,  2023).  However,  research  indicates  challenges  relating  to  risks  of  misdiagnosis and  a  lack  of  clinical  tests  on  the  effectiveness  and  validity  of  AI.  For  example,  a scoping review of AI-powered chatbots found limited evidence supporting the efficacy of chatbots for improving mental health in young people (Balan et al., 2024). Another scoping review, found that just 44% of chatbots effectively addressed suicidal thoughts, causing  concern  for  their  capacity  to  respond  to  crisis  situations  (Xue  et  al.,  2023). Further, the use of ChatGPT in child protection settings has yielded inaccurate output data  and  breached  privacy  principles  involving  third-party  access  to  service  user  data (Victorian  Government,  2024).  This  evidence  suggested  that  without  rigorous  testing and validation, there is risk of overestimating the effectiveness of AI and potentially compromising the quality of healthcare.

## Social Work and AI

AI has the potential to transform the profession's capacity and effectiveness for improving  positive  outcomes  for  service  users  in  clinical,  administrative,  and  policy  contexts (Reamer,  2023).  Although  still  in  its  early  stages,  social  work-specific  research  has explored  AI  in  areas  of  child  welfare  (Lehtiniemi,  2024),  counselling  (Chan  &amp;  Li, 2023), mental health (Walsh et al., 2017), young people (Rice &amp; Tambe, 2018), and domestic violence (Petering et al., 2018). According to Meilvang and Dahler (2024), the use of AI for undertaking administrative tasks could benefit social workers by freeing up more time to concentrate on core professional tasks. In addition, the advancement of interdisciplinary collaboration between social workers and computer scientists to address social problems using AI shows potential to promote AI for social good (e.g., Centre for AI in Society at the University of California, https://www.cais.usc.edu) (Rice &amp; Tambe, 2018). These developments and applications of AI have the capacity to advance social work's mission  and  aims  towards  enhancing  human  wellbeing  and  promoting  social  justice outcomes.

As pointed out by Gough and Spencer (2019), technologies, however, 'are not neutral, independent and non-invasive' instruments (p. 252). Rather, AI-generated data may be algorithmically biased and not representative of marginalised groups due to its reliance on large volumes of historical datasets (Dankwa-Mullan et al., 2021; Khawaja &amp; BélislePipon, 2023; Reamer, 2023). This reliance on historical datasets means that the dominance of colonial knowledges in AI algorithms are reinforced, and the ongoing colonisation and oppression of First Nations Peoples perpetuated (Cave &amp; Dihal, 2020). Further, considerations of gender, race, ethnicity, and sexual orientation may be nonexistent or significantly prejudiced and discriminative. Research pioneered by computer scientists Buolamwini  and  Gebru  (2018)  found  that  gender  classification  systems  produced  an error rate up to 34.7% for darker-skinned females. The 'black box' problem further complicates this situation when complex AI decision-making algorithms are not interpretable


<!-- PAGE 5 -->


<!-- image -->

or  understandable  by  AI  users,  service  providers,  and  AI  developers  (Wadden,  2021). These issues are further exacerbated by a lack of community involvement in AI development (Cave &amp; Dihal, 2020; Dankwa-Mullan et al., 2021), which means that algorithms supporting AI rarely consider diverse perspectives.

AI significantly influences various aspects of interaction between service users and practitioners.  Gough  and  Spencer  (2019)  raised  concerns  about  the  ethics  of  replacing  an empathic,  reciprocal  relationship  between  service  users  and  practitioners  with  technologies.  They  argued  that  fostering  trust,  rapport,  and  genuine  relationships  with  service users requires social workers to demonstrate empathy towards their situation (Gough &amp; Spencer, 2019), including an appreciation of their diverse experiences, emotional status, and relative disadvantage. Khawaja and Bélisle-Pipon (2023) applied the term 'therapeutic misconception', cautioning that service users may not fully understand the limitations of AI (p. 3). For example, chatbots lack capacity to provide individualised responses, instead providing  responses  that  are  based  on  a  dataset  representing  a  certain  group  of  people (Khawaja &amp; Bélisle-Pipon, 2023). They argued that developing a 'digital therapeutic alliance' with AI is more reasonable due to various issues; for example, chatbots cannot integrate accumulated knowledge and experiences with service users over time, nor identify subtle  emotional  nuances  and  nonverbal  cues  specific  to  service  users  (Khawaja  &amp; Bélisle-Pipon,  2023,  p.  6).  In  addition,  concerns  have  been  raised  about  AI  access  and equity issues, highlighting the digital divide and 'information poverty' for marginalised groups (Dali &amp; Caidi, 2023, p. 6; Gough &amp; Spencer, 2019). These issues raise significant concerns for social work about how to ensure AI advancements comply with ethical practice, while at the same time enhancing positive outcomes for service users.

AI has the capacity to influence politics and social policy decisions relevant to social work services. Meilvang and Dahler (2024) drew attention to the propensity for political actors  to  favour  positivist  approaches  to  social  policy,  including  efforts  to  standardise casework and promote objectivity, to avoid politically damaging high-profile cases leveraged  by  the  media.  In  addition,  there  is  potential  for  the  public  to  persuade  political actors to implement positivist AI approaches to decision-making processes in contested areas, such as child protection, which has the effect of negating professional discretion (Meilvang &amp; Dahler, 2024). The politics of AI is further accentuated by the spreading of misinformation and disinformation across online media networks that has the effect of shifting public opinion towards distrust, and causing civil unrest, political instability, and conflict (WEF, 2024). For example, the creation of deepfake content in election campaigns  has  altered  public  perceptions  and  influenced  voter  preferences  in  many countries,  including  the  United  States,  India,  and  Slovakia  (Garimella  &amp;  Chauchard, 2024). There are concerns that AI may become the platform for new public management strategies in welfare state administration (James &amp; Whelan, 2022) and as the solution for addressing  an  overloaded  health  and  social  services  system  (Meilvang,  2023).  These issues have potential to usher in a new wave of AI-generated politics that could undermine social work's mission and values.

While professional policy documents consider the ethical use of technology, there is little guidance for social workers operating in the context of contemporary AI environments. The International Federation of Social Workers (IFSW, 2018) affirmed the ethical use  of  technology  and  social  media  as  an  ethical  principle  with  specific  reference  to privacy and confidentiality, conflicts of interest, competence, and knowledge to safeguard


<!-- PAGE 6 -->


<!-- image -->

against unethical practice. Many national policy documents relating to technologies in social  work  exist,  for  example,  in  Canada  (Canadian  Association  of  Social  Work, CASW, 2014),  United  States  (National  Association  of  Social  Workers,  NASW,  2017), and  Australia  (AASW,  2016).  However,  according  to  research  by  Dali  and  Caidi (2023),  these  documents  do  not  provide  information  relating  to  the  new  challenges posed by AI. This highlights the need for professional bodies to modernise their policies to consider contemporary challenges relating to AI.

## The EPIC Model: Method and Core Components

As  the  social  work  profession  increasingly  engages  with  AI,  a  planned  approach  that aligns with the mission and values underpinning social work is warranted. A comprehensive review of literature was conducted to examine existing research on the intersection of AI and social work. The literature review included a wide range of sources, such as peerreviewed journal articles, book chapters, and case studies. Drawing on insights from this review, the EPIC model was developed to guide the integration of AI into the profession. The model consists of four components: (E) ethics and justice; (P) policy development and  advocacy;  (I)  intersectoral  collaboration;  and  (C)  community  engagement  and empowerment (see Figure 1). These components are not mutually exclusive, but rather overlap to form a holistic and relational approach for integrating AI into the profession. The components of the EPIC model are outlined below.

## Ethics and Justice

Addressing algorithmic biases in AI is a critical concern for ethical practice, particularly as AI systems become more prevalent in delivering social work services. AI's dependence

Figure 1. The EPIC model.

<!-- image -->


<!-- PAGE 7 -->


6

<!-- image -->

on historical datasets that are not representative of marginalised groups have the potential to cause significant harm via misdiagnosis, exclusion, and discriminatory outcomes (Dankwa-Mullan et al., 2021; Khawaja &amp; Bélisle-Pipon, 2023; Reamer, 2023). To redress this structural bias, urgent macro policy initiatives are needed to decolonise AI datasets involving a radical shift towards First Nations' and ethnic data sovereignty and control, transparency,  and  local  community-based  ownership  (Dankwa-Mullan  et  al.,  2021; Murphy &amp; Largacha-Martínez, 2022). In addition, advocacy for employment opportunities  for  marginalised  groups  to  represent  diverse  perspectives,  and  the  hiring  of social  workers  in  organisations  responsible  for  deploying  AI  systems  are  needed  to ensure ethical, safe,  and  regulated  use  in  health  and  social  services  (Mathiyazhagan  &amp; Patton, 2024).

At the micro level of practice, AI applications in social work services require a dual human-technology approach, whereby core practice methods are not replaced or substituted  with  AI-generated  decision-making  processes  (Grant,  2018;  Reamer,  2023). Instead, AI is useful for providing 'decision-support' by identifying potential oversights in decision-making processes made by social workers, as well as prejudices formed from existing AI datasets (Meilvang, 2023, p. 12; Meilvang &amp; Dahler, 2024). This dual humantechnology approach can be supported at the mezzo level of practice by organisations that  establish  AI  governing  principles  and  protocols.  For  example,  organisations  can form digital ethics steering committees, convene diverse reference groups, conduct AI model  simulations,  and  develop  social  worker  guidelines  for  the  ethical  use  of  AI (Reamer, 2023). This approach highlights the importance of integrating AI as a supportive tool in decision making while maintaining human management and organisational safeguards.

Respecting the service user-practitioner relationship is crucial for ethical practice at the  micro level too. Reamer (2023) highlighted the importance of gaining appropriate informed consent from service users to ensure that the benefits, limitations, and risks associated with AI are clarified (Reamer, 2023). For example, ensuring privacy and confidentiality in relation to third party access of service user data and informing service users about  risks  and  breaches  are  essential  for  transparent  practice  (Reamer,  2023).  In addition, when service users communicate significant distress to AI devices, practitioners need  to  respond  in  a  timely  manner  by  communicating  directly  with  service  users  to avoid 'client abandonment' (Reamer, 2023, pp. 60-61). These considerations emphasise the need for practitioners to prioritise transparency, informed consent, and responsive care to maintain trust and ethical standards in their interactions with service users. Strategies for promoting ethical and just practice are summarised in Table 1.

## Policy Development and Advocacy

Enhancing social worker capabilities in AI requires leadership from professional governing  bodies  to  guide  and  empower  social  workers  to  use  AI.  While  international  and national  policy  documents affirm the ethical  use of  technology and social media (e.g., IFSW, 2018; CASW, 2014; NASW, 2017), locating AI more explicitly within professional social work policy documents is lacking. Rather, inclusion of AI content in course accreditation  requirements  and  practice  standards  is  critical  for  ensuring  practitioners  can appropriately  navigate  this  new  era  of  frontier  technologies  (Dali  &amp;  Caidi,  2023).  At


<!-- PAGE 8 -->


<!-- image -->

Table 1 Strategies for Promoting Ethical and Just Practice

| Ethics and Justice                                 | Strategies                                                                                                                                                                                                                                              |
|----------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Addressing biases, discrimination, and exclusion   | . Decolonisation processes ensuring First Nations' and ethnic data sovereignty and control . Creation of AI employment pathways for underrepresented groups . Expansion of social work employment in organisations responsible for deploying AI systems |
| Dual human-technology approach                     | . AI provision of decision-making support in core social work tasks e.g., assessments . AI supplementation of some social worker administrative tasks e.g., managing schedules . Implementation of AI guiding principles in organisations               |
| Valuing the service-user-practitioner relationship | . Informed consent inclusive of information about AI benefits, limitations, and risks . Privacy and confidentiality relating to third party data access . Regular, timely, direct communication with service users utilising AI devices                 |

the organisational level, the establishment of policies and procedures outlining a governance body and ethical principles for the use of AI is needed (Reamer, 2019). Organisational policies provide  the  foundation  for  actively  engaging  with  service  users, consulting  with  diverse  groups,  undertaking  periodic  testing  of  AI,  and  staff  training. These  proactive  measures  are  to  ensure  that  social  work  has  a  defining  role  in  the control and implementation of AI within social work services (Meilvang, 2023).

Government policies and regulatory guidelines are essential for augmenting the benefits of AI, while minimising risk of harm posed to communities. Given that large technology companies primarily are purposed towards profit making (Gough &amp; Spencer, 2019), ensuring appropriate legal protection and empowerment of marginalised groups is essential. The storage and use of personal data by large AI companies is not transparent or democratic (Hodgson et al., 2022), creating a new digital form of surveillance of service user information  (Reamer,  2023).  While  international  collaboration,  such  as  the  United  Nations' agreement  on  promoting  secure  AI  is  evident  (UN,  2024),  continued  leadership  is needed  to tackle structural biases and social injustice. National governments  are working on regulations, but these often overlook unique issues specific to clinical settings (Blumenthal &amp; Patel, 2014) and do not address issues associated with generative AI algorithms (Huang et al., 2024). As a collective, social workers have a role to play in advocating for  government  policies  and  regulations  that  protect  marginalised  communities,  ensure transparency, and address the ethical use of AI in clinical settings. Strategies for promoting policy development and advocacy are summarised in Table 2.

Table 2 Strategies for Promoting Policy Development and Advocacy

| Policy Development & Advocacy   | Strategies                                                                                                                                                                                                                                                           |
|---------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Professional social work policy | . Inclusion of AI content in relevant professional documents . Implementation of AI policies in social work organisations                                                                                                                                            |
| Policy advocacy                 | . Increase community awareness of primary profit motive of AI companies and associated power imbalances . Advocacy promoting legal protection and self-governance of personal data . Advocacy for international and national collaborative governance and regulation |


<!-- PAGE 9 -->


<!-- image -->

## Intersectoral Collaboration

Effective  engagement  with  AI  requires  interdisciplinary  collaboration  between  social scientists,  including  social  workers,  computer  scientists,  governments,  and  the  private sector.  Although  limited,  there  is  evidence  of  growing  intersectoral  collaboration between social workers and computer scientists to address complex societal issues. For example, the establishment of the Centre for AI in Society at the University of California has examined HIV prevention for homeless young people and domestic violence (Rice &amp; Tambe, 2018). Further, intersectoral  collaborations  have  evaluated  the  effectiveness  of AI-generated behaviour-change interventions (Michie et al., 2017) and the development of AI-generated chatbots in nondominant languages (Chan &amp; Li, 2023). While AI developers, such as computer scientists, commonly adopt a positivist approach that prioritises statistical and experimental knowledge, social workers have the expertise to incorporate contextual, interactional, and situational knowledge that often is lacking in AI development (Jacobi &amp; Christensen, 2023).

Interdisciplinary  research  constitutes  a  significant  component  for  developing  professional  capacity  to  manage  and  implement  AI  in  social  work  services  (Hodgson et al., 2022). Rice and Tambe (2018) asserted that social workers can contribute to interdisciplinary research by ensuring that marginalised groups are represented in large datasets  used  to  create  predictive  models.  In  addition,  these  authors  contend  that  while traditional forms of AI research emphasised fast-paced, technological innovations, interdisciplinary research 'goes beyond technical breakthroughs' to assess the impact of AI on  society  (p.  13).  Further,  Jacobi  and  Christensen  (2023)  challenged  the  dichotomy that  can  occur  between  the  development  and  application  stages  of  AI.  Their  research identified  that  social  workers  rarely  are  involved  in  the  development  stage,  but  rather at  the  application  or  output  stage  only.  This  intersectoral collaboration  calls for  social work  researchers,  educators,  and  practitioners  to  forge  partnerships  with  computer scientists, governments, and the private sector. Strategies for promoting intersectoral collaboration are summarised in Table 3.

## Community Engagement and Empowerment

Community engagement and empowerment are essential for understanding diverse perspectives and varying needs of people and communities using AI. While ethical issues associated  with  AI  commonly  are  discussed  in  social  work  literature,  there  is  little

Table 3 Practice Strategies for Promoting Intersectoral Collaboration

| Intersectoral Collaboration    | Strategies                                                                                                                                                                                                                                                                    |
|--------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Interdisciplinary partnerships | . Increase interdisciplinary collaboration between social workers, computer scientists, governments, and the private sector . Contribution of social work expertise in contextual, interactional, and situational knowledge                                                   |
| Interdisciplinary research     | . Increase in social work AI research, involving social work researchers, educators, and practitioners . Research collaboration with computer scientists, governments, and the private sector . Research to include social worker involvement in AI design and implementation |


<!-- PAGE 10 -->


<!-- image -->

Table 4 Practice Strategies for Promoting Community Engagement and Empowerment

| Community Engagement & Empowerment          | Strategies                                                                                                                                                                                                                                                                              |
|---------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Stakeholder engagement in AI life cycle     | . Increase participation of service users and underrepresented groups in AI design and development . Advocate for First Nations' data governance and sovereignty . Community engagement through organisational practices, such as reference groups, and codesigned research initiatives |
| Building community awareness and capability | . Develop education opportunities for increasing community AI knowledge and skills . Increase awareness about risks associated with AI misinformation and disinformation . Foster civic engagement and collective action against the misuse of AI                                       |

dialogue  about  the  need  to  directly  engage  with  and  involve  service  users.  DankwaMullan  et  al.  (2021)  proposed  a  framework  underpinned  by  community  engagement for integrating health equity and racial justice in AI development. This framework integrated  engagement  with  all  stakeholders,  including  community  members  and  service users,  involving  transparency  and  feedback  in  all  stages  of  the  AI  life  cycle  (DankwaMullan et al., 2021). Importantly, the authors outlined specific decolonisation guidelines, advocating  for  racial  and  ethnic  data  governance  and  sovereignty,  rather  than  mere assurances of data diversity  and  inclusion (Dankwa-Mullan  et  al.,  2021). Social workers can implement community engagement strategies by developing organisational policies and governance structures, including the creation of digital ethics steering committees, the formation of diverse reference groups (Reamer, 2023), and through community codesigned research initiatives (Black et al., 2020).

In addition, building community knowledge and skills in AI, including recognising how false information is presented as credible, can help educate the public about potential risks. Raising awareness about AI misinformation and disinformation is crucial for protecting individuals and groups from the harmful effects of inaccurate and fabricated content (Benzie &amp; Montasari, 2022). Even without the intent of spreading false information, AI technologies like ChatGPT can mislead communities by incorporating subjective  opinions  in  the  information  generated  from  large  datasets  (Shin  et  al.,  2024). Empowering communities through interventions such as workshops with service user groups, public education campaigns, resource mobilisation for community-led AI projects,  and  capacity  building  for  identifying  false  information  (e.g.,  fact  checking)  can be  effective  strategies.  This  increased  knowledge  can  promote  civic  engagement  and encourage collective action to combat the misuse of AI. Strategies for promoting community engagement and empowerment are summarised in Table 4.

## Discussion

The EPIC model introduces a multidimensional approach to integrating AI into social work. The model's core components-ethics and justice, policy development and advocacy,  intersectoral  collaboration,  and  community  engagement  and  empowermentprovide  a  guide  for  ensuring  that  the  implementation  of  AI  aligns  with  the  mission and values of the profession. However, the integration of AI into social work practice raises  significant ethical challenges. At the core of these challenges is AI's dependence


<!-- PAGE 11 -->


<!-- image -->

on historical datasets that are not representative of First Nations' perspectives and marginalised groups, posing significant harm via misdiagnosis, exclusion, and discriminatory outcomes  (Dankwa-Mullan  et  al.,  2021;  Khawaja  &amp;  Bélisle-Pipon,  2023;  Reamer,  2023). Further,  the  balance  between  human  judgement  and  technological  decision  making  is crucial to ensure that AI enhances rather than replaces the nuanced understanding that social  workers  bring  to  practice  (Grant,  2018;  Reamer,  2023).  When  used  responsibly, AI can support social workers in decision-making processes and potentially enhance the quality-of-service  delivery  (Meilvang,  2023,  p.  12;  Meilvang  &amp;  Dahler,  2024).  However, this  balance  requires  ongoing  vigilance  to  prevent  overreliance  on  AI  systems  and  to ensure that the service user-practitioner relationship remains central to practice.

The model highlights the need for social work professionals to advocate for policies that protect service users. At the professional level, there is an urgent need to integrate AI into standards and accreditation, ensuring social workers are prepared to navigate AI complexities (Dali &amp; Caidi, 2023). At the organisational level, ethical governance of AI is crucial for accountability and transparency (Reamer, 2023). Additionally, advocating for government policies that enhance AI benefits while protecting marginalised communities from biases is vital for equity and justice (Blumenthal &amp; Patel, 2014; Huang et al., 2024). However, while the model emphasises ethical governance, the rapidly evolving nature of AI technology will likely outpace the development of policies and practices that effectively address new challenges. This misalignment potentially could leave social workers ill-equipped to navigate emerging  ethical  dilemmas  unless  policies  are  based  on  flexible,  adaptive  frameworks that prioritise continuous dialogue, collaborative governance, and evaluation processes.

The  model  highlights  the  importance  of  collaboration  between  social  workers  and specialists from other fields, particularly computer scientists, to ensure that AI systems are  designed  and  implemented  in  ways  that  reflect  the  social  realities  of  marginalised communities. Social work scholars assert that the profession can contribute to interdisciplinary AI development and application with skills focusing on the representation of marginalised groups in datasets and the lived experience of societal impacts (Jacobi &amp; Christensen, 2023; Rice &amp; Tambe, 2018). However, a major challenge relating to interdisciplinary collaboration is the varying levels of understanding and expertise between social workers and technical specialists. This gap in knowledge may hinder effective communication,  subsequently  affecting  the  proactive  development  of  AI  systems  that  are  both socially responsible and technically sound. To bridge this gap, social workers can facilitate  mutual  learning  through  cross-disciplinary  training,  knowledge-exchange  forums, and peer-learning opportunities.

The model emphasises the need for community engagement and empowerment in the development and deployment of AI. Involving service users in the conversation about how AI affects their lives is crucial to ensure that AI systems reflect their needs and concerns (Dankwa-Mullan et al., 2021). Moreover, social workers can play a pivotal role in educating communities about the risks of misinformation and disinformation in AI-generated content.

## Limitations

Although community engagement is emphasised, the model assumes that service users and  communities  will  have  the  resources  and  access  to  actively  participate  in  AI


<!-- PAGE 12 -->


<!-- image -->

discussions, which may not always be the case, particularly for marginalised groups (Dali &amp; Caidi, 2023; Gough &amp; Spencer, 2019). To address AI access and equity issues, social work can support community-based initiatives that provide public access to computers or create mobile units that transport technology to communities. Partnering with local organisations,  such  as  schools  and  libraries,  may  provide  opportunities  to  improve access and promote training programs that focus on AI digital literacy.

## Conclusion

Within the context of accelerating AI, social  workers are at  the  forefront  of  changing workplace environments, which concurrently impact service user experiences and outcomes. While AI provides opportunities to address social problems and advance socially just outcomes, there are paradoxical risks that undermine the profession's commitment to ethical and just practice. These risks include structurally biased algorithms that cause discriminatory and unjust outcomes, a lack of social worker and community engagement in the AI life cycle, limited regulatory policies, the formation of ingenuine service userpractitioner relationships, and the negative impacts of AI misinformation and disinformation.  As  AI  increasingly  infiltrates  the  workplace  environments  of  social  workers, these issues are reshaping their roles and responsibilities. This article presents an EPIC model,  consisting  of  four  components:  (E)  ethics  and  justice;  (P)  policy  development and  advocacy;  (I)  intersectoral  collaboration,  and  (C)  community  engagement  and empowerment.  This  model  contributes  to  developing  an  articulated  and  collective approach  for  augmenting  the  advantages  of  AI,  while  mitigating  the  risks  posed  to ethical and just practice.

## Disclosure Statement

No potential conflict of interest was reported by the author(s).

## ORCID

Heather Boetto http://orcid.org/0000-0002-3606-7878

## References

- Alowais, S. A., Alghamdi, S. S., Alsuhebany, N., Alqahtani, T., Alshaya, A. I., Almohareb, S. N., Aldairem, A.,  Alrashed,  M.,  Bin  Saleh,  K.,  Badreldin,  H.  A.,  Al  Yami,  M.  S.,  Al  Harbi,  S.,  &amp; Albekairy, A. M. (2023). Revolutionizing healthcare: The role of artificial intelligence in clinical practice. BMC Medical Education , 23 (1), 1-689. https://doi.org/10.1186/s12909-023-04698-z
- Australian Association of Social Workers. (2016). Social media, information and communication technology:  Part  3. https://www.aasw.asn.au/about-aasw/ethics-standards/ethics-and-practiceguidelines/
- Balan, R., Dobrean, A., &amp; Poetar, C. R. (2024). Use of automated conversational agents in improving  young  population  mental  health:  A  scoping  review. NPJ  Digital  Medicine , 7 (1),  75-75. https://doi.org/10.1038/s41746-024-01072-1
- Benzie, A., &amp; Montasari, R. (2022). Artificial intelligence and the spread of mis- and disinformation.  In  R.  Montasari  (Ed.), Artificial  intelligence  and  national  security (pp.  1-18).  Springer. https://doi.org/10.1007/978-3-031-06709-9\_1


<!-- PAGE 13 -->


<!-- image -->

- Black, E., Williams, J., Madaio, M. A., &amp; Donti, P. L. (2020, April). A call for universities to develop requirements  for  community  engagement  in  AI  research.  In The  Fair  and  Responsible  AI Workshop at the 2020 CHI Conference on Human Factors in Computing Systems .  https://fairai.academicwebsite.com/publications/1480-a-call-for-universities-to-develop-requirementsfor-community-engagement-in-ai-research
- Blumenthal, D., &amp; Patel, B. (2014). The regulation of clinical artificial intelligence. NEJM AI , 1 (8). https://doi.org/10.1056/AIpc2400545
- Buolamwini, J., &amp; Gebru, T. (2018). Gender shades: Intersectional accuracy disparities in commercial gender classification. In Proceedings of Machine Learning Research 81:115, 2018 Conference on  Fairness,  Accountability,  and  Transparency (pp.  1-15).  https://proceedings.mlr.press/v81/ buolamwini18a.html
- Canadian Association of Social Workers. (2014). Social media use and social work practice. https:// www.casw-acts.ca/en/javascript%3A%20void%280%29%3B/casw-social-media-use-and-socialwork-practice
- Cave,  S.,  &amp;  Dihal,  K.  (2020).  The  whiteness  of  AI. Philosophy  &amp;  Technology , 33 (4),  685-703. https://doi.org/10.1007/s13347-020-00415-6
- Chan, C., &amp; Li, F. (2023). Developing a natural language-based AI-chatbot for social work training: An  illustrative  case  study. China  Journal  of  Social  Work , 16 (2),  121-136.  https://doi.org/10. 1080/17525098.2023.2176901
- Coghlan, S., Leins, K., Sheldrick, S., Cheong, M., Gooding, P., &amp; D'Alfonso, S. (2023). To chat or bot to chat: Ethical issues with using chatbots in mental health. Digital Health , 9 , 20552076231183542-20552076231183542. https://doi.org/10.1177/20552076231183542
- Dali,  K.,  &amp;  Caidi,  N.  (2023).  Social  work  education  for  the  digital  age:  Insight  from  information science. Social Work Education , 42 (5), 663-693. https://doi.org/10.1080/02615479.2022. 2057942
- Dankwa-Mullan, I., Scheufele, E. L., Matheny, M. E., Quintana, Y., Chapman, W. W., Jackson, G., &amp; South, B. R. (2021). A proposed framework on integrating health equity and racial justice into the  artificial  intelligence  development  lifecycle. Journal  of  Health  Care  for  the  Poor  and Underserved , 32 (2), 300-317. https://doi.org/10.1353/hpu.2021.0065
- Dung  Le, J., Chung, K., Quach, S., &amp; Thaichon, P. (2023). Introduction to artificial intelligence (AI): definition and scope of AI. In P. Thaichon, &amp; S. Quach (Eds.), Artificial intelligence  for  marketing  management (pp.  3-17).  Routledge.  https://doi.org/10.4324/978100328 0392-2
- Field, A., Coston, A., Gandhi, N., Chouldechova, A., Putnam-Hornstein, E., Steier, D., &amp; Tsvetkov, Y. (2023). Examining risks of racial biases in NLP tools for child protective services. Proceedings of  the  2023  ACM Conference on Fairness, Accountability, and Transparency (pp. 1479-1492). https://doi.org/10.1145/3593013.3594094
- Garimella, K., &amp; Chauchard, S. (2024). Is AI misinformation influencing elections in India? Nature (London) , 630(8015) , 32-34. https://doi.org/10.1038/d41586-024-01588-2
- Gignac, G. E., &amp; Szodorai, E. T. (2024). Defining intelligence: Bridging the gap between human and artificial perspectives. Intelligence (Norwood) , 104 , 101832. https://doi.org/10.1016/j.intell.2024. 101832
- Gough,  J.,  &amp;  Spencer,  E.  (2019).  Ethical  social  work  practice  in  the  technological  era.  In  S.M. Marson  &amp;  R.E.  McKinney  (Eds.), The  Routledge  handbook  of  social  work  ethics  and  values (pp. 249-256). Routledge. https://doi.org/10.4324/9780429438813-32
- Grant, D. G. (2018). Ethics and artificial intelligence in public health social work. In M. Tambe, &amp; E. Rice (Eds.), Artificial intelligence and social work (pp. 231-249). Cambridge. https://doi.org/ 10.1017/9781108669016.015
- Hodgson, D., Goldingay, S., Boddy, J., Nipperess, S., &amp; Watts, L. (2022). Problematising artificial intelligence in social work education: Challenges, issues and possibilities. The British Journal of Social Work , 52 (4), 1878-1895. https://doi.org/10.1093/bjsw/bcab168
- Huang, K., Joshi, A., Dun, S., &amp; Hamilton, N. (2024). AI regulations. In K. Huang, Y. Wang, B. Goertzel, Y. Li, S. Wright, &amp; J. Ponnapalli (Eds.), Generative AI security: Theories and practices (pp. 61-98). Springer. https://doi.org/10.1007/978-3-031-54252-7\_3


<!-- PAGE 14 -->


- Hui, V., Constantino, R. E., &amp; Lee, Y. J. (2023). Harnessing machine learning in tackling domestic violence - An integrative review. International Journal of Environmental Research and Public Health , 20 (6), 4984. https://doi.org/10.3390/ijerph20064984
- International Federation of Social Workers. (2018). Global social work statement of ethical principles. https://www.ifsw.org/global-social-work-statement-of-ethical-principles/
- Jacobi, C. B., &amp; Christensen, M. (2023). Functions, utilities and limitations: A scoping study of decision  support  algorithms  in  social  work. Journal  of  Evidence-Based  Social  Work , 20 (3), 323-341. https://doi.org/10.1080/26408066.2022.2159777
- James, A., &amp; Whelan, A. (2022). 'Ethical' artificial intelligence in the welfare state: Discourse and discrepancy in Australian social services. Critical Social Policy , 42 (1), 22-42. https://doi.org/10. 1177/0261018320985463
- Janiesch, C., Zschech, P., &amp; Heinrich, K. (2021). Machine learning and deep learning. Electronic Markets , 31 , 685-695. https://doi.org/10.1007/s12525-021-00475-2
- Kalota,  F.  (2024).  A  primer  on  generative  artificial  intelligence. Education  Sciences , 14 (2),  172. https://doi.org/10.3390/educsci14020172
- Khawaja,  Z., &amp;  Bélisle-Pipon, J. C. (2023). Your  robot  therapist is not your therapist: Understanding the role of AI-powered mental health chatbots. Frontiers in Digital Health , 5 , 1278186-1278186. https://doi.org/10.3389/fdgth.2023.1278186
- Kumar, V., Barik, S., Aggarwal, S., Kumar, D., &amp; Raj, V. (2023). The use of artificial intelligence for persons  with  disability:  A  bright  and  promising  future  ahead. Disability  and  Rehabilitation: Assistive Technology , 1-3. https://doi.org/10.1080/17483107.2023.2288241
- Lehtiniemi,  T.  (2024).  Contextual  social  valences  for  artificial  intelligence:  Anticipation  that matters in social work. Information, Communication &amp; Society , 27 (6), 1110-1125. https://doi. org/10.1080/1369118X.2023.2234987
- Mathiyazhagan, S., &amp; Patton, D. U. (2024). Towards just and equitable Web3: Social work recommendations for inclusive practice of AI policies. AI &amp; Society . Advance online publication. https://doi.org/10.1007/s00146-024-01994-0
- Meilvang, M. L. (2023). Working the boundaries of social work: Artificial intelligence and the profession of social work. Professions and Professionalism , 13 (1). https://doi.org/10.7577/pp.5108
- Meilvang, M. L., &amp; Dahler, A. M. (2024). Decision support and algorithmic support: The construction of algorithms and professional discretion in social work. European Journal of Social Work , 27 (1), 30-42. https://doi.org/10.1080/13691457.2022.2063806
- Michie, S., Thomas, J., Johnston, M., Aonghusa, P. M., Shawe-Taylor, J., Kelly, M. P., Deleris, L. A., Finnerty, A. N., Marques, M. M., Norris, E., O'Mara-Eves, A., &amp; West, R. (2017). The human behaviour-change project: Harnessing the power of artificial intelligence and machine learning for evidence synthesis and interpretation. Implementation Science: IS , 12 (1), 121-121. https:// doi.org/10.1186/s13012-017-0641-5
- Murphy,  J.  W.,  &amp;  Largacha-Martínez,  C.  (2022).  Decolonization  of  AI:  A  crucial  blind  spot. Philosophy &amp; Technology , 35 (4), 102. https://doi.org/10.1007/s13347-022-00588-2
- National  Association  of  Social  Workers  (NASW).  (2017). Standards  for  technology  in  social work  practice .  https://www.socialworkers.org/LinkClick.aspx?fleticket=lcTcdsHUcng%3d&amp;por talid=0
- Nordin, N., Zainol, Z., Mohd Noor, M. H., &amp; Chan, L. F. (2022). Suicidal behaviour prediction models  using  machine  learning  techniques:  A  systematic  review. Artificial  Intelligence  in Medicine , 132 , 102395-102395.
- Petering, R., Um, M., Alipourfard, N., Tavabi, N., Kumari, R., &amp; Gilani, S. N. (2018). Artificial intelligence to predict intimate partner violence. In M. Tambe, &amp; E. Rice (Eds.), Artificial intelligence  and  social  work (pp.  195-210).  Cambridge  University  Press.  https://doi.org/10.1017/ 9781108669016.002
- Reamer, F. G. (2023). Artificial intelligence in social work: Emerging ethical issues. International Journal of Social Work Values and Ethics , 20 (2), 52-71. https://doi.org/10.55521/10-020-205
- Rice, E., &amp; Tambe, M. (2018). Merging social work science and computer science for social good. In  M.  Tambe,  &amp;  E.  Rice  (Eds.), Artificial  intelligence  and  social  work (pp.  3-15).  Cambridge University Press. https://doi.org/10.1017/9781108669016.002


<!-- PAGE 15 -->


<!-- image -->

- Sheikh, H., Prins, C., &amp; Schrijvers, E. (2023). Mission AI: The new systems technology .  Springer. https://doi.org/10.1007/978-3-031-21448-6\_2
- Shin, D., Koerber, A., &amp; Lim, J. S. (2024). Impact of misinformation from generative AI on user information  processing:  How  people  understand  misinformation  from  generative  AI. New Media &amp; Society . Advance online publication. https://doi.org/10.1177/14614448241234040
- Taouktsis, X., &amp; Zikopoulos, C. (2024). A decision-making tool for the determination of the distribution center location in a humanitarian logistics network. Expert Systems with Applications , 238 , 122010. https://doi.org/10.1016/j.eswa.2023.122010
- United Nations. (2024). Seizing the opportunities of safe, secure, and trustworthy artificial intelligence systems for sustainable development. https://press.un.org/en/2024/ga12588.doc.htm
- Victorian Government. (2024). Investigation into the use of ChatGPT by a child protection worker . Office of Victorian Information Commissioner. https://ovic.vic.gov.au/regulatory-action/ investigation-into-the-use-of-chatgpt-by-a-child-protection-worker/
- Wadden, J. J. (2021). Defining the undefinable: The black box problem in healthcare artificial intelligence. Journal  of  Medical  Ethics , 48 (10),  764-768.  https://doi.org/10.1136/medethics-2021107529
- Walsh, C. G., Ribeiro, J. D., &amp; Franklin, J. C. (2017). Predicting risk of suicide attempts over time through  machine  learning. Clinical  Psychological  Science , 5 (3),  457-469.  https://doi.org/10. 1177/2167702617691560
- World  Economic  Forum.  (2024). The  global  risks  report (19th  ed.).  https://www.weforum.org/ publications/global-risks-report-2024/
- Xue, J., Zhang, B., Zhao, Y., Zhang, Q., Zheng, C., Jiang, J., Li, H., Liu, N., Li, Z., Fu, W., Peng, Y., Logan, J., Zhang, J., &amp; Xiang, X. (2023). Evaluation of the current state of chatbots for digital health:  Scoping  review. Journal  of  Medical  Internet  Research , 25 (1),  e47217-e47217.  https:// doi.org/10.2196/47217