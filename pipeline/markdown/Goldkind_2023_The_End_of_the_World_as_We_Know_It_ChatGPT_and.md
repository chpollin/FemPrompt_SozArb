---
source_file: Goldkind_2023_The_End_of_the_World_as_We_Know_It_ChatGPT_and.pdf
conversion_date: 2026-02-03T18:29:27.267751
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
## COMMENTARY

## The End of the World as We Know It? ChatGPT and Social Work

Lauri Goldkind, Lea Wolf, Alexis Glennon, Juan Rios, and Laura Nissen

R eleased on November 30, 2022, Chat GPT is a chatbot powered by artificial intelligence (AI) that responds to prompts posed as questions, producing intelligible, mostly accurate text responses. ChatGPT is built on natural language processing , a branch of AI initiated in the 1960s that seeks to program a computer's capacity to understand text and spoken words (Wei et al., 2018). The introduction of ChatGPT was explosive, generating both awe and fear from users and pundits across domains, age, and expertise. Historically, social work has neither embraced nor capitalized on the opportunities presented by new technologies (Goldkind et al., 2016), and AI is no exception. ChatGPT offers us an opportunity to consider how AI will disrupt social work practice in the near term, by providing a portal through which to reflect on strategies that promote the most just use of technology. We urge social workers to join existing cross-disciplinary global conversations that purposefully engage the evolution of AI, explore its implications, and advocate for its fair use.

## CHATGPT OVERVIEW

The Oxford Dictionary of English defines AI as the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision making, and translation between languages (Stevenson, 2015). While the term evokes a future populated by human-like machines, AI already shapes and speeds up our daily lives, powering Amazon recommendations, employment screening, social media feeds, and the smartphone traffic apps that guide us to work.

ChatGPT is among the most complex language models yet assembled, and its responses imitate the language patterns of humans with shocking verisimilitude. ChatGPT was trained on a massive 40 gigabytes of text data (while the entire works of

Shakespeare comprise about 5 megabytes; Kitchin, 2014). The extant texts training these language models are generally not inclusive of diverse perspectives and frequently reflect larger biases of society. Unlike prior bots, ChatGPT is adept at answering openended questions and can admit mistakes and challenge flawed logic. While its creators have attempted to address some ethical implications of the tool, making good-faith attempts to censor bias and hate speech, concerns persist, inspiring constant media attention.

## CHATGPT IN ACTION

Anenthusiastic public has already engaged ChatGPT in everything from writing love letters to grant proposals. For social workers, the best way to comprehend how the chatbot could augment or disrupt practice is to watch it work. Figure 1 illustrates a ChatGPT-generated case note for a client diagnosed with anxiety. The document, while generic, offers compelling evidence of ChatGPT's ability to produce contextually appropriate, 'human-sounding' text.

Public reaction to ChatGPT has emphasized its novelty, describing the tool either as a crisis or as an unprecedented opportunity. Yet ChatGPT represents one single node in the development of AI: a powerful, captivatingly simple interface that has evolved already since its introduction. In this commentary we offer prompts to actively consider ChatGPT's potential across several domains, challenging readers to engage both its specific effects across dimensions of practice and, more broadly, the sociopolitical implications of this tool in use.

Social work education is reckoning with the reality that ChatGPT allows students to generate course assignments or to immediately produce written items in an internship setting by using a simple typed question. Such actions eliminate


<!-- PAGE 2 -->


## Figure 1: A Case Note Composed by ChatGPT

<!-- image -->

fundamental engagement with production of professional knowledge. Social work educators might consider the role ChatGPT will play in their classrooms and how to teach students to ethically use these tools. Additionally, alternative assessment strategies could be deployed to allow for meaningful demonstrations of competency. Social work education must expand training on the Code of Ethics to speak to new AI tools. Every example of ChatGPT in practice should be paired with an activity that asks learners to conceptualize the reality of its impact across populations, institutions, and culture.

In practice, ChatGPT could support transformational efficiencies at the organizational level, speeding the production of grant writing and fundraising activity, easing documentation demands, providing easy access to advanced technical problem solving, and potentially lowering the cost of staffing. Organizations will need to move rapidly to consider and distribute policies that allow them to maximize the utility of AI with practices that align with their mission. AI and chatbots will continue to evolve, and the advent of ChatGPT offers organizations a critical opportunity to conceptualize which tasks can be ethically automated, and to invest in providing ongoing training to employees across levels and functions.

ChatGPT offers resources to clients and provides social workers with novel tools to support them. Clients can generate vital documents, speed up job duties, or write a letter to a landlord or judge. Social workers can produce treatment plans, generate psychoeducation materials, and rapidly document client contact or progress. Workers and clients can collaborate in real time to reflect upon goals, to advance shared learning, or to materialize their discoveries.

Few practitioners have access to training that would position them to interrogate the use of ChatGPT or its implications. Congruent with the ethical imperative to maintain competency, professionals will need channels to learn about emerging AI tools, seeking guidance from professional organizations, translating the Code of Ethics into new contexts, crowdsourcing effective practice, and supporting clients to think critically about emerging technologies.

## SOCIAL JUSTICE IMPLICATIONS

AI is a sophisticated set of mechanisms, and even individuals whose access to technology is augmented by a functional knowledge of its workings may lack the skills necessary to navigate machine learning tools or to discern when and how AI is


<!-- PAGE 3 -->


shaping their experience. As AI tools grow in capacity and complexity, and as they are incorporated, increasingly, into the structures that govern social life, vulnerable populations may face accelerating marginalization. Evidence shows that the existing use of advanced technological tools-in arenas like sentencing or risk assessment in child welfare-has exerted disproportionate impact upon marginalized populations, because the construction and deployment of these technologies amplifies existing bias and discrimination (Gillingham, 2019). Post hoc fixes that control for cumulative bias across AI-driven technologies are in development, but so far offer insufficient redress. Social workers are not uniquely responsible for assessing and remediating the ethical harms associated with AI: An entire global ecosystem is working on new types of regulations, ethics, guidelines, and functional capacities to promote meaningful and life-affirming use of AI. It is, however, critical for individual social workers and the profession to override hesitation, seek information, and enter this dialogue.

## CONCLUSION

ChatGPT is-fleetingly-the most advanced publicly available AI; however, the questions it poses for social work are both urgent and foundational. Its advent asks us to undertake a realistic census of the core functions of social work and contemplate which human actions should not be supplanted by intelligent machines. AI tools may automate some human tasks, but they have no intrinsic ethics, do not build relationships or identify social problems, and cannot build community. Our work is not to assign a moral valence to emerging tools but to consider a complex human-AI ecology approach; engage in developmental, relational, and political dialogue; and insist that imagination be grounded in human rights. ChatGPT offers an opportunity to commit to the functional necessity of futures thinking. SW

## REFERENCES

- Gillingham, P. (2019). Decision support systems, social justice and algorithmic accountability in social work: A new challenge. Practice , 31 , 277-290.
- Goldkind, L., Wolf, L., &amp; Jones, J. (2016). Late adapters? Howsocial workers acquire knowledge and skills about technology tools. Journal of Technology in Human Services , 34 , 338-358.
- Kitchin, R. (2014). The data revolution: Big data, open data, data infrastructures and their consequences . SAGE.
- Stevenson, A. (Ed.). (2015). Artificial intelligence. In Oxford dictionary of English (3rd ed.). Retrieved October 30, 2023, from https://www.oxfordreference.com/ display/10.1093/acref/9780199571123.001.0001/ m\_en\_gb0042040?rskey ¼ rVXgY0&amp;result ¼ 1
- Wei, C., Yu, Z., &amp; Fong, S. (2018, February 26). How to build a chatbot: chatbot framework and its capabilities. In Proceedings of the 2018 10th International Conference on Machine Learning and Computing (pp. 369-373). Association for Computing Machinery. https://doi .org/10.1145/3195106.3195169

Lauri Goldkind, PhD, LMSW, is associate professor, Graduate School of Social Service, Fordham University, 113 West 60th Street, New York, NY 10023, USA; email: goldkind@fordham.edu. Lea Wolf, LMSW, is a doctoral candidate, Graduate Center, City University of New York, New York, NY, USA. Alexis Glennon, LMSW, is a doctoral candidate, School of Social Work, University of Buffalo, Buffalo, NY, USA. Juan Rios, DSW, LMSW, is assistant professor, Department of Sociology, Anthropology, Social Work and Criminal Justice, Seton Hall University, South Orange, NJ, USA. Laura Nissen, PhD, LMSW, is professor, School of Social Work, Portland State University, Portland, OR,USA.

Original manuscript received February 15, 2023 Editorial decision February 27, 2023 Accepted March 6, 2023

Advance Access Publication November 16, 2023