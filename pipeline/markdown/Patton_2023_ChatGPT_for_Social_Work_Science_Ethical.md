---
source_file: Patton_2023_ChatGPT_for_Social_Work_Science_Ethical.pdf
conversion_date: 2026-02-03T18:46:00.864092
converter: docling
quality_score: 95
---

<!-- PAGE 1 -->
## ChatGPT for Social Work Science: Ethical Challenges and Opportunities

Desmond Upton Patton University of Pennsylvania Aviv Y. Landau University of Pennsylvania Siva Mathiyazhagan University of Pennsylvania

ABSTRACT In this invited paper, we describe the potential use of ChatGPT in social workscience,exploringopportunitiesandethicalchallengesrelated to thedeployment of large language models (LLM), speci /uniFB01 cally ChatGPT, for social work science. We offer several preliminary recommendations for the ethical use of ChatGPT in social work science and call on the profession ' s governing organizations to develop a comprehensive ethical framework for the use of LLMs such as ChatGPT in social work research.

KEYWORDS: generative arti /uniFB01 cial intelligence, large language models, ChatGPT, social work research, social work ethics doi: 10.1086/726042

A rti /uniFB01 cial intelligence (AI) innovations have radically changed how society functions, impacting how humans engage and communicate with each other in online and of /uniFB02 ine environments. AI systems -technologies that enable computers to perform advanced tasks ' in a way that is similar to how humans solve problems ' (Brown, 2021, para. 8) -have become universal, informing the entire continuum of human decision-making (e.g., driving, ordering food, banking, hiring, medical treatment, and child welfare responses). Among the AI tools that affect social work research and practice, the generative AI tool ChatGPT has garnered signi /uniFB01 cant attention and popularity (Singer et al., 2023).

ChatGPT offers exciting opportunities for innovation in social work science, surfacing theories, ideas, innovations, processes, and approaches that could fundamentally reshape the discipline. In the not-so-distant future, we anticipate social work scientists may use ChatGPT for education, research, practice, social media, and other allied creative and scienti /uniFB01 c activities related to social work. The social work scienti /uniFB01 c community should be prepared to address critical questions around client wellbeing, misinformation, credibility, ethical practices, and bias and harm caused by sourceless information.


<!-- PAGE 2 -->


Given these justi /uniFB01 ed cautions, we posit that the social work science community should undertake conversations that aim to identify, understand, and provide thought leadership for the potentially problematic features of AI that will affect social work science. In this invited paper, we describe the potential use of ChatGPT in social work science, exploring opportunities and ethical challenges related to the deployment of large language models (LLMs), speci /uniFB01 cally ChatGPT for social work science.

ChatGPT is an arti /uniFB01 cial intelligence chatbot. It is a /uniFB01 ne-tuned version of an LLM -an arti /uniFB01 cial intelligence system that processes and analyzes natural language, processing data such as text, speech, and other forms of communication. As a pretrained system, ChatGPT /uniFB01 nished training on natural language data in early 2022 by OpenAI, the AI laboratory that aims to create advanced AI systems that aid society. Recently, OpenAI introduced GPT-4, a large multimodal model that has been incorporated into the Bing search engine. GPT-4 allows users to type or upload images for an immediate human-like reply (OpenAI, 2023a), and it can be /uniFB01 ne-tuned for speci /uniFB01 c tasks such as language translation, answering questions, creating content, and text completion (e.g., completing sentences). Because LLMs are trained on large amounts of data that may re /uniFB02 ect the biases and viewpoints of the individuals and groups who create them, some ethicists and researchers are concerned that LLMs operating in search engines may perpetuate bias and reinforce inequality through the information presented in search results (Okerlund et al., 2022).

## The Ethics of Using ChatGPT for Social Work Science

Before we critique the limitations of ChatGPT in social work science, we will begin by outlining some of its exciting potential opportunities. Social work scientists have long been leaders in reimagining how the social science community conducts research. Social work scientists research, design, and implement rigorous studies that center community-level expertise from a strengths-based perspective, using interdisciplinary collaboration to address global challenges. ChatGPT offers an opportunity to push the boundaries of what we study, fostering new conversations and elevating emerging methods, editing, research, and presentation approaches powered by LLMs. Tools such as ChatGPT can help to uncover links among data sets, disciplines, and ideas that we have yet to pursue, or for which we have conducted only cursory analysis. Moreover, ChatGPT enables us to effectively and ef /uniFB01 -ciently transfer social justice and antiracist values and practices to the next generation of social work scientists.

## Unpacking the Possibilities

## New Conversations

As an AI tool for social work science, ChatGPT can generate text for possible research ideas and/or clinical simulations that force researchers and clinicians to challenge assumptions. For example, a group of social work scientists used


<!-- PAGE 3 -->


ChatGPT to answer multiple-choice questions on the Association of Social Work Boards exam to identify validity challenges (Victor et al., 2023). ChatGPT has the potential to help social work scientists ask innovative questions by providing a proof of concept. The tool can also help to create simulated environments that challenge assumptions baked into the type of questions we ask, the tools we use to ask those questions, who is involved in analyzing those questions, and how /uniFB01 ndings are disseminated. The following section will provide examples of how ChatGPT could potentially support how we develop and critique research questions.

## Innovative Questions

ChatGPT may become a foundation for drafting surveys, developing qualitative interview prompts, and developing new study metrics and other research tools. If it does, social work scientists may generate unexpected, original, and interdisciplinary research questions that could illuminate some of the black-box challenges in data sets with large amounts of unstructured text (e.g., interviews, case notes, surveys; Dwivedi et al., 2023).

## Social Justice and Antiracist Lens

Social work scientists may /uniFB01 ne-tune ChatGPT capabilities through a social justice and antiracist lens applied to language analysis, text summarization, and feedback/prompts. First, ChatGPT could identify language in case notes and referrals (e.g., child welfare/child abuse and neglect) that might contain biased or discriminatory language, which could reproduce bias in the data and labeling used in natural language processing research. ChatGPT might also help social work scientists generate content that provides the pros and cons of abolitionist perspectives on the child welfare system, potentially prompting new research questions or informing evidence-based discussions. Lastly, ChatGPT could also be used to provide feedback on research manuscripts, case notes, and grant applications, identifying biased language or validating labels or annotations of textual data between student annotators and community experts engaged in participatory action research. A free version of ChatGPT could potentially support scholars who are Black, Indigenous, and People of Color (BIPOC) and from underresourced institutions, leveraging costeffective generative AI technology to advance innovative interdisciplinary and antiracist research.

## Advancing Qualitative Methods With ChatGPT

## Research Assistance

ChatGPT has the potential to identify, explore, and develop emerging interdisciplinary and domain-speci /uniFB01 c sample research questions and identify new areas of research. As a research assistant used in collaboration with human intelligence, ChatGPT could provide budding researchers with a wider range of questions and


<!-- PAGE 4 -->


ideas that would expand social work ' s horizons. For example, a social work scientist could input a prompt describing the social work professional ' s involvement in policing and then ask ChatGPT to provide examples of how this collaboration could be harmful and helpful; these examples could then be used as prompts for simulated experiments to test assumptions under conditions where social work involvement in policing was either abolished or present.

## Generating Qualitative Themes

ChatGPT can support social work scientists in generating qualitative themes. For example, ChatGPT can provide an overview of general ideas from interviews, focus group discussions, and observations, helping researchers to brainstorm new perspectives and generate new themes from qualitative data. Furthermore, ChatGPT could help explore meanings and patterns within data to help better organize qualitative data sets.

## Qualitative Data Editor

Social work scientists conduct mixed-methods research and implementation science -both online and of /uniFB02 ine -with individuals, groups, and communities and generate a considerable amount of unstructured data from research meeting transcripts. ChatGPT can address errors in transcription and synthesize data sets into standard English. For example, if ChatGPT is asked to edit qualitative transcripts with a list of conditions, it can instantly edit and provide a more re /uniFB01 ned version; doing so conserves time and human effort and hastens delivery of results. However, such edits require human validation prior to professional or scienti /uniFB01 c dissemination.

## Presentation Development Assistant

ChatGPT can help social work scientists with preparation of professional presentations and data tables by rapidly generating simpli /uniFB01 ed versions of complex topics, theories, approaches, and frameworks. This assistance helps social work scientists to convey concepts easily, gather information ef /uniFB01 ciently, and present creatively and effectively.

## Limitations of ChatGPT in Social Work Science

The applications of LLMs in social work research are in their infancy, and a range of concerns emerge as we consider the implications of its use in the /uniFB01 eld. As social work scientists, we must recognize and raise awareness of ChatGPT ' s limitations, including its ability to think and generate new ideas. In their paper on the bureaucratic roots of Big Data and algorithms, Caplan and Boyd (2018) argued that algorithms like ChatGPT are themselves bureaucrats, leveraging existing oppressive institutional thinking to work ef /uniFB01 ciently. Like a bureaucratic system, ChatGPT enforces thought without compassion, reason, speculation, or imagination. Although AI tools such as ChatGPT may afford the 21st century social work scientist opportunities to produce new conversations, innovative questions, and new data sets, we


<!-- PAGE 5 -->


must constantly engage in critically re /uniFB02 ective dialogue on the utility of AI tools for addressing our most pressing social problems; share our concerns at our respective universities, organizations, and national conversations; locate potential opportunities; and determine parameters for ethical and empirically sound use of AI tools in social work research.

## Addressing Bias

The amount of data and computational power required to train LLMs can present barriers to use, particularly for researchers, academic departments, and universities with limited resources. As an AI model, ChatGPT is trained with a large corpus of nonveri /uniFB01 able text from the Internet. This could lead to bias, especially if the text used to train it does not represent diverse perspectives or scholarship by BIPOC, people with disabilities, LGBTQIA 1 individuals, and those with other underrepresented identities. Further, ChatGPT generates text by predicting the next word based on the previous words. Thus, it could amplify and perpetuate existing bias based on race, gender, sexuality, ability, caste, and other identities by selecting words or phrases that only fall within mainstream white English.

## Legal and Ethical Considerations

OpenAI ' s ChatGPT disclaimer clearly indicates that ChatGPT may produce inaccurate information about people, places, and/or facts (OpenAI, 2023b). Social work scientists should be aware of this limitation, as well as other legal and ethical challenges related to the use of ChatGPT in scienti /uniFB01 c work, including critical questions around data privacy, con /uniFB01 dentiality, and informed consent. For example, without sources, it is unclear how data is collected and processed or how consent is received to release data.

## Data Privacy, Con /uniFB01 dentiality, and Informed Consent

Since ChatGPT offers text from referenceless Internet sources, it has a risk of amplifying legal and ethical issues related to data privacy and informed consent from the authors of the content. There is no clear evidence for ChatGPT maintaining con /uniFB01 -dentiality about individual personal data, and how ChatGPT ensures privacy and con /uniFB01 dentiality is unclear. This limitation might lead to legal and ethical consequences for social work scientists, who should consider whether sensitive data such as names, ZIP codes, mental health conditions, income, or identity-related information are protected within the AI system and are not collected for further algorithm development. It is also important to note that it is the responsibility of social work scientists to cross-validate the source of the information, data privacy, con /uniFB01 dentiality regulations, and informed consent requirements prior to use of any information from ChatGPT in their scienti /uniFB01 c work. Furthermore, social work scientists should prepare data security plans with their institutional review board to prevent ethical breaches by using ChatGPT in their scienti /uniFB01 c work.


<!-- PAGE 6 -->


## Academic Misconduct

As in many areas of academia, the topic of academic misconduct is the focus of discussions in social work science. The broader academic community has voiced concern in public media that students will use ChatGPT to plagiarize assignments, research papers, /uniFB01 eld reports, and other academic writings (Huang, 2023). Although OpenAI offers a new, though limited, classi /uniFB01 er to distinguish between AI-generated and human-written text, AI-generated content cannot be identi /uniFB01 ed or distinguished from human-written content by plagiarism or similarity-check software.

OpenAI ' s features do allow social work scientists to cross-validate the credibility of academic writing. However, the technology is too immature to determine how effectively this feature would support social work scientists ' expectation of academic integrity. Assessment of social work students ' academic papers and research manuscripts may need to employ new techniques and tools to identify academic misconduct. Arriving at a standard approach for validating materials submitted by students, staff, and scholars will require critical conversations at national academic meetings as well as content modules for instructors, academic affairs of /uniFB01 cers, and deans.

Social work is a practice-driven, transdisciplinary profession that promotes people-centric, evidence-based approaches. ChatGPT offers basic, foundation-level, synthesized information to its users. It is not equipped to provide context or detailed nuance. As such, ChatGPT is best suited as an assistive technology tool for social work scientists. Recognizing this limited utility, several schools restrict access to ChatGPT on school computers (Roose, 2023). Social work research requires a high level of local context and re /uniFB02 exivity to generate new knowledge, case reports, and adherence to a code of ethics. ChatGPT provides large-scale meta-level analyses, but social work science writing requires nuanced, micro-level analysis, which must be done by humans.

## Recommendations for Use of ChatGPT in Social Work Science

Social work scientists incorporating ChatGPT and other LLMs in academic and professional writing for public dissemination and scienti /uniFB01 c publication should ensure academic integrity by adhering to ethical considerations. Guidance is being developed for academic use of ChatGPT and other LLMs in academic writing (Else, 2023; Marquart &amp; Goldkind, 2023; Nature, 2023; Stokel-Walker, 2023). We offer the following recommendations for ensuring ethical use of AI-driven resources in scienti /uniFB01 c writing.

## 1. Transparency

Currently, there are few requirements to disclose whether AI is used in content generation. Academic writing must clearly document the use of ChatGPT/LLMs, highlight which LLM was used, describe and disclose all potential con /uniFB02 icts of interest,


<!-- PAGE 7 -->


explain in detail how the LLM was used with prompts to understand the context, explain where in the writing LLMs were used, and discuss limitations of use and results.

## 2. Fact-Checking

Generative AI offers unveri /uniFB01 ed information without citing appropriate sources. Academic writing must clearly state how authors verify information sources, cite authors appropriately, validate the accuracy of the information presented, and ensure that no misinformation is present.

## 3. Authorship

ChatGPT/LLMs should not be credited as authors/coauthors of any form of academic writing within social work science. Social work scientists should retain ownership of their research and research products while cautiously and ethically using AI tools to support their work.

## 4. Attribution

Academic papers should credit the original sources of ideas presented by LLMs. If social work scientists cannot locate original sources, they should clearly explain what efforts have been made to locate and appropriately cite original sources.

## 5. Inclusion and Social Justice

LLMs commonly scrape information from online sources and, after scraping, provide top-rated or most-accessed content without identifying the sources used. Thus, LLMs may be more likely to offer Eurocentric and white-centric content and to ignore literature and other information from BIPOC authors and authors from the Global South. If so, this practice would perpetuate existing social and academic exclusions. Social work scientists must be aware of social justice and antiracist principles when using LLMs. To practice social justice and inclusion in LLM-supported academic writing, social work scientists should adopt an antiracist research framework and approaches (Goings et al., 2023) to develop prompts that explicitly ask to identify the work of BIPOC scholars and resources and perspectives from underrepresented communities (van Dis et al., 2023), which will enable ChatGPT to offer more inclusive and social-justice-driven responses to research inquiries.

Building on these preliminary recommendations, the National Association of Social Workers, Council of Social Work Education, Society for Social Work and Research, American Psychological Association, and International Federation of Social Workers should develop a comprehensive ethical framework within which social work scientists can agree to use ChatGPT and other LLMs in professional and academic writing and practice.


<!-- PAGE 8 -->


## Conclusion

ChatGPT could be a valuable tool for social work science. However, the social work scienti /uniFB01 c communitymustwrestlewith the uncertainties of ChatGPT and broader hyperbolic AI headlines that come with big promises to revolutionize research (Chomsky, 2023). The prominence of tools such as ChatGPT offers an opportunity for scienti /uniFB01 c social work organizations such as the Society for Social Work and Research to engage in timely conversations and agenda setting through working groups or a congressonthespeci /uniFB01 c andnuancedopportunitiesandchallengesofAIandtools like ChatGPT for social work science.

Although this paper focuses on the ethics of applying ChatGPT for social work science, future dialogue may also include a closer look at how AI and LLMs impact how social work scientists design research, including how we generate research questions and deeper moral thinking about use of AI to advance science in traditional social work spaces, including, but not limited to, child welfare, criminal justice, and mental health.

Social work scientists might also consider advancing antiracist and social justice frameworks as ethical guidelines or essential characteristics. New frameworks and guidelines could help social work and other scientists determine if and when they should use AI or tools like ChatGPT for their research or inform new processes that shape how AI tools are used in social work science. In deciding whether social work science should take up ChatGPT, social work scientists should ask themselves several questions:

- How does ChatGPT affect the future of social work research?
- Could ChatGPT aid social work science in reimagining research ethics?
- Can ChatGPT push researchers in social work and related disciplines to ask new, deeper, more re /uniFB01 ned questions centered on ethics, community, and antiracist approaches?

It is important for the broader social work science community to directly engage with ChatGPT and other AI tools to fully explore and understand the potential role of AI in advancing social work science. Through direct engagement with ChatGPT (e.g., free or paid subscription to OpenAI, reading groups, panel discussions, and conference presentations), social work scientists may gain a deeper understanding of its capabilities and limitations, as well as its potential impact on the /uniFB01 eld. This engagement can help us develop strategies to effectively integrate AI into research, create ethical guidelines and framework aligned with social work ' s code of ethics, or create new avenues that provide evidence-based critiques for deploying AI across traditional social work research practice areas. Ignoring the role of ChatGPT and other AI tools in social work science would be a missed opportunity to leverage the strengths of social work science (e.g., holistic approaches, community


<!-- PAGE 9 -->


empowerment, interdisciplinary collaboration) to advance research, theory, and ethics to address complex social problems.

Social innovation, ethics, and critical re /uniFB02 exivity are essential for advancement in social work science, opening opportunities for social work scientists to provide an inclusion and justice lens for advances in AI science and social work. We advocate for social work scientists to engage ChatGPT with care and caution, following the profession ' s ethical guidelines while simultaneously promoting professional integrity. It is time for the social work profession to formulate ethical guidelines that provide guardrails for the use of AI tools in social work science while centering human rights and social justice.

## Author Notes

- Desmond Upton Patton , PhD, MSW, is the Schwartz University Professor at the University of Pennsylvania School of Social Policy and Practice, Annenberg School for Communication, and Department of Psychiatry.
- Aviv Y. Landau , PhD, MSW, is a research assistant professor at the University of Pennsylvania School of Social Policy and Practice.
- Siva Mathiyazhagan , PhD, is a research assistant professor at the University of Pennsylvania School of Social Policy and Practice.
- Correspondence regarding this article should be directed to Desmond Upton Patton, 3901 Walnut, Philadelphia, PA 19130 or via e-mail to dupatton@upenn.edu.

## Acknowledgments

We thank Elisha Lim, PhD, for their thoughtful feedback on this commentary.

## References

- Brown, S. (2021, April 21). Machine learning, explained . MIT Sloan School of Management. https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained
- Caplan, R., &amp; Boyd, D. (2018). Isomorphism through algorithms: Institutional dependencies in the case of Facebook. Big Data &amp; Society , 5 (1). https://doi.org/10.1177/2053951718757253
- Chomsky, N. (2023, March 8). Noam Chomsky: The false promise of ChatGPT. The New York Times . https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html
- Dwivedi, Y. K., Kshetri, N., Hughes, L., Slade, E. L., Jeyaraj, A., Kar, A. K., Baabdullah, A. M., Koohang, A., Raghavan, V., Ahuja, M., Albanna, H., Albashrawi, M. A., Al-Busaidi, A. S., Balakrishnan, J., Barlette, Y., Basu, S., Bose, I., Brooks, L., Buhalis, D., . . . Wright, R. (2023). ' So what if ChatGPT wrote it? ' Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management , 71 , Article 102642. https://doi.org/10.1016/j .ijinfomgt.2023.102642
- Else, H. (2023, January 12). Abstracts written by ChatGPT fool scientists. Nature . https://doi.org /10.1038/d41586-023-00056-7
- Goings, T. C., Belgrave, F. Z., Mosavel, M., &amp; Evans, C. B. R. (2023). An antiracist research framework: Principles, challenges, and recommendations for dismantling racism through research. Journal of the Society for Social Work and Research , 14 (1), 101 -128. https://doi.org/10 .1086/720983


<!-- PAGE 10 -->


- Huang, K. (2023, January 16). Alarmed by AI chatbots, universities start revamping how they teach. The New York Times . https://www.nytimes.com/2023/01/16/technology/chatgpt -arti /uniFB01 cial-intelligence-universities.html
- Marquart, M., &amp; Goldkind, L. (2023, March 8). ChatGPT: Implications for social work education and practice [Virtual session]. 2023 NASW-NYC Social Work Month Series. https://academic commons.columbia.edu/doi/10.7916/axhj-x577
- Nature. (2023, January 24). Tools such as ChatGPT threaten transparent science; here are our ground rules for their use . https://doi.org/10.1038/d41586-023-00191-1
- Okerlund, J., Klasky, E., Middha, A., Kim, S., Rosenfeld, H., Kleinman, M., &amp; Parthasarathy, S. (2022). What ' s in the Chatterbox? Large language models, why they matter, and what we should do about them (Technology Assessment Project report). University of Michigan, Gerald R. Ford School of Public Policy, Science, Technology, and Public Policy Program. https://stpp.ford school.umich.edu/sites/stpp/ /uniFB01 les/2022-05/large-language-models-TAP-2022/uniFB01 nal-051622 .pdf
- OpenAI. (2023a). GPT-4 technical report . https://arxiv.org/abs/2303.08774
- OpenAI. (2023b). Terms of use . https://openai.com/policies/terms-of-use
- Roose, K. (2023, January 12). Don ' t ban ChatGPT in schools. Teach with it. The New York Times . https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html
- Stokel-Walker, C. (2023, January 18). ChatGPT listed as author on research papers: Many scientists disapprove. Nature . https://doi.org/10.1038/d41586-023-00107-z
- Singer, J. B., BÃ¡ez, J. C., &amp; Rios, J. A. (2023). AI creates the message: Integrating AI language learning models into social work education and practice. Journal of Social Work Education , 59 (2), 294 -302. https://doi.org/10.1080/10437797.2023.2189878
- van Dis, E. A., Bollen, J., Zuidema, W., van Rooij, R., &amp; Bockting, C. L. (2023). ChatGPT: Five priorities for research. Nature , 614 (7947), 224 -226. https://www.nature.com/articles/d41586 -023-00288-7
- Victor, B. G., Kubiak, S., Angell, B., &amp; Perron, B. E. (2023). Time to move beyond the ASWB licensing exams: Can generative arti /uniFB01 cial intelligence offer a way forward for social work? Research on Social Work Practice , 33 (5), 511 -517. https://doi.org/10.1177/10497315231166125

Manuscript submitted: March 14, 2023

First revision submitted: April 9, 2023

Second revision submitted: May 4, 2023

Accepted: May 4, 2023

Electronically published: August 3, 2023