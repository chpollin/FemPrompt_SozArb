---
source_file: Ahn_2025_Artificial_Intelligence_(AI)_literacy_for_social.pdf
conversion_date: 2026-02-03T08:40:25.201710
converter: docling
quality_score: 95
---

## Arti /uniFB01 cial Intelligence (AI) Literacy for Social Work: Implications for Core Competencies

Eunhye Ahn

Washington University in St. Louis

Moon Choi

Korea Advanced Institute of Science and Technology

Patrick Fowler

Washington University in St. Louis

In Han Song

Yonsei University

ABSTRACT Artificial intelligence (AI) is fundamentally reshaping society, offering new opportunities while potentially intensifying socioeconomic inequalities. For social workers working with marginalized populations, understanding AI ' s societal impact is crucial, even if they do not directly engage with AI tools. This invited paper explores how AI literacy -the knowledge and skills to understand, use, and critically evaluate AI systems -can enhance social workers ' ability to support communities navigating AI-driven changes. We review AI ' s impacts and applications in social work, explore their implications for the profession, and discuss their effects on social work core competencies. Speci /uniFB01 cally, we discuss how each of the social work com­ petencies should evolve in response to AI-driven societal changes to better prepare social workers to support affected communities. By embedding AI literacy into core competencies, social workers can better address emerging challenges and promote equity in an AI-in /uniFB02 uenced society.

KEYWORDS: arti /uniFB01 cial intelligence (AI) literacy, social work core competencies, AI impacts on social work, AI-driven social change, AI ethics in social work

doi:

10.1086/735187

A rti /uniFB01 cial intelligence (AI) in /uniFB02 uences many aspects of daily life, reshaping how people work, learn, communicate, and make decisions across various sectors (Maslej et al., 2024). The U.S. National Arti /uniFB01 cial Intelligence Initiative Act has reinforced this shift by prioritizing AI research in critical areas such as health care and workforce development (Harris, 2023). In social work, AI has shown potential to support human decision-making by identifying unmet needs and optimizing re­ source allocation through predictive analytics and pattern recognition (Cresswell et al., 2020; Lee et al., 2024; McAdams et al., 2022).

Machine learning models analyze patterns in past data to estimate the likelihood of future events. For instance, a supervised machine learning model uses prelabeled outcomes -such as data from prior cohorts linking student sociodemographic and

©

2025

Society

Society for

for

Social

Social

Work

Work and

and

Research.

Research.

All rights

reserved.

Published https://doi.org/10.1086/735187

by

The

University of

Chicago

Press for

the

academic characteristics to high school graduation -to help identify students who may bene /uniFB01 t from additional support. Unsupervised machine learning, on the other hand, does not use prelabeled outcomes but instead groups individuals based on shared patterns in data, such as recognizing students who may have undiagnosed learning disabilities based on standardized test trends. Neural networks, including large lan­ guage models and generative AI, learn meaningful patterns of associations across multiple layers that represent complex hierarchies similar to the human brain. Recent advances in generative AI offer additional promise for social work applications, includ­ ing innovations in education, research, and practice (Patton et al., 2023; Rodriguez et al., 2024; Singer et al., 2023). Uses span real-time spelling and grammar editing such as Grammarly, software coding autocompletion like Co-Pilot, and AI-powered mental health chatbots. At the same time, AI raises critical concerns about inequalities, ethics, and transparency (Coeckelbergh, 2022; Eubanks, 2019; O ' Neil, 2016). These complexities highlight the importance of equipping social workers with competencies to address these issues effectively, ensuring equitable data and AI practices (Berzin et al., 2015; Coulton et al., 2015).

Although scholars have explored AI applications in social work ( Jung et al., 2024; Lee et al., 2024; Tambe &amp; Rice, 2018) and noted the importance of AI education for social workers (Patton et al., 2023; Rodriguez et al., 2024; Singer et al., 2023), system­ atic strategies for developing an adequate understanding of AI ' s capabilities, biases, and limitations among social workers remain underexplored. Addressing this gap is critical because AI systems potentially deepen inequalities among people relying on social work services (Capraro et al., 2024; Coeckelbergh, 2022). Social workers need to appreciate the potential uses and misuses of AI to advocate effectively for individ­ uals navigating AI-driven systems and services -even when not directly using AI tools (Mathiyazhagan &amp; Patton, 2025). This paper discusses how efforts to build AI literacy can inform social work practice by exploring AI ' s impact on social inequal­ ities across sectors and demonstrating how social work core competencies must evolve in response to AI-driven societal changes. Drawing on Long and Magerko ' s (2020) AI literacy framework, we propose integrating a social-work-speci /uniFB01 c AI liter­ acy framework into the profession ' s core competencies to equip social workers to ad­ dress emerging challenges while upholding professional values.

## De /uniFB01 ning Arti /uniFB01 cial Intelligence and Arti /uniFB01 cial Intelligence Literacy

AI refers to computer systems designed to perform tasks that typically require hu­ man intelligence, such as learning from data, solving problems, and making deci­ sions under uncertain conditions (McCarthy et al., 1955; Minsky, 1968; Russell &amp; Norvig, 2010). AI does not refer to a single technology but rather is an umbrella term encompassing various approaches and applications. AI systems vary in complexity and autonomy, handling diverse tasks from language understanding and generation to pattern recognition and recommendation systems (Leist et al., 2022).

Since its emergence in the 1950s (McCarthy et al., 1955), AI has evolved from simple rule-based systems to sophisticated technologies (Brynjolfsson et al., 2018; Fjelland, 2020). Predictive and prescriptive analytics use machine learning to help identify individuals and families who may bene /uniFB01 t from additional support, such as connecting families experiencing complex challenges with child welfare services or recognizing trends in community housing needs (Ahn, An, et al., 2024; Choul­ dechova et al., 2018; Mashiat et al., 2024). Simulation strategies model complex real-world scenarios to guide social workers with resource allocation, optimizing ef­ /uniFB01 ciency and equal access to services (Fowler et al., 2022; Kube et al., 2019).

Recent AI advances have introduced more transformative technologies. Deep learning, which mimics human neural networks, enables AI systems to recognize complex patterns in large datasets. Among these innovations, generative AI, pow­ ered by large language models like ChatGPT, has practical applications in social work, including creating accessible summaries of case histories, personalizing com­ munication, and drafting reports while maintaining person-centered care (Patton et al., 2023; Rodriguez et al., 2024). Computer vision can support the well-being of individuals, like older adults, by detecting falls in their homes to ensure timely assis­ tance (Gaya-Morey et al., 2024). Reinforcement learning develops optimal decisionmaking strategies for people seeking substance use treatment (Baucum et al., 2023). Whereas generative AI focuses on content creation, these other technologies focus on speci /uniFB01 c tasks such as object detection, process optimization, and trend analysis.

The rapid advancement of AI technologies following the public release of gen­ erative AI (e.g., ChatGPT) in 2022 has created ripple effects that can exacerbate existing social inequalities (Maslej et al., 2024). A critical need exists for under­ standing and evaluating the deployment of these transformative technologies. Long and Magerko ' s (2020) conceptual framework of AI literacy, outlined in Table 1, explores /uniFB01 ve key aspects of AI literacy: understanding AI concepts and types, rec­ ognizing its capabilities and limitations, comprehending its underlying processes, addressing ethical and societal implications, and examining public perceptions. AI literacy -de /uniFB01 ned as the ability to critically evaluate, collaborate with, and use AI technologies responsibly (Long &amp; Magerko, 2020) -provides a foundation for fos­ tering informed and meaningful public engagement in AI development and deployment.

## The Importance of Arti /uniFB01 cial Intelligence Literacy for Social Work

AI literacy among social workers is essential for three reasons: (a) to understand and address AI ' s role in perpetuating and intensifying social inequalities, (b) to con­ tribute meaningfully to the ethical development and governance of AI systems, and (c) to thoughtfully integrate AI applications into practice. Importantly, the /uniFB01 rst two reasons emphasize the need for AI literacy even without direct engagement with AI tools.

Table 1 Arti /uniFB01 cial Intelligence (AI) Literacy Framework

| Area                       | Description                                                                                   | Key Skill Set                                                                                                                              |
|----------------------------|-----------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|
| What is AI?                | Understanding the concept, de /uniFB01 nitions, and types of AI                               | Recognizing AI, analyzing intelligence (human vs. AI), understanding interdisciplinary nature, and assessing general versus narrow AI      |
| What can AI do?            | Exploring AI ' s strengths, weaknesses, and possibilities                                     | Identifying AI ' s strengths and limitations, imagining future AI applications, and evaluating societal impacts                            |
| How does AI work?          | Understanding underlying concepts like representations, decision-making, and machine learning | Grasping AI representations, decision-making processes, steps in machine learning, human roles in AI, data literacy, and critical analysis |
| How should AI be used?     | Addressing ethical considerations and societal implications of AI                             | Evaluating AI ethics (privacy, bias, accountability), embedding fairness, and leveraging diverse viewpoints                                |
| How do people perceive AI? | Examining public and individual perceptions of AI shaped by experience, media, and culture    | Recognizing programmability, addressing misconceptions, leveraging interests, and balancing complexity for understanding                   |

Note . Adapted from D. Long &amp; B. Magerko (2020), ' What is AI literacy? Competencies and design considerations. ' Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . Copyright 2020 by Association for Computing Machinery.

## Understanding the Role of Arti /uniFB01 cial Intelligence in Societal Inequalities

AI technologies are fundamentally transforming societal systems, in /uniFB02 uencing access to resources, decision-making processes, and policy outcomes (Harris, 2023; Maslej et al., 2024). Although these technologies offer signi /uniFB01 cant potential, they can also exacerbate existing inequalities, particularly when developed predominantly by privileged and homogenous groups (Coeckelbergh, 2022; Joyce et al., 2021). AI sys­ tems can perpetuate and amplify structural biases, disproportionately affecting mar­ ginalized populations such as low-income individuals, communities of color, and people with disabilities (Eubanks, 2019; Frank et al., 2019; McGovern et al., 2022). These deepening disparities are particularly concerning for social workers, whose mission is to serve and advocate for marginalized groups.

Figure 1 highlights the multifaceted ways in which AI affects societal inequali­ ties, categorized into socioeconomic and resource disparities, digital and environ­ mental justice, and governance and global inequality. One critical area of concern is the digital divide, which is a fundamental driver that determines access to AIenhanced technologies. Marginalized communities are often excluded from these tools, widening gaps in resource inequities and access (Eruchalu et al., 2021; Hepo­ niemi et al., 2020).

These inequalities manifest in various ways. Socioeconomic and resource dispar­ ities emerge as AI tools in /uniFB01 nance and education reinforce systemic biases, creating additional barriers to /uniFB01 nancial stability and perpetuating disparities in academic achievement (Holstein &amp; Doroudi, 2022). Digital and environmental justice further illustrates the interconnected nature of these challenges. Limited digital access and literacy exclude marginalized communities from leveraging AI solutions to address climate-related risks, thus widening disparities (McGovern et al., 2022). Governance and global disparities are ampli /uniFB01 ed by concentration of AI development in wealthier nations, leaving marginalized communities excluded from policymaking processes while AI-driven misinformation undermines civic engagement and democratic

Figure 1 . Circle of Transformation: The Impact of Arti /uniFB01 cial Intelligence (AI) on Social Inequalities

<!-- image -->

representation (Coeckelbergh, 2022; Eubanks, 2019). Addressing these intercon­ nected challenges requires that social workers develop AI literacy, enabling them to critically evaluate systems, advocate for equitable governance, and support clients who are navigating technological barriers.

## Guiding Ethical Implementation and Governance of Arti /uniFB01 cial Intelligence Systems

Although AI systems have signi /uniFB01 cant potential, they often lack the capacity to account for context, ethical reasoning, or the complex realities of individuals. These limitations can inadvertently perpetuate biases or lead to unintended consequences, particularly for individuals from underserved or underrepresented groups (Abràmoff et al., 2023; Gichoya et al., 2021; Reamer, 2023). For instance, AI models have been implicated in falsely accusing innocent individuals of crimes, underscoring the need for rigorous oversight and accountability (Hill, 2024). Similarly, deepfake technology facilitates the creation of manipulated content (Pascale, 2023). Even well-intended applications can yield harmful consequences, such as tools designed to detect traf /uniFB01 cking that in­ advertently expose survivors to further risk if privacy protections are inadequate (Deeb-Swihart et al., 2022). Furthermore, the recent tragic death of a teenager by sui­ cide following interactions with an AI chatbot highlights how these technologies can worsen mental health struggles and isolation, emphasizing the critical need for safeguards and ethical governance (Roose, 2024). As Roose recounted, the teen devel­ oped an emotional attachment to a chatbot based on a /uniFB01 ctional character, whose re­ sponses failed to appropriately address their distress and contributed to their death.

Social workers are well-positioned to contribute to the ethical implementation and governance of AI systems. Their expertise in addressing systemic inequities and experience working with diverse communities can provide valuable insights into the needs and perspectives of those who may be disproportionately affected by technology (Mathiyazhagan &amp; Patton, 2025). By participating in policy discus­ sions, system design, and implementation, social workers can address gaps in gov­ ernance frameworks that often exclude marginalized voices. Although AI bias and fairness research has focused primarily on statistical parity, this approach may over­ simplify impacts on marginalized communities (Mehrabi et al., 2021; Obermeyer et al., 2019). Each family service context requires examination within the broader history of systemic discrimination to align metrics and strategies with speci /uniFB01 c ser­ vice objectives (Ahn, Tejeda, et al., 2024; Chouldechova &amp; Roth, 2020; Schelter &amp; Sto­ yanovich, 2020). To ful /uniFB01 ll this role effectively, social workers must develop AI literacy, which will allow them to collaborate with interdisciplinary teams to inform AI technologies that not only innovate but also promote inclusion and equity.

## Integrating Arti /uniFB01 cial Intelligence for Strengthened Social Work Practice

AI presents transformative opportunities to enhance social work practice by improv­ ing operational ef /uniFB01 ciency, generating data-driven insights, and expanding service

access (Rodriguez et al., 2024). At the operational level, automation tools can stream­ line administrative tasks such as scheduling, data entry, and documentation, allow­ ing social workers to focus more on client-centered activities and complex case management. Additionally, AI chatbots can handle basic inquiries, provide imme­ diate information about available resources, and facilitate resource connections (Habicht et al., 2024). By offering 24/7 support, these tools promote informed engage­ ment, reduce workload, and improve service accessibility. Moreover, AI-powered outreach tools can extend services to previously underserved populations, particu­ larly in rural or remote areas where physical access is limited ( Jat &amp; Grønli, 2023).

AI also enhances decision-making and service planning in social work through multiple analytic capabilities. Predictive analytics help identify underserved popu­ lations in need of support (Lee et al., 2024), whereas imaging analysis addresses data gaps in resource-limited regions ( Jung et al., 2024). Natural language processing tools can assist in collecting and analyzing client narratives at scale (Tai et al., 2024), offering insights into culturally responsive interventions. Additionally, AI technolo­ gies can simulate decision-making scenarios, offering social workers a way to explore the potential outcomes of different interventions (Fowler et al., 2022). Thoughtful im­ plementation of these technologies can strengthen social workers ' ability to address structural inequalities and advance social justice through improved community en­ gagement and resource delivery.

However, social workers must also consider potential legal consequences, as highlighted in recent scrutiny of algorithmic tools by federal authorities (Ho &amp; Burke, 2023). This investigation emphasizes the importance of understanding the legal and ethical frameworks surrounding AI use in social work practice.

## Evolving Social Work Competencies in an AI-Driven Landscape

The Council on Social Work Education (CSWE) mandates that both the baccalaureate and master ' s-level social work programs align their curricula with nine core compe­ tencies, as outlined in the Educational Policy and Accreditation Standards (EPAS). These competencies ensure that graduates can address social issues with ethical judgment, cultural sensitivity, policy knowledge, and intervention skills (Council on Social Work Education, 2022). These competencies have evolved over time to re­ /uniFB02 ect shifting priorities, emerging issues, and new educational strategies in social work. Because AI is expected to in /uniFB02 uence social systems and services, CSWE must explicitly incorporate AI literacy into the 2029 EPAS. Building on recent efforts, such as the proposal to add a 10th competency addressing AI for social workers (Rodri­ guez et al., 2024), CSWE must ensure that the nine current competencies and any additions re /uniFB02 ect the challenges and opportunities posed by an AI-driven society. To remain effective and aligned with social work ' s mission, it is also essential to reex­ amine how each of these competencies should evolve in response to emerging AIdriven opportunities and challenges.

Table 2 outlines how the nine competencies can integrate AI considerations, un­ derscoring three reasons why AI literacy is essential for social workers. First, several competencies are directly relevant to understanding AI ' s role in reinforcing inequal­ ities. Social work ' s commitment to advancing human rights and justice (Compe­ tency 2) involves recognizing and addressing how AI can introduce new barriers, such as digital divides that disproportionately affect marginalized communities (Eruchalu et al., 2021; Heponiemi et al., 2020). Similarly, engaging in antiracism, di­ versity, equity, and inclusion (Competency 3) demands confronting biases embedded in AI, such as algorithmic redlining in housing or discriminatory hiring practices (Frank et al., 2019; Safransky, 2020). Assessment (Competency 7) also needs to be adapted, accounting for AI-related vulnerabilities such as inequitable educational opportunities or environmental justice concerns (Holstein &amp; Doroudi, 2022; McGov­ ern et al., 2022). Social workers with AI literacy can critically evaluate these emerg­ ing risks and advocate for just interventions.

Second, guiding the ethical implementation and governance of AI systems directly ties to several other core competencies. Demonstrating ethical and professional be­ havior (Competency 1) requires a nuanced understanding of how AI intersects with social work values, emphasizing inclusion and community-centered perspectives (Capraro et al., 2024; Joyce et al., 2021). Policy practice (Competency 5) must expand to include advocating transparency, accountability, and justice in AI governance, en­ suring that AI technologies serve the public good rather than exacerbate inequalities. Furthermore, practice evaluation (Competency 9) also needs to evolve to account for the impact of AI-driven practices on individuals and groups, particularly when sys­ tems overlook or misrepresent marginalized communities. Social workers with AI lit­ eracy can collaborate on interdisciplinary teams, in /uniFB02 uence policy decisions, and guide ethical standards for AI implementation.

Finally, AI also presents opportunities to strengthen social work practice. Researchinformed practice (Competency 4) should involve evaluating AI-based research tools to ensure they do not perpetuate discrimination or exclude marginalized communities (Obermeyer et al., 2019). Engagement with individuals, families, groups, and communities (Competency 6) can bene /uniFB01 t from AI platforms that ex­ pand access to resources, although social workers must remain vigilant about the digital divide. Interventions (Competency 8) can also be enhanced by helping clients understand AI-driven systems, address immediate needs, and develop the skills to advocate equitable access. With thoughtful integration of AI liter­ acy, social workers can remain responsive to the diverse needs of clients and communities.

## AI Literacy Framework for Social Work

To effectively address evolving social work competencies, social workers need a structured approach that supports ethical practice, policy advocacy, and community

Table 2 Evolving Social Work Competencies With Arti /uniFB01 cial Intelligence (AI) Considerations

| Social Work Competency                                                          | Key AI Considerations                                                                                                                                                                                                                                                                                                                                                                                    |
|---------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. Demonstrate ethical and professional behavior                                | Expand ethical decision-making in social work to systematically evaluate AI-speci /uniFB01 c issues like algorithmic bias, transparency, and ac­ countability through a context-based lens that considers both direct and indirect con­ sequences for affected communities.                                                                                                                                |
| 2. Advance human rights and social, racial, economic, and environmental justice | Critically evaluate AI systems ' impact on human rights and justice by examining how these technologies may amplify or mitigate existing power structures, advocating for equitable AI resource distribution and ensuring AI tools actively advance rather than hinder social, racial, economic, and environmental justice across all system levels.                                                     |
| 3. Engage in antiracism, diversity, equity, and inclusion in practice           | Examine AI systems through antiracist and intersectional lenses, understanding how algorithmic biases can perpetuate systemic oppression through data, design, and deployment choices. This requires ensuring AI tools are accessible and inclusive for people of all abilities, re /uniFB02 ect diverse lived experiences and knowledge systems, and actively work to eliminate digital discrimination. |
| 4. Engage in practice-informed research and research-informed practice          | Use AI tools with caution, understanding po­ tential systemic inequalities, and apply evidence-based solutions in practice with critical evaluation of AI-informed research.                                                                                                                                                                                                                              |
| 5. Engage in policy practice                                                    | Evaluate how AI-driven policies and automated systems affect service delivery and human rights across governance levels while advocating for policy frameworks that address algorithmic bias, promote transparency, and center the voices of people most impacted by these technologies in social services.                                                                                              |
| 6. Engage with individuals, families, groups, organizations, and communities    | BalanceAIintegrationwithauthentichuman engagement, ensuring technological tools enhance rather than replace relationship- building while remaining mindful of how automated systems affect power dynamics and cultural responsiveness in practice settings.                                                                                                                                              |

Table 2 ( continued )

| Social Work Competency                                                                   | Key AI Considerations                                                                                                                                                                                                                                                                                                            |
|------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 7. Assess individuals, families, groups, organizations, and communities                  | Ensure AI assessment tools enhance professional judgment and collaborative processes while critically evaluating algorithmic impacts on decision-making, assessing AI-related vulnerabilities in clients ' lives, and preserving self- determination through culturally                                                          |
| 8. Intervene with individuals, families, groups, organizations, and communities          | responsive, person-centered approaches. Carefully assess AI-supported interventions to ensure they enhance culturally responsive practice and client outcomes while preserving human agency in intervention selection and advocating for equitable access to evidence-informed AI tools that align with client goals and values. |
| 9. Evaluate practice with individuals, fami­ lies, groups, organizations, and communities | Intentionally use AI-powered evaluation tools while accounting for unmeasured AI impacts across diverse community contexts, ensuring automated metrics enhance rather than oversimplify assess­ ment of practice effectiveness.                                                                                                   |

engagement. Long and Magerko ' s (2020) AI literacy framework provides a founda­ tional tool to help social workers navigate AI ' s dual role in exacerbating inequalities and creating opportunities for advancing practice. This dual role requires ethical oversight and informed application, grounded in a nuanced understanding of AI ' s capabilities and limitations. This framework ' s /uniFB01 ve key areas offer essential guid­ ance for navigating AI-driven social transformation, aligning with core social work competencies.

## Area 1: ' What is AI? '

This domain focuses on de /uniFB01 ning AI and understanding its boundaries, emphasiz­ ing the importance of distinguishing between different AI technologies when used in practice. Recognizing whether a system is rule-based, is powered by machine learning, or uses generative AI is crucial for ethical and effective application. For

example, in managing a community support program, a rule-based system might automatically sort applicants based on /uniFB01 xed criteria like income level or family size, ensuring consistent but rigid decision-making. A machine learning model, on the other hand, could analyze patterns in client data to predict future resource needs, offering dynamic insights but potentially overlooking unique unrepresented cases (Ahn, Tejeda, et al., 2024). Generative AI, such as text-generation tools, can add an­ other dimension by summarizing case histories or drafting client communications, saving time but requiring human oversight to ensure fairness and accuracy. By un­ derstanding these distinctions, social workers can thoughtfully apply AI tools to en­ hance their practice and better support clients.

## Area 2: ' What Can AI Do? '

This area highlights the capabilities and limitations of AI that clients might expe­ rience, ensuring that social workers can help them interpret AI-driven outcomes critically. Consider a family that approaches a social worker after being denied a mortgage based on an AI-driven lending platform ' s assessment. The social worker understands that although the algorithm can analyze large datasets to predict repay­ ment risks, it may not consider community-speci /uniFB01 c lending practices or informal in­ come sources. Recognizing these limitations, the social worker can encourage the family to request a manual review, providing advocacy and support to ensure they are treated equally. By understanding AI ' s potential and constraints, social workers can safeguard clients ' rights.

## Area 3: ' How Does AI Work? '

This topic emphasizes that understanding the processes behind AI -from data selec­ tion and model training to ongoing evaluation -can empower social workers to iden­ tify where biases might occur and question the representativeness of data sources. For instance, a nonpro /uniFB01 t mental health agency ' s predictive model might be trained predominantly on data from English-speaking clients with insurance. A social worker versed in how AI is developed could critically examine this bias and advocate for more inclusive data. This research-informed vigilance allows social workers to push for policy changes, continuous model evaluations, and greater transparency, ensur­ ing that marginalized groups are not systematically overlooked.

## Area 4: ' How Should AI Be Used? '

This domain examines the ethical implications of integrating AI into decisionmaking processes. Social workers must navigate issues of privacy, accountability, eq­ uity, and client autonomy. For example, in child welfare settings where AI identi /uniFB01 es families that may need support, practitioners must consider protecting privacy, avoiding stereotype reinforcement, establishing fair appeals processes, and aligning identi /uniFB01 ed needs with available service capacity. AI-based identi /uniFB01 cation of needs

must align with available resources, as identifying families without adequate service capacity can delay essential care and potentially affect their eligibility for other sup­ port options (Ahn, An, et al., 2024).

As private companies increasingly develop AI tools without suf /uniFB01 cient consider­ ation of human well-being and rights (Coeckelbergh, 2022), social workers must de­ velop AI literacy to critically evaluate where and how AI should be used in practice settings. AI should be avoided where human judgment is irreplaceable, particularly in building therapeutic relationships and making nuanced clinical decisions based on nonverbal cues and cultural contexts. System limitations that could cause harm must also be considered, as shown by facial recognition systems leading to wrongful arrests of people of color and AI chatbots linked to tragic outcomes like teen suicide (Hill, 2024; Roose, 2024). Similarly, service contexts requiring direct human insight, such as child welfare assessments where understanding family dynamic is crucial, should remain human centered. AI literacy enables social workers to carefully eval­ uate AI recommendations considering systemic biases, service context, and potential impacts on individuals and families. By applying ethical principles and advocating for policies that require human review of AI decisions and informed consent for data use, social workers can ensure that AI augments rather than undermines ethical practice.

The classroom provides a place to engage in fruitful conversations regarding the appropriate use of AI in social work. Teachers and universities are increasingly encouraged to explicitly articulate policies for generative AI in completing assign­ ments that can provide opportunities for dialogue and level setting. Classroom activ­ ities that ask students to use large language models for information gathering, interpretation, and decision-making can elucidate the strengths and limitations of technologies addressing the human and social aspects of the practice. Discussions of AI uses in social work research -such as generating questions, summarizing liter­ ature, and analyzing and interpreting data -allow for probing fundamental episte­ mic questions about knowledge and the social responsibilities for disseminating credible evidence (Birhane et al., 2023; Messeri &amp; Crockett, 2024). It is important to model re /uniFB02 exive practice in considering the ethical implications for teaching and research.

## Area 5: ' How Do People Perceive AI? '

This area emphasizes that recognizing and addressing community perceptions and distrust of AI is crucial for ethical implementation. For example, when community members express skepticism toward an AI-driven child welfare referral system, so­ cial workers can foster transparency and trust through community forums and in­ clusive dialogue (Brown et al., 2019). By engaging residents, inviting technologists to explain the system ' s logic, and incorporating community feedback, social workers can ensure that the technology aligns with community values.

Equally important is understanding social workers ' perception of AI. Not all so­ cial workers may feel prepared or con /uniFB01 dent about integrating AI into their practice, with valid concerns about data privacy, algorithmic bias, and ethical challenges posed by technology (Stapleton et al., 2022). Building AI literacy in social work re­ quires directly addressing these concerns. By understanding how social workers per­ ceive AI, organizations can better identify adoption barriers and develop effective training resources.

The /uniFB01 ve areas of this framework -understanding what AI is, what it can do, how it works, how it should be used, and how it is perceived -offer social workers a valu­ able starting point for addressing the societal impacts of AI thoughtfully and ethi­ cally. Although these areas may not fully encompass the complexities of AI ' s impacts on and integration into social work, they provide a foundational structure to begin de­ /uniFB01 ning and developing AI literacy tailored to social work ' s core competencies.

## Discussion

AI literacy has become essential for social workers as AI systems increasingly reshape societal structures and decision-making processes, particularly affecting people who experience marginalization and rely on social work services. Understanding AI ' s capabilities, limitations, and societal impact has become fundamental to effective social work practice, enabling practitioners and researchers to better understand, support, and advocate for people navigating AI-transformed systems.

Our paper demonstrates how AI literacy intersects with and strengthens social workers ' ability to uphold core professional competencies in an AI-driven landscape. From ethical practice and social justice advocacy to engagement with communities and policy development, AI literacy will enhance social workers ' capacity to address emerging challenges while maintaining professional values. Long and Magerko ' s (2020) AI literacy framework provides a foundation for a structured approach to de­ veloping these essential capabilities.

Although recent research has begun addressing the importance of AI education in social work (Patton et al., 2023; Rodriguez et al., 2024; Singer et al., 2023), including proposals to establish AI competency as the 10th element of the profession ' s core competencies, we propose that AI literacy should also be integrated across existing core competencies. This integration would re /uniFB02 ect how AI ' s in /uniFB02 uence permeates var­ ious aspects of social work practice and emphasize the need for practitioners to un­ derstand AI ' s societal impact holistically.

Looking forward, the social work profession must develop systematic approaches to assessing and fostering social-work-speci /uniFB01 c AI literacy among practitioners and re­ searchers. Building on well-established AI literacy literature (e.g., Long &amp; Magerko, 2020), the /uniFB01 eld needs to collectively de /uniFB01 ne what AI literacy means for social work practice. Although recent work has begun this conversation (Patton et al., 2023; Rodriguez et al., 2024; Singer et al., 2023), more comprehensive strategies are needed

to assess and promote AI literacy among social workers. These strategies include in­ tegrating AI literacy into social work education and professional development, en­ gaging social workers in AI policy discussions and ethical guidelines, building bridges between social work practice and AI development, supporting research on AI ' s impact on communities experiencing marginalization, and ensuring that social work values guide AI implementation in social services. Additionally, researchers need to examine the social work AI literacy framework empirically by collecting and analyzing primary data.

## Author Notes

Eunhye Ahn , PhD, is an assistant professor at the Brown School, Washington University in St. Louis.

- Moon Choi , PhD, is an associate professor at the Graduate School of Science and Technology Policy, Korea Advanced Institute of Science and Technology.

Patrick Fowler , PhD, is a professor at the Brown School, Washington University in St. Louis. In Han Song , PhD, is a professor at the Yonsei University School of Social Welfare.

Correspondence regarding this article should be directed to Eunhye Ahn at ahne@wustl.edu.

## Acknowledgments

Moon Choi was supported by a Korean ARPA-H Project grant through the Korea Health Indus­ try Development Institute, funded by the Ministry of Health &amp; Welfare, Republic of Korea (Grant No. RS-2024-00512374). Patrick Fowler received support from the National Science Foundation (Awards 2127752, 2127754, and 2402856).

## References

- Abràmoff, M. D., Tarver, M. E., Loyo-Berrios, N., Trujillo, S., Char, D., Obermeyer, Z., Eydelman, M. B., Foundational Principles of Ophthalmic Imaging and Algorithmic Interpretation Working Group of the Collaborative Community for Ophthalmic Imaging Foundation, &amp; Maisel, W. H. (2023). Considerations for addressing bias in arti /uniFB01 cial intelligence for health equity. NPJ Digital Medicine , 6 , Article 170. https://doi.org/10.1038/s41746-023-00913-9
- Ahn, E., An, R., Jonson-Reid, M., &amp; Palmer, L. (2024). Leveraging machine learning for effec­ tive child maltreatment prevention: A case study of home visiting service assessments. Child Abuse &amp; Neglect , 151 , Article 106706. https://doi.org/10.1016/j.chiabu.2024.106706
- Ahn, E., Tejeda, Y., &amp; Yang, Y. (2024). Examining fairness in machine learning applied to sup­ port families: A case study of preventive services. Family Relations . Advance online publi­ cation. https://doi.org/10.1111/fare.13114
- Baucum, M., Khojandi, A., Myers, C., &amp; Kessler, L. (2023). Optimizing substance use treatment selection using reinforcement learning. ACM Transactions on Management Information Systems , 14 (2), 1 -30. https://doi.org/10.1145/3563778
- Berzin, S. C., Singer, J., &amp; Chan, C. (2015). Practice innovation through technology in the digital age (Working Paper No. 12). American Academy of Social Work and Social Welfare. https:// grandchallengesforsocialwork.org/wp-content/uploads/2015/12/WP12-with-cover.pdf
- Birhane, A., Kasirzadeh, A., Leslie, D., &amp; Wachter, S. (2023). Science in the age of large language models. Nature Reviews Physics , 5 (5), 277 -280. https://doi.org/10.1038/s42254-023-00581-4

- Brown, A., Chouldechova, A., Putnam-Hornstein, E., Tobin, A., &amp; Vaithianathan, R. (2019). Toward algorithmic accountability in public services: A qualitative study of affected community perspectives on algorithmic decision-making in child welfare services. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems -CHI ' 19 (pp. 1 -12). Association for Computing Machinery. https://doi.org/10.1145/3290605.3300271
- Brynjolfsson, E., Mitchell, T., &amp; Rock, D. (2018). What can machines learn and what does it mean for occupations and the economy? AEA Papers and Proceedings , 108 , 43 -47. https:// doi.org/10.1257/pandp.20181019
- Capraro, V., Lentsch, A., Acemoglu, D., Akgun, S., Akhmedova, A., Bilancini, E., Bonnefon, J.-F., Brañas-Garza, P., Butera, L., Douglas, K. M., Everett, J. A. C., Gigerenzer, G., Greenhow, C., Hashimoto, D. A., Holt-Lunstad, J., Jetten, J., Johnson, S., Kunz, W. H., Longoni, C., . . . Viale, R. (2024). The impact of generative arti /uniFB01 cial intelligence on socioeconomic inequalities and policy making. PNAS Nexus , 3 (6), Article pgae191. https://doi.org/10.1093/pnasnexus /pgae191
- Chouldechova, A., Benavides-Prado, D., Fialko, O., &amp; Vaithianathan, R. (2018). A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. Proceedings of the 1st Conference on Fairness, Accountability and Transparency , 81 , 134 -148. http://proceedings.mlr.press/v81/chouldechova18a.html
- Chouldechova, A., &amp; Roth, A. (2020). A snapshot of the frontiers of fairness in machine learn­ ing. Communications of the ACM , 63 (5), 82 -89. https://doi.org/10.1145/3376898
- Coeckelbergh, M. (2022). The political philosophy of AI: An introduction . Polity.
- Coulton, C., Goerge, R., Putnam-Hornstein, E., &amp; de Hann, B. (2015). Harnessing big data for social good: A grand challenge for social work (Working Paper No. 11). American Academy of Social Work &amp; Social Welfare. https://grandchallengesforsocialwork.org/wp-content/uploads/2015 /12/WP11-with-cover.pdf
- Council on Social Work Education. (2022). Educational Policy and Accreditation Standards (EPAS) 2022 . https://www.cswe.org/getmedia/bb5d8afe-7680-42dc-a332-a6e6103f4998/2022-Educa tional-Policy-and-Accreditation-Standards-(EPAS).pdf
- Cresswell, K., Callaghan, M., Khan, S., Sheikh, Z., Mozaffar, H., &amp; Sheikh, A. (2020). Investigat­ ing the use of data-driven arti /uniFB01 cial intelligence in computerised decision support systems for health and social care: A systematic review. Health Informatics Journal , 26 (3), 2138 -2147. https://doi.org/10.1177/1460458219900452
- Deeb-Swihart, J., Endert, A., &amp; Bruckman, A. (2022). Ethical tensions in applications of AI for addressing human traf /uniFB01 cking: A human rights perspective. Proceedings of the ACM on Human-Computer Interaction , 6 (CSCW2), 1 -29. https://doi.org/10.1145/3555186
- Eruchalu, C. N., Pichardo, M. S., Bharadwaj, M., Rodriguez, C. B., Rodriguez, J. A., Bergmark, R. W., Bates, D. W., &amp; Ortega, G. (2021). The expanding digital divide: Digital health access inequities during the COVID-19 pandemic in New York City. Journal of Urban Health , 98 (2), 183 -186. https://doi.org/10.1007/s11524-020-00508-9
- Eubanks, V. (2019). Automating inequality: How high-tech tools pro /uniFB01 le, police, and punish the poor . St. Martin ' s Press.
- Fjelland, R. (2020). Why general arti /uniFB01 cial intelligence will not be realized. Humanities and Social Sciences Communications , 7 , Article 10. https://doi.org/10.1057/s41599-020-0494-4
- Fowler, P. J., Marcal, K. E., &amp; Hovmand, P. S. (2022). Meeting housing needs of child welfareinvolved families: Policy insights from simulation modeling. Child Abuse &amp; Neglect , 132 , Ar­ ticle 105809. https://doi.org/10.1016/j.chiabu.2022.105809

- Frank, M. R., Autor, D., Bessen, J. E., Brynjolfsson, E., Cebrian, M., Deming, D. J., Feldman, M., Groh, M., Lobo, J., Moro, E., Wang, D., Youn, H., &amp; Rahwan, I. (2019). Toward understand­ ing the impact of arti /uniFB01 cial intelligence on labor. Proceedings of the National Academy of Sciences , 116 (14), 6531 -6539. https://doi.org/10.1073/pnas.1900949116
- Gaya-Morey, F. X., Manresa-Yee, C., &amp; Buades-Rubio, J. M. (2024). Deep learning for computer vision based activity recognition and fall detection of the elderly: A systematic review. Applied Intelligence , 54 (19), 8982 -9007. https://doi.org/10.1007/s10489-024-05645-1
- Gichoya, J. W., McCoy, L. G., Celi, L. A., &amp; Ghassemi, M. (2021). Equity in essence: A call for operationalising fairness in machine learning for healthcare. BMJ Health &amp; Care Informatics , 28 (1), Article e100289. https://doi.org/10.1136/bmjhci-2020-100289
- Habicht, J., Viswanathan, S., Carrington, B., Hauser, T. U., Harper, R., &amp; Rollwage, M. (2024). Closing the accessibility gap to mental health treatment with a personalized selfreferral chatbot. Nature Medicine , 30 (2), 595 -602. https://doi.org/10.1038/s41591-023 -02766-x
- Harris, L. A. (2023, August 4). Arti /uniFB01 cial intelligence: Overview, recent advances, and considerations for the 118th Congress . Congressional Research Service. https://crsreports.congress.gov/product /pdf/R/R47644
- Heponiemi, T., Jormanainen, V., Leemann, L., Manderbacka, K., Aalto, A.-M., &amp; Hyppönen, H. (2020). Digital divide in perceived bene /uniFB01 ts of online health care and social welfare ser­ vices: National cross-sectional survey study. Journal of Medical Internet Research , 22 (7), Arti­ cle e17616. https://doi.org/10.2196/17616
- Hill, K. (2024, June 29). Facial recognition led to wrongful arrests. So Detroit is making changes. The New York Times . https://www.nytimes.com/2024/06/29/technology/detroit-facial -recognition-false-arrests.html
- Ho, S., &amp; Burke, G. (2023, March 15). Child welfare algorithm faces Justice Department scrutiny. AP News . https://apnews.com/article/justice-scrutinizes-pittsburgh-child-welfare-ai-tool -4f61f45bfc3245fd2556e886c2da988b
- Holstein, K., &amp; Doroudi, S. (2022). Equity and arti /uniFB01 cial intelligence in education. In W. Holmes &amp; K. Porayska-Pomsta (Eds.), The ethics of arti /uniFB01 cial intelligence in education (pp. 23 -45). Routledge. https://doi.org/10.4324/9780429329067-9
- Jat, A. S., &amp; Grønli, T.-M. (2023). Harnessing the digital revolution: A comprehensive review of mHealth applications for remote monitoring in transforming healthcare delivery. In M. Younas, I. Awan, &amp; T.-M. Grønli (Eds.), Mobile web and intelligent information systems (pp. 55 -67). Springer Nature. https://doi.org/10.1007/978-3-031-39764-6\_4
- Joyce, K., Smith-Doerr, L., Alegria, S., Bell, S., Cruz, T., Hoffman, S. G., Noble, S. U., &amp; Shestakofsky, B. (2021). Toward a sociology of arti /uniFB01 cial intelligence: A call for research on inequalities and structural change. Socius: Sociological Research for a Dynamic World , 7 . https://doi.org/10.1177/2378023121999581
- Jung, W., Kim, A. H., &amp; Chear, C. (2024). Data science and social work. In W. Jung, A. H. Kim, &amp; C. Chear, Encyclopedia of social work . NASW Press and Oxford University Press. https://doi.org /10.1093/acrefore/9780199975839.013.1649
- Kube, A., Das, S., &amp; Fowler, P. J. (2019). Allocating interventions based on predicted outcomes: A case study on homelessness services. Proceedings of the AAAI Conference on Arti /uniFB01 cial Intelligence , 33 (1), 622 -629. https://doi.org/10.1609/aaai.v33i01.3301622
- Lee, J. Y., Ahn, E., Xu, A., Yang, Y., Chang, Y., Cha, H., &amp; Ammari, T. (2024). Arti /uniFB01 cial intelligence in applied family research involving families with young children: A scoping review. Family Relations . Advance online publication. https://doi.org/10.1111/fare.13090

- Leist, A. K., Klee, M., Kim, J. H., Rehkopf, D. H., Bordas, S. P. A., Muniz-Terrera, G., &amp; Wade, S. (2022). Mapping of machine learning approaches for description, prediction, and causal inference in the social and health sciences. Science Advances , 8 (42), Article eabk1942. https://doi.org/10.1126/sciadv.abk1942
- Long, D., &amp; Magerko, B. (2020). What is AI literacy? Competencies and design considerations. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1 -16). Association for Computing Machinery. https://doi.org/10.1145/3313831.3376727
- Mashiat, T., DiChristofano, A., Fowler, P. J., &amp; Das, S. (2024, June). Beyond eviction prediction: Leveraging local spatiotemporal public records to inform action. In The 2024 ACM Conference on Fairness, Accountability, and Transparency (pp. 1383 -1394). Association for Computing Machinery. https://doi.org/10.1145/3630106.3658978
- Maslej, N., Fattorini, L., Perrault, R., Parli, V., Reuel, A., Brynjolfsson, E., Etchemendy, J., Ligett, K., Lyons, T., Manyika, J., Niebles, J. C., Shoham, Y., Wald, R., &amp; Clark, J. (2024). The AI index 2024 annual report . AI Index Steering Committee, Institute for Human-Centered AI, Stan­ ford University. https://hai-production.s3.amazonaws.com/ /uniFB01 les/hai\_ai-index-report-2024 -smaller2.pdf
- Mathiyazhagan, S., &amp; Patton, D. U. (2025). Towards just and equitable Web3: Social work rec­ ommendations for inclusive practice of AI policies. AI &amp; Society , 40 , 1549 -1551. https://doi .org/10.1007/s00146-024-01994-0
- McAdams, R. M., Kaur, R., Sun, Y., Bindra, H., Cho, S. J., &amp; Singh, H. (2022). Predicting clinical outcomes using arti /uniFB01 cial intelligence and machine learning in neonatal intensive care units: A systematic review. Journal of Perinatology , 42 (12), 1561 -1575. https://doi.org/10 .1038/s41372-022-01392-8
- McCarthy, J., Minsky, M., Rochester, N., &amp; Shannon, C. E. (1955). A proposal for the Dartmouth Summer Research Project on Arti /uniFB01 cial Intelligence . Dartmouth College. http://jmc.stanford .edu/articles/dartmouth/dartmouth.pdf
- McGovern, A., Ebert-Uphoff, I., Gagne, D. J., &amp; Bostrom, A. (2022). Why we need to focus on de­ veloping ethical, responsible, and trustworthy arti /uniFB01 cial intelligence approaches for environ­ mental science. Environmental Data Science , 1 , Article e6. https://doi.org/10.1017/eds.2022.5
- Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., &amp; Galstyan, A. (2021). A survey on bias and fairness in machine learning. ACM Computing Surveys , 54 (6), 1 -35. https://doi.org/10.1145 /3457607
- Messeri, L., &amp; Crockett, M. J. (2024). Arti /uniFB01 cial intelligence and illusions of understanding in scienti /uniFB01 c research. Nature , 627 (8002), 49 -58. https://doi.org/10.1038/s41586-024-07146-0 Minsky, M. L. (1968). Semantic information processing . MIT Press.
- Obermeyer, Z., Powers, B., Vogeli, C., &amp; Mullainathan, S. (2019). Dissecting racial bias in an algorithm used to manage the health of populations. Science , 366 (6464), 447 -453. https:// doi.org/10.1126/science.aax2342
- O ' Neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy . Crown.
- Pascale, E. (2023). Deeply dehumanizing, degrading, and violating: Deepfake pornography and the path to legal recourse. Syracuse Law Review , 73 , 335 -366.
- Patton, D. U., Landau, A. Y., &amp; Mathiyazhagan, S. (2023). ChatGPT for social work science: Eth­ ical challenges and opportunities. Journal of the Society for Social Work and Research , 14 (3), 553 -562. https://doi.org/10.1086/726042
- Reamer, F. G. (2023). Arti /uniFB01 cial intelligence in social work: Emerging ethical issues. International Journal of Social Work Values and Ethics , 20 (2), 52 -71. https://doi.org/10.55521/10-020-205

- Rodriguez, M. Y., Goldkind, L., Victor, B. G., Hiltz, B., &amp; Perron, B. E. (2024). Introducing gener­ ative arti /uniFB01 cial intelligence into the MSW curriculum: A proposal for the 2029 Educational Policy and Accreditation Standards. Journal of Social Work Education , 60 (2), 174 -182. https:// doi.org/10.1080/10437797.2024.2340931
- Roose, K. (2024, October 23). Can A.I. be blamed for a teen ' s suicide? The New York Times . https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html
- Russell, S. J., &amp; Norvig, P. (2010). Arti /uniFB01 cial intelligence: A modern approach (3rd ed.). Prentice Hall. Safransky, S. (2020). Geographies of algorithmic violence: Redlining the smart city. International Journal of Urban and Regional Research , 44 (2), 200 -218. https://doi.org/10.1111/1468 -2427.12833
- Schelter, S., &amp; Stoyanovich, J. (2020). Taming technical bias in machine learning pipelines. Bulletin of the Technical Committee on Data Engineering , 43 (4), 39 -50.
- Singer, J. B., Báez, J. C., &amp; Rios, J. A. (2023). AI creates the message: Integrating AI language learning models into social work education and practice. Journal of Social Work Education , 59 (2), 294 -302. https://doi.org/10.1080/10437797.2023.2189878
- Stapleton, L., Lee, M. H., Qing, D., Wright, M., Chouldechova, A., Holstein, K., Wu, Z. S., &amp; Zhu, H. (2022). Imagining new futures beyond predictive systems in child welfare: A qual­ itative study with impacted stakeholders. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (pp. 1162 -1177). Association for Computing Machinery. https://doi.org/10.1145/3531146.3533177
- Tai, R. H., Bentley, L. R., Xia, X., Sitt, J. M., Fankhauser, S. C., Chicas-Mosier, A. M., &amp; Monteith, B. G. (2024). An examination of the use of large language models to aid analysis of tex­ tual data. International Journal of Qualitative Methods , 23 , 1 -14. https://doi.org/10.1177 /16094069241231168
- Tambe, M., &amp; Rice, E. (Eds.). (2018). Arti /uniFB01 cial intelligence and social work . Cambridge University Press.
- Wulczyn, F., Kaligotla, C., Hummel, J., Wagner, A., &amp; MacLeod, A. (2024). Agent-based simu­ lation and child protection systems: Rationale, implementation, and veri /uniFB01 cation. Child Abuse &amp; Neglect , 147 , Article 106578. https://doi.org/10.1016/j.chiabu.2023.106578

Manuscript submitted: January 7, 2025

First revision submitted: January 31, 2025

Accepted: February 4, 2025

Electronically published: May 9, 2025