---
source_file: Ruiz_2024_AI_Literacy_A_Framework_to_Understand,_Evaluate,.pdf
conversion_date: 2026-02-03T09:17:40.391420
converter: docling
quality_score: 95
---

AI Literacy: A Framework to

## Understand, Evaluate, and Use

## Emerging Technology

Kelly Mills, Pati Ruiz, Keun-woo Lee, Merijke Coenraad, Judi Fusco, Jeremy Roschelle, &amp; Josh Weisgrau

June 2024

<!-- image -->

## Table of Contents

| Acknowledgments                                                           |   3 |
|---------------------------------------------------------------------------|-----|
| Introduction                                                              |   4 |
| AI Literacy Framework                                                     |   5 |
| AI Literacy Practices                                                     |   7 |
| Understanding AI                                                          |  11 |
| Evaluating AI                                                             |  15 |
| Using AI                                                                  |  18 |
| Putting It All Together                                                   |  22 |
| Strategies to Promote AI Literacy in K-12 Education                       |  26 |
| Strategy 1: Provide Guidance for Adoption and Evaluation                  |  26 |
| Strategy 2: Integrate AI Literacy Across Grades and Subject-Area Learning |  28 |
| Strategy 3: Facilitate Ongoing, Just-In-Time Professional Learning        |  30 |
| Strategy 4: Design Powerful Learning Experiences                          |  31 |
| Strategy 5: Promote Awareness and Agency                                  |  33 |
| Conclusion                                                                |  35 |
| References                                                                |  36 |

## Suggested Citation

Mills, K , Ruiz, P , Lee, K , Coenraad, M , Fusco, J , Roschelle, J  &amp; Weisgrau, J  (2024, May)

AI Literacy: A Framework to Understand, Evaluate, and Use Emerging Technology https://doi org/10 51388/20 500 12265/218

## Acknowledgments

This report was developed under the guidance of Dr  Kelly Mills, Dr  Pati Ruiz, Keun-woo Lee, Dr  Merijke Coenraad, Dr  Judi Fusco, Dr  Jeremy Roschelle, and Josh Weisgrau with support from Teresa Solorzano, Alessandra Rangel, Erica Lawton Weinschenk, My Nguyen, Sarah Martin, Carolina Belloc, Marsha Choc, Gabrielle Lue, and Alisha Workman of Digital Promise  The authors thank the experts that reviewed the content of this paper and offered guidance including:

-  Dr  Nicole Adell, Digital Promise
-  Dr  Amanda LaTasha Armstrong, Digital Promise
-  Anthony Baker, Digital Promise
-  Dr  Quinn Burke, Digital Promise
-  Dr  Michael Chang, U C  Berkeley
-  Dr  An-Me Chung, New America
-  Dr  Shayla Cornick, Digital Promise
-  Todd DeSando, Digital Promise
-  Sofia De Jesus, Carnegie Mellon University
-  Diane W  Doersch, Digital Promise
-  Dr  Ximena Dominguez, Digital Promise
-  Charlotte Dungan, The Mark Cuban Foundation
-  Charles Fadel, Center for Curriculum Redesign
-  Andrew Fenstermaker, Iowa City Community School District
-  Brian Giovanini, Indian Prairie School District 204
-  Dr  Patrick Gittisriboongul, Lynwood Unified School District
-  Dr  Kip Glazer, Mountain View High School
-  Lisa Guernsey, New America
-  Chaula Gupta, Digital Promise
-  Akira Harper, University of Massachusetts Dartmouth
-  Sallie Holloway, Gwinnett County Public Schools
-  Jessica K  Jackson, Digital Promise
-  Sana Karim, Digital Promise
-  Dr  Clifford Lee, Northeastern University
-  Dr  Crystal Chen Lee, North Carolina State University
-  Sherry L  Loftin, Digital Promise
-  Tania Moneim, Indian Prairie School District 204
-  Dr  Brooke Morgan, Talladega County Schools
-  Dr  Julie Neisler, Digital Promise
-  Dr  Hillary Greene Nolan, Digital Promise
-  Khyati Sanjana, Digital Promise
-  Dr  Allison Scott, Kapor Center
-  Elena Silva, New America
-  Jeffrey Starr, Digital Promise
-  Lucara Stewart, Digital Promise
-  Dr  Medha Tare, Joan Ganz Cooney Center at Sesame Workshop
-  Dr  D'Andre Weaver, Digital Promise
-  Erica Lawton Weinschenk, Digital Promise
-  Shana White, The Kapor Center
-  Dr  Julio Vazquez, North Salem Central School District
-  Dr  Jason C  Yip, University of Washington
-  Pat Yongpradit, TeachAI
-  Tyron Young, Digital Promise
-  Dr  Viki Young, Digital Promise

## Introduction

Generative AI (GenAI) systems and tools are entering the classroom at a rapid pace Given the well-documented examples of AI tools perpetuating and reproducing systemic bias (Benjamin, 2019; Broussard, 2023; Buolamwini, 2023; Noble, 2018; O'Neil, 2016) and violations of data privacy (Ingram, 2023; Federal Trade Commission, 2024), concern and skepticism is well-founded What will educators and learners need to know and be able to do in order to use AI safely and effectively?

Digital Promise believes that safe and effective use of AI requires informed users and therefore calls on school leaders and policymakers to support AI literacy for all learners, educators, and community members to use emerging tech responsibly We define AI literacy as follows:

AI literacy includes the knowledge and skills that enable people to critically understand, evaluate, and use AI systems and tools to safely and effectively participate in an increasingly digital world.

For educators, the development of AI literacy is a necessary prerequisite to harnessing the power of emerging technologies for powerful teaching and learning  For learners, AI literacy can equip them with essential skill sets to responsibly use emerging technology for the good of society throughout their lives and in the workforce (World Economic Forum, 2024)  Using the concepts of AI literacy, learners, leaders, educators and caregivers can work collaboratively to make more informed decisions about if and how to adopt emerging technologies to promote safe and effective use of AI tools in our lives

To enable all who participate in educational settings to leverage AI tools for powerful learning, this paper describes a framework and strategies for educational leaders to design and implement a clear approach to AI literacy for their specific audiences (e g  learners, teachers, or others)  The first part of the paper describes a framework that identifies essential components of AI literacy and connects them to existing initiatives  The second part of the paper identifies strategies and illustrative examples as guidance for educational leaders to integrate AI literacy in K-12 education and adapt to their unique contexts

## AI Literacy Framework

To provide educational leaders with a concise and comprehensive AI Literacy Framework, Digital Promise took several perspectives into account  We incorporated insights about AI literacy from research-based frameworks such as Almatrafi et al , 2024, Druga et al , 2021, Ng et al , 2021 and Lee and Long (in press)  From an ethical decision making perspective, we considered the SAFE Benchmarks Framework (EdSAFE AI Alliance, 2024)  Finally, from a human justice perspective, we bring in the considerable body of research and journalism on algorithmic and technological bias (e g , Benjamin, 2019; Broussard, 2023; Buolamwini, 2023; Noble, 2018; O'Neil, 2016) and work within education on responsible AI and tech justice (White &amp; Scott, 2024)  We also took into account a longstanding history and research base of related media and computational literacies and their existing and historical applications in school settings  Based upon this body of work and listening to practitioners, we recognized that understanding, evaluating, and using are interconnected ways to engage with AI  Building and facilitating AI literacy necessitates all three  Further, understanding and evaluating AI is critical to making informed decisions about if and how to use AI in different contexts Underscoring our framework is human judgment and justice, which are core values for applying AI in appropriate contexts and mitigating the harmful effects of algorithms

The framework, pictured below, includes three Modes of Engagement: Understand, Evaluate, and Use  The interconnectedness of the framework indicates that Understanding, Evaluating, and Using happen concurrently and together support robust engagement in AI literacy

Figure 1 AI Literacy Framework includes three interconnected Modes of Engagement: Understand, Evaluate, and Use

<!-- image -->

We describe essential components of AI literacy for educational leaders to adapt to their contexts, including AI Literacy Practices to articulate how users engage in understanding and evaluating AI systems and tools, which are underpinned by Core Values that emphasize the importance of centering human judgment and centering justice in any application of AI  The AI Literacy Practices and Core Values are operationalized through three Types of Use The figure to the right elaborates our framework with each of the components

<!-- image -->

Table 1 Components of the AI Literacy Framework

| Framework Component   | Description                                                                                                | Examples                                                  |
|-----------------------|------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------|
| AI Literacy Practices | Actionable practices of understand and evaluate that learners can demonstrate                              | Data Privacy & Security, Information & Mis/Disinformation |
| Core Values           | Underlying principles that support learners to safely and effectively use AI tools                         | Human Judgment, Centering Justice                         |
| Modes of Engagement   | Interconnected ways users can engage with AI-enabled tools in order to demonstrate AI literacy Understand, | Evaluate, Use                                             |
| Types of Use          | Distinct purposes for which users engage with AI-enabled tools Interact,                                   | Create, Problem Solve                                     |

Each component of this framework is elaborated in the following sections of this paper  We begin by describing the AI Literacy Practices and connecting them to existing initiatives

Figure 2 Expanded AI Literacy Framework, including Core Values, Modes of Engagement, Types of Use, and AI Literacy Practices Create

## AI Literacy Practices

AI Literacy Practices are actionable skills that learners can demonstrate  These practices define how users can Understand and Evaluate AI-enabled tools and how educators can support AI literacy development  Breaking down complex topics such as AI literacy into practices can support leaders to define and implement AI literacy programs in their contexts  For example, AI Literacy Practices can be used to develop integrated learning opportunities or tools such as walk-through documents for coaches/administrators and formative assessments for teachers (Mills et al , 2020)  In the table below, we provide descriptions and examples of each of the AI Literacy Practices

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

Table 2 Description and Look fors for six AI Literacy practices

| AI Literacy Practice   | AI Literacy Practice                              | Description                                                                                                                                                                                                                                           | Student Look Fors                                                                                                                                                                                                                                                                                       |
|------------------------|---------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                        | Algorithmic Thinking, Abstraction & Decomposition | Develop and/or use a computer's ability to recognize data and create a prediction or perform an action based on both the situation and stored information without explicit human guidance                                                             | • Training and/or prompting AI tools and systems • Defining procedures as algorithms • Testing and debugging • Breaking down problems into smaller parts                                                                                                                                                |
|                        | Data Analysis & Inference                         | Consider the context of datasets, data visualizations, and data collection with criticality Assess quality of training data for AI tools and leverage AI models and methods to collect, analyze, and visualize data                                   | • Determine quality (accuracy, completeness, validity, etc ) of dataset • Analyzing and organizing datasets • Describing patterns and relationships • Evaluating and deducing information                                                                                                               |
|                        | Data Privacy & Security                           | Develop awareness of data privacy and security while fostering ownership and agency of how to protect data in AI- enabled systems This includes the privacy and security of personal data collected by an AI system or tool and how that data is used | • Identifying how personal information is being collected, used, and shared • Preventing tools from collecting data and/ or deleting data that was collected • Investigating AI models and methods that were used to develop a tool • Identifying datasets that were used to train an AI model          |
|                        | Digital Communication & Expression                | Understand how AI Systems create synthetic content, evaluate synthetic AI creations, and consider ethical responsibilities when consuming, creating, and sharing AI-enabled products                                                                  | • Understand norms and best practices of use, development, and application AI systems • Evaluate outputs of AI-enabled system for appropriate tone, audience, and content • Responsibly engage in the consumption, creation, or sharing of AI-enabled products, including ethical sourcing and citation |

<!-- image -->

<!-- image -->

| Ethics & Impact                   | Examine the outputs of algorithms and question the biases inherent in the AI systems and tools being used Consider the benefits and harms of AI tools to the environment, people, or society Importantly, it includes considering how datasets, including their accessibility and representation, reproduce bias in our society   | • Understand how values, beliefs, and points of view are applied through AI-enabled systems and outputs • Determine if and how an AI algorithm is the right tool for the job • Consider the benefits and/or costs of AI to individuals, society, and the environment • Understand if AI is perpetuating issues of access and equity   |
|-----------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Information & Mis/ Disinformation | Determine credibility of AI system outputs in digital landscapes This includes evaluating datasets and AI products/outputs for false, inaccurate or misleading information                                                                                                                                                        | • Analyze and synthesize multiple perspectives to support lateral reading • Cite valid, reliable data and evidence that apply in a variety of situations across contexts • Evaluate the credibility or accuracy of an output or prediction • Identify how bias in data collection informs reporting                                   |

These AI literacy practices support learners to understand and evaluate AI systems and tools  It's important to note that each of these practices can be learned and/or taught without the use of an AI tool  In fact, we suggest that learners should explicitly engage in AI literacy skill development (such as analyzing and organizing datasets) without AI tools, particularly in the early grades Existing initiatives, such as media literacy, digital citizenship, computational thinking and data literacy provide useful guidance and resources for leaders to understand how to build capacity for AI literacy  We elaborate on connections to existing initiatives and AI literacy practices in the following section

## Connecting AI Literacy to Existing Initiatives

AI literacy skills connect to initiatives that educators have been discussing and implementing in response to emerging technologies for decades  These include, but aren't limited to, computational thinking, data literacy, digital citizenship, and media literacy  These deep connections can allow school leaders to expand on existing initiatives and learning pathways to include AI literacy, or to introduce additional related learning objectives alongside AI literacy initiatives  Below, we explain how AI literacy practices are connected to existing initiatives, illustrated in Figure 3

Computational thinking , defined as solving problems systematically so that a computer could support the process or product development (Mills et al , 2021)  Computational thinking includes practices such as automation, data practice, and modeling and relates to AI literacy practices such as algorithmic thinking, abstraction and decomposition, information and mis/disinformation, data analysis and inference, and communication and expression

Digital citizenship , defined as the responsible use of technology to learn, create, and participate (James et al , 2021)  Digital citizenship includes media balance and well being, privacy and security, digital footprint and identity, relationships and communication, cyberbullying, digital drama and hate speech, and news and media literacy (Common Sense Media, 2024a)  It relates to AI literacy practices such as Ethics and Impact, Data Privacy and Security and Communication and Expression

Data literacy , defined as interacting with data (e g  collecting, analyzing, visualizing, interpreting) with criticality, uncertainty, and intrigue includes components such as context, aggregation, variability, visualization, and inference (Rubin et al , 2020)  It connects to AI literacy practices such as data privacy and security, information and mis/disinformation, and data analysis and inference

Media literacy , defined as the ability to access, analyze, evaluate, create, and act using all forms of communication includes critical analysis, inference, creative expression, bias, personal awareness, codes, conventions and constructions, mindful media habits and personal media management (National Association for Media Literacy Education, 2024)  It connects to AI literacy practices such as Ethics and Impact, Information and Mis/Disinformation, Data Analysis and Inference and Communication and Expression

Figure 3 Connections among AI literacy practices and Digital Citizenship, Media Literacy, Computational Thinking and Data Literacy

<!-- image -->

These existing initiatives provide leaders a starting point to understand how to build capacity to teach AI literacy  Learners will be better prepared to apply these practices to AI tools if they have opportunities to develop them early and often across grades and subject area learning

Over time we anticipate that the increasing prominence and ongoing development of AI tools will shift priority skills within these foundational literacies  For instance, programming has been viewed as a priority skill for Creating Automations, a key practice in Computational Thinking, but AI systems now have the ability to automate on their own, with human oversight, and the skills for this oversight may overtake programming as the key skill for understanding and creating automated systems  To understand how these practices are specifically applicable to AI systems, and how those skills will continue to shift with the innovation of emerging technologies, educators should have a foundational understanding of AI and how it works  In the following section, we provide an overview of AI, intended for leaders to adapt for their context and audience

## Understanding AI

When users are working to understand AI, they should ask 'how does it work?' and 'how can we make it better?' (Druga et al , 2021)  Understanding AI is an essential component of AI literacy because in order to make informed decisions about using and evaluating AI, users should have a basic understanding of what AI can do and how it works  In this section, we provide a general scope of information that leaders should adapt to their unique contexts, including a brief overview of the history of AI, how it works, and how it's being used

## A Brief History of AI

Many people associate AI with futuristic visions of technology or Sci-Fi movies, but AI has existed for decades  It was established as a field of study in the 1950s  At its origination, it was considered a subset of mathematics and computer science  Advances in technology have enabled computational devices to become increasingly integrated throughout all sectors of life and work Computers can now collect and store data about almost anything and are equipped with the processing speed to analyze it quickly  These advances have enabled AI to move from a field of study to a much more interdisciplinary and relevant tool

## How Does Artificial Intelligence Work?

We strongly recommend that you provide your audience with an explanation of what AI is and how it works  We recommend that this not be couched in metaphors like 'human-like' or examples of AI's powers, but rather be a mechanistic discussion  Key points it should cover include how AI uses data; that models rely on statistics and are based on identifying and analyzing key features of data; and that it synthesizes new content by using statistical models and predicting outputs, such as the next word or pixel  Of course, your own explanation may do this at many levels of detail, depending on your audience  Here we provide an example from MIT Media Lab Personal Robots Group and the MIT STEP Lab (2024) that we've adapted  As illustrated in Figure 4 below, AI systems are generally developed in three steps:

- 1 Obtaining and curating data Machine Learning systems require digital data and modern life is flooded with it  This data includes pictures, text messages, all social media posts, images, and videos, and really, everything that is in digital form on the internet  People who program and develop AI tools make choices about what data to use in order to train AI systems and determine how that data is aggregated, categorized, and prioritized

<!-- image -->

- 2 Train a model Models are useful simplifications of reality  The pictures, text, posts, and videos (discussed above) are the data that inform the models; the model simplifies the actual data and only keeps a much smaller (but still very large) set of statistics about the relationships among the words, for language models, or pixels, for pictures and image models  For example, a GenAI system that creates text has statistics about the relationship among words and how they are used in language
- 3 Using the model to receive an output For GenAI systems that generate text, a person may ask a question in the form of a prompt  That prompt then serves as input for the statistical model  The statistical model translates this prompt into numbers  Then, it runs computations in that model to predict an output based on statistical associations  For example, text GenAI systems generate words to answer the question

Figure 4 Diagram Overview of How AI Systems are Developed in Three Steps

<!-- image -->

What if we wanted to make a GenAI system that generates predictions as its outputs? We could consider the example of a simple AI model that could predict when a person might be hungry based on just two types of data: (1) What time of day it is and (2) When the person last had something to eat  The developers of the AI system might make a model that suggests when people might be hungry by time of day, but shifts the times later if people ate recently  We could use the model by putting in the time of day for a particular person, as well as when they last ate, and get a prediction for how hungry they are

A more advanced model could include other relevant data, such as personalized biometric data, activity level, and the other types of food that they ate  The AI system would determine statistical associations among all of these data points in order to make a prediction as its output  AI systems apply this automation to all kinds of things that might be sensed and predicted by developing associations among billions of data points in order to make a prediction  Below, Figure 5 illustrates the inner workings of a specific type of AI model called an artificial neural network  It is arranged in layers of 'nodes' representing data starting with an input layer, hidden layers as a black box, and then an output layer  The nodes are connected by lines representing weighted associations which indicate the mathematical strength of each connection  In this type of model, there are hidden layers that perform statistical functions that are intractable because of the sheer number of connections and parameters  Because we are not able to understand these models, it's as if they are in a black box  Given AI systems and tools rely on black boxes that do not allow humans to understand how outputs are decided on, these AI systems and tools should not be used for high-stakes applications

Figure 5 Depiction of an Artificial Neural Network Model

<!-- image -->

In summary, AI systems are trained with extremely large amounts of data  Computers analyze the data for patterns through automated statistical analysis, to generate a prediction or synthetic content  To train an AI system, humans must make decisions about what data to use, and how to aggregate, categorize, and prioritize each piece of data  It is important to note that with GenAI, each data point (e g , word, pixel, etc ) is only one part of the output  Because there are multiple parts to the output, the model must be run many, many times to generate an output that has many parts, for example, an essay that has paragraphs  Next, we provide some examples of how AI is being used so that users are aware and familiar with common applications of AI, and the types of things it can do

## How Is Artificial Intelligence Being Applied?

AI is very much integrated across tools and sectors in our day to day lives in ways that we may or may not recognize  For instance, AI systems are used for facial recognition, document translation, and personalized recommendations  In education, AI is applied for teaching, learning, assessment, and administrative tasks  Some familiar examples of how AI is currently used in education are in the table below  More detailed applications can be found as case studies in the recently released World Economic Forum (2024) report, Shaping the Future of Learning, The Role of AI in Education 4.0

Table 3 Examples of Applications of AI in Education

| Level of Support   | Examples of Applications                                                                                                 |
|--------------------|--------------------------------------------------------------------------------------------------------------------------|
| Systems Support    | • Early warning systems • Automation/optimization of school operations (scheduling, resource allocation, inventory, etc) |
| Teacher Support    | • Automatic feedback/grading • Lesson generation • Student data analysis                                                 |
| Classroom Material | • Generation of activity-specific content (flashcards, quizzes, graphic organizers, differentiated content, etc )        |
| Student Support    | • Intelligent tutoring systems • Early reading coaches • College/career advising                                         |

AI will continue to be integrated in educational contexts in existing and novel ways  Educational leaders should support all users of AI to understand and evaluate AI-enabled systems to ensure the safe, efficacious and ethical use of AI  As such, evaluating AI is a main component of our AI Literacy Framework, and discussed more in the next section

## Evaluating AI

Evaluating AI is an essential component of AI literacy  Leaders must support users of AI to be critical consumers because we know that AI can perpetuate biases and incorrect information (Broussard, 2023; Buolamwini, 2023; Noble, 2018; O'Neil, 2016; Webb, 2024)  If left unchecked, AI has the potential to cause harm to individuals and communities  We must constantly consider the benefits and/or costs of AI to individuals, society, and the environment  Human judgment is ultimately responsible

<!-- image -->

for determining if and how it is appropriate to integrate AI outputs or predictions in our lives  The core values elaborated in the following section provide additional context and explanation of how and why to evaluate AI systems and tools

## Core Values

Core values are overarching practices that support learners to safely and effectively evaluate AI tools  In this section, we name two core values, Centering Human Judgment and Centering Justice To support AI literacy development, leaders have a responsibility to connect these core values to the specific applications of AI systems and tools in their unique context

## Centering Human Judgment

Developers design AI systems that use hardware, algorithms, and data to do things like make decisions, discover patterns, and perform actions  While AI appears to mimic human intelligence; it is not the same  Humans and computers are good at different things  Computers are very good at performing mathematical calculations quickly and following a precise set of instructions Computers can analyze large amounts of data in order to make predictions, but the applicability of those predictions is limited to the scope of the data that was collected  Computers cannot take into account information that they do not have access to, such as context and emotions For example, AI can't detect human-to-human sarcasm or understand different contexts or situations  AI also does not have consciousness; it is not reflective or able to assess its actions (Huckins, 2023)  Because of this, we caution against anthropomorphizing AI  We remind users that AI tools should be referred to as 'it' rather than pronouns and avoid referencing GenAI errors as 'hallucinations' to avoid making light of mental health issues (Ruiz &amp; Glazer, 2024)

Our world is increasingly becoming one in which computers and humans work together to solve problems (Roschelle et al , 2021; Roschelle, 2020) Humans have a responsibility to apply their unique skill sets to the application of AI systems and tools, including understanding complexity, handling vague or ambiguous situations, understanding context, empathizing, and ethical decision-making (Heintz, 2022)  Centering human judgment includes identifying

<!-- image -->

appropriate tasks for computers to support and determining if and how it is appropriate to integrate outputs or predictions in our lives  Further, it considers how values, beliefs, and points of view are applied through AI-enabled systems/outputs  For example, if we continue to power our planet through fossil fuels, large AI systems will likely harm our environment through unchecked energy consumption (Dhar, 2020; Keller et al , 2024)  Human judgment must weigh the benefits alongside associated costs of implementing AI systems  To ensure ethical application of AI systems and tools, it is essential that humans remain at the center of if and how we integrate artificial intelligence into any context

## Centering Justice

AI systems are impacting the lives of nearly everyone within modern society, but their results do not equally represent the interests of all people  They can and have exacerbated existing oppression and prejudice within society  Druga et al  (2021) provided examples of biases that children identified in AI systems including race and ethnicity bias (facial recognition systems recognizing white faces with more accuracy than faces from other races), age bias (AI systems not acknowledging young voices) and gender bias (AI voice assistants using female voices enforce gender norms)  One cause of this bias is the data used to train algorithms within the AI systems and tools  This data often underrepresents historically excluded communities (Benjamin, 2019; Buolamwini, 2023)  Yet, fixing this disparity is not as easy as collecting more data  Efforts to do so in the past have caused more harm to communities (Hollister, 2019) and there are important ethical concerns around the digital surveillance of marginalized communities, particularly the collection of images and audio to be included within large-scale datasets without proper consent for people's data (Buolamwini, 2023)  Individuals must be aware that AI can collect and use data unethically  For example training datasets sometimes come from public forums on the internet  Large language models (LLMs), such as ChatGPT, use a large amount of the written material available on the web, without accreditation or consent, leading to biased and erroneous outputs

Another cause of bias within AI systems involves the variables, or information, included in the algorithm  For example, a model that evaluates risk based on historical data might not use race, religion, gender, or age variables, but the proxy variables used like zip code and education level  can be just as discriminatory (O'Neil, 2016)  The individuals that design AI systems, as well as the individuals in leadership positions to determine if and how they should be used, are disproportionately white and male (U S  Bureau of Labor Statistics, 2024; Wachter-Boettcher, 2017)  Therefore, algorithms are currently designed and implemented with a drastic lack of representation from marginalized communities, including communities of color and people with disabilities (Noble, 2018)  Algorithmic bias and the harms it can cause have impacted communities in many ways  In every context in which AI is applied, there is a risk of implementing automated decision-making at scale based on AI systems which perpetuate harm Users must center justice while understanding, evaluating, and using AI in order to ensure that all people, particularly those who have been historically and systematically excluded, are not harmed by the use of AI (White &amp; Scott, 2024)  This is particularly crucial within the education system as

young people are being asked to engage with AI systems without choice about what tools they may use  Teachers and leaders in learning environments must be judicious in understanding the tools they choose and how their learners, in all their variability, will be impacted

Users must constantly center these core values in any use or application of AI systems and tools Of course, there are unique risks associated depending on the use and or context of the AI  The following section elaborates these specific risks in the final dimension of our framework, Using AI  It distinguishes between three different Types of Use: Interacting with AI, Creating with AI, and Problem Solving with A  For each type of use, it describes AI literacy practices and specifies considerations for evaluation

## Using AI

Educational participants use AI for different purposes  In this section, we describe three Types of Use: Interacting with AI, Creating with AI, and Problem Solving with AI Interacting with AI systems is engaging with adaptive technology in multiple modalities that adjusts to data collected, such as when learners use adaptive tutors in math or reading to receive content at their level of understanding Creating with AI can translate or synthesize automated content, such as using tools that use LLMs to generate text Problem Solving

<!-- image -->

with AI is leveraging AI tools to engage in inquiry, such as decomposing problems and innovating novel automated solutions  In all of these cases, we need to apply specific skills to remain critically aware of the information they are collecting, using, and sharing in what they do  The chart below provides examples of each type of use

<!-- image -->

<!-- image -->

<!-- image -->

Table 4 Description and Examples of Different Types of AI Use

| Types of Use            | Description                                                                              | Examples                                                                                                                                                                                                                                                                                                                                                                                           |
|-------------------------|------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Interacting with AI     | Engaging with adaptive technology that adjusts to data collected                         | • Scrolling through a feed on a social media platform with 'recommended' posts • Speaking to virtual assistants (Siri, Alexa, etc) • EdTech platform that personalizes learning (automate question difficulty, text-to-speech accommodation, etc )                                                                                                                                                 |
| Creating with AI        | Translating or synthesizing content                                                      | • Prompting an AI-powered image animator • Prompting a chatbot to create synthetic text • Using AI to transcribe an audio file • Using an AI wrapper to create a chatbot • Generating activity-specific content (flashcards, quizzes, graphic organizers, differentiated content, etc)                                                                                                             |
| Problem Solving with AI | Engaging in inquiry, including decomposing problems, and developing innovating solutions | • Constructing an AI-enabled tool to address novel ways of better connecting ideas to address a real-world problem (e g building an image detection algorithm to clean litter or a sensor to monitor water quality) • Analyzing existing data to investigate problems, forinstance, using AI tools to interrogate how writers with different backgrounds or perspectives might analyze a situation |

AI literacy requires understanding the risks inherent to each of these types of use  In the following sections we explain how AI literacy practices can be uniquely applied to each use type in order to effectively understand and evaluate AI-enabled systems and tools

<!-- image -->

Interacting with AI involves engaging with adaptive technology in multiple modalities that adjusts to data collected  Using these tools can make certain tasks or decisions easier  For example, suggesting songs to make your perfectly curated road trip playlist requires access to data about songs (e g  genre, artist, tempo), as well as features of the songs that you like to listen to

Interacting with AI often requires enabling AI tools access to personal data in order for it to automate a process or make a prediction  With regard to interacting with AI, there is a risk of personal data that is being collected or shared without consent  All too often people use AI passively without considering the privacy, safety, or societal implications of doing so  To be truly AI literate, users must take a more active approach, with critical awareness of what data the algorithm is using and how it is being applied and shared  In the table below, we connect each AI literacy practice as it relates to users interacting with AI

Table 5 AI Literacy Practices for Interacting with AI

<!-- image -->

| AI Literacy Practice   | AI Literacy Practice                              | Example Application to Interacting with AI                                                                                                                                                                                                   |
|------------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                        | Algorithmic Thinking, Abstraction & Decomposition | Understand how AI tools make automated recommendations and how to influence recommendations for specific goals                                                                                                                               |
|                        | Data Analysis & Inference                         | Identify the data that the AI model is taking into account, and how it influences recommendations                                                                                                                                            |
|                        | Data Privacy & Security                           | Understand what data is being collected and shared and how to control settings that protect data privacy                                                                                                                                     |
|                        | Digital Communication & Expression                | Responsibly engage with and share AI-influenced or AI-created content online                                                                                                                                                                 |
|                        | Ethics & Impact                                   | Responsibly interact with age-appropriate tools and platforms Be aware of the impact of consumption of AI-influenced content on self, others, and environment                                                                                |
|                        | Information & Mis/Disinformation                  | Navigate the information landscape to understand what suggestions are relevant and appropriate Fact check content the algorithms recommend Seek information outside of 'filter bubbles' which can limit exposure to different points of view |

<!-- image -->

Generative AI platforms such as ChatGPT, Claude, Gemini, and other LLMs can generate text responses to prompts and platforms such as DALL-E can generate images  The outputs are synthetic content based on associations among billions of data points  To create an output, the person using a GenAI has to enter a prompt  The skill of GenAI prompting involves creating good questions or commands that get the system to produce something that humans consider to be a quality output  While prompting itself is a skill, it requires an understanding of the desired outputs and of how to verify and validate that those outputs are accurate  Effectively prompting a GenAI system or tool takes time and often requires clear communication, specificity, experimentation, and patience

There are also risks associated with Creating with AI  Since data used to make predictions are historical, they may contain biases and assumptions that we do not want to perpetuate  For example if asked to generate an image of a doctor, a GenAI model might be more likely to generate a white male  There is another risk that GenAI might generate something completely wrong  LLMs have a tendency to include subtly wrong or harmfully wrong information (Webb, 2024)  For this reason, GenAI systems should not be used to learn new information about that topic  LLMs are also capable of easily being used to produce nefarious outputs, such as deep fakes (Ferrara, 2024)  Technological guardrails are often slow to appear or easily circumvented Humans need to provide significant oversight about the content the LLMs are producing, particularly for vulnerable populations such as children  We remind users to check acceptable use policies before encouraging learners to directly use GenAI platforms given that many are for users ages 13 and up  After ensuring ethical use of GenAI, and verifying the synthetic product is accurate and reliable, users should cite and acknowledge use of the GenAI tool when sharing its outputs

Table 6 AI Literacy Practices for Creating with AI

<!-- image -->

| AI Literacy Practice   | AI Literacy Practice                              | Application to Creating with AI                                                                                                  |
|------------------------|---------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|
|                        | Algorithmic Thinking, Abstraction & Decomposition | Distinguish between essential and nonessential components of a prompt to produce an appropriate output                           |
|                        | Data Analysis & Inference                         | Identify the context and source of the dataset the AI platform was trained on                                                    |
|                        | Data Privacy & Security                           | Understand what and how data is being collected and shared by GenAI tools, and how to control settings that protect data privacy |

<!-- image -->

| Digital Communication & Expression   | Recognize appropriate opportunities to use AI to create more efficiently or augment creative skill sets Evaluate how generated outputs are appropriate for the audience communications/relationships (emails, birthday cards, etc)                                                                     |
|--------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Ethics & Impact                      | Consider how your creation aligns to personal values/ethics Ensure appropriate and ethical application of synthetic content (e g citing appropriately, mitigating harm of deep fakes, etc) Become aware of the impact of consumption of GenAI created content on self, others, environment and society |
| Information & Mis/Disinformation     | Identify mis/disinformation in synthesized outputs/products Evaluate whether you are perpetuating false information when creating (e g do not include mis/disinformation in prompts)                                                                                                                   |

<!-- image -->

Problem solving with AI is using AI-enabled systems and tools to engage in inquiry, such as to decompose problems or develop innovative solutions  An example is training an algorithm for image detection, such as distinguishing between marine animals and litter as part of an automated system to clean up aquatic ecosystems (Code org, 2024)  Taking it a step further, another example is of learners in Delhi, India who applied computer science learnings to build an AI sensor boat to monitor water quality for local villagers and protect aquatic animals (Kumar, 2023)

Likewise, there are risks associated with Problem Solving with AI  Developers need to be aware that algorithms take on the biases that are already represented in the data and all data includes human biases  Therefore, evaluating the sources, contexts and organization of the training data is essential  Most of the training data available to AI systems comes from public interfaces on the internet, which is overrepresented as white and male (Buolamwini, 2023; Noble, 2018) Furthermore, the data used to train these models has often been used without the authors' or artists' consent which has created legal issues and challenges currently in litigation (Ingram, 2023) Additionally, developers must ensure ethical application of the prediction or product from the AI-enabled system  This is particularly important because with AI systems, a human may not be able to understand the rules the algorithm is creating and using to make decisions  Therefore, it's important to consider values, beliefs, and points of view when applying predictions from AI tools to make decisions  The more we understand about the data and algorithms in the AI-enabled systems we use, the better we can make decisions about if and how to use them

Table 7 AI Literacy Practices for Problem Solving with AI

<!-- image -->

| AI Literacy Practice   | AI Literacy Practice                              | Application to Problem Solving with AI                                                                                                                                                                      |
|------------------------|---------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                        | Algorithmic Thinking, Abstraction & Decomposition | Understand how to leverage large datasets to train an AI system to perform a task                                                                                                                           |
|                        | Data Analysis & Inference                         | Evaluate the sources, contexts, and organization of data on which the algorithm is trained                                                                                                                  |
|                        | Data Privacy & Security                           | Consider what personal identifiable information (PII) or sensitive data you are collecting in your approach to problem solving and how to protect user privacy and security                                 |
|                        | Digital Communication & Expression                | Understand norms and best practices to develop and share AI systems Evaluate how the outputs of the AI-enabled system you programmed are shared and communicated to the user                                |
|                        | Ethics & Impact                                   | Consider the underlying values, ethics, and intended impact of your AI tool on self, others, environment, and society Evaluate whether the prediction or application in your algorithm is perpetuating bias |
|                        | Information & Mis/Disinformation                  | Identify bias and representation in the training data or incorrect results                                                                                                                                  |

## Putting It All Together

We are applying this framework to support educators and leaders in designing AI literacy learning experiences for specific audiences  The following graphic illustrates an example of the framework in action for a high school student, following a winding pathway of the three Modes of Engagement  It demonstrates how engagement in AI literacy is non-linear and intertwined, where each mode of engagement builds and strengthens on each other to foster overall AI literacy  The lesson example builds on Common Sense Media's AI Literacy Lessons for Grades 6-12, specifically, Lesson 3: 'AI Chatbots: Who's Behind the Screen?' (Common Sense Media, 2024b)

<!-- image -->

<!-- image -->

<!-- image -->

While this example helps us to understand what a learning experience for AI literacy could look like in high school, there are systems-level policies and structures that will enable these learning experiences to occur  In the second part of this paper, we identify five strategies for systems leaders to promote AI literacy in K-12 education: providing guidance for adoption and evaluation, integrating AI literacy across grades and subject-area learning, facilitating professional learning, designing powerful learning experiences, and promoting awareness and agency

## Strategies to Promote AI Literacy in K-12 Education

AI literacy has emerged as a skill set for everyone to safely and ethically participate in an increasingly digital world  Public schools have a critical role to integrate AI literacy throughout K-12 education so that our current and future communities are aware and able to critically evaluate AI systems  Our AI Literacy Framework provides guidance on how leaders can design AI literacy programs so that users can safely and effectively use, understand, and evaluate AI tools in their contexts  This section identifies five strategies to promote AI literacy in K-12 education, and provides examples and guidance for implementing each strategy

## Strategy 1: Provide Guidance for Adoption and Evaluation

## Systems Leaders and Policymakers

There is a need for policymakers and school leaders, in partnership with educators, students, and families, to develop guidance for the adoption and evaluation of AI tools in K-12 education  This guidance is a pressing need for educators and families as many AI tools are purposefully trying to market directly to teachers and bypass their administrators (Oakes, 2021)  There are several factors to consider when choosing to adopt or use an AI system or tool, including accessibility and equity, data ownership and privacy, transparency, and impact  Digital Promise, with funding from the U S  National Science Foundation along with educational leaders, technology specialists, teachers, students, and families co-designed an Emerging Technology Adoption Framework for PK-12 Education that provides guidance for informed evaluations and procurement decisions including the initial evaluation of tools, as well as factors to consider as tools as adopted and used (Ruiz et al , 2022)

In developing acceptable use policies for adoption and evaluation, leaders should consider the following:

- Inclusivity Elevate the needs, interest, and voice of marginalized communities in the development of policy and guidance in order to ensure AI tools are accessible to all students and do not perpetuate harmful biases  Support policies and programs that promote digital equity and accessibility through initiatives that impact access, affordability, and adoption (Weaver, 2022)
- Adaptability There are new platforms for AI systems and tools emerging everyday Guidance should be adaptable in order to be responsive to the risks of new applications as they arise  Additionally, AI systems and tools are being used across environments  While

Digital Promise school systems have control over the technology that they provide, they have much less control over the technology that students bring to school, use outside of school programs, or use at home  Responsible use guidelines and policies should promote responsible use across contexts, both at school and outside of school

- Impact Understand the impacts of integrating AI systems and tools in learning environments, including safety and equity across students of different backgrounds, abilities, and demographics  Take a careful approach, go at a pace where you can ensure that technology adoption does not harm students in your charge or their communities
- Awareness, Agency, and Transparency School districts should require usable platforms and features that promote individual awareness of data ownership and privacy, as well agency to opt-out  Chief Information and Technology Officers have made progress in managing data privacy and security risks and these policies should remain agile as new technologies and platforms continue to emerge

## Iowa City Community School District Provides Guidance for Teachers and Students

Iowa City Community School District is developing AI responsible use guidelines for teachers and students  They currently have several GenAI tools available for teachers to use, and a subset of GenAI tools available for high school students

To develop responsible use guidelines for their district, they established a working group of district leaders, school leaders, and teachers  Inviting educators to be on the committee was central to their responsive approach, rooted in what the teachers need

The group explored tools, engaged in discussions around safe, ethical, and responsible use, and provided feedback on multiple drafts of responsible use guidelines for teachers and students  The final draft includes definitions, permitted uses of AI, prohibited uses of AI, responsibilities of students and staff, response to violations, and special considerations such as transparency and communication

In addition to the Responsible Use Guidelines, the AI working group drafted teacher and student guidelines, pictured below These documents are intended to be posted in classrooms for quick uptake and reminders about responsible use  They summarize what students need to be mindful of when using AI for learning, and what teachers need to consider when leveraging AI for instructional design

®

AI Literacy: A Framework to Understand, Evaluate, and Use Emerging Technology

Figure 7 Guidance for Teachers and Students to use AI from Iowa City Community School District.

<!-- image -->

<!-- image -->

27

In the future, Iowa City plans to share the responsible use guidelines districtwide, and align them with the academic code of conduct and board policies  They are also planning to provide foundational learning for teachers, establish a scope and sequence for equipping students with the knowledge to stay safe when using AI tools, and identify one teacher from each building to champion the work, providing just-in-time learning to colleagues and co-designing examples of generative AI in lesson planning, differentiation, and feedback/assessment

## Strategy 2: Integrate AI Literacy Across Grades and Subject-Area Learning

## System and School Administrators

It is essential that educators integrate AI literacy within the topics they already teach, such as math and ELA  While library media and computer science courses are certainly programs that can build AI literacy foundational skills and technical knowledge, integrating AI literacy across subject area learning enables students to experience the cross-disciplinary application of AI tools Integrating AI literacy across disciplines is advantageous for several reasons  One is that library media and computer science courses are typically elective courses which are not mandated for all students  Computer science courses also disproportionately enroll white males (Code org et al , 2023)  In order to promote AI literacy for all students, particularly females and students of color, it is essential to integrate AI Literacy Practices into core subject areas like math and ELA Another reason to integrate AI literacy across subjects is to realize its potential to introduce novel teaching strategies and enhance learning  For instance, students can learn about homonyms in English Language Arts by using and evaluating text-to-speech systems  If complementary integration points are identified, AI literacy can become a value-add to disciplinary learning and not an add-on to an already overscheduled school day  Finally, cross-disciplinary integration of AI literacy enables students to make connections to cross-sector application of AI, which is relevant to their career and workforce awareness and preparation

We also recommend that AI literacy skills should be integrated cumulatively throughout grades K-12  In the younger grades, students should build foundational skills without necessarily using AI-enabled tools themselves  For example, students might study probability in math and describe patterns and relationships in the data  They could develop a program in Scratch (Algorithmic Thinking, Abstraction and Decomposition) and determine the implications of sharing their program within the Scratch community (Data Privacy and Security; Digital Communication &amp; Expression)  They could also collect data in science or social studies classes and discuss what the sample includes and does not include (Data Analysis &amp; Inference)  In fact, because AI literacy is so dependent on the existing initiatives described earlier, some of these sorts of lessons are likely already taking place in many schools within initiatives already dedicated to media literacy, digital citizenship, and computational thinking  Building these foundational skills is essential to prepare students to engage critically with AI tools when developmentally appropriate   We can build

from well-established bodies of work that support our understanding of learning progressions for these foundational skills (Rich et al , 2017, Rich et al , 2018, Rich et al , 2019) and strategies to integrate them across disciplines and content areas (Mills et al , 2024)

There is no straightforward answer to what age or grade is most appropriate to integrate AI systems or tools  The minimum age that federal law states that students can create their own digital accounts is 13 years, however this depends on the system and not all tools require account creation or some tools might be used by students under a teacher or guardian's account  We suggest educators take a nuanced approach to integrating AI tools in learning environments depending on the students developmental milestones, cognitive readiness, the context and the purpose of use  Additionally, educators should ensure that students' personal data is protected, provide guidance and oversight about how to remain critically conscious of its use and implications, and communicate about how they are using the tools with parents and caregivers

## Talladega County Public Schools Designs K-12 Learning Pathways for AI Literacy

Talladega County Public Schools has designed and implemented K-12 cumulative, consistent and competency based integrated learning experiences for computational thinking  Their CT pathway was developed by teachers from each grade level in alignment with Alabama Digital Literacy and Computer Science Standards  Talladega continues to expand on their CT pathway, and is now engaging teachers to design learning experiences that specifically integrate AI literacy

Learn more about:

-  Designing K-12 Learning Pathways
-  Talladega County's Computational Thinking pathway

Figure 8 Example of a Learning Pathway Integrating Algorithmic Thinking, an AI Literacy Practice Across Subject Areas in Middle School

<!-- image -->

## Strategy 3: Facilitate Ongoing, Just-In-Time Professional Learning

## Instructional Leaders

Safe and effective integration of AI tools in education depends on AI literate teachers  However, it is not reasonable to assume that teachers will learn how to use, understand, and evaluate AI tools on their own  Professional learning aimed at enhancing AI literacy can support teachers to understand how to promote AI literacy skill development  AI literacy for teachers is two-fold Teachers need to be literate in using AI tools for both teaching and learning  For teaching, they may focus on lesson planning, smart content creation, or grading  A focus on learning includes facilitating powerful learning experiences that promote students to develop AI literacy skills, as well as scaffolding and supporting students to leverage AI tools for learning  AI can only be used ethically and effectively in teaching and learning if teachers are literate in its use

A challenge to providing professional learning for integrating emerging technologies such as GenAI is that new tools and platforms are constantly evolving, along with teachers' support needs  In working with districts from across the country, Digital Promise has found that districts are designing professional learning structures that are responsive to these needs, expanding beyond traditional workshops  These professional learning ecosystems leverage existing systems and structures, are sustained, provide point people, and include wrap-around supports (Coenraad et al , 2024)  We elaborate on examples and strategies that specific districts are using below

## Districts Support Teachers to Integrate AI Literacy

Broward County Public Schools has integrated AI literacy workshops into existing professional learning opportunities for teachers  In these workshops, teachers learn what AI is, discuss ethics and explore lessons that can be done in different subject areas and grade levels  They engage in hands-on learning opportunities to develop AI literacy skills (both plugged and unplugged) Teachers work collaboratively to draft an AI Bill of Rights (e g  EngageAI Bill of Rights Task Force, 2024) to guide best practices for AI in teaching and learning  Finally, they collaboratively design lessons that integrate AI tools into their classrooms, with just-in-time support from expert facilitators

To remain responsive to the emerging AI-enabled platforms, and the affordances and risks of each, Broward and other districts are expanding professional learning systems beyond traditional workshop-based approaches (Coenraad et al , 2024)  Below, we identify several examples of teacher support that supplement traditional workshops, are sustained over time, and offer justin-time support for teachers

<!-- image -->

Curated Teaching Resources In Broward County Public Schools, the STEM+CS program provides a suite of curated resources that have been reviewed and are regularly updated by district staff for teachers and school leaders, eliminating the barrier of finding materials to integrate AI literacy

Digital Promise

®

AI Literacy: A Framework to Understand, Evaluate, and Use Emerging Technology

30

<!-- image -->

<!-- image -->

School-Based Champion Talladega County Schools and Iowa City Community School District both leverage a champion within each school as point-people that advocate for and lead the effort of AI literacy within the school building

Content and Grade Alike Collaborators North Salem Central School District is leveraging their context as a small district to support districtwide professional learning across grade levels and content areas so teachers can turn to each other as partners and collaborators

## Strategy 4: Design Powerful Learning Experiences

## Teachers and Instructional Leaders

Technology for learning is enacted through a pedagogical lens (Mishra &amp; Koehler, 2006), and AI is no exception  That is, technology can be used in ways that promote critical thinking, exploration and creative expression  In the case of AI, this might include leveraging a LLM such as ChatGPT to brainstorm ideas  On the contrary, AI can also be used for skill and drill exercises or standardized assessment  For instance, algorithms are commonly used for individualizing recommendations of standardized learning content on computers  We support the recommendations from the National Education Technology Plan to integrate technology, such as AI, in ways that promote critical thinking, collaboration, creativity, and communication in order to close the digital use divide (U S  Department of Education, 2024)

If used in this way, AI tools have the potential to promote Powerful Learning experiences (Digital Promise, 2024)  Powerful Learning experiences are:

Personal and Accessible

Collaborative and Connected

Authentic and Challenging

Inquisitive and Reflective

Powerful learning experiences integrate AI tools in ways that promote learner-agency, openended problem solving and human connection (Resnick, 2024)  Learning sciences research provides a valuable lens through which to understand how AI-enabled tools can promote powerful learning, taking into account a social, collaborative view of learning in ways not always measured by typical tests (Fusco et al , 2020)  Learning sciences can help us understand how AI tools should scaffold or enhance a learner's ability to engage in critical thinking, creativity, collaboration, and creativity, and not replace or hinder it

Educators should scaffold students to understand and critically evaluate AI tools everytime they are integrated into learning environments  For example, a lesson may require that a student pulls from personal experience or emotional intelligence to edit a response from a GenAI system,

Digital Promise which would inherently require the student to evaluate the output  Druga et al  (2021) discovered that one way that children can engage in critical awareness of AI is by trying to 'trick the AI ' For instance, they drew nonsense images to 'trick' image recognition systems and wore masks to 'trick' facial recognition systems  Tricking the system reveals flaws and biases of the designers Users can evaluate what the designers valued and what they ignored  Designing lessons in this way also alleviates concerns about misconduct with AI tools, such as plagiarism or inappropriately using the technology to learn new ideas, which could be fraught with misinformation  We elaborate a more specific example of what this could look like in classroom practice below

The expectation, however, is that each of these designs and implementations will differ slightly due to the variance of context and student needs within and between classrooms  With that variance in mind, it is important for policy to position the teacher, who is the context expert, in a way that allows them to design safely for their particular students  Teacher expertise should be leveraged to fine tune broader implementation of AI tools for teaching and learning, and district policy and procedure should facilitate that

## Special Education Class Leveraging AI Tools to Scaffold Writing

Mr  Matthew Jones, a middle school teacher in the Suffern Central School District, leveraged ChatGPT in his Foundations classroom-a program with a particular focus on core academic skills for students with Individualized Education Plans (IEPs) that are significantly below grade level  The objective of the lesson was to support reading and writing skills by internalizing key elements of a story (e g  character, setting, plot, genre, tone, etc )  Prior to this activity, students practiced this skill by identifying key elements in short stories  The next step was for students to apply their learning by generating their own story elements

Inspired by a short story they read in class, students were prompted to create their own story adding a superpower of their choice  They used an 'AI Prompt Organizer' which the teacher input into ChatGPT, while removing any personally identifiable data, asking it to generate a story using the details the students brainstormed  The students then practiced reading fluency, excited to recite a story about their own ideas, and analyzed the output to edit  To further build on this lesson, next year students will draw pictures of their story and animate it using an AI image animator

This use-case allowed for scaffolded support of writing instruction, especially given students in this class often struggled with the stamina to construct passages  Mr  Jones explained, 'Due to the nature of the students in a 12:1:1 class, being able to write full stories for themselves is a goal that would take many, many weeks or months of writing and revision  It is a task that would have consumed an entire quarter

®

Figure 9 AI prompt organizer to scaffold story creation with GenAI in a Special Education class.

<!-- image -->

AI Literacy: A Framework to Understand, Evaluate, and Use Emerging Technology

32

or more  By using ChatGPT as an assistive technology the students were able to learn about and use the story elements to write a story that they can be proud of that was dynamic, personal, and unique '

This lesson exemplifies designing for learning because the AI tool created an opportunity for creative expression, encouraging students to see the vast potential of their own ideas  The output of ChatGPT, in this case, expanded learning opportunities for students with diverse needs  The teacher ensured that the story centered student voice with

Mr. Matthew Jones and Mr. Howard Fox (Teacher Aide) supporting students in filling out their prompt organizer.

<!-- image -->

the prompt organizer which scaffolds prompt generation  Notably, Mr  Jones controlled the information entered into ChatGPT to protect student privacy and comply with age restrictions of the platform  This was a team effort made possible by the teaching team including: Howard Fox (Teacher Aide), Jane Torrance (Vision Teacher), JD Wissner (Teacher Assistant), and Vicky Machado (ENL Teacher)

## Strategy 5: Promote Awareness and Agency

Leaders, Teachers, Learners, Caregivers, and Community Members

Because AI literacy is a skill for everyone, schools and districts can support not only their students but also families and caregivers and their broader community to be aware of how AI tools are being used, and to understand the agency they have in deciding if and how they will use them to impact their lives and society  This includes increasing critical consciousness of how AI tools can perpetuate and exacerbate existing inequities in our society and raising awareness about algorithmic bias and advocating for changes in policies around algorithms and automation in our society

We identify the following tactics for students, teachers, and caregivers to promote awareness and agency while using AI tools:

- Learn Information is power, and awareness and agency of AI tools is enhanced with increasing knowledge about how AI works  Opportunities for students, teachers and caregivers to learn about AI and its applications in education should be provided in accessible modalities and languages
- Communicate School districts have a responsibility to be transparent with parents and caregivers about how AI technologies are being used in schools, including data privacy and ownership and decision making power of algorithms  Parents and caregivers should

be afforded the opportunity to learn about these AI tools, and then prompted with an opportunity to opt in or out of such use

- Ask There are many unknowns with emerging technologies and most people likely do not know what questions to ask in order to promote safe and ethical application of AI tools Schools and districts should develop resources to help students, teachers and caregivers understand what questions to ask and where to go for more information
- Advocate Emerging technologies are evolving with unknown risks  We all have a responsibility to understand what our rights are in regards to data privacy and ownership, as well as the decision making power of AI tools  We know that in some cases policy and guidance will be responsive to foul play and we should proactively create spaces to advocate for our own rights and protections in this evolving technological landscape

## Students Teach Parents at Ballard High School MisinfoNight

MisinfoDay is an annual media literacy educational event hosted by the University of Washington Information School to teach high school students, teachers, and librarians to evaluate online information  It has since expanded its resource repository to support educators in running their own MisinfoDay event on their campus

Successful community engagement occurred during MisinfoNight at Ballard High School in Seattle where teachers planned and hosted an event inviting parents, caregivers, and other adults in the community to learn from 300 9th-grade world history students on topics such as confirmation bias, influence of algorithms, AI-generated deep fake images, and methods to assess the reliability of information  The event was set up with interactive displays and stations presented by students

Students Presenting on Misinformation at Ballard High School in Seattle, WA.

<!-- image -->

At the end of the night, students even asked family members and attendees to pull out their phones and practice their new learnings on sample online posts

## Learn more about:

-  MisinfoDay Resource Library
-  NPR Article about MisinfoDay: AI images and conspiracy theories are driving a push for media literacy education
-  MisinfoNight at Ballard High School

## Conclusion

Our AI Literacy Framework seeks to inform educational leaders across contexts to make decisions about how to design learning opportunities to promote AI literacy  To better understand how to promote AI literacy, we build from foundational work across media literacy, data literacy, digital citizenship and computational thinking  We emphasize that understanding, evaluating, and using AI are coinciding Modes of Engagement that can support each other  Further, understanding and evaluating AI, while centering human judgment and justice, are critical to making informed decisions about if and how to use AI in different contexts

We propose five strategies for leaders, educators, learners, and families to promote AI literacy for all  These strategies include providing guidance for adoption and evaluation, integrating AI literacy across grades and subject-area learning, facilitating professional learning, designing powerful learning experiences, and promoting awareness and agency

AI literacy equips us with skill sets to promote individual agency and awareness in order to make informed decisions about how to leverage AI tools for individual and societal benefit  Looking ahead, we call for and seek to support the development of additional resources and guidance for educators, learners, and families to help them make informed decisions about if and when to integrate AI-enabled systems and tools in various contexts, as well as how to provide appropriate scaffoldings to learners when they do

## References

- Almatrafi, O , Johri, A , &amp; Lee, H  (2024)  A systematic review of AI literacy conceptualization, constructs, and implementation and assessment Efforts (2019-2023) Computers and Education Open , 100173
- Benjamin, R  (2019) Race after technology: Abolitionist tools for the New Jim Code Polity Press
- Broussard, M  (2023) More than a glitch: Confronting race, gender, and ability bias in tech MIT Press
- Buolamwini, J  (2023) Unmasking AI: My mission to protect what is human in a world of machines. Penguin Random House
- Code org (2024)  AI for oceans  https://code org/oceans
- Code org, CSTA, &amp; ECEP Alliance  (2023)  2023 state of computer science education  https://advocacy code org/stateofcs
- Coenraad, M , Rangel, A , Burke, Q , Mills, K , Ruiz, P , &amp; Dunbar, K  (2024, March)  Champion, collaborator, curator, anchor: Supporting K-12 teachers to integrate computational thinking  In Proceedings of the 55th ACM technical symposium on computer science education V. 2 (pp 1608-1609)
- Common Sense Media  (2024a)  Digital citizenship curriculum  https://www commonsense org/ education/digital-citizenship/curriculum
- Common Sense Media  (2024b)  AI chatbots: Who's behind the screen? https://www commonsense org/education/digital-citizenship/lesson/ai-chatbots-whos-behind-the-screen
- Digital Promise  (2024)  Powerful learning  https://digitalpromise org/powerful-learning/
- Dhar, P  (2020)  The carbon impact of artificial intelligence Nat. Mach. Intell., 2 (8), 423-425
- Druga, S , Yip, J , Preston, M , &amp; Dillon, D  (2021)  The 4As: Ask, adapt, author, analyze - AI lLiteracy framework for families  In Algorithmic Rights and Protections for Children https://doi org/10 1162/ ba67f642 646d0673
- EdSAFE AI Alliance  (2024)  S A F E  benchmarks framework  https://www edsafeai org/safe
- EngageAI Bill of Rights Task Force  (2024, May)  An AI bill of rights for educators  EngageAI Institute https://engageai org/nexus-conversations/nexus-resources/
- Executive Order on the Safe, Secure, and Trustworthy Development and Use of AI, 15 U S C  9401(3) (2023, October 30)  https://www govinfo gov/app/details/FR-2023-11-01/2023-24283/summary
- Federal Trade Commission (2024, January 9)  AI companies: Uphold your privacy and confidentiality commitments  https://www ftc gov/policy/advocacy-research/tech-at-ftc/2024/01/ ai-companies-uphold-your-privacy-confidentiality-commitments

- Ferrara, E  (2024)  GenAI against humanity: Nefarious applications of generative artificial intelligence and large language models Journal of Computational Social Science , 1-21
- Fusco, J , Roschelle, J , &amp; Ruiz, P  (2020, March 10) What is learning sciences and why does it matter? https://digitalpromise org/2020/03/10/ what-is-learning-sciences-and-why-does-it-matter/
- Heintz, F  (2022)  The computational thinking and artificial intelligence duality  In S  C  Kong, &amp; H Abelson (Eds ) Computational thinking education in K-12: Artificial intelligence literacy and physical computing. MIT Press
- Hollister, S  (2019, October 2)  Google contractors reportedly targeted homeless people for Pixel 4 facial recognition The Verge. https://www theverge com/2019/10/2/20896181/ google-contractor-reportedly-targeted-homeless-people-for-pixel-4-facial-recognition
- Huckins, G  (2023, Oct 16)  Minds of machines: The great AI consciousness conundrum MIT Technology Review  https://www technologyreview com/2023/10/16/1081149/ ai-consciousness-conundrum/
- Ingram, M  (2023, October 26)  An AI engine scans a book  Is that copyright infringement or fair use? Columbia Journalism Review  https://www cjr org/the\_media\_today/an-ai-enginescans-a-book-is-that-copyright-infringement-or-fair-use php
- Lee, V  R , &amp; Long, D  (in press)  AI Literacy: Definitions and directions for an essential new digital literacy  In J  Castek, J  Coiro, E  Forzani, C  Kiili, M  S  Hagerman, &amp; J  R  Sparks (Eds ), The international handbook Of research In digital literacies Routledge
- James, C , Weinstein, E , &amp; Mendoza, K  (2021)  Teaching digital citizens in today's world: Research and insights behind the Common Sense K-12 Digital Citizenship Curriculum  (Version 2) Common Sense Media
- Keller, J  B , Donoghoe, M , &amp; Perry, A  M  (2024, Jan 29)  The US must balance climate justice challenges in the era of artificial intelligence  Brookings  https://www brookings edu/articles/ the-us-must-balance-climate-justice-challenges-in-the-era-of-artificial-intelligence/
- Kumar, A  (2023, April 24)  How students use AI to design solutions for their community  EdSurge  https://www edsurge com/ news/2023-04-24-how-students-use-ai-to-design-solutions-for-their-community
- Mills, K , Burke, Q , &amp; Ruiz, R  (2020, August 24)  How to integrate computational thinking with 'look fors ' Digital Promise  https://digitalpromise org/2020/08/24/ how-to-integrate-computational-thinking-with-look-fors/
- Mills, K , Coenraad, M , Ruiz, P , Burke, Q , &amp; Weisgrau J  (2021, December)  Computational thinking for an inclusive world: A resource for educators to learn and lead  Digital Promise https://doi org/10 51388/20 500 12265/138

- Mills, K , Weisgrau, J , Burke, Q , Lee, K , Solorzano, T , &amp; Coenraad, M  (2024, March)  Shifting education with learning pathways: Becoming your portrait of a graduate  Digital Promise  doi org/10 51388/20 500 12265/205
- Mishra, P , &amp; Koehler, M  J  (2006)  Technological pedagogical content knowledge: A framework for teacher knowledge Teachers College Record , 108 (6), 1017-1054
- MIT Media Lab Personal Robots Group and the MIT STEP Lab (2024)  The DAILy Curriculum for middle school students  https://raise mit edu/daily/
- National Association for Media Literacy Education (2024)  What is media literacy? Media literacy defined  https://namle org/resources/media-literacy-defined/
- Ng, D  T  K , Leung, J  K  L , Chu, S  K  W , &amp; Qiao, M  S  (2021)  Conceptualizing AI literacy: An exploratory review Computers and Education: Artificial Intelligence , 2 , 100041
- Noble, S  U  (2018) Algorithms of oppression: How search engines reinforce racism New York University Press
- Oakes, S  (2021, Jan 28)  How to pivot your edtech product directly to consumers  Backpack Interactive  https://backpackinteractive com/insights/ creating-educational-products-for-consumers-2/
- O'Neil, C  (2016) Weapons of math destruction: How big data increases inequality and threatens democracy Crown
- Resnick, Mitchel  2024  Generative AI and creative learning: Concerns, opportunities, and choices An MIT Exploration of Generative AI , March  https://doi org/10 21428/e4baedd9 cf3e35e5
- Rich, K  M , Strickland, C , Binkowski, T  A , Moran, C , &amp; Franklin, D  (2017, August)  K-8 learning trajectories derived from research literature: Sequence, repetition, conditionals  In Proceedings of the 2017 ACM conference on international computing education research (pp  182-190)
- Rich, K  M , Binkowski, T  A , Strickland, C , &amp; Franklin, D  (2018, August)  Decomposition: A K-8 computational thinking learning trajectory  In Proceedings of the 2018 ACM conference on international computing education research (pp  124-132)
- Rich, K  M , Strickland, C , Binkowski, T  A , &amp; Franklin, D  (2019, February)  A K-8 debugging learning trajectory derived from research literature  In Proceedings of the 50th ACM technical symposium on computer science education (pp  745-751)
- Roschelle, J , Ruiz, P , &amp; Fusco, J  (2021, March 15) AI or intelligence augmentation for education? Blog@CACM  https://cacm acm org/blogcacm/ ai-or-intelligence-augmentation-for-education/

- Roschelle, J  (2020, April 13) Computational thinking or computational teamwork? Blog@CACM https://cacm acm org/blogcacm/computational-thinking-or-computational-teamwork/
- Rubin, A  (2020)  Learning to reason with data: How did we get here and what do we know? Journal of the Learning Sciences , 29 :1, 154-164, DOI: 10 1080/10508406 2019 1705665
- Ruiz, P , &amp; Glazer, K  (2024, January 15)  Anthropomorphism of AI in learning environments: Risks of humanizing the machine  EdSurge  April 29, 2024  https://www edsurge com/news/202401-15-anthropomorphism-of-ai-in-learning-environments-risks-of-humanizing-themachine
- Ruiz, P , Richard, E , Chillmon, C , Shah, Z , Kurth, A , Fekete, A , Glazer, K , Pattenhouse, M , Fusco, J , Fennelly-Atkinson, R , Lin, L , Arriola, S , Lockett, D , Crawford-Meyer, V , Karim, S , Hampton, S , &amp; Beckford, B  (2022)  Emerging technology adoption framework: For PK-12 education  [Educator CIRCLS white paper]  Digital Promise  https://doi org/10 51388/20 500 12265/161
- U S  Bureau of Labor Statistics  (2024)  Employed persons by detailed occupation, sex, race, and Hispanic or Latino ethnicity  https://www bls gov/cps/cpsaat11 pdf
- U S  Department of Education, Office of Educational Technology  (2024) National Educational Technology Plan , Washington, DC  https://tech ed gov/netp/
- Wachter-Boettcher, S  (2017) Technically wrong: Sexist apps, biased algorithms, and other threats of toxic tech WW Norton &amp; Company
- Weaver (2022)  Delivering on the promise of digital equity  Digital Promise  https://digitalpromise org/wp-content/uploads/2022/12/Delivering-on-the-Promise-of-Digital-Equity pdf
- Webb, M  (2024, March 4)  A generative AI primer  Jisc  https://nationalcentreforai jiscinvolve org/ wp/2024/03/04/generative-ai-primer/
- White, S V  &amp; Scott, A  (2024) Responsible AI and tech justice: A guide for K-12 education. Kapor Foundation  https://kaporfoundation org/wp-content/uploads/2024/01/Responsible-AIGuide-Kapor-Foundation pdf
- World Economic Forum  (2024, April)  Shaping the future of learning: The role of AI in education 4 0  https://www weforum org/publications/ shaping-the-future-of-learning-the-role-of-ai-in-education-4-0/

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

CC BY-NC-ND 4 0 Deed | Attribution-NonCommercial-NoDerivs 4 0 International

<!-- image -->

Washington, D C :

1001 Connecticut Ave  NW, Suite 935

Washington, D C  20036

Website:

https://digitalpromise org/

Redwood City, CA: 702 Marshall St , Suite 340

Redwood City, CA 94063