{
  "metadata": {
    "title": "Indecision on the use of artificial intelligence in healthcare - A qualitative study of patient perspectives on trust, responsibility and self-determination using AI-CDSS",
    "authors": [
      "Diana Schneider",
      "Wenke Liedtke",
      "Andrea Diana Klausen",
      "Myriam Lipprandt",
      "Florian Funer",
      "Tanja Bratan",
      "Nils B. Heyen",
      "Heike Aichinger",
      "Martin Langanke"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie nehmen Patienten die Implementierung von KI-gestützten klinischen Entscheidungsunterstützungssystemen wahr, insbesondere bezüglich Vertrauen, Verantwortung und Selbstbestimmung?",
    "methodology": "Empirisch: Qualitativ. Drei Fokusgruppen mit insgesamt 18 Patienten (n=18, 5-7 pro Gruppe, April 2021-April 2022). Strukturierte qualitative Inhaltsanalyse nach Kuckartz und Rädiker (2022). Präsentation von AI-CDSS-Fallvignetten (Chirurgie, Nephrologie, Home-Care) als Stimuli.",
    "key_finding": "Patienten zeigen erhebliche Unsicherheit gegenüber AI-CDSS-Implementierung. Die Wahrnehmung oszilliert zwischen supportivem Werkzeug und Zweitmeinung, wobei enge Verflechtungen zwischen Vertrauen, Verantwortung und Selbstbestimmung bestehen, die durch unzureichendes Verständnis der KI-Funktionalität gefährdet sind.",
    "data_basis": "n=18 Patienten in 3 Fokusgruppen (Zeitraum April 2021-April 2022), Rekrutierung via Selbsthilfegruppen in Deutschland"
  },
  "arguments": [
    "Vertrauen und Verantwortung in der Arzt-Patient-Beziehung basieren auf gemeinsamen Voraussetzungen: technische Expertise der Fachleute, empirisches Wissen und die Fähigkeit, Standards mit individuellen Patientensituationen zu verbinden.",
    "Patienten befürchten einen Verlust von Selbstbestimmung durch AI-CDSS, insbesondere hinsichtlich informationeller Selbstbestimmung, des Rechts nicht-zu-wissen, und der Gefahr der Entmenschlichung und Objektivierung in der Pflege.",
    "Die Implementierung von AI-CDSS erfordert neue Formen von AI-Literalität bei Fachkräften und verbesserte Kommunikation/Transparenz, um Patienten als aktive Partner in geteilten Entscheidungsfindungsprozessen einzubeziehen."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Patienten und Fachleute müssen 'AI literacy in ongoing work processes' entwickeln. 'It is therefore of importance to provide patients and healthcare professionals with information to prevent indecision.' Die Studie zeigt, dass 'the patients' perspective is profoundly influenced by the individuals' comprehension of the functionality of AI-CDSS.'",
    "KI_Sonstige": "Fokus auf AI-CDSS (Clinical Decision Support Systems) mit Machine Learning in Radiologie, Chirurgie, Nephrologie und Home-Ventilation. Explizit: 'AI-based clinical decision support systems (AI-CDSS) aim to assist healthcare professionals and patients in making decisions.'",
    "Soziale_Arbeit": "Studie analysiert Patientenperspektiven in Gesundheitsversorgung, Care-Kontexten (Home-Ventilation), und die professionelle Beziehung zwischen Patientinnen und Fachkräften. Fokus auf Selbstbestimmung und Partizipation vulnerable Gruppen (chronisch erkrankte, home-ventilierte Patienten). Ein Autor arbeitet am 'Department of Social Work' der Protestant University of Applied Sciences.",
    "Bias_Ungleichheit": "Patienten befürchten Diskriminierungsmöglichkeiten durch Algorithmen: 'the reliability of technology and possible risks of discriminating algorithms.' Besorgnis um marginalisierte Gruppen und ungleiche Auswirkungen: 'possible loss of human interaction in the entire care process' führt zu unterschiedlichen Zugängen je nach Patientenlage.",
    "Diversitaet": "Studie rekrutiert verschiedene Patientengruppen über Selbsthilfegruppen in unterschiedlichen medizinischen Domänen (Nephrologie, Chirurgie, Home-Care), um unterschiedliche Perspektiven zu erfassen. Fokus auf Inklusion von Patientenperspektiven: 'Special consideration must be given to the AI-CDSS implementation from all users' perspectives.' Heterogene Fokusgruppen als 'homogeneous groups.'",
    "Fairness": "Studie thematisiert algorithmische Fairness durch Patientenperspektive: 'concerns like data security, responsibility, fairness and autonomy are being discussed, yet remain unsolved.' Forderung nach fairem Design: 'algorithms should thus be developed with a wider spectrum of stakeholders than just the doctor to ensure that the people affected by the system's analysis can also understand the system's results.' Verteilungsgerechtigkeit bei Ressourcen und Verantwortung."
  },
  "references": [
    {
      "author": "Rajpurkar et al.",
      "year": 2022,
      "short_title": "AI In health and medicine"
    },
    {
      "author": "Amann et al.",
      "year": 2020,
      "short_title": "Explainability for artificial intelligence in healthcare: a multidisciplinary perspective"
    },
    {
      "author": "Obermeyer & Topol",
      "year": 2021,
      "short_title": "Artificial intelligence, bias, and patients' perspectives"
    },
    {
      "author": "Jeyakumar et al.",
      "year": 2023,
      "short_title": "Preparing for an artificial intelligence-enabled future: patient perspectives on engagement"
    },
    {
      "author": "Vallès-Peris et al.",
      "year": 2021,
      "short_title": "Robots in healthcare? What patients say"
    },
    {
      "author": "Dlugatch et al.",
      "year": 2023,
      "short_title": "Trustworthy artificial intelligence and ethical design: public perceptions"
    },
    {
      "author": "Kerasidou",
      "year": 2020,
      "short_title": "Artificial intelligence and the ongoing need for empathy, compassion and trust in healthcare"
    },
    {
      "author": "Sauerbrei et al.",
      "year": 2023,
      "short_title": "The impact of artificial intelligence on the person-centred, doctor-patient relationship"
    },
    {
      "author": "Topol",
      "year": 2019,
      "short_title": "High-performance medicine: the convergence of human and artificial intelligence"
    },
    {
      "author": "Kuckartz & Rädiker",
      "year": 2022,
      "short_title": "Qualitative Inhaltsanalyse"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit: Die Studie thematisiert ethische Implikationen von AI-Systemen aus Patientenperspektive, fokussiert auf Selbstbestimmung, Partizipation und professionelle Beziehungen - zentrale Anliegen Sozialer Arbeit. Die explorative Methode und der Fokus auf vulnerable Gruppen (chronisch Kranke, Home-Care-Patienten) sind für sozialarbeiterische Kontexte hochrelevant.",
    "unique_contribution": "Die Studie füllt eine Forschungslücke, indem sie (anders als bisherige Akzeptanzstudien) tiefergehend die ethischen Implikationen von AI-CDSS aus Patientenperspektive untersucht, insbesondere die Verflechtung von Vertrauen, Verantwortung und Selbstbestimmung als dynamische relationale Konzepte im Kontext der Arzt-Patient-Beziehung.",
    "limitations": "Kleine Stichprobe (n=18), Convenience-Sampling via Selbsthilfegruppen (Selection-Bias), Fokusgruppen nur online durchgeführt, theoretisches Konzeptverständnis von 'Responsibility', 'Trust', 'Self-Determination' nicht vorab definiert sondern exploratif erhoben, kultureller Kontext Deutschland (begrenzte Generalisierbarkeit), hypothetische Vignetten statt reale Erfahrungen."
  },
  "target_group": "Sozialarbeiter und Care-Professionelle in Gesundheitsversorgung, KI-Entwickler und Medical Informatics-Fachleute, Policymaker im Gesundheitswesen, Ethiker und Bioethiker, Patientenvertreter und Selbsthilfegruppen, Forschende im Bereich Mensch-Maschine-Interaktion und digitaler Transformation in der Medizin"
}