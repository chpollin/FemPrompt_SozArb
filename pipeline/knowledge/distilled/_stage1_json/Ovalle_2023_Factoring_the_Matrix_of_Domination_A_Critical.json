{
  "metadata": {
    "title": "Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness",
    "authors": [
      "Anaelia Ovalle",
      "Arjun Subramonian",
      "Vagrant Gautam",
      "Gilbert Gee",
      "Kaiwei Chang"
    ],
    "year": 2023,
    "type": "conferencePaper",
    "language": "en"
  },
  "core": {
    "research_question": "Wie wird Intersektionalität in der AI-Fairness-Literatur diskutiert und welche Lücken entstehen zwischen der Konzeptualisierung und Operationalisierung intersektionaler Frameworks?",
    "methodology": "Kritische Literaturanalyse; deduktive und induktive Codierung von 30 AI-Fairness-Papers gegen Collins und Bilges Intersektionalitäts-Tenets; Mixed-Methods mit Interannotator-Agreement-Messungen (Randolph's κ)",
    "key_finding": "AI-Fairness-Forscher reduzieren Intersektionalität primär auf Fairness-Metriken für demographische Subgruppen und ignorieren dabei zentrale intersektionale Prinzipien wie Machtrelationen, soziale Kontexte und kritisches Handeln für Gerechtigkeit.",
    "data_basis": "n=30 peer-reviewed AI-Fairness-Papers; 11 Papiere wurden von 3 Annotatoren kodiert, 19 weitere von mindestens 1 Annotator"
  },
  "arguments": [
    "Intersektionalität ist ein kritisches Praxis-Framework zur Analyse von Machtstrukturen und struktureller Unterdrückung, nicht bloß ein statistisches Problem der Fairness-Optimierung über Subgruppen.",
    "Die epistemologischen Fundamente der KI-Forschung sind in kolonialer Wissenschaft verwurzelt; Intersektionalität kann helfen, diese zu hinterfragen und marginalisierte Wissensproduktion zu zentralisieren.",
    "Vier Hauptlücken wurden identifiziert: (1) fehlende Auseinandersetzung mit Machtrelationen über das KI-System hinaus, (2) schwache Zitierpraxen intersektionaler Literatur, (3) Verlust von Relationalität zwischen Strukturen durch statistische Operationalisierung, (4) mangelnde soziale Gerechtigkeit als explizites Praxisziel."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": true,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Kritische Analyse von Wissensproduktion und epistemologischen Grundlagen in der KI-Forschung: 'The epistemologies of AI research are not divorced from scientific colonialism's legacy.'",
    "KI_Sonstige": "Breite Kritik auf algorithmische Fairness, ML-Systeme, predictive systems und deren Machteffekte fokussiert.",
    "Soziale_Arbeit": "Expliziter Bezug zu Sozialen Systemen und struktureller Unterdrückung: 'intersectionality [...] allows us to examine how social inequalities persist through domains of structure and discipline'; Engagement mit carceral systems und sozialer Gerechtigkeit.",
    "Bias_Ungleichheit": "Zentrale Analyse algorithmischen Bias und struktureller Ungleichheit: 'the goal of minimizing negative outcomes across demographic groups, including groups associated with multiple, intersectional demographic attributes'",
    "Gender": "Expliziter Gender-Fokus mit Referenzen auf Black women, gender-intersections und geschlechtsspezifische Dimensionen von Unterdrückung.",
    "Diversitaet": "Kernfokus auf Intersektionalität, marginalisierte Communities und intersektionale Perspektiven: 'examining interlocking mechanisms of structural oppression [...] which produce inequality'",
    "Feministisch": "Explizit feministische Theorie (Crenshaw, Collins, Black Feminist epistemology, hooks): 'Black feminist knowledge' wird zentralisiert; Referenzen zu 'gentrification of intersectionality' und Schutz Black feminist Wissensproduktion.",
    "Fairness": "Zentrale Kritik der Fairness-Literatur: 'The majority of the papers we review approach intersectionality from the narrow perspective of subgroup fairness.'"
  },
  "references": [
    {
      "author": "Crenshaw",
      "year": 1989,
      "short_title": "Demarginalizing the Intersection of Race and Sex (Intersectionality foundational work)"
    },
    {
      "author": "Collins",
      "year": 2000,
      "short_title": "Black Feminist Thought (Matrix of Domination framework)"
    },
    {
      "author": "Buolamwini & Gebru",
      "year": 2018,
      "short_title": "Gender Shades (intersectional subgroups in computer vision)"
    },
    {
      "author": "D'Ignazio & Klein",
      "year": 2020,
      "short_title": "Data Feminism"
    },
    {
      "author": "Eubanks",
      "year": 2019,
      "short_title": "Automating Inequality (algorithmic systems and surveillance)"
    },
    {
      "author": "hooks, bell",
      "year": 2000,
      "short_title": "Feminist Theory: From Margin to Center"
    },
    {
      "author": "Freeman",
      "year": 1978,
      "short_title": "Legitimizing Racial Discrimination Through Antidiscrimination Law (critical legal studies)"
    },
    {
      "author": "Mitchell et al.",
      "year": 2019,
      "short_title": "Model Cards for Model Reporting"
    },
    {
      "author": "Constanza-Chock",
      "year": 2020,
      "short_title": "Design Justice (intersectional critical design)"
    },
    {
      "author": "Alexander-Floyd",
      "year": 2012,
      "short_title": "Black Feminist Knowledge and Black Feminist Erasure (citational praxis)"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle AI/Soziale Arbeit/Gender: Das Paper verbindet kritische sozialwissenschaftliche Theorie (intersektionaler Feminismus, Dekolonialität) mit technischer KI-Forschung und zeigt, wie soziale Gerechtigkeit in AI-Systemen operationalisiert werden kann. Besonders wertvoll für Sozialarbeiter und KI-Entwickler, die kritische Reflexion suchen.",
    "unique_contribution": "Das Paper bietet die erste systematische kritische Analyse, wie AI-Fairness-Papiere intersektionale Theorie (miss)verwenden, und entwickelt ein operationalisierbares Framework (Collins/Bilges Tenets) zur Messung echter intersektionaler Praxis versus oberflächlicher Fairness-Optimierung.",
    "limitations": "Fokus auf englischsprachige, akademische peer-reviewed Papiere (nicht Industrie oder globale Perspektiven); begrenzte Analyse praktischer Implementierungen außerhalb des AI-Pipelines; Positioniertheit der Autoren auf US/Europa kann globale Kontexte limitieren."
  },
  "target_group": "AI-Forscher und -Entwickler mit Fairness-Fokus; Sozialwissenschaftler und kritische Theoretiker; Policy-Maker; Lehrende in KI-Ethik; Community-Organizer und soziale Gerechtigkeit Aktivisten; Studierenden in Gender Studies, KI-Ethik, Sozialer Arbeit"
}