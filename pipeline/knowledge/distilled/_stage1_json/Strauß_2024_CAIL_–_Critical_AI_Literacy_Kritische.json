{
  "metadata": {
    "title": "CAIL - Critical AI Literacy: Kritische Technikkompetenz für konstruktiven Umgang mit KI-basierter Technologie in Betrieben",
    "authors": [
      "Stefan Strauß",
      "Titus Udrea"
    ],
    "year": 2024,
    "type": "report",
    "language": "de"
  },
  "core": {
    "research_question": "Wie können Arbeitnehmer:innen durch Critical AI Literacy (CAIL) befähigt werden, KI-basierte Technologien in Betrieben konstruktiv und kritisch zu nutzen, und welche Herausforderungen entstehen durch neue Automatisierungsformen?",
    "methodology": "Mixed Methods: Literaturanalyse, qualitative Interviews mit Betriebsräten und Arbeitnehmer:innen, Workshops mit Stakeholdern (GPA, Arbeiterkammer Wien), Technikfolgenabschätzung",
    "key_finding": "KI-basierte Automatisierung unterscheidet sich durch höhere Dynamik, Volatilität und Intransparenz von klassischen Automatisierungsformen. Das Risiko von Deep Automation Bias stellt ein Meta-Risiko dar, das durch kritische KI-Kompetenzen und bewusstes, zweckorientiertes System-Design reduziert werden kann.",
    "data_basis": "Interviews mit Mitgliedern des Beirats für Arbeit und Technik (BAT), Workshop-Teilnehmer:innen, Mitarbeiter:innen der Arbeiterkammer Wien; spezifische n nicht angegeben"
  },
  "arguments": [
    "KI-basierte Automatisierung ist komplexer, dynamischer und volatiler als klassische Automatisierung, weil KI-Systeme nicht nur regelbasiert sind, sondern ihre Funktionsweisen adaptieren können, was zu geringerer Kontrollierbarkeit führt.",
    "Deep Automation Bias ist ein Meta-Risiko des KI-Einsatzes, das durch das Zusammenspiel von Systemkomplexität, mangelndem Problembewusstsein bei Nutzer:innen, Zeitmangel und Ressourcenknappheit verstärkt wird und letztlich zu unentdeckten Systemfehlern führt.",
    "KI-Mehrwert entsteht nur durch bewussten, zweckorientierten Einsatz als Expertensystem mit klaren Tätigkeitsbezügen – nicht durch diffuse En-passant-Nutzung. Dies erfordert Transparenz sowohl über Funktionsweise als auch über Nutzungsziele."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": false,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Critical AI Literacy (CAIL) als zentrale Kompetenz zur Handlungsfähigkeit: 'Grundkompetenzen umfasst Critical AI Literacy und mit welchen Ansätzen ist das entsprechende Wissen vermittelbar?' CAIL-Framework mit Kategorien wie Funktionswissen, Kontextualisierung, Interpretationsfähigkeit.",
    "KI_Sonstige": "Umfassende Behandlung von klassischem Machine Learning (unterschiedliche ML-Verfahren, Deep Learning, regelbasierte Systeme), Automatisierungsformen, KI-Anwendungen in Medizin, Journalismus, Bildung und bereichsübergreifend.",
    "Bias_Ungleichheit": "Deep Automation Bias als zentrales Risiko; Ungleichheiten in Handlungsfähigkeit zwischen Expert:innen und Laien; 'Click Workers' in Kenia exploitiert für KI-Training; Abhängigkeitsverhältnisse zu großen Softwareanbietern benachteiligen kleine Betriebe.",
    "Fairness": "Algorithmic Fairness implizit durch Fokus auf Zuverlässigkeit, Überprüfbarkeit und korrekte Funktionsweise von KI-Systemen; Qualitätssicherung und Fehlererkennung als Fairness-Maßnahmen."
  },
  "references": [
    {
      "author": "Strauß, Stefan",
      "year": 2021,
      "short_title": "Don't let me be misunderstood: Critical AI literacy for the constructive use of AI technology"
    },
    {
      "author": "Strauß, Stefan",
      "year": 2021,
      "short_title": "Deep automation bias. How to tackle a wicked problem of AI?"
    },
    {
      "author": "Lyell, David & Coiera, Enrico",
      "year": 2016,
      "short_title": "Automation bias and verification complexity: A systematic review"
    },
    {
      "author": "Goddard, Keith et al.",
      "year": 2012,
      "short_title": "Automation Bias studies"
    },
    {
      "author": "Raisch, Sebastian & Krakowski, Stefan",
      "year": 2021,
      "short_title": "Artificial Intelligence and Management: The Automation-Augmentation Paradox"
    },
    {
      "author": "von Richthofen, Gero et al.",
      "year": 2023,
      "short_title": "KI in der Wissensarbeit. Handlungsfelder und Ansätze für eine beschäftigtenorientierte Gestaltung"
    },
    {
      "author": "Stowasser, Sascha",
      "year": 2023,
      "short_title": "Künstliche Intelligenz (KI) und Arbeit: Leitfaden zur soziotechnischen Gestaltung"
    },
    {
      "author": "OECD",
      "year": 2023,
      "short_title": "The Impact of AI on the Workplace: Evidence from OECD Case Studies"
    }
  ],
  "assessment": {
    "domain_fit": "Hoch relevant für Arbeitssoziologie und Technikfolgenabschätzung. Bezug zu Sozialer Arbeit nur marginal (Erwähnung von Qualifikationsbedarf), aber zentral für Arbeitnehmer:innenschutz und partizipative Gestaltung von KI-Systemen in Organisationen.",
    "unique_contribution": "Entwicklung des CAIL-Frameworks als umfassender Ansatz zur Vermittlung kritischer KI-Kompetenzen; Konzeptualisierung von Deep Automation Bias als systemisches Risiko mit Einflussfaktoren-Modell.",
    "limitations": "Fehlende explizite Perspektive auf marginalisierte Gruppen und intersektionale Dimensionen; Gender-Perspektive nicht integriert; empirische Datenbasis (Interviewzahlen) nicht detailliert dokumentiert; Fokus auf österreichische Kontexte mit generalisierungsbegrenzten Erkenntnissen."
  },
  "target_group": "Betriebsräte, Gewerkschaften, Arbeitnehmer:innen in Wissensarbeit, HR-Professional:innen, Policymaker im Bereich Arbeit und Digitalisierung, Betriebliche Interessenvertreter:innen, KI-Implementierer in Organisationen"
}