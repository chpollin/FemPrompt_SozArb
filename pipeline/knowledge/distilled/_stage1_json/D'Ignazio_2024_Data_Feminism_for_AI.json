{
  "metadata": {
    "title": "Data Feminism for AI",
    "authors": [
      "Lauren Klein",
      "Catherine D'Ignazio"
    ],
    "year": 2024,
    "type": "conferencePaper",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können intersektional-feministische Prinzipien dazu beitragen, ungleiche Machtverhältnisse in der KI-Forschung, -Entwicklung und -Bereitstellung zu identifizieren und zu verändern?",
    "methodology": "Theoretisch/Literature Review: Reartikulierung und Erweiterung der sieben Data-Feminism-Prinzipien auf AI sowie Entwicklung zweier neuer Prinzipien zu Umweltauswirkungen und Consent; basierend auf intersektionaler feministischer Theorie und bestehender Literatur zu Feminismus, AI und Data Justice.",
    "key_finding": "Feministische Prinzipien - insbesondere die Fokussierung auf Machtverhältnisse, Pluralismus, Sichtbarmachung von Arbeit und Kontext - sind essentiell zur Entwicklung gerechter, ethischer und nachhaltiger KI-Systeme. Die Autor:innen schlagen zudem zwei neue Prinzipien vor: Berücksichtigung von Umweltauswirkungen und intersektionales Verständnis von Konsens.",
    "data_basis": "Keine empirische Datenerhebung; Literaturanalyse und theoretische Reflexion auf Basis von akademischen und aktivistischen Arbeiten zu Feminismus, KI-Ethik, Data Justice und strukturellen Machtasymmetrien."
  },
  "arguments": [
    "Intersektionaler Feminismus bietet analytische Werkzeuge zur Offenlegung von Machtverhältnissen in KI-Systemen: Die Fokussierung auf Intersektionalität (Crenshaw) und 'interlocking systems of oppression' (Combahee River Collective) ermöglicht es, komplexe Ungleichheiten zu verstehen, die über Gender hinausgehen und Race, Klasse, Kolonialismus einschließen.",
    "Die sieben Data-Feminism-Prinzipien sind auf AI übertragbar und adressieren zentrale ethische Probleme: 'Examine Power' offenbart, wie Großkonzerne und Regierungen Daten zur Machtausübung nutzen; 'Challenge Power', 'Consider Context' und 'Make Labor Visible' zeigen auf, wie Trainings-Daten, Design-Prozesse und globale Arbeitsteilung strukturelle Ausbeutung reproduzieren.",
    "Umweltgerechtigkeit und Konsens sind notwendige neue Prinzipien für eine feministische KI: Ökofeministische und Indigenous-feministische Perspektiven verbinden Umweltzerstörung mit globaler Ungleichheit (Nord/Süd-Divide, Wasserbedarf von Data Centers); erweitertes Verständnis von Konsens (jenseits binär, individualistischer Modelle) adressiert Nicht-Konsent in Datenbeschaffung und Deepfakes."
  ],
  "categories": {
    "AI_Literacies": false,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": true,
    "Fairness": true
  },
  "category_evidence": {
    "Generative_KI": "Explizite Analysen von LLMs und deren Trainings-Praktiken: 'the work of data science replicated professional hierarchies, with credentialed data scientists at the top' und Beispiel von ChatGPT mit Arbeitern in Kenia, die 'screening potentially offensive responses in real-time' durchführten.",
    "KI_Sonstige": "Breite KI-Fokussierung auf Computer Vision (Buolamwini & Gebru), NLP, Algorithmen, algorithmische Entscheidungssysteme, ML-Trainings-Praktiken.",
    "Bias_Ungleichheit": "Zentrales Thema durchgehend: 'unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment'; Analyse von Datenbias, Geschlechterbias in Sprachmodellen, reproduktion von sexistischen, rassistischen und kolonialen Vorurteilen in Text-to-Image-Modellen.",
    "Gender": "Explizite Behandlung von Geschlechterperspektiven: Deepfakes von Frauen, Nicht-Konsent bei Audio/visueller Generierung, Geschlechterbias in NLP und Autocomplete-Systemen, Frauenrepräsentation in Tech/AI-Feldern.",
    "Diversitaet": "Intersektionale Perspektive auf marginalisierte Communities: Indigenous feminists, Black feminists, Latin American feminists, Global South vs. North Asymmetrien, Analysen von Repräsentation und Exklusion in AI-Forschung und -Entwicklung.",
    "Feministisch": "Explizit feministische Theorie durchgehend: Intersektionaliät (Crenshaw, Combahee River Collective, Patricia Hill Collins 'matrix of domination'), feministische Epistemologie, Black Feminism, Ökofeminismus, Indigenous Feminism, reproductive justice, trans justice.",
    "Fairness": "Direkte Behandlung algorithmischer Fairness: 'fairness research', Fairness-Aspekte in ML-Entwicklung, Kritik an unzureichender Operationalisierung von Intersektionalität in AI-Fairness-Forschung."
  },
  "references": [
    {
      "author": "D'Ignazio, Catherine; Klein, Lauren",
      "year": 2020,
      "short_title": "Data Feminism"
    },
    {
      "author": "Crenshaw, Kimberlé",
      "year": 1989,
      "short_title": "Intersectionality"
    },
    {
      "author": "Combahee River Collective",
      "year": 1977,
      "short_title": "A Black Feminist Statement"
    },
    {
      "author": "Buolamwini, Joy; Gebru, Timnit",
      "year": 2018,
      "short_title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification"
    },
    {
      "author": "Collins, Patricia Hill",
      "year": 2000,
      "short_title": "Black Feminist Thought: Knowledge, Consciousness, and the Politics of Empowerment"
    },
    {
      "author": "Hampton, Leila Marie",
      "year": 2021,
      "short_title": "Black Feminism and Algorithmic Oppression"
    },
    {
      "author": "Birhane, Abeba et al.",
      "year": 2022,
      "short_title": "Meta-analysis of AI Ethics Research at FAccT"
    },
    {
      "author": "Jo, Eun Seo; Gebru, Timnit",
      "year": 2020,
      "short_title": "Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning"
    },
    {
      "author": "Mitchell, Margaret et al.",
      "year": 2019,
      "short_title": "Model Cards for Model Reporting"
    },
    {
      "author": "Zuboff, Shoshana",
      "year": 2019,
      "short_title": "The Age of Surveillance Capitalism"
    }
  ],
  "assessment": {
    "domain_fit": "Hohes Potenzial für die Schnittstelle AI/Soziale Arbeit/Gender Studies: Das Paper bietet einen umfassenden feministischen Rahmen zur Kritik struktureller Ungleichheiten in KI-Systemen und adressiert besonders auch Fragen von Datenjustice, Arbeitsbedingungen und Körperautonomie, die für Soziale Arbeit und intersektionale Praxis zentral sind.",
    "unique_contribution": "Die Reartikulierung der sieben Data-Feminism-Prinzipien speziell für AI sowie die Vorschläge für zwei neue Prinzipien (Umweltgerechtigkeit, erweitertes Konsens-Verständnis) bieten einen kohärenten, intersektional-feministischen Kritikrahmen, der über Gender-Bias hinausgeht und strukturelle, koloniale und kapitalistische Machtdynamiken explizit adressiert.",
    "limitations": "Das Paper ist primär literaturbasiert und theoretisch; es fehlen empirische Validierungen oder Fallstudien zur praktischen Implementierung der Prinzipien in konkreten AI-Entwicklungs- oder Einsatzszenarien. Die Autor:innen sind weiße, überwiegend heterosexuelle, nicht-behinderte Frauen, was die eigenen positionalen Grenzen widerspiegelt."
  },
  "target_group": "AI-Forschende und -Entwickler:innen (besonders in FAccT-Community), Policymaker:innen und Regulatoren, Sozialarbeiter:innen und Care-Professionals, Feminist Scholar:innen und Gender Studies Akademiker:innen, Aktivist:innen im Bereich Data Justice und Digital Rights, Lehrende in Computer Science und Digital Humanities, Civil-Society-Organisationen zur Algorithmic Justice."
}