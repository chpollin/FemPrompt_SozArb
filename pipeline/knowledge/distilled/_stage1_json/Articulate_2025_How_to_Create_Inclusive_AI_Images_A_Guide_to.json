{
  "metadata": {
    "title": "How to Create Inclusive AI Images: A Guide to Bias-Free Prompting",
    "authors": [
      "Morgan Jefferson"
    ],
    "year": 2025,
    "type": "report",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können AI-Image-Generatoren durch bewusste Prompt-Engineering dazu gebracht werden, inklusivere und weniger stereotypische Bilder zu produzieren?",
    "methodology": "Theoretisch/Review-basiert mit praktischen Handlungsempfehlungen; Analyse von AI-Bias-Quellen und systematische Präsentation von Prompting-Techniken",
    "key_finding": "AI-Bildgeneratoren reproduzieren durch unverzerrte Trainingsdaten bedingte stereotype Standardausgaben (weiß, männlich, jung, schlank). Durch spezifische, intentionale Prompt-Engineering-Techniken können Nutzer diese Defaults unterbrechen und inklusivere Darstellungen erreichen.",
    "data_basis": "nicht angegeben"
  },
  "arguments": [
    "AI-Bildgeneratoren perpetuieren existente Biases, weil ihre Trainingsdaten aus dem Internet nicht ausgewogen sind und bestimmte Bevölkerungsgruppen überrepräsentieren oder stereotypisieren (z.B. Ärzte als weiße Männer, Pflegepersonen als Frauen).",
    "Inclusive Prompt Engineering ermöglicht es, AI-Systeme durch präzise, spezifische und kontextbewusste Sprachanweisung zu lenken, um vielfältigere und gerechtere Darstellungen zu generieren.",
    "Effektive inklusive Prompts kombinieren mehrere Strategien: explizite Beschreibung sichtbarer Identitätsmerkmale (Alter, Rasse, Geschlecht, Körpergröße, Behinderung), respektvolle Sprache, Kontextualisierung und Aufforderung zur Diversität."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": true,
    "KI_Sonstige": false,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Gesamtfokus auf Kompetenz- und Wissensaufbau: 'with a few thoughtful techniques, you can generate images that respectfully and accurately reflect the full spectrum of human experience' und 'Inclusive representation takes deliberate, informed choices. It means educating ourselves, challenging assumptions, and crafting visuals'",
    "Generative_KI": "Fokus auf Text-to-Image AI-Generatoren: 'AI image generators are trained on massive datasets scraped from the internet' und 'Ask an artificial intelligence tool to generate a person'",
    "Prompting": "Kernthema des gesamten Artikels: 'inclusive prompt engineering: writing image prompts that account for identity, context, and representation so that the AI model doesn't make assumptions for us' und detaillierte Techniken wie 'Specify visible identity details', 'Use respectful, people-first language', 'Add cultural, social, and emotional context'",
    "Bias_Ungleichheit": "Explizite Analyse von Bias-Mechanismen: 'The images available online and their associated captions and metadata tend to overrepresent certain demographics while underrepresenting or stereotyping others. That skew gets baked into the AI model.' sowie 'Doctors, CEOs, and lawyers often appear as white men, while caregivers are usually women. Service workers are more likely to show up with darker skin, and people with disabilities are rarely represented at all.'",
    "Diversitaet": "Kernfokus auf Repräsentation und Inklusion: 'These default outputs are harmful. They erase people, reinforce biases, and exclude audiences.' und Detailbehandlung von Altersvielfalt, rassischer/ethnischer Vielfalt, Geschlechteridentitäten, Körpergrößenvielfalt und Behindertenrepräsentation",
    "Fairness": "Adressierung von fairness im AI-System: 'Bias is an AI default. When generated images misrepresent or stereotype people, the solution isn't to blame the tool. The responsibility lies with us.' und Diskussion von ausgewogener Repräsentation als Fairness-Anforderung"
  },
  "references": [
    {
      "author": "Heather Hiles",
      "year": 2025,
      "short_title": "Black Girls Code (Chair Statement)"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper hat hohe Relevanz für die KI-Literacies und praktische Fairness in generativen AI-Systemen, mit klarem Fokus auf Diversität und Bias-Mitigation. Es ist weniger relevant für traditionelle Soziale Arbeit, bietet aber praktische Werkzeuge für alle, die mit AI-generierten Inhalten arbeiten.",
    "unique_contribution": "Der praktische Beitrag liegt in der systematischen, anwendungsorientierten Anleitung zum Prompt-Engineering für Inklusion, die theoretische Erkenntnisse zu AI-Bias mit konkreten, reproduzierbaren Techniken verbindet.",
    "limitations": "Das Paper ist keine empirische Forschung und präsentiert keine Evaluationsdaten über die tatsächliche Effektivität der vorgeschlagenen Prompting-Techniken; es fehlt auch eine tiefere Analyse der Grenzen und unbeabsichtigten Konsequenzen von Inclusion-through-Prompting."
  },
  "target_group": "Praktiker:innen, die mit AI-Bildgeneratoren arbeiten (Content Creator, Designer, Trainer, Marketing-Fachleute), AI-Literacy-Vermittler:innen, Organisationen, die vielfältige visuelle Inhalte produzieren, und alle, die sich mit Fairness und Bias in generativen KI-Systemen beschäftigen"
}