{
  "metadata": {
    "title": "Imagination, Algorithms and News: Developing AI Literacy for Journalism",
    "authors": [
      "Mark Deuze",
      "Charlie Beckett"
    ],
    "year": 2022,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können Journalist:innen und die Nachrichtenindustrie AI-Literalität entwickeln, um KI-Systeme kreativ, ethisch und verantwortungsvoll in ihrer Arbeit einzusetzen?",
    "methodology": "Theoretisch/Konzeptionell basierend auf track record der Autoren in Medientechnologie-Forschung und der LSE JournalismAI Initiative; Taxonomie-Entwicklung und konzeptuelle Analyse",
    "key_finding": "AI-Literalität für Journalismus erfordert nicht nur technisches Wissen, sondern auch kritisches Verständnis der normativen Dimensionen von KI, die Fähigkeit zur Reflexion über Einsatzmöglichkeiten, und eine Kultur der Imagination statt bloßer instrumenteller Anwendung. Ein großes Wissensdefizit in der Nachrichtenindustrie gefährdet deren Autonomie gegenüber Tech-Konzernen.",
    "data_basis": "nicht angegeben"
  },
  "arguments": [
    "Die Nachrichtenindustrie überemphasiert instrumentale über imaginative Ansätze zu KI, wodurch die kreativen Potenziale ungenutzt bleiben und technische Lösungen als Selbstzweck behandelt werden.",
    "Das Narrativ von KI als allmächtige, perfekte Technologie ist historisch fallacious und verschleiert die messy Infrastruktur, ethischen Probleme (Bias, Exploitation, Datenschutz, Umweltfolgen) und die menschliche Gestaltung von KI-Systemen.",
    "AI-Literalität sollte als reflexiver Prozess verstanden werden, der nicht nur Wissen über KI umfasst, sondern auch die Fähigkeit zur kreativen Anwendung, zum kritischen Umgang mit Bias und Ungleichheit, sowie zur Imaginierung neuer journalistischer Praktiken jenseits bloßer Automation."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "AI literacy defined as 'knowledge and beliefs about artificial intelligence which aid their recognition, management, and application' with three key components: knowledge about AI, ability to recognize instances where AI should/shouldn't be applied, and skills to teach others about AI implementation.",
    "KI_Sonstige": "Discusses machine learning, natural language processing, automated statistical data analysis, algorithms, and their pervasive role in journalism workflows from story ideation to monetization.",
    "Bias_Ungleichheit": "AI systems are 'vulnerable to manipulations and mistakes, tend to be systemically biased, amplifying and exacerbating existing inequalities.' Paper identifies urgent historical-ethical concerns including 'technology bias, machine-driven exploitation of human labor, loss of human dignity at work governed by automated systems... particularly affect society's least privileged individuals and communities.'",
    "Diversitaet": "AI presented 'as an amplifier of all existing issues that benchmark contemporary journalism and its role in society, including how it wins (and loses) trust, how it covers and exemplifies diversity and inclusion, and how it assumes responsibility for the key challenges we all face in the 21st century.'",
    "Fairness": "Discusses fairness concerns in relation to AI's role in journalism: 'how it covers and exemplifies diversity and inclusion' and the danger of 'journalism being captured by technology (and the tech sector)' rather than using it responsibly. Emphasizes critical awareness of 'ways in which AI tends to amplify existing social and digital inequalities when left to technology companies.'"
  },
  "references": [
    {
      "author": "Anderson, C. W.",
      "year": 2018,
      "short_title": "Apostles of Certainty: Data Journalism and the Politics of Doubt"
    },
    {
      "author": "Beckett, C., and M. Deuze",
      "year": 2016,
      "short_title": "On the Role of Emotion in the Future of Journalism"
    },
    {
      "author": "Deuze, M.",
      "year": 2023,
      "short_title": "Life in Media"
    },
    {
      "author": "Kissinger, H. A., E. Schmidt, and D. Huttenlocher",
      "year": 2021,
      "short_title": "The Age of AI and Our Human Future"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper ist relevant für die KI-Literacy-Debatte und thematisiert systemische Ungleichheiten sowie Bias in KI-Systemen, hat aber keinen direkten Bezug zu Sozialer Arbeit oder Gender Studies. Die Perspektive auf marginalisierte Communities und Fairness ist jedoch transferierbar auf andere Domänen.",
    "unique_contribution": "Das Paper entwickelt ein theoretisches Framework für AI-Literacy in der Journalistik, das über technisches Wissen hinausgeht und normative, ethische und imaginative Dimensionen integriert, sowie vor der Mythologisierung von KI als allmächtige Technologie warnt.",
    "limitations": "Keine empirischen Daten oder Fallstudien; fokussiert primär auf Journalismus ohne Bezug zu anderen Branchen oder Sozialer Arbeit; Evidenz für AI-Knowledge-Defizite stammt hauptsächlich aus der LSE JournalismAI Initiative ohne breitere Datenbasis."
  },
  "target_group": "Journalist:innen, Medienschaffende, Redakteur:innen, Medieneducator:innen, Policymaker im Medienbereich, KI-Ethiker:innen, sowie Personen interessiert in Fragen von Algorithmen-Governance und Digital Literacy in professionellen Kontexten"
}