{
  "metadata": {
    "title": "Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time",
    "authors": [
      "Vagner Figueredo de Santana",
      "Sara E Berger",
      "Heloísa Caroline Candello",
      "Tiago Machado",
      "Cassia Sampaio Sanctos",
      "Tianyu Su",
      "Lemara Williams"
    ],
    "year": 2025,
    "type": "conferencePaper",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können Recommender-Systeme IT-Professionelle dabei unterstützen, verantwortungsvoll mit Generative-AI-Systemen zu interagieren und dabei RAI-Praktiken zu fördern?",
    "methodology": "Mixed Methods: 10 qualitative Interviews mit IT-Professionellen, Entwicklung eines open-source Recommender-Systems, 20 Usability-Sessions mit Think-Aloud-Protokoll und retrospektivem End-User Walkthrough",
    "key_finding": "Responsible Prompting Recommendations haben das Potenzial, anfängliche Prompt-Engineers zu unterstützen und Bewusstsein für Responsible AI zu schärfen, sollten aber gleichzeitig Prompt-Ähnlichkeit und Diversität sozialer Werte maximieren.",
    "data_basis": "10 Interviews mit IT-Professionellen, 20 User Sessions mit IT-Professionellen"
  },
  "arguments": [
    "Generative AI erfordert zusätzliche Designüberlegungen für User Interfaces und benötigt Nutzerleitfaden zu Affordanzen, Inputs und Outputs; ein Recommender-System kann Responsible AI Praktiken beim Prompting fördern.",
    "IT-Professionelle unterscheiden sich in ihren Prompting-Praktiken nach Rolle (Client-facing vs. Research): Client-facing Teams betonen Iterativität und Laboriösität, Research-Teams fokussieren auf Spezifizität und Nuancen bei komplexen Problemen.",
    "Benutzerempfehlungen sollten Additions- und Removal-Empfehlungen bieten, um sowohl positive Werte zu verstärken als auch potentiell schädliche Inhalte zu flaggen; Human-in-the-Loop ist essentiell zur Vermeidung von False Positives."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": true,
    "KI_Sonstige": false,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Responsible Prompting als Prozess wird definiert als Kommunikation mit KI-Systemen unter Vermeidung von Schäden und Förderung verantwortungsvoller Praktiken. Das Paper bietet praktische Leitfäden für Nutzer zum kompetenten Umgang mit GenAI.",
    "Generative_KI": "Focus auf Large Language Models (LLMs) und generative AI (GenAI), einschließlich Stochastizität, Variabilität und Halluzination von generativen Systemen.",
    "Prompting": "Zentral sind Prompt Engineering, Prompt-Strategien, Template-Empfehlungen und Best Practices beim Strukturieren von Eingaben für Text-Generierung und Bild-Generierung.",
    "Bias_Ungleichheit": "GenAI kann zu 'erasing or obfuscating social terms or issues, stereotyping or misrepresenting people' führen. Adversarial prompting und Jailbreaks werden als Sicherheitsrisiken thematisiert. Concerns um fairness, bias, und marginalisierte Communities werden erwähnt.",
    "Diversitaet": "Mehrere Teilnehmer aus Brasilien äußern Bedenken bezüglich Priorisierung des Englischen gegenüber anderen Sprachen. Research-Teams arbeiten mit spezifischen Populationen (z.B. ALS-Patienten) und betonen Notwendigkeit, Nuancen und Variationen in Sprachverwendung zu erfassen.",
    "Fairness": "Responsible AI als umbrella term für faire, ethische und verantwortungsvolle KI-Entwicklung. Fairness-Überlegungen in Bias-Mitigation, Systembewertung und Value Alignment werden integriert."
  },
  "references": [
    {
      "author": "Sunrise, Mark",
      "year": 2020,
      "short_title": "Responsible Innovation"
    },
    {
      "author": "Zwitter, Andrej",
      "year": 2014,
      "short_title": "Responsible Innovation Framework"
    },
    {
      "author": "Floridi, Luciano & Cowley, Josh",
      "year": 2019,
      "short_title": "AI Ethics Framework"
    },
    {
      "author": "Greshake, Kai et al.",
      "year": 2023,
      "short_title": "Prompt Injection Attacks"
    },
    {
      "author": "Sap, Maarten et al.",
      "year": 2019,
      "short_title": "Social Bias in AI"
    },
    {
      "author": "OpenAI",
      "year": 2023,
      "short_title": "Prompt Engineering Guide"
    },
    {
      "author": "Vallada, Anna-Maria et al.",
      "year": 2023,
      "short_title": "Red Teaming Dataset"
    },
    {
      "author": "Braun, Virginia & Clarke, Victoria",
      "year": 2006,
      "short_title": "Thematic Analysis Methods"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper trägt zu Responsible AI und HCI bei, hat aber keinen direkten Bezug zu Sozialer Arbeit oder Gender Studies. Die Relevanz liegt in der Schnittstelle von KI-Kompetenzen, Fairness und inklusiver Gestaltung von KI-Systemen.",
    "unique_contribution": "Erstmaliges open-source Recommender-System, das RAI-Praktiken direkt in den Prompting-Prozess integriert und empirisch validiert, mit Differenzierung zwischen verschiedenen beruflichen Rollen und Praktiken.",
    "limitations": "Begrenzte Sample-Größe (20 Usability-Sessions), Fokus auf IT-Professionelle (keine Diversity in Benutzerprofilen), fehlende Analyse langfristiger Auswirkungen auf Prompting-Verhalten und Responsible AI Kultur."
  },
  "target_group": "KI-Entwickler, Prompt-Engineers, UX-Designer von GenAI-Systemen, Verantwortliche für Responsible AI in Technologieunternehmen, HCI-Forscher, Policy-Maker für AI Governance"
}