{
  "metadata": {
    "title": "Gender Bias in Artificial Intelligence: Empowering Women Through Digital Literacy",
    "authors": [
      "Syed Sibghatullah Shah"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie manifestieren sich Geschlechtsbias in KI-Systemen und inwiefern können digitale Literaturinitiativen Frauen befähigen, kritisch mit KI-Technologien umzugehen und Geschlechtsungleichheiten in diesem Bereich abzubauen?",
    "methodology": "Theoretisch: Narrative Review von Fachliteratur aus 2010-2024; systematische Literatursuche in Web of Science, Scopus, IEEE Xplore, Google Scholar, ACM Digital Library; thematische Analyse nach Braun und Clarke; Schneeballmethode für Referenzen",
    "key_finding": "Digitale Literaturprogramme sind ein vielversprechendes Instrument zur Bekämpfung von Geschlechtsbias in KI, indem sie kritisches Denken fördern, Frauen zum Verfolgen von KI-Karrieren ermutigen und frauengeführte KI-Projekte katalysieren. Systemische Veränderungen in KI-Entwicklung, Design und Bildungspolitik sind jedoch notwendig.",
    "data_basis": "Narrative Review: 107 ausgewählte Quellen aus initialen 300 gefundenen Quellen; keine primären empirischen Daten; Analysefokus auf Peer-reviewed Artikel, Reports und Case Studies"
  },
  "arguments": [
    "Geschlechtsbias in KI ist systemisch und entsteht durch: Unterrepräsentation von Frauen in Entwicklungsteams, verzerrte Trainingsdaten und algorithmische Design-Entscheidungen, die Geschlechterstereotypen verstärken.",
    "Geschlechtsbias in KI wirkt sich kaskadierend auf Frauenkarrieren aus: Mangel an Rollenvorbildern, Stereotype-Threat, unhöfliche Arbeitskultur und hohe Abgangsquoten führen zu fortgesetzter Unterrepräsentation.",
    "Digitale Literaturprogramme (z.B. AI4ALL mit 78% STEM-Fortsetzungsquote und 91% erhöhtem KI-Interesse) befähigen Frauen durch kritisches Denken, verbesserte Karrierechancen und brechen Exklusionszyklen auf."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Digital literacy includes not only knowing how to use technology but also how to think about, criticise, and deal with digital technologies, like AI systems. [...] Digital literacy programs are important because they teach women how to think critically, which helps them find bugs in AI systems and fix them.",
    "KI_Sonstige": "Gender bias in AI is well-documented, manifesting in various ways, including biased algorithms, the under-representation of women in AI development teams [...] AI-based hiring tools are less helpful for women and voice recognition systems often do not work well with female sounds.",
    "Bias_Ungleichheit": "The findings reveal systemic gender biases embedded in AI applications across diverse domains, such as recruitment, healthcare, and financial services. [...] AI systems can reinforce gender stereotypes and biases without trying to if the people who work on them are not diverse.",
    "Gender": "Only 22% of AI workers around the world are women. [...] Gender bias in AI goes beyond the number of women working in the field and includes the data and algorithms that support these technologies. [...] AI-assisted performance review systems were 23% less likely to suggest women for senior positions than reviews done by humans only.",
    "Diversitaet": "More diverse development teams using inclusive AI design methods have been shown to reduce gender bias. [...] Putting gender-sensitive STEM education at the top of policy lists has a big impact on the number of women working in AI.",
    "Fairness": "AI not only mirrors but also potentially exacerbates existing social problems, such as gender bias, when observed in the actual world. [...] The study highlights the importance of inclusive AI design, gender-responsive education policies, and sustained research efforts to mitigate bias and promote equity."
  },
  "references": [
    {
      "author": "Priyadarshini & Priyadarshini",
      "year": 2024,
      "short_title": "Gender disparity in artificial intelligence: creating awareness of unconscious bias"
    },
    {
      "author": "Andrews & Bucher",
      "year": 2022,
      "short_title": "Automating discrimination: AI hiring practices and gender inequality"
    },
    {
      "author": "Hussien et al.",
      "year": 2024,
      "short_title": "Unpacking the double-edged sword: how artificial intelligence shapes hiring process through biased HR data"
    },
    {
      "author": "Strengers & Kennedy",
      "year": 2021,
      "short_title": "The smart wife: Why Siri, Alexa, and other smart home devices need a feminist reboot"
    },
    {
      "author": "Mehrabi et al.",
      "year": 2021,
      "short_title": "A survey on bias and fairness in machine learning"
    },
    {
      "author": "World Economic Forum",
      "year": 2019,
      "short_title": "Why AI is failing the next generation of women"
    },
    {
      "author": "Roopaei et al.",
      "year": 2021,
      "short_title": "Women in AI: barriers and solutions"
    },
    {
      "author": "Hall & Ellis",
      "year": 2023,
      "short_title": "A systematic review of socio-technical gender bias in AI algorithms"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper ist hochgradig relevant für die Schnittstelle von KI, Digitale Literatur und Gender, adressiert aber Soziale Arbeit nicht explizit. Es bietet wertvollen Überblick über strukturelle Geschlechterbias in KI-Systemen und Lösungsansätze durch Bildung, relevant für sozialpolitische Interventionen.",
    "unique_contribution": "Systematische Synthese der Verschränkung von Geschlechterbias in KI mit digitalen Literaturinitiativen als Empowerment-Tool, mit globalem Fokus auf unterschiedliche Kontexte (HICs vs. LMICs).",
    "limitations": "Narrative Review ohne primäre empirische Datenerhebung; Fokus auf englischsprachige Literatur; begrenzte Diskussion intersektionaler Perspektiven trotz Erwähnung; keine Implementierungs- oder Skalierungsempfehlungen für LMICs."
  },
  "target_group": "AI-Entwickler, Policymaker in Tech und Bildung, Frauen in Tech-Karrieren, Gender-Forscher, digitale Literatur-Pädagogen, Organisationen zur Förderung von Frauen in STEM, internationale Entwicklungsorganisationen"
}