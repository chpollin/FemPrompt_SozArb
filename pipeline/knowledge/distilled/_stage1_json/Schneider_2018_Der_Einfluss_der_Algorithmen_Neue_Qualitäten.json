{
  "metadata": {
    "title": "Der Einfluss der Algorithmen: Neue Qualitäten durch Big Data Analytics und Künstliche Intelligenz",
    "authors": [
      "Diana Schneider",
      "Udo Seelmeyer"
    ],
    "year": 2018,
    "type": "journalArticle",
    "language": "de"
  },
  "core": {
    "research_question": "Welche Veränderungen und Herausforderungen bringt der Einsatz von Big Data und Künstlicher Intelligenz in der Sozialen Arbeit mit sich und welche neuen Anforderungen ergeben sich daraus für die Professionalität von Fachkräften?",
    "methodology": "Theoretisch-konzeptionell; kombiniert Technikphilosophie (Formalisierungstheorie) mit fallstudienartiger Analyse (CFRA-Tool); konzeptionelle Literaturanalyse",
    "key_finding": "Big Data und KI verkleinern die von Rolf beschriebene 'vorläufige Formalisierungslücke' erheblich, führen aber zu neuen Herausforderungen hinsichtlich vermeintlicher Objektivität, Bias-Reproduktion und Ermessensspielraum-Einschränkung. Neue Anforderungen an Fachlichkeit entstehen durch erforderliche 'data literacy' und konsistenten Persönlichkeitsschutz.",
    "data_basis": "nicht empirisch; konzeptionelle Analyse mit Referenzen auf internationale Fallbeispiele (insbesondere CFRA in USA)"
  },
  "arguments": [
    "Software-Einsatz in der Sozialen Arbeit folgt einem dreischrittigen Formalisierungsprozess (Semiotisierung, Formalisierung, Algorithmisierung), wobei soziale Realität nur begrenzt als Code abbildbar ist; es existieren notwendige und vorläufige Formalisierungslücken.",
    "Künstliche Intelligenz und maschinelles Lernen mittels neuronaler Netze ermöglichen die Verarbeitung unstrukturierter Daten und schließen die vorläufige Formalisierungslücke rasant, schaffen aber neue Risiken durch versteckte Bias, subjektive Datenextraktion und fehlende Transparenz der Entscheidungskriterien.",
    "Algorithmen in der Sozialen Arbeit (z.B. CFRA für Kindeswohlgefährdung) können zu De-Professionalisierung, Ermessensspielraum-Verengung und fehlerhafter Gleichsetzung von Prognosekompetenz mit Interventionsentscheidung führen; dabei werden Lösungsansätze und Ursachenstrukturen ignoriert.",
    "Formalisierung wird fälschlicherweise mit Objektivierung gleichgesetzt, obwohl Vorurteile in unstrukturierten Daten sowie durch Forscher:innen und Entwickler:innen in der Datenaufbereitung entstehen und durch selbstlernende Systeme verstärkt werden."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Zentrale Forderung: 'Sowohl data literacy als kompetenter Umgang mit komplexen Datenquellen und anspruchsvollen Verfahren zu deren Verarbeitung als auch ein konsequenter Persönlichkeitsschutz bilden neue Anforderungen an die Professionalität von Fachkräften.'",
    "KI_Sonstige": "Ausführliche Behandlung von maschinellem Lernen, neuronalen Netzen, Big Data Analytics, Mustererkennung und algorithmischen Entscheidungssystemen: 'Das Neue an Technologien wie Big Data Analytics, maschinellem Lernen und Künstlicher Intelligenz (KI) besteht darin, dass nicht nur strukturierte Daten, sondern auch unstrukturierte Daten wie (Frei-) Texte, Audio- und Videodaten maschinell verarbeitet werden können.'",
    "Soziale_Arbeit": "Direkter Fokus auf Soziale Arbeit als Anwendungsfeld: 'Digitalisierung prägt zunehmend auch Arbeitsvollzüge und Entscheidungsprozesse in der Sozialen Arbeit.' Fallbeispiele aus Jugendhilfe (CFRA, Kindeswohlgefährdung). Autoren arbeiten an FH Bielefeld, Fachbereich Sozialwesen.",
    "Bias_Ungleichheit": "Kritische Analyse von Bias-Reproduktion: 'Da ein Algorithmus die in ihm enthaltenden Daten nur kristallisieren und verschärfen kann, besteht stets die Gefahr, hier Vorurteile zu reproduzieren bzw. zu verstärken.' Stigmatisierungspotenzial durch Milieu-basierte Durchschnittsprognosen.",
    "Diversitaet": "Implizite Adressierung durch Fokus auf Ermessensspielraum-Einschränkung und Standardisierung, die ganzheitliche Betrachtung von Individuen erschwert: 'wird doch nicht das hinter den Ergebnissen der Datenanalyse stehende Individuum betrachtet, sondern lediglich die Häufigkeitsverteilung innerhalb seines Milieus'.",
    "Fairness": "Expliziter Fokus auf algorithmische Fairness und faire Entscheidungsfindung: 'Gleichsam wird deutlich, dass ein gelingender Umgang mit den genannten Herausforderungen allein damit noch nicht gewährleistet ist.' Kritik an vermeintlicher Objektivität und fehlerhaften Korrelationen; Forderung nach Systemen, die Entscheidungen unterstützen statt ersetzen."
  },
  "references": [
    {
      "author": "Rolf",
      "year": 2008,
      "short_title": "Formalisierungslücken und Software-Transformation sozialer Wirklichkeit"
    },
    {
      "author": "Høybye-Mortensen",
      "year": 2015,
      "short_title": "Standardisierung und Ermessensspielraum"
    },
    {
      "author": "Schrödter et al.",
      "year": 2018,
      "short_title": "Prognosekompetenz vs. Interventionsentscheidung bei Risikoeinschätzung"
    },
    {
      "author": "Gillingham & Graham",
      "year": 2016,
      "short_title": "Subjektive Einfärbung durch Datenextraktion und -aufbereitung"
    },
    {
      "author": "Datta et al.",
      "year": 2015,
      "short_title": "Bias-Reproduktion durch Algorithmen"
    },
    {
      "author": "Ley & Seelmeyer",
      "year": 2004,
      "short_title": "Software-Einfluss auf Ermächtigung und De-Professionalisierung"
    },
    {
      "author": "Finck & Janneck",
      "year": 2008,
      "short_title": "Technologien als soziotechnische Systeme"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI und Soziale Arbeit. Das Paper adressiert zentral die Frage, wie algorithmische Systeme und KI die Professionalisierung, Ethik und Handlungsfähigkeit in Sozialen Diensten verändern, besonders im Kontext von Entscheidungsfindung und Bias.",
    "unique_contribution": "Systematische Analyse der Formalisierungsprozesse, die KI in der Sozialen Arbeit ermöglichen, verbunden mit kritischer Reflexion der damit verbundenen Herausforderungen (Bias, Objektivierungsmythos, De-Professionalisierung) und konkreten Regulierungsempfehlungen.",
    "limitations": "Keine empirische Erhebung; konzeptionelle Analyse basiert auf Literatur und einem internationalen Fallbeispiel (CFRA); Geschlechterperspektive und intersektionale Dimensionen nicht explizit thematisiert; zukünftige Entwicklung von KI schwer vorhersehbar."
  },
  "target_group": "Sozialarbeiter:innen und Fachkräfte in Sozialen Diensten, KI-Entwickler:innen und Softwareanbieter für Sozialbereich, Policymaker und Regulierungsinstitutionen, Hochschullehrende in Sozialer Arbeit, Forscher:innen an der Schnittstelle von KI und Soziale Arbeit, Interessierte an Algorithmenethik und digitaler Gerechtigkeit"
}