{
  "metadata": {
    "title": "Faires KI-Prompting – Ein Leitfaden für Unternehmen",
    "authors": [
      "Eva Gengler",
      "Andreas Kraus",
      "Kristina Bodrožić-Brnić"
    ],
    "year": 2024,
    "type": "report",
    "language": "de"
  },
  "core": {
    "research_question": "Wie können kleine und mittlere Unternehmen Generative KI-Systeme durch bewusstes und faires Prompting verantwortungsvoll einsetzen und dabei Diskriminierung vermeiden?",
    "methodology": "Theoretisch/Praktisch: Leitfaden basierend auf Literaturrecherche und Expertise im Bereich feministische KI, mit praktischen Beispielen und Fallstudien zur Bildgenerierung und Textgenerierung",
    "key_finding": "Ein strukturiertes KI-FAIRNESS-Framework (Kontext, Input, Fokus, Ausschnitt, Iterationen, Repertoire, Nachbessern, Eignung, Sprache, Sinn) ermöglicht es Nutzer:innen, faire und diverse Ergebnisse aus Generativer KI zu gestalten. Organisationales Mindset, klare KI-Strategie und Werteorientierung sind grundlegend für fairen KI-Einsatz.",
    "data_basis": "nicht angegeben (qualitatives Expertenleitfaden-Format, keine quantitativen Daten)"
  },
  "arguments": [
    "Generative KI reproduziert strukturelle Ungerechtigkeiten aus Trainingsdaten (Bias, Stereotype, Gender-Data-Gap), wenn nicht bewusst dagegen gesteuert wird. Der Zweck der KI-Entwicklung und -Nutzung – ob zur Reproduktion oder Transformation bestehender Prozesse – ist entscheidend.",
    "Faires KI-Prompting ist ein erlernbarer Skill: Durch systematische Prompt-Gestaltung (Kontext, Sprache, Diversitätsanforderungen, Iterationen) können Nutzer:innen faire und diverse Ergebnisse erzielen und damit gesellschaftliche Ungleichheiten abbauen.",
    "Organisationale Verankerung ist essentiell: KI-Strategie auf Führungsebene, Werteorientierung, diversitätsaffine Governance, Mindset-Entwicklung auf allen Ebenen und kontinuierliche Reflexion eigener Vorurteile ermöglichen verantwortungsvollen KI-Einsatz in KMU."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": true,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": true,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Gesamter Leitfaden vermittelt KI-Kompetenzen: 'Der Guide vermittelt Ihnen nicht nur das 'Was' und 'Wie', sondern auch das 'Warum' des Einsatzes Generativer KI.' Kapitel 1 behandelt 'Grundlagen: KI, Generative KI und KI-Prompting' und Best Practices beim Prompting.",
    "Generative_KI": "Fokus auf Generative KI-Systeme: 'Generative KI-Systeme - Programme, die selbstständig Texte, Bilder und vieles mehr erzeugen können'. Detaillierte Übersicht zu TextgeneratorenTools (ChatGPT 4, Claude 3, Gemini, DALL-E 2, Midjourney) in Kapitel 2.3.",
    "Prompting": "Zentral: Kapitel 5 'Promptingstrategien' mit KI-FAIRNESS-Framework (K-I-F-A-I-R-N-E-S-S). Punkt 'Sprache ist Macht' behandelt englisches Prompting, Neutralität vs. Diversität, Anonymisierung, Tonalität.",
    "KI_Sonstige": "Behandlung klassischer ML-Probleme wie Halluzinationen, Datenschutz, unzureichende Aktualität in Kapitel 2.2: 'Das sogenannte Halluzinieren, bei dem die Künstliche Intelligenz Informationen erfindet oder verfälscht.'",
    "Bias_Ungleichheit": "Umfassende Behandlung: Kapitel 3 'Problemstellung: Warum Fair AI Prompting?' behandelt historische Daten, Gender-Data-Gap, Stereotype, Überrepräsentation weißer Männer: 'Viele Entscheidungsträger*innen und Entwickler*innen sind weiß, männlich* und privilegiert.' Praktische Beispiele zeigen Diskriminierung in KI-generierten Bildern (nur schlanke Menschen, lange Haare, priviligierte Kontexte).",
    "Gender": "Explizit thematisiert: Gender-Data-Gap, genderstereotypische Beschreibungen, Repräsentation von Frauen in Berufsfeldern. Beispiel MissJourney: 'sich darauf spezialisiert hat, Bilder von Frauen in verschiedenen Berufsfeldern zu erstellen.' Hinweis auf Gefahr genderstereotypischer Formulierungen bei Empfehlungsschreiben.",
    "Diversitaet": "Kernthema: 'Ziel dieses Leitfadens ist es...diese mit Blick auf eine diverse Gesellschaft nutzen zu können.' KI-FAIRNESS-Framework fordert explizit diverse Darstellung. Beispiel: 'Es könnte z.B. explizit gefordert werden, dass Frauen und Männer, Menschen unterschiedlicher Hautfarbe und sozialer Schicht dargestellt werden sollen.'",
    "Feministisch": "Leitfaden basiert auf feministischer KI-Perspektive: Co-Autorin Eva Gengler ist 'Expertin im Bereich feministischer KI' und Co-Founderin von 'feminist AI'. Referenzen auf D'Ignazio & Klein 'Data Feminism', Caroline Criado-Perez 'Unsichtbare Frauen' (Gender-Data-Gap). Konzept 'Feministische KI': 'Es gibt bereits einige Beispiele von KI mit feministischem Zweck und für die Stärkung der Rechte marginalisierter Gruppen.'",
    "Fairness": "Zentral: Kap. 4.5 'Werteorientierung bei Entwicklung und Einsatz von KI', Kap. 4.6 'KI-Governance: Prinzipien, Prozesse und Strukturen für KI' mit Fairness-Definition: 'Fairness im Kontext von KI bedeutet, dass alle Menschen gleichberechtigt und diskriminierungsfrei von KI-Systemen behandelt werden: Gleiche Chancen, Verbot der Diskriminierung, Transparenz und Nachvollziehbarkeit, Rechenschaftspflicht.' KI-FAIRNESS-Framework als systematischer Ansatz."
  },
  "references": [
    {
      "author": "D'Ignazio, Catherine & Klein, Lauren F.",
      "year": 2020,
      "short_title": "Data Feminism"
    },
    {
      "author": "Criado-Perez, Caroline",
      "year": 2019,
      "short_title": "Unsichtbare Frauen (Invisible Women: Data Bias in a World Designed for Men)"
    },
    {
      "author": "Nuseir et al.",
      "year": "nicht angegeben",
      "short_title": "Studie zu Diversity in KI-Entwicklungsteams"
    },
    {
      "author": "OpenAI",
      "year": 2024,
      "short_title": "ChatGPT 4"
    },
    {
      "author": "Midjourney",
      "year": 2024,
      "short_title": "Bildgenerierungs-Tool mit Fokus auf Diversität"
    },
    {
      "author": "MissJourney (Project)",
      "year": "nicht angegeben",
      "short_title": "Bilder von Frauen in Berufsfeldern generieren"
    },
    {
      "author": "DAIR.AI",
      "year": "nicht angegeben",
      "short_title": "Prompt Engineering Guide"
    },
    {
      "author": "bitkom",
      "year": 2024,
      "short_title": "Leitfaden: Generative KI in Unternehmen"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI/Fairness/Gender: Der Leitfaden verbindet technisches Wissen über Generative KI explizit mit feministischen und Diversity-Perspektiven und zielt auf praktische Anwendung in Unternehmen ab. Die Fokussierung auf KMU adressiert auch eine sozialpolitisch relevante Gruppe.",
    "unique_contribution": "Systematisches KI-FAIRNESS-Framework, das Prompting-Praxis direkt mit organisationalen Strukturveränderungen (Governance, Mindset, Werteorientierung) verknüpft und konkrete Strategien zur Vermeidung von Diskriminierung in KI-generierten Inhalten bietet.",
    "limitations": "Leitfaden basiert nicht auf empirischer Evaluation des KI-FAIRNESS-Frameworks; keine quantitative Überprüfung der Effektivität; Fokus auf deutschsprachige KMU, begrenzte Übertragbarkeit auf andere Kontexte."
  },
  "target_group": "Primär: Führungskräfte und Mitarbeiter:innen in kleinen und mittleren Unternehmen (KMU). Sekundär: KI-Trainer:innen, Berater:innen, HR-Fachkräfte, Policymaker zu digitaler Gerechtigkeit, KI-Ethiker:innen. Interessant auch für: Sozialarbeitende, die KI in ihren Organisationen einführen oder kritisch hinterfragen."
}