{
  "metadata": {
    "title": "Avoiding Catastrophe Through Intersectionality in Global AI Governance",
    "authors": [
      "Laine McCrory"
    ],
    "year": 2025,
    "type": "workingPaper",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können intersektionale und feministische Perspektiven in die globale AI-Sicherheitsgovernance integriert werden, um gegenwärtige Schäden marginalisierter Gruppen mit zukünftigen existenziellen Risiken zu verbinden?",
    "methodology": "Theoretisch/Analyse: Feminist Policy Analysis Framework angewendet auf 7 internationale AI-Sicherheitsinitiativen mittels eines entwickelten 4-Ziel-Bewertungssystems (Intersectionality, Context, Neutrality, Power)",
    "key_finding": "Keine der sieben analysierten globalen AI-Sicherheitsinitiativen erfüllt die Ziele eines intersektionalen feministischen Ansatzes; sie vernachlässigen gegenwärtige Schäden marginalisierter Gruppen und mangelt es an aussagekräftiger Partizipation betroffener Gemeinschaften.",
    "data_basis": "Dokumentenanalyse von 7 internationalen AI-Governance-Initiativen (UN-Resolution, OECD-Prinzipien, Asilomar Principles, Bletchley Declaration, Seoul Declaration, Frontier AI Safety Commitments, weitere Industrie-Commitments)"
  },
  "arguments": [
    "Die AI-Safety-Bewegung fokussiert auf zukünftige existenzielle Risiken durch AGI, während sie gegenwärtige, bereits auftretende existenzielle Schäden für marginalisierte Gruppen (durch diskriminierende Algorithmen, Datenextraktion, Umweltschäden) ignoriert und damit Verantwortung für aktuelle Harms abwälzt.",
    "Ein intersektionaler feministischer Policy-Rahmen muss vier zentrale Ziele verfolgen: Intersectionality promoten, diverse Kontexte berücksichtigen, falsche Neutralitätsannahmen bekämpfen und Macht für marginalisierte Gruppen erhöhen – ein Ansatz, den bestehende Governance-Initiativen systematisch verfehlen.",
    "Accountability und Partizipation sind zentral: Zukünftige AI-Sicherheitspolitik muss von betroffenen marginalierten Communities mitgestaltet werden, kompound identities systematisch adressieren und strukturelle Diskriminierung als Fundament AGI-geleiteter Systeme bekämpfen."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": true,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Die OECD definiert 'AI knowledge' als 'skills and resources required to understand and participate in the AI system lifecycle' – McCrory kritisiert, dass gelebte Erfahrung marginalisierter Gruppen ausgeschlossen wird und alternative Epistemologien in Expertise-Definitionen fehlen.",
    "KI_Sonstige": "Analysen von AI-Safety-Instituten, AGI-Risiken, algorithmischen Entscheidungssystemen und deren Implementierung in globalen Governance-Rahmen; Fokus auf ML-Modelle und deren strukturelle Verzerrungen.",
    "Soziale_Arbeit": "Expliziter Bezug zu Sozialpolitik-Analyse (McPhail, Kanenberg), Vulnerable Populationen, Social Welfare Systeme (Eubanks-Referenz zu Automating Inequality in Sozialhilfe-Kontexten), Care und Community Governance.",
    "Bias_Ungleichheit": "Kern-These: 'AI reinforces inequalities related to race, sexuality, class and gender'; diskriminierende Algorithmen als existenziell für low-income families; 'technological redlining' durch systematische Benachteiligung; Power Dynamics und strukturelle Diskriminierung.",
    "Diversitaet": "Intersectionality als Framework-Kern; marginalisierte Communities, race, ethnicity, gender identity, class, carceral status, ability als überlappende Identitäten; Forderung nach 'diverse perspectives within technical development' und Repräsentation in Policy-Narrativen.",
    "Feministisch": "Explizit feministische Theorie: Crenshaw's Intersectionality (1991), D'Ignazio & Klein's Data Feminism (2020), McPhail's Feminist Policy Analysis Framework (2003), Kanenberg et al.'s intersektionale Policy-Analyse; feministische Prinzipien wie Accountability, Partizipation, Power-Analyse zentral."
  },
  "references": [
    {
      "author": "Buolamwini & Gebru",
      "year": 2018,
      "short_title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification"
    },
    {
      "author": "Crenshaw",
      "year": 1991,
      "short_title": "Mapping the Margins: Intersectionality, Identity Politics, and Violence Against Women of Color"
    },
    {
      "author": "D'Ignazio & Klein",
      "year": 2020,
      "short_title": "Data Feminism"
    },
    {
      "author": "Eubanks",
      "year": 2018,
      "short_title": "Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor"
    },
    {
      "author": "Crawford",
      "year": 2021,
      "short_title": "The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence"
    },
    {
      "author": "Benjamin",
      "year": 2019,
      "short_title": "Race after Technology: Abolitionist Tools for the New Jim Code"
    },
    {
      "author": "Gebru & Torres",
      "year": 2024,
      "short_title": "The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence"
    },
    {
      "author": "Kanenberg, Leal & Erich",
      "year": 2020,
      "short_title": "Revising McPhail's Feminist Policy Analysis Framework: Updates for Use in Contemporary Social Policy Research"
    },
    {
      "author": "Noble",
      "year": 2018,
      "short_title": "Algorithms of Oppression: How Search Engines Reinforce Racism"
    },
    {
      "author": "Bostrom",
      "year": 2014,
      "short_title": "Superintelligence: Paths, Dangers, Strategies"
    }
  ],
  "assessment": {
    "domain_fit": "Extrem relevant für die Schnittstelle AI/Soziale Arbeit/Gender Studies: Das Paper verbindet AI-Governance-Kritik mit sozialpolitischer Theorie, marginalisierte Populationen und strukturelle Gerechtigkeit – zentral für kritische Soziale Arbeit im digitalen Zeitalter.",
    "unique_contribution": "Entwicklung eines operationalisierbaren feministischen AI-Policy-Analyse-Frameworks mit empirischer Anwendung auf 7 globale Governance-Initiativen, die systematisch zeigt, dass AI-Safety-Diskurse gegenwärtige Harms ignorieren und Partizipation marginalisierter Gruppen ausschließen.",
    "limitations": "Dokumentenanalyse ohne primäre Daten von betroffenen Communities; Framework-Validität nicht durch externe Reviewer getestet; begrenzte Sample (7 Initiativen); keine Empfehlungen zu Implementierungsmetriken oder Monitoring-Mechanismen für Fem-AI-Standards."
  },
  "target_group": "Policy-Maker in AI-Governance, Feminist AI-Forschende, Sozialarbeiter:innen in digitalen Kontexten, Critical Data Studies Scholar:innen, marginalisierte Community-Organisationen, Tech-Worker mit ethischem Fokus, Aktivist:innen für Tech-Gerechtigkeit"
}