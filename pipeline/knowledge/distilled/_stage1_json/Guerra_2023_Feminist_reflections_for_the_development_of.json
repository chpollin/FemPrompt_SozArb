{
  "metadata": {
    "title": "Towards a feminist framework for AI development: from principles to practice",
    "authors": [
      "Juliana Guerra"
    ],
    "year": 2023,
    "type": "report",
    "language": "en"
  },
  "core": {
    "research_question": "Ist es möglich, KI-Systeme zu entwickeln, die keine Logiken der Unterdrückung reproduzieren, und wie können feministische Praktiken in der KI-Entwicklung in Lateinamerika integriert werden?",
    "methodology": "Mixed Methods: Nicht-erschöpfende Literaturanalyse von Audit-Frameworks und Fairness-Assessments; systematische Analyse von sechs Statements zu feministischen Prinzipien für digitale Technologien; qualitative Interviews mit sieben Frauen in KI/Data Science in Lateinamerika; interpretative Analyse von Erfahrungen vor dem Hintergrund feministischer und Social-Justice-Perspektiven",
    "key_finding": "Feministische KI-Entwicklung erfordert nicht nur technische Lösungen, sondern eine Transformation von Praktiken in Design, Produktion, Deployment und Governance unter Berücksichtigung lokaler Kontexte, Care-Arbeit und intersektionaler Machtdynamiken in Lateinamerika.",
    "data_basis": "n=7 qualitative Interviews mit Frauen in KI/Data Science aus Lateinamerika; systematische Analyse von 6 feministischen Prinzipien-Statements; Review von 3 feministischen Praxis-Guides aus Lateinamerika"
  },
  "arguments": [
    "KI-Systeme werden von einer homogenen Gruppe (überwiegend weiße Männer in den USA) entwickelt, deren Perspektive als neutral und objektiv dargestellt wird, aber tatsächlich Unterdrückungslogiken reproduziert. Die Hegemonie von Silicon-Valley-Modellen in Lateinamerika ist nicht nur eine Frage der Unterinvestition, sondern der strukturellen Reproduktion kolonialer Machtverhältnisse.",
    "Feministische KI-Entwicklung muss die Materialität und Sichtbarmachung von Care-Arbeit, Infrastruktur und deren Kontrolle thematisieren. Dies umfasst sowohl digitale Infrastruktur als auch die oft feminisierte, prekäre und unsichtbar gemachte Arbeit in der Produktion und Wartung von KI-Systemen.",
    "Alternative Ansätze wie Tequiologie (kolaborative, auf gegenseitiger Unterstützung basierende Technologieentwicklung) und Designjustice ermöglichen kontextgebundene, gemeinschaftsorientierte KI-Entwicklung, die nicht auf Marktlogiken und Effizienz reduziert ist, sondern auf lokale Bedürfnisse und Autonomie ausgerichtet ist."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": true,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Fokus auf Wissenstransfer, kritische Reflexion und Kompetenzerwerb in KI-Entwicklung: 'recognizing and making visible the multiple and diverse forms of the technical reconfigures our perception of who is part of a technology'",
    "KI_Sonstige": "Thematisierung von Natural Language Processing, Computer Vision, Robotics, algorithmischen Entscheidungssystemen, Machine Learning und Bias in Datenbanken und Audit-Frameworks.",
    "Soziale_Arbeit": "Fokus auf Soziale Dienste und technologische Interventionen in Kontexten von Gewalt gegen Frauen, Care-Arbeit und Gemeinschaftsorganisierung. Beispiel: 'app to tackle violence against women' und Analyse feministischer kollektiver Praxis.",
    "Bias_Ungleichheit": "Zentrale Thematisierung von Bias in Datenbanken, strukturellen Ungleichheiten in Latinamerika (indigene Sprachen, Geschlechter-Digital-Divide, Arbeitsbedingungen in Elektronik-Fabriken): 'if you are born speaking an indigenous language your chances are going to be very different'",
    "Gender": "Expliziter Fokus auf Geschlechterperspektive: Frauen im Tech/AI-Bereich, Geschlechter-Bias in Datensätzen, Gender-basierte Gewalt als Anwendungsfall, Unterrepräsentation von Frauen in datengetriebenen Rollen.",
    "Diversitaet": "Intersektionale Analyse mit Fokus auf marginalisierte Gruppen: indigene Bevölkerung, Frauen, nicht-binäre Personen, Arbeiter:innen, Geflüchtete. 'It is essential that we listen to and learn from the embodied experiences of datafication...in the lives of women and girls, indigenous communities, immigrants, refugees, platform workers, non-binary people, and rural communities'",
    "Feministisch": "Explizite Verwendung feministischer Theorie (Haraway, D'Ignazio & Klein, hooks implizit durch Critical Race Theory, Crenshaw-Konzepte durch Intersektionalität): 'a feminist perspective', Referenz zu 'Feminist Principles of the Internet', 'Data Feminism', Manifesto for hackfeminist algorithms, Design Justice, Decolonial Feminism.",
    "Fairness": "Thematisierung von Fairness in Algorithmen, Audit-Frameworks, Bias-Mitigation, algorithmischer Gerechtigkeit und Impact-Assessment: 'algorithmic or datasets biases', 'Equalized Odds, Demographic Parity', auditability und reusability von Daten."
  },
  "references": [
    {
      "author": "D'Ignazio, Catherine & Klein, Lauren F.",
      "year": 2020,
      "short_title": "Data Feminism"
    },
    {
      "author": "Benjamin, Ruha",
      "year": 2019,
      "short_title": "Race after Technology. Abolitionist tools for the New Jim Code"
    },
    {
      "author": "Noble, Safiya Umoja",
      "year": 2016,
      "short_title": "Traversing Technologies. A Future for Intersectional Black Feminist Technology Studies"
    },
    {
      "author": "Peña, Paz & Varón, Joana",
      "year": 2021,
      "short_title": "Oppressive A.I.: Feminist Categories to Understand its Political Effects"
    },
    {
      "author": "Velasco, Patricio & Venturini, Jamila",
      "year": 2021,
      "short_title": "Automated decision-making in public administration in Latin America"
    },
    {
      "author": "Aguilar Gil, Yásnaya Elena",
      "year": 2020,
      "short_title": "A modest proposal to save the world"
    },
    {
      "author": "Design Justice Network",
      "year": 2020,
      "short_title": "Design Justice Network Principles"
    },
    {
      "author": "Ricaurte, Paola",
      "year": 2022,
      "short_title": "Artificial Intelligence and the Feminist Decolonial Imagination"
    },
    {
      "author": "Wajcman, Judy",
      "year": 2006,
      "short_title": "Technofeminism"
    },
    {
      "author": "Toupin, Sophie & Spideralex",
      "year": 2018,
      "short_title": "Radical Feminist Storytelling and Speculative Fiction: Creating new worlds by re-imagining hacking"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit/Gender. Das Paper adressiert direkt die Entwicklung von KI-Systemen, die keine Unterdrückungslogiken reproduzieren, mit explizitem Fokus auf Lateinamerika, feministische Methodik und Anwendungen im Sozialbereich (Gewalt gegen Frauen, Gemeinschaftsorganisierung, Care-Infrastrukturen).",
    "unique_contribution": "Das Paper leistet einen originären Beitrag durch die Kombination von feministischer Theorie mit praktischen, lokalisierten Interviews von Frauen in KI/Data Science in Lateinamerika und entwickelt einen kontextgebundenen Handlungsleitfaden für feministische KI-Entwicklung, der über anglo-amerikanische Diskurse hinausgeht.",
    "limitations": "Die Studie ist begrenzt auf n=7 Interviews und hat keine Evaluationsindikatoren für die konkrete Wirksamkeit der vorgeschlagenen Praktiken; die Systematisierung bleibt explorativer Art; der Leitfaden ist noch in Entwicklung und wenig operationalisiert."
  },
  "target_group": "KI-Entwickler:innen und Informatiker:innen mit Interesse an sozialer Transformation; Sozialarbeiter:innen und Social-Change-Organisationen, die KI-Systeme einsetzen oder hinterfragen möchten; feministische Tech-Kollektive und digitale Aktivist:innen in Lateinamerika; Policymaker:innen und Ethiker:innen im Bereich digitale Gerechtigkeit; Akademiker:innen in KI Ethics, Gender Studies und Digital Humanities."
}