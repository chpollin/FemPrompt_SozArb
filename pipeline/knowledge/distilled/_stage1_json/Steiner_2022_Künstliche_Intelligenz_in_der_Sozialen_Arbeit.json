{
  "metadata": {
    "title": "Künstliche Intelligenz in der Sozialen Arbeit: Grundlagen, Entwicklungen, Herausforderungen",
    "authors": [
      "Olivier Steiner",
      "Dominik Tschopp"
    ],
    "year": 2022,
    "type": "journalArticle",
    "language": "de"
  },
  "core": {
    "research_question": "Welche Potenziale, Grenzen und Risiken ergeben sich durch den Einsatz von Künstlicher Intelligenz in der Sozialen Arbeit?",
    "methodology": "Theoretisch/Review: Systematische Analyse von KI-Technologien und deren Anwendungsszenarien in der Sozialen Arbeit mit kritischer Reflexion bestehender Pilotprojekte und Forschungsliteratur",
    "key_finding": "Während KI-Technologien wie Predictive Risk Modeling und Chatbots vielversprechende Potenziale für die Soziale Arbeit bieten, bestehen erhebliche Risiken durch Algorithmen-Bias, Datenschutzproblematiken und die Gefahr der Automatisierung sozialer Exklusion, insbesondere wenn KI zu Kosteneinsparungen statt professioneller Unterstützung eingesetzt wird.",
    "data_basis": "Sekundäranalyse: Review von wissenschaftlichen Studien, Praxisbeispielen und Pilotprojekten (Neuseeland, Niederlande, klinisch-psychologische Settings); keine primäre Datenerhebung"
  },
  "arguments": [
    "KI ist ein interdisziplinäres und heterogenes Feld, das von enger spezialisierter KI bis zu genereller KI reicht; aktuelle Anwendungen basieren meist auf Machine Learning, Deep Learning und neuronalen Netzwerken, die eigenständig lernen und sich optimieren, aber eine 'Black-Box'-Charakteristik aufweisen, die Nachvollziehbarkeit erschwert.",
    "Predictive Risk Modeling in der Sozialen Arbeit (insbesondere Kindesschutz) verspricht Risikovorhersagen, reproduziert aber strukturelle Ungleichheiten und bestehende Biase der Trainingsdaten, während gleichzeitig reflexive Professionalität gefährdet wird und Datenschutzprobleme entstehen (function creeping, nationale Datenvernetzung).",
    "Chatbots zeigen hohe Akzeptanz und Engagement bei Nutzer:innen und könnten Beratung und Fallrekonstruktion unterstützen, dürfen aber menschliche Beziehungsarbeit nicht ersetzen und werfen Fragen zu Datensicherheit, digitaler Exklusion und der neo-liberalen Instrumentalisierung von Technologie zur Sparmaßnahmen auf.",
    "Die zentrale Problematik liegt nicht in der Technologie selbst, sondern in deren managerialisierter Nutzung im Kontext ökonomisierter Wohlfahrtsstaatlichkeit und der unzureichenden ethischen Reflexion sowie Verantwortungszumessung bei KI-gestützten Entscheidungen, die vulnerable Bevölkerungsgruppen betreffen."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Paper bietet umfassende Begriffserklärungen zu KI-Technologien (Algorithmen, Machine Learning, neuronale Netzwerke, Deep Learning) und diskutiert notwendiges Verständnis für Fachkräfte in der Sozialen Arbeit: 'Um einen groben Einblick in die Funktionsweise aktueller KI-Technologien zu geben, werden im folgenden Abschnitt einige zentrale Begriffe kurz dargestellt'",
    "KI_Sonstige": "Ausführliche Behandlung von Predictive Risk Modeling und Algorithmen im sozialen Bereich: 'Predictive Modelling soll im sozialen Bereich datenbasierte Vorhersagen mittels Algorithmen über menschliches Verhalten und Entwicklung treffen'; Analyse von Machine Learning und neuronalen Netzwerken in Entscheidungsunterstützungssystemen",
    "Soziale_Arbeit": "Direkter Fokus auf KI-Anwendungen in Sozialer Arbeit: Kindesschutz, Beratung, Fallrekonstruktion; kritische Analyse zweier Anwendungsszenarien (PRM und Chatbots) und deren Auswirkungen auf professionelle Praxis und Klient:innen",
    "Bias_Ungleichheit": "Explizite Thematisierung von Algorithmen-Bias: 'die eingesetzten Algorithmen selbst sind mitnichten neutral, sondern bilden oftmals ungerechte Lebensbedingungen ab und drohen diese durch ihren Bias zu verstetigen'; Warnung vor 'automatisierter sozialer Exklusion durch Algorithmen' und Risiken für vulnerable Bevölkerungsgruppen",
    "Diversitaet": "Reflexion von Differenzen und Vulnerabilität: Fokus auf unterschiedliche Lebenssituationen, marginalisierte Gruppen (Armutspopulationen, Kinder in Gefährdungssituationen), Jugendliche mit chronischen Erkrankungen; Warnung vor technologischer Exklusion: 'Chatbots können Personen nicht zur Kommunikation animieren, die nicht an Hilfe interessiert sind'",
    "Fairness": "Diskussion von Fairness in algorithmischen Entscheidungssystemen: Potenzial zur Verminderung von 'practitioner bias' durch Standardisierung, aber gleichzeitige Gefahr der Reproduktion bestehender Ungerechtigkeiten; Qualität und Vollständigkeit von Trainingsdaten als Voraussetzung für faire Prädiktionen"
  },
  "references": [
    {
      "author": "Eubanks",
      "year": 2018,
      "short_title": "Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor"
    },
    {
      "author": "Gillingham",
      "year": 2016,
      "short_title": "Predictive Risk Modelling to Prevent Child Maltreatment"
    },
    {
      "author": "Oak",
      "year": 2016,
      "short_title": "A Minority Report for Social Work? PRM and Tuituia Assessment Framework"
    },
    {
      "author": "Keymolen & Broeders",
      "year": 2013,
      "short_title": "Innocence Lost: Care and Control in Dutch Digital Youth Care"
    },
    {
      "author": "de Haan & Connolly",
      "year": 2014,
      "short_title": "Another Pandora's Box? Predictive Risk Modeling"
    },
    {
      "author": "Schneider & Seelmeyer",
      "year": 2019,
      "short_title": "Challenges in Using Big Data for Decision Support Systems in Social Work"
    },
    {
      "author": "Bendig et al.",
      "year": 2019,
      "short_title": "The Next Generation: Chatbots in Clinical Psychology and Psychotherapy"
    },
    {
      "author": "Jonas",
      "year": 1984,
      "short_title": "The Imperative of Responsibility: Ethics for the Technological Age"
    },
    {
      "author": "Steiner",
      "year": 2021,
      "short_title": "Social Work in the Digital Era: Theoretical, Ethical and Practical Considerations"
    },
    {
      "author": "Lenzen",
      "year": 2020,
      "short_title": "Künstliche Intelligenz: Fakten, Chancen, Risiken"
    }
  ],
  "assessment": {
    "domain_fit": "Sehr hohe Relevanz für die Schnittstelle KI und Soziale Arbeit. Das Paper bietet eine systematische Einführung in KI-Technologien speziell für Sozialarbeitende und analysiert konkrete Anwendungsszenarien kritisch. Besonders wertvoll ist die ethische Reflexion und die Warnung vor der neo-liberalen Instrumentalisierung von KI zur Kostenreduktion.",
    "unique_contribution": "Das Paper leistet einen wichtigen deutschsprachigen Beitrag zur kritischen Analyse von KI in der Sozialen Arbeit, indem es technische Grundlagen mit ethischer Reflexion verbindet und die Gefahren für vulnerable Gruppen sowie die Professionalisierung von Sozialer Arbeit zentral setzt, anstatt nur Optimierungspotenziale zu betonen.",
    "limitations": "Das Paper ist eine Literaturanalyse und Theoriereflexion ohne primäre empirische Datenerhebung; die Diskussion von Gender-Aspekten und intersektionalen Perspektiven bleibt unterentwickelt; Fokus liegt primär auf Kindesschutz und nicht auf andere Bereiche Sozialer Arbeit (z.B. Alter, Behinderung, Migration)."
  },
  "target_group": "Sozialarbeiter:innen, Fachkräfte in Wohlfahrtsorganisationen, Lehrende und Studierende der Sozialen Arbeit, Policy-Maker im Bereich Digitalisierung und Soziale Dienste, KI-Entwickler:innen im sozialen Sektor, sowie Ethiker:innen und Kritiker:innen von Technologisierung in Care-Arbeit"
}