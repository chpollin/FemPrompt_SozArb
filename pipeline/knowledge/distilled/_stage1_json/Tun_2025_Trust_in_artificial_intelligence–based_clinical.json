{
  "metadata": {
    "title": "Trust in Artificial Intelligence-Based Clinical Decision Support Systems Among Health Care Workers: Systematic Review",
    "authors": [
      "Hein Minn Tun",
      "Hanif Abdul Rahman",
      "Lin Naing",
      "Owais Ahmed Malik"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Welche Faktoren beeinflussen das Vertrauen von Gesundheitsfachkräften in KI-basierte klinische Entscheidungsunterstützungssysteme und wie können diese Systeme vertrauenswürdiger gestaltet werden?",
    "methodology": "Systematischer Review; Mixed Methods (16 qualitative, 6 quantitative, 5 mixed-method Studien); Cochrane Collaboration Handbook und PRISMA 2020; Literatursuche in PubMed, Scopus, Google Scholar (Januar 2020 - November 2024); CASP-Tool für Qualitätsbewertung",
    "key_finding": "Acht zentrale Themen prägen das Vertrauen von Gesundheitsfachkräften in AI-CDSSs: Systemtransparenz, Training und Vertrautheit, Usability, klinische Zuverlässigkeit, Glaubwürdigkeit und Validierung, ethische Überlegungen, Human-Centric Design und Customization mit Kontrolle. Algorithmische Intransparenz und unzureichendes Training gelten als Hauptbarrieren.",
    "data_basis": "27 eingeschlossene Studien; Sample-Größen von kleinen Fokusgruppen bis über 1000 Teilnehmer; überwiegend Krankenhaussettings; diverse Gesundheitsfachkräfte (Ärzte, Krankenschwestern, Apotheker, Spezialisten)"
  },
  "arguments": [
    "Vertrauen ist kein statisches Konzept, sondern entwickelt sich durch Interaktion und Erfahrung mit der Technologie; es erfordert drei Dimensionen: Glaube an Wahrheitsgehalt, Vertrauen in Commitments und Glaube an Kompetenz des Systems.",
    "Systemtransparenz und Erklärbarkeit sind zentral für Vertrauen; Kliniker benötigen Verständnis für die Funktionsweise des Systems, insbesondere die Rationale hinter Empfehlungen, um Vertrauen aufzubauen und algorithmen-induced Dehumanisierung zu vermeiden.",
    "Human-Centric Design mit Bewahrung von Kliniker-Autonomie und Einbeziehung aller Stakeholder (inkl. Patienten und Familien) ist essentiell; Customization für spezifische klinische Kontexte und ethische Überprüfung (Fairness, medizinisch-rechtliche Haftung) sind Erfolgsfaktoren."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Training and Familiarity als Schlüsselthema: 'highlighting the importance of knowledge sharing and user education' [Results]; Fokus auf Kliniker-Kompetenzen: 'Knowledge of AI' und 'Confidence in interpreting radiographs' als Einflussfaktoren [York et al].",
    "KI_Sonstige": "Breites KI-Spektrum behandelt: machine learning models, deep learning, reinforcement learning, large language models (ChatGPT); Klassifizierung, Prognose und Optimierungsalgorithmen; Fokus auf Clinical Decision Support Systems und deren algorithmische Funktionsweise.",
    "Bias_Ungleichheit": "Algorithmic bias und Fehler werden thematisiert: 'algorithmic bias' und 'false positives/negatives' als Vertrauensbarrieren; Diverse klinische Kontexte und Validierung in unterschiedlichen Settings erwähnt; jedoch keine explizite Analyse sozialer Ungleichheiten.",
    "Diversitaet": "Diverse Gesundheitsfachkräfte: 'diverse health care workers, predominantly in hospitalized settings' inkl. Ärzte, Krankenschwestern, Apotheker, Spezialisten verschiedener Disziplinen; Empfehlungen für 'diverse demographics, cross-cultural perspectives, and contextual differences in trust across various health care professions'.",
    "Fairness": "Ethical Consideration als eines von 8 Schlüsselthemen: 'examining medicolegal liability, fairness, and adherence to ethical standards'; Fairness in algorithmic performance across diverse contexts; Calibration und Performance-Konsistenz als Vertrauensfaktoren."
  },
  "references": [
    {
      "author": "Vereschak et al",
      "year": 2020,
      "short_title": "Theoretical elements of trust in human-AI systems (vulnerability, positive expectations, attitude)"
    },
    {
      "author": "Stacy et al",
      "year": 2024,
      "short_title": "QRhythm model for optimal rhythm management in atrial fibrillation"
    },
    {
      "author": "Sivaraman et al",
      "year": 2023,
      "short_title": "AI Clinician: Reinforcement learning for sepsis treatment recommendations"
    },
    {
      "author": "Burgess et al",
      "year": 2023,
      "short_title": "Healthcare AI treatment decision support design principles for clinician adoption"
    },
    {
      "author": "Liu et al",
      "year": 2023,
      "short_title": "Using ChatGPT to optimize clinical decision support alerts"
    },
    {
      "author": "Anjara et al",
      "year": 2023,
      "short_title": "Explainable AI for lung cancer relapse prediction using think-aloud protocols"
    },
    {
      "author": "Jones et al",
      "year": 2024,
      "short_title": "Multinational study on clinician control and liability in ophthalmology AI-CDSS"
    },
    {
      "author": "Nasarian et al",
      "year": 2024,
      "short_title": "Interpretable ML systems to enhance trust in healthcare and clinician-AI collaboration"
    },
    {
      "author": "Labkoff et al",
      "year": 2024,
      "short_title": "Recommendations for responsible AI-enabled clinical decision support"
    },
    {
      "author": "McKee & Wouters",
      "year": 2023,
      "short_title": "Challenges of regulating artificial intelligence in healthcare"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper hat mittlere Relevanz für die Schnittstelle KI/Soziale Arbeit: Der Fokus liegt auf klinische Gesundheitsberufe, nicht auf Soziale Arbeit; die Thematisierung von ethischen Überlegungen, Human-Centered Design, Diversität und Fairness sind jedoch übertragbar auf sozialpädagogische Kontexte und algorithmengestützte Entscheidungsfindung in Sozialen Diensten.",
    "unique_contribution": "Dieses systematische Review bietet die erste umfassende Synthese von 27 Studien zu acht zentralen Vertrauensfaktoren in AI-CDSSs und liefert konkrete, umsetzbare Empfehlungen für die Gestaltung von Systemen, die klinisches Vertrauen fördern, statt es zu untergraben.",
    "limitations": "Heterogenität der Studiendesigns und Mangel an spezifischen Vertrauensmessdaten begrenzen Meta-Analyse; Fokus auf Krankenhaussettings mit Überrepräsentation westlicher Länder; keine Analyse geschlechtsspezifischer oder intersektionaler Vertrauensunterschiede."
  },
  "target_group": "KI-Entwickler und Health Tech-Unternehmen, Kliniker und Gesundheitsadministratoren, Policymaker im Healthcare, Forscher im Bereich Human-AI Interaction, Health Informatics Profis, indirekt relevant für Sozialarbeiter in digitalisierten Entscheidungskontexten"
}