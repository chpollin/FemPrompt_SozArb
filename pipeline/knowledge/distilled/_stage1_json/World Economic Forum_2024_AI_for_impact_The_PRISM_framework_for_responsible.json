{
  "metadata": {
    "title": "AI for Impact: The PRISM Framework for Responsible AI in Social Innovation",
    "authors": [
      "World Economic Forum",
      "EY",
      "Microsoft",
      "Schwab Foundation for Social Entrepreneurship"
    ],
    "year": 2024,
    "type": "report",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können soziale Innovatoren künstliche Intelligenz verantwortungsvoll und effektiv für soziale Auswirkungen integrieren?",
    "methodology": "Mixed-Methods: Empirisch (Analyse von über 300 sozialen Innovatoren, 22 tiefgehende Interviews, interaktive Workshops) kombiniert mit Literaturanalyse und Best-Practice-Synthese",
    "key_finding": "Das PRISM Framework bietet einen iterativen, schichtenweisen Ansatz zur verantwortungsvollen KI-Einführung, der Organisationsbereitschaft über technologische Fähigkeit priorisiert und fünf kritische Capabilites and Risks (Ethics, Data, Business/Organization, Technology, Costs/Metrics) identifiziert.",
    "data_basis": "n=300+ Soziale Innovatoren (April 2024 Vorgängerstudie), 22 tiefgehende Interviews, mehrere interaktive Workshops mit Sozialunternehmen und Tech-Führungskräften"
  },
  "arguments": [
    "Soziale Innovatoren müssen mit niedrig-komplexen, niedrig-kostigen KI-Anwendungen beginnen und iterativ vorgehen, nicht mit großangelegten technologischen Implementierungen starten, um Risiken zu minimieren und Erfolg zu maximieren.",
    "Ethische Überlegungen (Fairness, Bias-Vermeidung, Transparenz, Accountability) sind kritisch für soziale Innovatoren, die mit vulnerablen und marginalisierten Gruppen arbeiten, da kommerzielle KI-Modelle oft mit Daten aus wohlhabenden Ländern trainiert wurden und lokale Kontexte nicht adäquat abbilden.",
    "Technology Leaders müssen aktiv mit sozialen Innovatoren zusammenarbeiten, um Transparenz, Explainability und Fairness in KI-Systemen zu verbessern, da proprietäre Modelle (ChatGPT, Gemini) den Zugang zu Algorithmen blockieren und ethische Implementierung erschweren."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": true,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Das gesamte PRISM Framework adressiert 'organizational readiness' und Kompetenzaufbau: 'The framework encourages organizations to start with low-risk, low-cost AI applications and stresses the importance of organizational readiness over mere technological capability.' Kapitel 2.3 behandelt Leadership Vision, Skills Development und Training Costs.",
    "Generative_KI": "Mehrfache Beispiele generativer KI-Nutzung: 'Dimagi built a tool based on Voice Engine, a new offering from the technology organization for the creation of custom voices, and ChatGPT-4' und Diskussion von proprietary Modellen wie ChatGPT und Gemini für Transparenzprobleme.",
    "KI_Sonstige": "Umfangreiche Abdeckung klassischer ML-Anwendungen: Predictive Analytics, Computer Vision (facial recognition), sentiment analysis, machine learning algorithms (MapBiomas), OCR-Tools für Digitalisierung.",
    "Soziale_Arbeit": "Fokus auf soziale Innovatoren und deren Arbeit mit vulnerablen Populationen: 'As social innovators often work with vulnerable and marginalized groups, this is one of the key considerations.' Beispiele: SAS Brasil (Gesundheit), High Resolves (Bildung), LifeBank (Gesundheitssystem), Haqdarshak (ökonomische Empowerment), Recode (digitale Inklusion in Slums).",
    "Bias_Ungleichheit": "Explizite Behandlung von Bias und struktureller Ungleichheit: 'AI is a mirror reflecting the data fed into it. When the reflection is distorted by biased data, the outcomes can perpetuate societal disparities.' Geographische Disparitäten: 'most commercially available models are trained on data from high-income countries, delivering sub-par results for low- and middle-income countries.' Gender Gap: 'just 25% of women-led social enterprises using AI compared to half in the broader sector.'",
    "Gender": "Explizite Geschlechterdisparität identifiziert: 'Gender disparities persist, with just 25% of women-led social enterprises using AI compared to half in the broader sector.' Figure 5 zeigt Verteilung nach Gründerinnen und CEO-Geschlecht.",
    "Diversitaet": "Betonung von Inklusivität und Repräsentation: 'to ensure that their AI systems act as lenses that correct, rather than amplify, biases' durch diverse Datenquellen. Geographische Diversität: 'There is no gap in implementation between low-/middle-income and high-income countries but a strong diversity in the sectors of implementation.' Adressierung marginalisierter Communities: Haqdarshak in Indien, RECODE in Brazil favelas, Swahili/Sheng-Sprachenunterstützung.",
    "Fairness": "Algorithmische Fairness ist zentrales Kapitel (2.1 Ethics): Fairness and avoiding bias, Transparenz, Accountability. Fairness-Metriken und -Frameworks werden diskutiert: 'In applications like facial recognition, where historical data may have underrepresented certain demographics, diverse data samples may need to be included.' Fairness als Schlüssel für vertrauenswürdige Systeme."
  },
  "references": [
    {
      "author": "Latanya Sweeney",
      "year": 2002,
      "short_title": "k-Anonymity: A model for protecting privacy"
    },
    {
      "author": "World Economic Forum AI Governance Alliance",
      "year": 2024,
      "short_title": "Presidio Framework"
    },
    {
      "author": "LIME Contributors",
      "year": 2016,
      "short_title": "Local Interpretable Model-Agnostic Explanations"
    },
    {
      "author": "OpenAI",
      "year": 2024,
      "short_title": "Navigating the Challenges and Opportunities of Synthetic Voices"
    },
    {
      "author": "MapBiomas",
      "year": 2023,
      "short_title": "Algorithm Theoretical Basis Document (ATBD)"
    },
    {
      "author": "Buolamwini & Gebru",
      "year": 2018,
      "short_title": "Gender Shades (implizit durch Facial Recognition Bias-Diskussion)"
    }
  ],
  "assessment": {
    "domain_fit": "Hochrelevant für KI/Soziale Arbeit/Gender-Schnittstelle: Das Paper adressiert direkt die Implementierung von KI in sozialwirtschaftlichen Organisationen mit explizitem Fokus auf ethische Gerechtigkeit, Bias-Vermeidung und Geschlechterparität. Es verbindet technische KI-Literatur mit Theorie und Praxis sozialer Innovation.",
    "unique_contribution": "Das PRISM Framework bietet einen praktischen, modularen Implementierungsrahmen spezifisch für soziale Innovatoren, der Organisationsbereitschaft priorisiert und die Klüfte zwischen Tech-Entwicklung und Impact-Organisationen in Global South/Middle Income Settings explizit adressiert.",
    "limitations": "Keine explizite feministische Theorieentwicklung; Gender ist quantitativ dokumentiert (25% vs. 50%), aber nicht tiefgehend analysiert. Keine explizite Intersektionalitätsanalyse. Methodische Gewichtung zwischen qualitativen Interviews und quantitativer Datenanalyse nicht vollständig transparent."
  },
  "target_group": "Soziale Innovatoren, Sozialunternehmer:innen, Nonprofit-Führungskräfte, KI-Entwickler:innen mit Social-Impact-Fokus, Policymaker im Bereich digitale Inklusion, internationale Entwicklungsorganisationen, Tech-Ethics-Praktiker:innen, Diversity & Inclusion Officer in Tech-Unternehmen"
}