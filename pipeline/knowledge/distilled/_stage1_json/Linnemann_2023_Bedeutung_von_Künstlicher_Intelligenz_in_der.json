{
  "metadata": {
    "title": "Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)",
    "authors": [
      "Gesa Alena Linnemann",
      "Julian Löhe",
      "Beate Rottkemper"
    ],
    "year": 2023,
    "type": "journalArticle",
    "language": "de"
  },
  "core": {
    "research_question": "Welche Implikationen und Chancen sowie Risiken ergeben sich aus dem Einsatz von Natural Language Processing (NLP) für die Praxis und Profession der Sozialen Arbeit in verschiedenen Handlungsfeldern?",
    "methodology": "Theoretisch-konzeptionell: Systematische Analyse unter Anwendung von Staub-Bernasconis Handlungstheorie, Uses-and-Gratification-Ansatz und Media Equation Theory; exemplarische Betrachtung verschiedener Handlungsfelder (Beratung, Kinder- und Jugendhilfe, Altenhilfe); Analyse von Praxisprojekten.",
    "key_finding": "NLP bietet sowohl Chancen (niederschwelliger Zugang, Teilhabe, erweiterte Wissensbasis) als auch erhebliche Risiken (Modularisierung der Profession, Reproduktion von Stereotypen und Diskriminierung, ethische Probleme) für die Soziale Arbeit; ein kritisch begleiteter Einsatz unter Wahrung von Menschenrechten und Transparenz ist erforderlich.",
    "data_basis": "Keine empirischen Daten; Analyse von bestehenden Projekten (Caritas 'Lernende Systeme in der Beratung', MAEWIN, CASoTex, KiJuAssistenz) und theoretischer Literatur"
  },
  "arguments": [
    "NLP ist für die Soziale Arbeit von besonderer Relevanz, da kommunikative Prozesse fundamental für die Praxis sind; zugleich berührt der Einsatz von KI alle drei Mandate der Profession (Gesellschaft, Klient*innen, Profession selbst) nach Staub-Bernasconi.",
    "Chatbots und Sprachassistenten können niederschwellige Erstkontakte ermöglichen und Gratifikationen wie Verfügbarkeit, Interaktivität und Autonomie bieten, müssen aber transparent gemacht werden und dürfen persönliche Beratung nicht ersetzen.",
    "Algorithmische Entscheidungssysteme (Predictive Analytics, Entscheidungsunterstützung) können Wissensbasis erweitern und Effizienz erhöhen, erfordern aber kritische Kompetenz von Fachkräften und bergen Risiken der Diskriminierung, Bias-Reproduktion und Modularisierung genuiner Sozialarbeitsleistungen."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Ausdrückliche Betonung der Notwendigkeit von Fachkompetenz: 'Fachkräfte müssen dazu befähigt werden, diese Wahrscheinlichkeiten zu interpretieren' und 'Es ist essenziell für den Einsatz von Entscheidungsunterstützungssystemen in der Praxis, dass transparent gemacht wird, mit welcher Wahrscheinlichkeit ein Ergebnis passend ist.'",
    "Generative_KI": "Explizite Diskussion von GPT-3 und ChatGPT: 'Das im Jahr 2020 veröffentlichte OpenAI GPT-3 nutzt DeepLearning-Applikationen und ist in der Lage, anhand von wenigen Input-Parametern qualitativ hochwertige Texte zu generieren' sowie 'ChatGPT' mit Verweis auf dessen Bestehen einer Jura-Prüfung 2023.",
    "KI_Sonstige": "Umfassende Behandlung von Natural Language Processing, Machine Learning, Deep Learning, Künstlichen Neuronalen Netzwerken und Predictive Analytics als zentrale Technologien.",
    "Soziale_Arbeit": "Expliziter Fokus auf alle Handlungsfelder: 'In verschiedenen Handlungsfeldern der Sozialen Arbeit wird der Einfluss von NLP exemplarisch dargestellt'; Analyse von Kinder- und Jugendhilfe, Altenhilfe, Beratung; Referenz zu Staub-Bernasconis Konzept der Menschenrechtsprofession.",
    "Bias_Ungleichheit": "Warnung vor Reproduktion von Diskriminierung: 'stereotype Rollenbilder wiederholt werden' und 'Ohne interdisziplinäre Teams in der Entwicklung von Werkzeugen, die NLP nutzen, besteht die Gefahr der Reproduktion von Diskriminierung und sogar weiterer Radikalisierung'.",
    "Diversitaet": "Thematisierung marginalisierter Gruppen durch NLP und Sprachassistenz: besondere Betrachtung älterer Menschen, von Einsamkeit betroffener Menschen, weniger digital affiner Hilfesuchender: 'grundsätzlich darf die digitale Kontaktaufnahme nicht die ausschließliche Form des Erstkontakts sein, da sonst weniger digital affine Hilfesuchende nicht mehr erreicht werden.'",
    "Fairness": "Explizite Forderung nach Fairness im Sinne der Menschenrechte: 'Im Bereich NLP sind insbesondere das Verbot von Diskriminierung, der Schutz der Freiheitssphäre des Einzelnen und die Meinungs- und Informationsfreiheit zu beachten.'"
  },
  "references": [
    {
      "author": "Staub-Bernasconi",
      "year": 2018,
      "short_title": "Soziale Arbeit als Handlungswissenschaft"
    },
    {
      "author": "Staub-Bernasconi",
      "year": 2007,
      "short_title": "Soziale Arbeit: Dienstleistung oder Menschenrechtsprofession"
    },
    {
      "author": "Nass & Brave",
      "year": 2005,
      "short_title": "Media Equation Theory"
    },
    {
      "author": "Russell & Norvig",
      "year": 2021,
      "short_title": "Artificial Intelligence: A Modern Approach"
    },
    {
      "author": "OpenAI",
      "year": 2020,
      "short_title": "GPT-3 Language Model"
    },
    {
      "author": "Beranek, Hill & Sagebiel",
      "year": 2019,
      "short_title": "Digitalisierung und Soziale Arbeit - Diskursüberblick"
    },
    {
      "author": "Schneider & Seelmeyer",
      "year": 2019,
      "short_title": "Challenges in Using Big Data for Decision Support Systems in Social Work"
    },
    {
      "author": "Lucy & Bamman",
      "year": 2021,
      "short_title": "Gender and Representation Bias in GPT-3 Generated Stories"
    },
    {
      "author": "McGuffie & Newhouse",
      "year": 2020,
      "short_title": "Radicalization Risks of GPT-3"
    },
    {
      "author": "Fellmann et al.",
      "year": 2020,
      "short_title": "Digitalisierung personennaher Dienstleistungen in der Kinder- und Jugendhilfe"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI und Soziale Arbeit: Das Paper bietet eine systematische, theoretisch fundierte Analyse des Einsatzes von NLP in verschiedenen sozialarbeiterischen Handlungsfeldern und diskutiert explizit die Spannung zwischen technologischen Chancen und professionalen sowie ethischen Standards der Menschenrechtsprofession.",
    "unique_contribution": "Das Paper leistet einen seltenen deutschsprachigen, systématischen Beitrag zur KI-Ethik in der Sozialen Arbeit, indem es NLP-Technologien nicht abstrakt, sondern feldspezifisch (Beratung, Altenhilfe, Kinder- und Jugendhilfe) durch die Linse von Staub-Bernasconis Tripelmandat analysiert und sowohl Chancen als auch strukturelle Risiken der Professionalisierung adressiert.",
    "limitations": "Das Paper ist rein konzeptionell-theoretisch ohne empirische Validierung der postulierten Chancen und Risiken in der Praxis; die Analyse von Gender-Bias bleibt oberflächlich und nutzt nicht explicitly feministische Theorien, obwohl Geschlechterdimensionen (insbesondere bei GPT-3 Bias) vorhanden sind."
  },
  "target_group": "Primär: Sozialarbeiter*innen, Lehrende in Sozialer Arbeit, Fachkräfte in Beratung, Kinder- und Jugendhilfe sowie Altenhilfe; Sekundär: KI-Ethiker*innen, Policymaker im Sozialwesen, Studierende der Sozialen Arbeit und angrenzender Disziplinen"
}