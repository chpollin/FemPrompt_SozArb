{
  "metadata": {
    "title": "Diskriminierung durch Algorithmen – Überlegungen zur Stärkung KI-bezogener Kompetenzen",
    "authors": [
      "Laura Sūna",
      "Dagmar Hoffmann",
      "Anne Mollen"
    ],
    "year": 2024,
    "type": "book",
    "language": "de"
  },
  "core": {
    "research_question": "Wie können digital benachteiligte Gruppen für algorithmische Diskriminierung sensibilisiert und zu einem kompetenten Umgang mit KI-Systemen ermächtigt werden?",
    "methodology": "Theoretisch-konzeptionell mit Integration empirischer Befunde aus Studien (qualitative Fokusgruppen mit 25 Personen mit Migrationsgeschichte, sowie Sekundäranalyse bestehender Forschungsliteratur)",
    "key_finding": "KI-bezogene Kompetenzen müssen drei Dimensionen umfassen (kognitiv, affektiv, handlungsbezogen), um algorithmen-basierte Diskriminierung zu erkennen und zu adressieren. Es besteht ein erhebliches Kompetenzdefizit und eine 'digitale Resignation' bei betroffenen Gruppen.",
    "data_basis": "Qualitative Studie: 25 Personen mit Migrationsgeschichte in 5 Fokusgruppen; Sekundärliteratur und Meta-Analysen bestehender Studien (MeMo:Ki 2021, Schober et al. 2022, Bozdag 2022)"
  },
  "arguments": [
    "Algorithmische Systeme reproduzieren und verstärken bestehende strukturelle Ungleichheiten durch drei ineinander greifende Mechanismen: verzerrte Trainingsdaten (Sample Bias), diskriminierende algorithmische Modelle (Proxy-Variablen), und diskriminierende Anwendung durch Automation Bias bei Entscheidungsträgern.",
    "Nutzer:innen, insbesondere aus marginalisierten Gruppen, nehmen algorithmische Diskriminierung oft nicht oder nur fragmentarisch wahr und entwickeln eine 'digitale Resignation', die ihre Handlungsfähigkeit einschränkt, während ihnen gleichzeitig Zugang zu den sie betreffenden Daten und Entscheidungskriterien fehlt.",
    "Medienmediopädagogische Arbeit auf drei Ebenen (informieren, sensibilisieren, ermächtigen) mit Fokus auf KI-Kompetenzen ist notwendig, muss aber durch regulatorische Anpassungen (AGG-Weiterentwicklung) und zivilgesellschaftliche Strukturen flankiert werden, um Betroffene nicht allein zu lasten."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "KI-bezogene Kompetenzen umfassen: 'das Bewusstsein und die Wahrnehmung der Allgegenwärtigkeit von algorithmen-basierten und KI-getriebenen Prozessen' sowie 'die Fähigkeit, KI-geprägte Entscheidungen kritisch und affektiv zu bewerten und zu hinterfragen'. Gefordert wird 'umfassende medienpädagogische Arbeit' auf allen Lebensbereichen.",
    "KI_Sonstige": "Fokus auf algorithmen-basierte Entscheidungssysteme, Empfehlungsalgorithmen, maschinelles Lernen und automatisierte Klassifikationssysteme in verschiedenen Anwendungsbereichen (Bildung, Arbeitsmarkt, Gesundheit, Justiz, predictive policing).",
    "Soziale_Arbeit": "Zielgruppen sind Menschen mit Migrationsgeschichte, im höheren Lebensalter, mit niedrigem Bildungsniveau – klassische Adressaten Sozialer Arbeit. Kontext: 'Zugang zu Sozialleistungen' als besonders anfälliger Bereich. Beratungsstrukturen und zivilgesellschaftliche Unterstützungsangebote werden als notwendig erachtet.",
    "Bias_Ungleichheit": "Zentrale These: 'diverse KI-basierte Systeme reproduzieren und verstärken Ungleichheit und Exklusion'. 'Strukturelle Ungleichheiten von Algorithmen werden teils sogar überbetont'. Spezifische Analyse von Mechanismen wie Sample Bias, Proxy-Variablen und Skalierungseffekten der Diskriminierung.",
    "Diversitaet": "Expliziter Fokus auf marginalisierte Gruppen: 'Gruppen, die von (digitaler) Ungleichheit besonders betroffen sind, wie beispielsweise Migrant*innen, Frauen, Menschen im höheren Lebensalter oder mit niedrigem Bildungsniveau'. Intersektionale Perspektive: 'Diskriminierung kann aus der Kombination unterschiedlicher geschützter Merkmale entstehen'.",
    "Fairness": "Algorithmen-basierte Diskriminierung wird als Fairness-Problem konzeptualisiert. 'Nutzer*innen werden aufgrund ihrer persönlichen Daten [...] ungerecht, unethisch oder einfach nur anders behandelt'. Fairness erfordert kritische Bewertung, Transparenz und Verantwortlichkeit von Systemen."
  },
  "references": [
    {
      "author": "AlgorithmWatch.Ch",
      "year": 2023,
      "short_title": "Positionspapier - Schutz vor algorithmischer Diskriminierung"
    },
    {
      "author": "Sūna, Laura & Hoffmann, Dagmar",
      "year": 2024,
      "short_title": "From AI imaginaries to AI literacy: Artificial intelligence technologies in everyday lives of migrants in Germany"
    },
    {
      "author": "Rentsch, Susanne",
      "year": 2023,
      "short_title": "'Computer sagt nein' - Gesellschaftliche Teilhabe und strukturelle Diskriminierung im Zeitalter Künstlicher Intelligenz"
    },
    {
      "author": "Criado, Natalia & Such, Jose M.",
      "year": 2019,
      "short_title": "Digital Discrimination"
    },
    {
      "author": "Lopez, Paola",
      "year": 2021,
      "short_title": "Diskriminierung durch Data Bias"
    },
    {
      "author": "Schober, Maximilian et al.",
      "year": 2022,
      "short_title": "'Was ich like, kommt zu mir.' Kompetenzen von Jugendlichen im Umgang mit algorithmischen Empfehlungssystemen"
    },
    {
      "author": "Bozdag, Çigdem",
      "year": 2022,
      "short_title": "Inclusive Media Education in the Diverse Classroom"
    },
    {
      "author": "Gruber, Jonathan & Hargittai, Eszter",
      "year": 2023,
      "short_title": "The importance of algorithm skills for informed Internet use"
    },
    {
      "author": "Heesen, Jessica, Reinhardt, Karoline & Schelenz, Laura",
      "year": 2021,
      "short_title": "Diskriminierung durch Algorithmen vermeiden"
    },
    {
      "author": "Kalogeropoulos, Elena et al.",
      "year": 2021,
      "short_title": "Wegweiser Digitale Debatten. Teil 2: Algorithmenvermittelte Diskriminierung"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper ist hochrelevant für die Schnittstelle KI/Soziale Arbeit/Diversität: Es adressiert vulnerable Gruppen (Migrant:innen, ältere Menschen, bildungsferne Personen), analysiert systematisch Diskriminierungsmechanismen in KI-Systemen und entwickelt einen medienpädagogischen Ansatz zur Befähigung betroffener Gruppen zu gesellschaftlicher Teilhabe.",
    "unique_contribution": "Der Beitrag verbindet Diskriminierungsanalyse (drei Ebenen: Daten, Modell, Anwendung) mit KI-Kompetenzentwicklung in einem dreidimensionalen Modell (kognitiv-affektiv-handlungsbezogen) und betont die Notwendigkeit von regulatorischer und zivilgesellschaftlicher Flankierung neben Medienpädagogik.",
    "limitations": "Empirische Basis auf relativ kleine qualitative Stichprobe (n=25) beschränkt; fehlende Evaluationen konkreter Interventionen zur Kompetenzteilung; begrenzte Analyse von Systemebenen-Lösungen jenseits individueller Kompetenzen."
  },
  "target_group": "Medienpädagog:innen, Sozialarbeiter:innen, Policymaker im Bereich Antidiskriminierung und Digitalisierung, Fachkräfte in der Arbeit mit migrierten und prekären Zielgruppen, KI-Ethik-Expert:innen, Interessensvertreter:innen marginalisierter Gruppen"
}