{
  "metadata": {
    "title": "Inclusive Prompt Engineering: A Methodology for Hacking Biased AI Image Generation",
    "authors": [
      "Rachel Skilton",
      "Alison Cardinal"
    ],
    "year": 2024,
    "type": "conferencePaper",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können Content Designer und technische Kommunikatoren strategisch Prompt Engineering einsetzen, um verzerrte KI-Bildgeneratoren zu umgehen und vielfältige, inklusive visuelle Darstellungen zu erzeugen?",
    "methodology": "Mixed Methods: Empirisch (systematische Experimente mit DALL-E durch iterative Prompt-Manipulation) kombiniert mit theoretischer Analyse der zugrundeliegenden Bias-Mechanismen; Zero-Shot Prompting zur Identifikation von Basis-Bias-Mustern.",
    "key_finding": "DALL-E betreibt sogenannte 'Toxic Positivity', die durch Content-Filter verursacht wird und dazu führt, dass der KI-Generator bei der Darstellung menschlicher Subjekte standardmäßig zu jungen, dünnen, schönen und weißen Menschen greift. Durch iteratives Prompt Engineering mit positiver Umformulierung von sensiblen Begriffen können Nutzer diese Verzerrungen umgehen und vielfältigere Darstellungen erhalten.",
    "data_basis": "Qualitativ: Umfangreiche Experimente mit DALL-E Image Generator; systematische Analyse von generierten Prompts und visuellen Outputs; Case Studies zu Begriffen wie 'low income', Alter und Körpermerkmalen."
  },
  "arguments": [
    "Content-Moderations-Filter in KI-Bildgeneratoren führen unbeabsichtigt zu rassistischen und ageistischen Outputs, indem sie vermeintlich negative Begriffe wie 'arm', 'alt' oder 'übergewichtig' mit negativen Konnotationen verbinden und dadurch Stereotypen verstärken, anstatt sie zu bekämpfen.",
    "Durch systematisches Prompt Engineering, insbesondere durch positive Umformulierung sensibler Begriffe und iterative Anpassung basierend auf dem von der KI zurückgegebenen Prompt, können Designer die toxische Positivität umgehen und authentische Repräsentationen menschlicher Vielfalt erzeugen.",
    "Technische und professionelle Kommunikation als Disziplin hat die Verantwortung und Expertise, Praktiker und Lernende in der kritischen Analyse und ethischen Nutzung von emergenten KI-Technologien zu schulen, um strukturelle Ungleichheiten zu adressieren."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": true,
    "KI_Sonstige": false,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "As a field that has historically addressed the social impact of visual content and has provided strategies for analyzing user interfaces, the field [of technical and professional communication] is poised to provide guidance to practitioners and scholars alike on how to analyze and use these technology tools. [...] we offer a methodology [...] for content designers and students for how to use them.",
    "Generative_KI": "With the emergent and rapidly expanding use cases of images created with AI image generators such as Midjourney, DALL-E, and Adobe Firefly [...] Through a series of prompt engineering practices, we show how users can bypass this toxic positivity to create images that better demonstrate the diversity of humanity.",
    "Prompting": "Through what we call 'toxic positivity,' DALL-E attempts to avoid negative stereotypes by defaulting to the 'least offensive' images. [...] Through a series of prompt engineering practices [...] we alter sections that misrepresent the subject. Through continued refining, we arrive at an image more aligned with our intended inclusive result.",
    "Bias_Ungleichheit": "AI image generators are known to create biased images [...] often defaulting to generating white men when asked to create images of humans without explicit direction. [...] what is considered an offensive stereotype is not clearly stated by the system in the list of restricted content. [...] the output is worse than intended. DALL-E's model reinforces the idea that disability, especially as it shows up in a person's body or physical appearance, is inherently negative.",
    "Diversitaet": "Our goal in this method is to help designers and technical communicators produce visuals that accurately reflect the diverse range of human experiences, including variations in age, body type, ethnicity, and gender. [...] we aim to counteract overly 'positive' and limited representations of humanity in AI-generated images.",
    "Fairness": "The intention of the user ultimately dictates how the program is used regardless of safeguards put in place. [...] By intentionally crafting prompts, we aim to counteract overly 'positive' and limited representations of humanity in AI-generated images."
  },
  "references": [
    {
      "author": "Walton, Moore, and Jones",
      "year": 2019,
      "short_title": "Technical Communication After the Social Justice Turn: Building Coalitions for Action"
    },
    {
      "author": "Benjamin, Ruha",
      "year": 2019,
      "short_title": "Race after technology: Abolitionist tools for the new Jim code"
    },
    {
      "author": "Wachter-Boettcher, Safiya",
      "year": 2017,
      "short_title": "Technically wrong: Sexist apps, biased algorithms, and other threats of toxic tech"
    },
    {
      "author": "Bolukbasi et al.",
      "year": 2016,
      "short_title": "Man is to computer programmer as woman is to homemaker?: Debiasing word embeddings"
    },
    {
      "author": "Bailey, A.H. et al.",
      "year": 2022,
      "short_title": "Based on billions of words on the internet, people = men"
    },
    {
      "author": "Haas, Angela M.",
      "year": 2012,
      "short_title": "Race, rhetoric, and technology: A case study of decolonial technical communication theory, methodology, and pedagogy"
    },
    {
      "author": "Jones, N.N. and Williams, M.F.",
      "year": 2018,
      "short_title": "Technologies of disenfranchisement: Literacy tests and black voters in the US from 1890 to 1965"
    },
    {
      "author": "Goodman, Wendy",
      "year": 2022,
      "short_title": "Toxic Positivity: Keeping it real in a world obsessed with being happy"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper adressiert die Schnittstelle zwischen KI-Literacies, Generative KI und Fragen sozialer Gerechtigkeit, insbesondere Bias und Diversität. Allerdings hat es keinen direkten Bezug zu Sozialer Arbeit als Praxis oder deren spezifischen Zielgruppen, sondern fokussiert auf Technical and Professional Communication und Content Design.",
    "unique_contribution": "Das Paper leistet einen innovativen praktischen Beitrag durch die Entwicklung einer systematischen Methodology (Inclusive Prompt Engineering), die Praktiker befähigt, strukturelle Bias in generativen KI-Systemen zu erkennen und durch iteratives Prompting zu umgehen, statt nur die Probleme zu beschreiben.",
    "limitations": "Die Forschung ist auf DALL-E beschränkt; es werden keine quantitativen Messungen der Bias-Reduktion durchgeführt; die Skalierbarkeit der Methode auf andere KI-Systeme oder Domänen wird nicht systematisch überprüft; keine Evaluation durch Nutzer aus marginalisierten Gruppen."
  },
  "target_group": "Content Designer, Technical und Professional Communicators, Hochschul-Lehrende in Design- und Kommunikationsprogrammen, Praktiker in Marketing und UX, sowie KI-Nutzer, die sich ethischer und inklusiver Bildgenerierung verpflichtet sehen; potenziell auch Policy-Maker und KI-Entwickler bei OpenAI und ähnlichen Unternehmen."
}