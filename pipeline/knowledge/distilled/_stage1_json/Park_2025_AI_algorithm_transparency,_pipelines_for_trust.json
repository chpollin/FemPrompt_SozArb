{
  "metadata": {
    "title": "AI algorithm transparency, pipelines for trust not prisms: mitigating general negative attitudes and enhancing trust toward AI",
    "authors": [
      "Keonyoung Park",
      "Ho Young Yoon"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie kann Transparenz von KI-Algorithmen negative Einstellungen gegenüber KI abschwächen und Vertrauen in KI-Systeme und ihre Unternehmen erhöhen?",
    "methodology": "Empirisch: Online-Experiment mit 2x2 zwischen-Subjekt-Design (AI-Algorithmen-Transparenz: Hoch vs. Niedrig × Issue-Involvement: Hoch vs. Niedrig); hierarchische Regressionsanalysen und PROCESS Macro Model 3 für moderierte Moderationseffekte; n=1059 Teilnehmer.",
    "key_finding": "Algorithmen-Transparenz vermindert signifikant die negative Beziehung zwischen allgemeiner negativer Einstellung gegenüber KI und Vertrauen in das Mutterunternehmen, besonders bei hohem Issue-Involvement. Transparenz funktioniert als Signalisierungsmechanismus für Organisationsverantwortung und nicht nur als Prism-Modell der Reputation.",
    "data_basis": "n=1059 Online-Umfrage-Teilnehmer, 2x2 experimentelles Design, Datenerhebung 29. Oktober bis 5. November 2023"
  },
  "arguments": [
    "Allgemeine negative Einstellungen gegenüber KI entstehen aus Besorgnis über Unkontrollierbarkeit und unvorhersehbare Folgen von KI-Systemen; diese negativen Einstellungen untergraben das Vertrauen in KI-Systeme und ihre Betreiber-Unternehmen.",
    "Das klassische Prism-Modell von Vertrauensaufbau (basierend auf Unternehmensreputation) ist für KI-Systeme unzureichend, da algorithmische Opazität und Informationsasymmetrien Skepsis erzeugen, besonders bei unbekannten Unternehmen; ein Pipeline-Modell durch Transparenz ist notwendig.",
    "Transparenz wirkt als direkter Pipeline-Effekt, der Wissen und Verständnis fördert, und signalisiert zugleich Organisationsverantwortlichkeit; bei hohem Issue-Involvement verstärkt sich dieser Effekt signifikant, wie das Elaboration Likelihood Model vorhersagt."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Die Studie untersucht, wie Transparenz von KI-Algorithmen das Wissen und Verständnis von Nutzern fördert: 'transparency can reduce uncertainty and enhance trust in AI systems' und 'transparency serves as a strategic tool to reduce uncertainty and enhance knowledge'.",
    "Generative_KI": "Expliziter Fokus auf generative KI wie ChatGPT: 'Given the growing importance of generative AI such as ChatGPT in stakeholder communications' und 'The integration of generative artificial intelligence (AI) with chatbots such as ChatGPT, is becoming increasingly prevalent'.",
    "KI_Sonstige": "Umfassende Behandlung algorithmischer Entscheidungssysteme: 'algorithmic systems may reinforce biases' und Analyse von Vertrauensdynamiken in KI-Systemen generell.",
    "Bias_Ungleichheit": "Adressiert algorithmische Verzerrungen und deren gesellschaftliche Auswirkungen: 'Recent studies have pointed out how algorithmic systems may reinforce biases or even spur radicalization' und 'promoting an inclusive approach to AI adoption that avoids technological disparity'.",
    "Diversitaet": "Berücksichtigung unterschiedlicher Stakeholder-Gruppen und Zugangsbarrieren: 'varying attitudes toward AI' und 'support ethical AI integration across diverse contexts'; Fokus auf inklusive KI-Adoption.",
    "Fairness": "Implizit adressiert durch Fokus auf Transparenz als Fairness-Mechanismus: 'transparency not only fosters understanding but also acts as a signaling mechanism for organizational accountability' und Engagement mit Konzepten von Vertrauenswürdigkeit und Integrität."
  },
  "references": [
    {
      "author": "Podolny",
      "year": 2001,
      "short_title": "Networks as the pipes and prisms of the market"
    },
    {
      "author": "Petty & Cacioppo",
      "year": 1981,
      "short_title": "Elaboration Likelihood Model of persuasion"
    },
    {
      "author": "Liu",
      "year": 2021,
      "short_title": "In AI we trust? Effects of agency locus and transparency on uncertainty reduction"
    },
    {
      "author": "Johnson & Verdicchio",
      "year": 2017,
      "short_title": "AI anxiety"
    },
    {
      "author": "Shin & Jitkajornwanich",
      "year": 2024,
      "short_title": "How algorithms promote self-radicalization"
    },
    {
      "author": "Murtarelli et al.",
      "year": 2023,
      "short_title": "Ethical challenges of AI-assisted and chatbot-based communications"
    },
    {
      "author": "Zhang & Dafoe",
      "year": 2019,
      "short_title": "Artificial intelligence: American attitudes and trends"
    },
    {
      "author": "Gefen et al.",
      "year": 2003,
      "short_title": "Trust and TAM in online shopping"
    },
    {
      "author": "European Union",
      "year": 2024,
      "short_title": "EU Artificial Intelligence Act"
    },
    {
      "author": "Schepman & Rodway",
      "year": 2023,
      "short_title": "General Attitudes towards Artificial Intelligence Scale (GAAIS)"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper hat begrenzte direkte Relevanz für die Soziale Arbeit, adressiert aber wichtige Schnittstellen zwischen KI-Literacies, Vertrauensbildung, und gesellschaftlicher Inklusion. Die Erkenntnisse zu Transparenz und Bias-Reduktion könnten für Sozialarbeiter bedeutsam sein, die mit KI-gestützten Systemen in der Praxis arbeiten.",
    "unique_contribution": "Innovative Verschiebung vom Reputations-Prism-Modell zum Wissens-fokussierten Pipeline-Modell des KI-Vertrauens, mit empirischem Nachweis, dass Transparenz als Signalisierungsmechanismus für Organisationsverantwortlichkeit fungiert.",
    "limitations": "Die Studie berücksichtigt nur Online-Umfrage-Daten mit US-amerikanischen Teilnehmern; kulturelle Unterschiede im Vertrauensverständnis und langfristige Effekte von Transparenz-Maßnahmen bleiben unterexpliziert; keine direkten Interaktionen mit realen KI-Systemen."
  },
  "target_group": "KI-Entwickler, Organisationen mit KI-Integration, Kommunikations- und PR-Profis, Policymaker im Bereich KI-Regulierung, KI-Literacy-Pädagogen, Verbraucher und Stakeholder-Gruppen mit skeptischer KI-Haltung"
}