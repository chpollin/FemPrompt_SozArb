{
  "metadata": {
    "title": "Leitfaden Digitale Verwaltung und Ethik. Praxisleitfaden für KI in der Verwaltung, Version 1.0",
    "authors": [
      "Peter Biegelbauer",
      "Caroline Lackinger",
      "Sven Schlarb",
      "Edgar Subak",
      "Pia Weinlinger"
    ],
    "year": 2023,
    "type": "report",
    "language": "de"
  },
  "core": {
    "research_question": "Wie können Verwaltungsbedienstete KI-basierte Anwendungen ethisch, rechtlich und nachhaltig in der öffentlichen Verwaltung planen, entwickeln, beschaffen, einsetzen und evaluieren?",
    "methodology": "Theoretisch/Mixed – Literaturanalyse, Stakeholder-Workshops mit Verwaltungsbediensteten, Expert:innen-Konsultation; Entwicklung von praktischen Checklisten und Kriterienkatalogen",
    "key_finding": "Ein menschenzentriertes KI-Governance-Modell für die öffentliche Verwaltung, das Rechtmäßigkeit als Minimalbedingung, aber ethische Prinzipien (Transparenz, Fairness, Sicherheit, Inklusion, Rechenschaftspflicht) als zentral für vertrauenswürdige KI positioniert.",
    "data_basis": "Workshops mit Verwaltungsbediensteten (Zeitverlauf dokumentiert), Integration von EU-Normierungen (AI Act, DSGVO), österreichische KI-Strategie (AIM AT 2030), Analyse bestehender KI-Folgenabschätzungsinstrumente"
  },
  "arguments": [
    "Rechtliche Compliance allein ist unzureichend für ethische KI: Der Leitfaden argumentiert, dass Gesetzeseinhaltung notwendig, aber nicht hinreichend ist; ethische Prinzipien müssen von Anfang an ('Ethics by Design') in KI-Systeme integriert werden, insbesondere um Grundrechte zu schützen.",
    "KI-Anwendungen in der Verwaltung erfordern kontinuierliche Risikofolgenabschätzung und externe Überwachung: Besonders bei Hochrisiko-Systemen (Strafverfolgung, Migration, Sozialleistungen) müssen vor, während und nach der Implementierung systematische Bewertungen durchgeführt werden, um unerwünschte gesellschaftliche Auswirkungen zu vermeiden.",
    "KI-Literacies und digitale Souveränität sind Voraussetzung für menschenzentrierte Governance: Verwaltungsbedienstete benötigen grundlegende KI-Kompetenzen, um auf Augenhöhe mit Dienstleistern zu verhandeln, sensible Daten zu schützen und die Effektivität von KI-Systemen zu bewerten."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "KI Literacy wird als eigenständige Maßnahme definiert: 'Förderung eines Grundverständnisses von KI-Anwendungen, deren Voraussetzungen und Anwendungen sowie deren Auswirkung auf Verwaltung, Staat und Gesellschaft als Grundbedingung'. Der Leitfaden fordert explizit: 'Durch welche Maßnahmen wird die KI-Kompetenz der Verwaltungsbediensteten gefördert' und 'Wie wird die KI-Kompetenz der breiten Öffentlichkeit [...] gefördert?'",
    "KI_Sonstige": "Der Leitfaden behandelt vielfältige KI-Technologien: Maschinelles Lernen, neuronale Netze, Chatbots, Algorithmen, Predictive Analytics. Kapitel 3 'Technik: Was ist KI?' bietet grundlegende technische Erklärungen. Der AI Act wird detailliert analysiert mit seiner Risikopyramide für verschiedene KI-Systeme.",
    "Soziale_Arbeit": "Die Verwaltung wird als Kontaktpunkt zwischen Bürgern und Staat mit sozialer Verantwortung positioniert: 'Vertrauen in öffentliche Institutionen kann bei negativen Auswirkungen von Verwaltungshandlungen rasch beschädigt werden'. Konkrete Auswirkungen auf vulnerable Gruppen werden thematisiert, z.B. in Bereichen Strafverfolgung, Migration, Infrastruktur, Sozialleistungen.",
    "Bias_Ungleichheit": "Unvoreingenommenheit und Fairness sind eigenständiges Kriterium: 'Verwendung vielfältiger Daten und Modelle, um zu vermeiden, dass bestehende Vorurteile fortbestehen bzw. in der KI-Anwendung implizit mitwirken'. Die Checkliste fragt: 'Wurde sichergestellt, dass die KI-Anwendung keine Personen stigmatisieren oder diskriminieren kann? (Z. B. aufgrund von Geschlecht, ethnischer oder sozialer Herkunft, Alter, sexueller Ausrichtung, Religion oder Weltanschauung)'.",
    "Diversitaet": "Barrierefreiheit und Inklusion werden als eigenständiges Kriterium verankert: 'Möglichkeit der Nutzung und Verfügbarkeit von KI-Technologien für Personen mit unterschiedlichen Fähigkeiten, Hintergründen und Kulturen'. Fragen zur Inklusion: 'Wie wird die KI-Anwendung für Menschen mit unterschiedlichen Fähigkeiten, Hintergründen und Kulturen zugänglich und integrativ gestaltet?'",
    "Fairness": "Fairness ist explizites Fairness-Kriterium im EKIV-Katalog: 'Unvoreingenommenheit und Fairness: Verwendung vielfältiger Daten und Modelle, um zu vermeiden, dass bestehende Vorurteile fortbestehen'. Der Leitfaden fragt: 'Welche Kriterien werden verwendet, um festzustellen, ob die Anwendung fair ist?' und 'Wie wird sichergestellt, dass die zum Training der KI-Anwendung verwendeten Daten vielfältig und repräsentativ sind?'"
  },
  "references": [
    {
      "author": "European Commission",
      "year": 2021,
      "short_title": "AI Act - Proposal for a Regulation"
    },
    {
      "author": "BMDW und BMK",
      "year": 2021,
      "short_title": "Artificial Intelligence Mission Austria 2030 (AIM AT 2030)"
    },
    {
      "author": "Ebers et al.",
      "year": 2021,
      "short_title": "Kritik am AI Act - Überregulierung und Grundrechtsschutz"
    },
    {
      "author": "EDRi (European Digital Rights)",
      "year": 2023,
      "short_title": "Fokus auf Grundrechte und Schutz von KI-System-Betroffenen"
    },
    {
      "author": "Hidvegi et al.",
      "year": 2021,
      "short_title": "Rechtebasierte Regulierung vs. risikobasierter Ansatz"
    },
    {
      "author": "Lachmayer",
      "year": 2018,
      "short_title": "Datenschutz und Verwaltungsrecht in Österreich"
    },
    {
      "author": "Access Now",
      "year": 2023,
      "short_title": "NGO-Kritik an risikobasiertem AI Act Zugang"
    },
    {
      "author": "Madiega",
      "year": 2022,
      "short_title": "EU AI Governance und Selbsteinschätzungsrisiken"
    }
  ],
  "assessment": {
    "domain_fit": "Hochrelevant für die Schnittstellenanalyse KI/Soziale Arbeit/öffentliche Dienste: Der Leitfaden adressiert explizit die Auswirkungen von KI auf vulnerable Zielgruppen der Verwaltung (Sozialleistungsempfänger, Migranten, Strafverfolgungsobjekte) und fordert menschenzentrierte Governance mit Inklusion und Fairness als Kernprinzipien.",
    "unique_contribution": "Der deutschsprachige Praxisleitfaden übersetzt komplexe EU-Normierungen (AI Act, DSGVO, AIM AT 2030) in einen operationalisierbaren Kriterienkatalog (EKIV) mit konkreten Checklisten und Maßnahmensätzen für österreichische Verwaltungspraktiker:innen.",
    "limitations": "Der Leitfaden ist primär normativ-empfehlend, basiert auf limitierter empirischer Datenerhebung (Workshop-Inputs dokumentiert, aber nicht systematisch evaluiert); fehlende Evidenz zur Effektivität der empfohlenen Maßnahmen in der Praxis; Gender und feministische Perspektiven werden nicht explizit berücksichtigt, obwohl diese bei KI-Bias zentral sind."
  },
  "target_group": "Primär: Verwaltungsbedienstete, Manager:innen und Entwickler:innen in der österreichischen Bundesverwaltung. Sekundär: Policymaker:innen, KI-Beschaffer, Aufsichtsbehörden, breite Öffentlichkeit als betroffene Bürger:innen, Sozialarbeitende in Kontakt mit Verwaltungssystemen, Forschende zu Government Innovation und KI-Governance."
}