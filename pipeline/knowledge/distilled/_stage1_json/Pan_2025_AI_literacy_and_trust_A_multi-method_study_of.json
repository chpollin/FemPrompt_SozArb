{
  "metadata": {
    "title": "AI literacy and trust: A multi-method study of Human-GAI team collaboration",
    "authors": [
      "Zilong Pan",
      "Ozias A. Moore",
      "Antigoni Papadimitriou",
      "Jiayan Zhu"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie beeinflussen AI Literacy und Vertrauen die Zusammenarbeit zwischen Menschen und generativer KI in Team-Settings?",
    "methodology": "Mixed Methods: Qualitativ (kodierte Interviews zu Trust-Kategorien) und Quantitativ (Multinomiale logistische Regression und lineare Regression mit n=116 Studierenden in 23 Projektteams)",
    "key_finding": "Higher AI literacy shows a paradox: while perceived value increases trust in GAI, greater knowledge can lead to distrust. The study identified three trust categories (trust 52%, distrust 26%, ambivalence 22%) and found that AI accuracy perceptions are critical determinants of trust formation.",
    "data_basis": "n=116 undergraduate team members across 23 project teams throughout a semester; qualitative and quantitative measures on AI literacy (knowledge, perceived value, concerns) and trust in GAI"
  },
  "arguments": [
    "Trust is a fundamental requirement for effective human-AI teamwork, but unlike human teams, GAI teams face unique challenges because trust-building mechanisms based on shared experiences and interpersonal familiarity are unavailable in human-GAI interactions.",
    "AI literacy is a multidimensional construct comprising knowledge about GAI, perceived value, and perceived concerns. Knowledge paradoxically increases distrust while perceived value increases trust, suggesting that critical technical understanding can prompt skepticism about GAI reliability.",
    "The educational context reveals real-world trust deficits in AI adoption across domains (healthcare, K-12 education, software development), necessitating targeted AI literacy development programs to foster both informed use and appropriate calibration of trust in AI systems."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": false,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": false,
    "Gender": false,
    "Diversitaet": false,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Long and Magerko (2020) define AI literacy as understanding basic AI concepts, recognizing practical applications, and evaluating social impacts. The study operationalizes AI literacy through three sub-constructs: knowledge about GAI, perceived value of GAI, and perceived concerns about GAI, with α=.75 overall reliability.",
    "Generative_KI": "Study focuses explicitly on human-generative AI (GAI) collaboration, defined as systems capable of generating new content based on training data, specifically examining LLMs like ChatGPT. Both Study 1 and Study 2 measure trust and perceptions of GAI as a teammate in collaborative settings.",
    "Fairness": "The National Institute of Standards and Technology (2023) AI Risk Management Framework is referenced, highlighting key attributes contributing to AI trustworthiness such as explainability, accuracy, reliability, and fairness as critical factors for positioning AI as a trustworthy collaborator."
  },
  "references": [
    {
      "author": "Lee & See",
      "year": 2004,
      "short_title": "Trust in automation: Designing for appropriate reliance"
    },
    {
      "author": "Mayer, Davis & Schoorman",
      "year": 1995,
      "short_title": "An integrative model of organizational trust"
    },
    {
      "author": "Kozlowski et al.",
      "year": 2015,
      "short_title": "Teams, teamwork, and team effectiveness: Implications for human systems integration"
    },
    {
      "author": "Fiore & Wiltshire",
      "year": 2016,
      "short_title": "Technology as a teammate: Cognition across members, artifacts, and technology"
    },
    {
      "author": "Long & Magerko",
      "year": 2020,
      "short_title": "What is AI literacy? Competencies and design considerations"
    },
    {
      "author": "Wilson & Daugherty",
      "year": 2018,
      "short_title": "Collaborative intelligence: Humans and AI are joining forces"
    },
    {
      "author": "Chan & Hu",
      "year": 2023,
      "short_title": "AI literacy measure with knowledge, perceived value, and concerns sub-constructs"
    },
    {
      "author": "O'Neill et al.",
      "year": 2022,
      "short_title": "Human-autonomy teaming: A review and analysis of the empirical literature"
    },
    {
      "author": "National Institute of Standards and Technology",
      "year": 2023,
      "short_title": "AI Risk Management Framework"
    },
    {
      "author": "Guzman & Lewis",
      "year": 2019,
      "short_title": "Artificial intelligence and communication: A human-machine communication research agenda"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper hat nur begrenzte Relevanz für die Schnittstelle AI/Soziale Arbeit/Gender. Der Fokus liegt auf Hochschulbildung und Teamarbeit in Lehrkontexten, nicht auf Sozialarbeitsfeldern oder vulnerablen Zielgruppen. Gender und Vielfalt werden nicht explizit untersucht.",
    "unique_contribution": "Das Paper trägt durch ein mixed-method Design zum Verständnis des Vertrauensparadoxons in GAI-Teams bei: Es zeigt, dass höhere AI Literacy zu mehr kritischem Bewusstsein und damit potentiell zu Misstrauen führen kann, während wahrgenommener Nutzen Vertrauen fördert.",
    "limitations": "Limitationen: Nicht angegeben im Abstract/Excerpt; methodisch wahrscheinlich: Kleine Stichprobe von Studierenden in einem Lehrsetting, begrenzte Generalisierbarkeit auf andere Populationen und professionelle Kontexte"
  },
  "target_group": "Bildungsforscher, Hochschullehrende, Organisationsentwickler, HR-Profis, KI-Literacy-Curriculum-Designer, Forscher im Bereich Human-AI Collaboration und Team-Management"
}