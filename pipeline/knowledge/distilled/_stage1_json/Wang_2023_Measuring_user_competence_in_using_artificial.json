{
  "metadata": {
    "title": "Measuring user competence in using artificial intelligence: validity and reliability of artificial intelligence literacy scale",
    "authors": [
      "Bingcheng Wang",
      "Pei-Luen Patrick Rau",
      "Tianyi Yuan"
    ],
    "year": 2023,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie kann die Kompetenz von Benutzer:innen im Umgang mit KI-Technologie zuverlässig und valide gemessen werden?",
    "methodology": "Empirisch - Quantitative Skalenkonstruktion mittels exploratorischer Faktorenanalyse (EFA), bestätigender Faktorenanalyse (CFA), Reliabilität- und Validitätstests basierend auf zwei Stichproben (Sample 1: Item-Reduktion, Sample 2: Validierung)",
    "key_finding": "Entwicklung und Validierung einer 12-Item-Skala (AILS - Artificial Intelligence Literacy Scale) mit vier stabilen Konstrukten (Awareness, Usage, Evaluation, Ethics), die Benutzer:innenkompetenz in KI-Nutzung reliabel und valide misst.",
    "data_basis": "Zwei Survey-Stichproben mit je ca. 300-400 Teilnehmenden; insgesamt 65 initiale Items, reduziert auf 12 Items"
  },
  "arguments": [
    "KI-Kompetenz ist zentral für die Interaktion mit KI-Systemen, da die Literalität eines Produkts das mentale Modell und die Interaktionsprozesse prägt - bisherige Messungen durch Vorerfahrung und Nutzungshäufigkeit sind unzureichend.",
    "Das vierdimensionale Modell (Awareness, Usage, Evaluation, Ethics) basiert auf etablierten Konzepten der Digital Literacy und berücksichtigt sowohl technische als auch ethische Dimensionen der KI-Nutzung.",
    "Die entwickelte Skala zeigt signifikante Zusammenhänge mit Digital Literacy, Roboter-Einstellungen und täglicher KI-Nutzung, wodurch deren praktische Validität und Anwendbarkeit für Human-AI Interaction-Forschung und KI-Produktdesign nachgewiesen wird."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": false,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": false,
    "Bias_Ungleichheit": false,
    "Gender": false,
    "Diversitaet": false,
    "Feministisch": false,
    "Fairness": false
  },
  "category_evidence": {
    "AI_Literacies": "AI literacy refers to the ability to properly identify, use, and evaluate AI-related products under the premise of ethical standards. The paper develops a 12-item scale measuring four core constructs: awareness, usage, evaluation, and ethics.",
    "KI_Sonstige": "The study examines human-AI interactions (HAII), human-robot interaction, smart devices, and AI-embedded applications as the broader context for understanding user competence with AI systems."
  },
  "references": [
    {
      "author": "Kandlhofer et al.",
      "year": 2016,
      "short_title": "Artificial Intelligence and Computer Science in Education"
    },
    {
      "author": "Long & Magerko",
      "year": 2020,
      "short_title": "What is AI Literacy? Competencies and Design Considerations"
    },
    {
      "author": "Calvani et al.",
      "year": 2008,
      "short_title": "Models and Instruments for Assessing Digital Competence at School"
    },
    {
      "author": "Ferrari",
      "year": 2012,
      "short_title": "Digital Competence in Practice: An Analysis of Frameworks"
    },
    {
      "author": "Wilson, Scalise & Gochyyev",
      "year": 2015,
      "short_title": "Rethinking ICT Literacy: From Computer Skills to Social Network Settings (KSAVE-Framework)"
    },
    {
      "author": "Eshet",
      "year": 2004,
      "short_title": "Digital Literacy: A Conceptual Framework for Survival Skills in the Digital Era"
    },
    {
      "author": "Gilster & Glister",
      "year": 1997,
      "short_title": "Digital Literacy"
    },
    {
      "author": "Norman",
      "year": 2013,
      "short_title": "The Design of Everyday Things: Revised and Expanded Edition"
    },
    {
      "author": "Hinkin",
      "year": 1998,
      "short_title": "A Brief Tutorial on the Development of Measures for Use in Survey Questionnaires"
    },
    {
      "author": "Nomura, Kanda & Suzuki",
      "year": 2006,
      "short_title": "Negative Attitudes Toward Robots Scale (NARS)"
    }
  ],
  "assessment": {
    "domain_fit": "Das Paper hat begrenzte Relevanz für die Schnittstelle KI-Literalität und Soziale Arbeit. Es adressiert KI-Kompetenzmessung für Allgemeinnutzer:innen, berücksichtigt jedoch nicht spezifische Kontexte Sozialer Arbeit, vulnerable Populationen oder sozialarbeiterische Praxis.",
    "unique_contribution": "Erste psychometrisch validierte und testgetestete Skala zur Messung von KI-Literalität in der Allgemeinbevölkerung, basierend auf einem integrierten Vier-Konstrukt-Modell, das technische und ethische Dimensionen verbindet.",
    "limitations": "Die Studie konzentriert sich auf individuelle Kompetenzen und berücksichtigt nicht strukturelle Ungleichheiten, unterschiedliche Zielgruppen oder kontextuelle Faktoren (z.B. Zugang, Ressourcen); keine Analyse von Geschlecht, Alter oder soziodemografischen Unterschieden."
  },
  "target_group": "KI-Forscher:innen (HCI, HAII), KI-Produktdesigner:innen, Bildungsforscher:innen, Psychometriker:innen; begrenzte Relevanz für Sozialarbeiter:innen und Policymaker im Sozialbereich"
}