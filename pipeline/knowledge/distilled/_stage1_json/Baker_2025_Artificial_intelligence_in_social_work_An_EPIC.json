{
  "metadata": {
    "title": "Artificial Intelligence in Social Work: An EPIC Model for Practice",
    "authors": [
      "Heather Boetto"
    ],
    "year": 2025,
    "type": "journalArticle",
    "language": "en"
  },
  "core": {
    "research_question": "Wie können KI-Systeme ethisch und gerecht in die Soziale Arbeit integriert werden, um Vorteile zu maximieren und Risiken zu minimieren?",
    "methodology": "Theoretisch: Umfassende Literaturreview zur Schnittstelle von KI und Sozialer Arbeit mit Entwicklung eines konzeptionellen Rahmenmodells (EPIC-Modell)",
    "key_finding": "Ein vierteiliges EPIC-Modell (Ethics and Justice, Policy Development and Advocacy, Intersectoral Collaboration, Community Engagement and Empowerment) wird als strukturierter Ansatz für die ethische Integration von KI in der Sozialen Arbeit vorgeschlagen.",
    "data_basis": "Keine empirische Datenerhebung; argumentativ-theoretische Synthese von Fachliteratur"
  },
  "arguments": [
    "KI-Systeme reproduzieren und verstärken strukturelle Biases, insbesondere gegen marginalisierte Gruppen, da sie auf historischen Datensätzen trainiert werden, die koloniale Machtverhältnisse und Diskriminierung enthalten.",
    "Sozialarbeiter:innen benötigen explizit in professionellen Standards verankerte KI-Richtlinien sowie ein 'duales Mensch-Technologie-Modell', das KI als Entscheidungsunterstützung nutzt, aber menschliche Beziehungen und professionelle Urteilskraft nicht ersetzt.",
    "Community Engagement und besonders First Nations Data Sovereignty sind essenziell für die Dekolonialisierung von KI-Systemen und können nur durch intersektorale Zusammenarbeit zwischen Sozialarbeiter:innen, Informatiker:innen und betroffenen Gemeinschaften erreicht werden."
  ],
  "categories": {
    "AI_Literacies": true,
    "Generative_KI": true,
    "Prompting": false,
    "KI_Sonstige": true,
    "Soziale_Arbeit": true,
    "Bias_Ungleichheit": true,
    "Gender": false,
    "Diversitaet": true,
    "Feministisch": false,
    "Fairness": true
  },
  "category_evidence": {
    "AI_Literacies": "Empfehlung für Inclusion of AI content in course accreditation requirements and practice standards is critical for ensuring practitioners can appropriately navigate this new era of frontier technologies",
    "Generative_KI": "The type of deep learning machines garnering much public debate is generative AI, which has the capacity to autonomously augment, synthesise, and innovate new data inspired from an original dataset. ChatGPT als Beispiel für Risiken: inaccurate output data and breached privacy principles involving third-party access to service user data",
    "KI_Sonstige": "AI applications in mental health and predictive risk assessment, AI-powered chatbots in clinical settings, predictive risk modelling for suicide, domestic violence, and child protection using machine learning algorithms",
    "Soziale_Arbeit": "As artificial intelligence (AI) permeates the workplace environments of social workers, there is a need to understand the risks and benefits posed to the mission and values of the profession. Examination of AI's influence across child welfare, counselling, mental health, and domestic violence contexts",
    "Bias_Ungleichheit": "gender classification systems produced an error rate up to 34.7% for darker-skinned females (Buolamwini & Gebru). The dominance of colonial knowledges in AI algorithms are reinforced, and the ongoing colonisation and oppression of First Nations Peoples perpetuated. Lack of community involvement in AI development means algorithms rarely consider diverse perspectives",
    "Diversitaet": "Lack of representative data for marginalised groups, digital divide and information poverty for marginalised groups, need for First Nations' data sovereignty and control, underrepresented groups in AI employment pathways, intersectionality concerns regarding gender, race, ethnicity, and sexual orientation",
    "Fairness": "Advocating for legal protection and self-governance of personal data, advocacy for international and national collaborative governance and regulation, addressing structural biases through decolonisation processes, ensuring AI systems reflect diverse needs and concerns through community engagement"
  },
  "references": [
    {
      "author": "Buolamwini & Gebru",
      "year": 2018,
      "short_title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification"
    },
    {
      "author": "Dankwa-Mullan et al.",
      "year": 2021,
      "short_title": "Framework on Integrating Health Equity and Racial Justice into AI Development Lifecycle"
    },
    {
      "author": "Reamer",
      "year": 2023,
      "short_title": "Artificial Intelligence in Social Work: Emerging Ethical Issues"
    },
    {
      "author": "Meilvang & Dahler",
      "year": 2024,
      "short_title": "Decision Support and Algorithmic Support in Social Work"
    },
    {
      "author": "Khawaja & Bélisle-Pipon",
      "year": 2023,
      "short_title": "Your Robot Therapist is Not Your Therapist: AI-Powered Mental Health Chatbots"
    },
    {
      "author": "Cave & Dihal",
      "year": 2020,
      "short_title": "The Whiteness of AI"
    },
    {
      "author": "Gough & Spencer",
      "year": 2019,
      "short_title": "Ethical Social Work Practice in the Technological Era"
    },
    {
      "author": "Rice & Tambe",
      "year": 2018,
      "short_title": "Merging Social Work Science and Computer Science for Social Good"
    },
    {
      "author": "Jacobi & Christensen",
      "year": 2023,
      "short_title": "Functions, Utilities and Limitations: Decision Support Algorithms in Social Work"
    },
    {
      "author": "World Economic Forum",
      "year": 2024,
      "short_title": "The Global Risks Report"
    }
  ],
  "assessment": {
    "domain_fit": "Hochgradig relevant für die Schnittstelle KI-Soziale Arbeit. Das Paper adressiert zentrale Fragen zur ethischen und gerechten Integration von KI in einem Profession, die mit vulnerablen und marginalisierten Gruppen arbeitet.",
    "unique_contribution": "Das EPIC-Modell bietet einen strukturierten, vier-dimensionalen Rahmen für die ethische KI-Integration in der Sozialen Arbeit mit explizitem Fokus auf Dekolonialisierung, First Nations Data Sovereignty und Community Empowerment.",
    "limitations": "Paper ist primär konzeptionell-theoretisch ohne empirische Validierung des EPIC-Modells; begrenzte Auseinandersetzung mit technischen Aspekten von KI-Systemen; begrenzte Diskussion der Ressourcenbarrieren für kleinere Sozialarbeitsorganisationen bei Implementation der Empfehlungen"
  },
  "target_group": "Sozialarbeiter:innen und Sozialarbeitsfachkräfte, Fachkräfte in Sozialdiensten, Sozialarbeitsakademiker:innen und Ausbildner:innen, Policymaker im Bereich Soziale Dienste, KI-Entwickler:innen im Sozialbereich, Vertreter:innen von First Nations Communities und marginalisierten Gruppen"
}