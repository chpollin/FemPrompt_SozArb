---
title: "Advancing Accountability in AI: Governing and Managing Risks Throughout the Lifecycle for Trustworthy AI"
authors: ["Karine Perset", "Luis Aranda"]
year: 2023
type: report
language: en
processed: 2026-02-05
source_file: OECD_2023_Advancing_Accountability_in_AI.md
confidence: 92
---

# Advancing Accountability in AI: Governing and Managing Risks Throughout the Lifecycle for Trustworthy AI

## Kernbefund

Das Papier präsentiert ein strukturiertes DEFINE-ASSESS-TREAT-GOVERN Rahmenwerk, das zeigt, wie Risikomanagement-Praktiken über den gesamten KI-Lebenszyklus (Planung, Datenerfassung, Modellentwicklung, Validierung, Deployment, Betrieb) konkrete technische und prozessuale Maßnahmen zur Umsetzung der OECD-KI-Prinzipien ermöglichen kann.

## Forschungsfrage

Wie können Risikomanagement-Ansätze die Umsetzung der OECD-KI-Prinzipien über den gesamten KI-System-Lebenszyklus hinweg ermöglichen und zu vertrauenswürdiger KI beitragen?

## Methodik

Theoretisch/Review - Systematische Analyse von Frameworks, Best Practices und technischen Ansätzen; basierend auf Konsultationen von ca. 200 Expert:innen in zwei Arbeitsgruppen (Classification & Risk, Tools & Accountability) zwischen Februar 2020 und Dezember 2022
**Datenbasis:** Nicht empirisch; Policy-Analyse basierend auf Expert-Input von 200 Teilnehmer:innen aus Regierung, Industrie, Zivilgesellschaft und akademischen Institutionen

## Hauptargumente

- Accountability in KI erfordert ein systematisches, lebenszyklusbasiertes Risikomanagement-Rahmenwerk (DEFINE-ASSESS-TREAT-GOVERN), das technische und prozessuale Ansätze kombiniert und kontinuierliche Überwachung, Dokumentation und Stakeholder-Konsultation einbezieht.
- Vertrauenswürdige KI-Systeme müssen mehrere Dimensionen adressieren: Human-centered values und Fairness, Transparenz und Erklärbarkeit, Robustheit/Sicherheit/Safety sowie Nutzen für Mensch und Planet, mit expliziten Strategien zur Behandlung von Zielkonflikten zwischen diesen Prinzipien.
- Organisationen müssen eine Risikokultur entwickeln, die technische Expertise mit prozessualen Governance-Strukturen verbindet, klare Verantwortlichkeiten für verschiedene Akteure (Provider, Nutzer, Regulatoren) definiert und dokumentation sowie Konsultation von Stakeholdern über alle Lifecycle-Phasen hinweg einbezieht.

## Kategorie-Evidenz

### Evidenz 1

Das Papier fordert Dokumentation, technisches Verständnis und Kompetenz in Risikomanagement: 'Provide technical documentation and user manuals for operators and users of the system' und 'Ensure that insights and disclosures are directed to the end-users affected by the model'

### Evidenz 2

Umfassende Behandlung von ML-Systemen, Robustness, Security, Safety, Adversarial Examples, Model Verification: 'AI systems should be robust, secure, and safe throughout their lifespan so that they function appropriately in conditions of normal use, foreseeable misuse, or other adverse conditions'

### Evidenz 3

Explizite Behandlung von Fairness, Bias-Mitigation und Diskriminierungsrisiken: 'Risks to human-centred values and fairness' einschließlich Proxy Discrimination, mit Verweis auf 'Prince and Schwarcz (2020) on Proxy Discrimination in the Age of Artificial Intelligence and Big Data'

### Evidenz 4

Betonung von Inklusion und verschiedenen Stakeholder-Perspektiven: 'Making AI Inclusive: 4 Guiding Principles for Ethical Engagement' und Einbeziehung von Civil Society, Geschäftsverbänden und Gewerkschaften in Governance-Prozesse

### Evidenz 5

Kernfokus auf Fairness-Metriken und -Behandlung: 'Human-centred values and fairness' als wesentliche OECD-Prinzipien mit Ansätzen wie Fairness Constraints, Learning Fair Representations, Adversarial Learning zur Bias-Mitigation

## Assessment-Relevanz

**Domain Fit:** Das Papier ist relevant für die Schnittstelle KI/Governance, adressiert aber nicht explizit Soziale Arbeit oder Gender-Perspektiven. Es liefert jedoch wichtige Governance- und Accountability-Frameworks, die für Sozialarbeiter:innen relevant sind, die mit KI-gestützten Entscheidungssystemen arbeiten oder diese kritisch evaluieren müssen.

**Unique Contribution:** Das Papier bietet ein systematisches, international abgestimmtes (OECD) Rahmenwerk zur Operationalisierung von KI-Ethik-Prinzipien durch konkrete technische und prozessuale Risikomanagement-Maßnahmen über den gesamten AI-Lebenszyklus, was über bisherige abstrakte Principles-Diskussionen hinausgeht.

**Limitations:** Das Papier adressiert nicht explizit Kontexte von Marginalisierung, Machtasymmetrien oder strukturelle Ungleichheitsauswirkungen von KI-Systemen auf vulnerable Populationen (etwa in Sozialleistungsverwaltung); auch fehlt eine differenzierte Perspektive auf die Machtdynamiken zwischen verschiedenen Stakeholdern (Provider vs. betroffene Communitys)

**Target Group:** Policymaker, Regulatoren, KI-Entwickler und Governance-Experten; sekundär relevant für Sozialarbeiter:innen und Fachkräfte in Kontexten, in denen KI-Systeme auf vulnerable Populationen angewendet werden; Organisationen, die KI implementieren oder regulieren

## Schlüsselreferenzen

- [[OECD_2019]] - OECD AI Principles
- [[Raji_et_al_2020]] - Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing
- [[Reisman_et_al_2019]] - Algorithmic impact assessment: a practical framework for public agency accountability
- [[Schwartz_et_al_2021]] - Proposal for Identifying and Managing Bias in Artificial Intelligence
- [[Suresh_Guttag_2021]] - A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle
- [[Molnar_Casalicchio_Bischl_2020]] - Explainable Machine Learning
- [[Prince_Schwarcz_2020]] - Proxy Discrimination in the Age of Artificial Intelligence and Big Data
- [[Paleyes_Urma_Lawrence_2020]] - Challenges in Deploying Machine Learning: a Survey of Case Studies
- [[Park_2022]] - Making AI Inclusive: 4 Guiding Principles for Ethical Engagement
- [[Zafar_et_al_2019]] - Fairness Constraints: A Flexible Approach for Fair Classification
