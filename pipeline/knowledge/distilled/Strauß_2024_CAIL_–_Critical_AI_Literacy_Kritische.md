---
title: "CAIL - Critical AI Literacy: Kritische Technikkompetenz für konstruktiven Umgang mit KI-basierter Technologie in Betrieben"
authors: ["Stefan Strauß", "Titus Udrea"]
year: 2024
type: report
language: de
processed: 2026-02-05
source_file: Strauß_2024_CAIL_–_Critical_AI_Literacy_Kritische.md
confidence: 91
---

# CAIL - Critical AI Literacy: Kritische Technikkompetenz für konstruktiven Umgang mit KI-basierter Technologie in Betrieben

## Kernbefund

KI-basierte Automatisierung unterscheidet sich durch höhere Dynamik, Volatilität und Intransparenz von klassischen Automatisierungsformen. Das Risiko von Deep Automation Bias stellt ein Meta-Risiko dar, das durch kritische KI-Kompetenzen und bewusstes, zweckorientiertes System-Design reduziert werden kann.

## Forschungsfrage

Wie können Arbeitnehmer:innen durch Critical AI Literacy (CAIL) befähigt werden, KI-basierte Technologien in Betrieben konstruktiv und kritisch zu nutzen, und welche Herausforderungen entstehen durch neue Automatisierungsformen?

## Methodik

Mixed Methods: Literaturanalyse, qualitative Interviews mit Betriebsräten und Arbeitnehmer:innen, Workshops mit Stakeholdern (GPA, Arbeiterkammer Wien), Technikfolgenabschätzung
**Datenbasis:** Interviews mit Mitgliedern des Beirats für Arbeit und Technik (BAT), Workshop-Teilnehmer:innen, Mitarbeiter:innen der Arbeiterkammer Wien; spezifische n nicht angegeben

## Hauptargumente

- KI-basierte Automatisierung ist komplexer, dynamischer und volatiler als klassische Automatisierung, weil KI-Systeme nicht nur regelbasiert sind, sondern ihre Funktionsweisen adaptieren können, was zu geringerer Kontrollierbarkeit führt.
- Deep Automation Bias ist ein Meta-Risiko des KI-Einsatzes, das durch das Zusammenspiel von Systemkomplexität, mangelndem Problembewusstsein bei Nutzer:innen, Zeitmangel und Ressourcenknappheit verstärkt wird und letztlich zu unentdeckten Systemfehlern führt.
- KI-Mehrwert entsteht nur durch bewussten, zweckorientierten Einsatz als Expertensystem mit klaren Tätigkeitsbezügen – nicht durch diffuse En-passant-Nutzung. Dies erfordert Transparenz sowohl über Funktionsweise als auch über Nutzungsziele.

## Kategorie-Evidenz

### Evidenz 1

Critical AI Literacy (CAIL) als zentrale Kompetenz zur Handlungsfähigkeit: 'Grundkompetenzen umfasst Critical AI Literacy und mit welchen Ansätzen ist das entsprechende Wissen vermittelbar?' CAIL-Framework mit Kategorien wie Funktionswissen, Kontextualisierung, Interpretationsfähigkeit.

### Evidenz 2

Umfassende Behandlung von klassischem Machine Learning (unterschiedliche ML-Verfahren, Deep Learning, regelbasierte Systeme), Automatisierungsformen, KI-Anwendungen in Medizin, Journalismus, Bildung und bereichsübergreifend.

### Evidenz 3

Deep Automation Bias als zentrales Risiko; Ungleichheiten in Handlungsfähigkeit zwischen Expert:innen und Laien; 'Click Workers' in Kenia exploitiert für KI-Training; Abhängigkeitsverhältnisse zu großen Softwareanbietern benachteiligen kleine Betriebe.

### Evidenz 4

Algorithmic Fairness implizit durch Fokus auf Zuverlässigkeit, Überprüfbarkeit und korrekte Funktionsweise von KI-Systemen; Qualitätssicherung und Fehlererkennung als Fairness-Maßnahmen.

## Assessment-Relevanz

**Domain Fit:** Hoch relevant für Arbeitssoziologie und Technikfolgenabschätzung. Bezug zu Sozialer Arbeit nur marginal (Erwähnung von Qualifikationsbedarf), aber zentral für Arbeitnehmer:innenschutz und partizipative Gestaltung von KI-Systemen in Organisationen.

**Unique Contribution:** Entwicklung des CAIL-Frameworks als umfassender Ansatz zur Vermittlung kritischer KI-Kompetenzen; Konzeptualisierung von Deep Automation Bias als systemisches Risiko mit Einflussfaktoren-Modell.

**Limitations:** Fehlende explizite Perspektive auf marginalisierte Gruppen und intersektionale Dimensionen; Gender-Perspektive nicht integriert; empirische Datenbasis (Interviewzahlen) nicht detailliert dokumentiert; Fokus auf österreichische Kontexte mit generalisierungsbegrenzten Erkenntnissen.

**Target Group:** Betriebsräte, Gewerkschaften, Arbeitnehmer:innen in Wissensarbeit, HR-Professional:innen, Policymaker im Bereich Arbeit und Digitalisierung, Betriebliche Interessenvertreter:innen, KI-Implementierer in Organisationen

## Schlüsselreferenzen

- [[Strauß_Stefan_2021]] - Don't let me be misunderstood: Critical AI literacy for the constructive use of AI technology
- [[Strauß_Stefan_2021]] - Deep automation bias. How to tackle a wicked problem of AI?
- [[Lyell_David_Coiera_Enrico_2016]] - Automation bias and verification complexity: A systematic review
- [[Goddard_Keith_et_al_2012]] - Automation Bias studies
- [[Raisch_Sebastian_Krakowski_Stefan_2021]] - Artificial Intelligence and Management: The Automation-Augmentation Paradox
- [[von_Richthofen_Gero_et_al_2023]] - KI in der Wissensarbeit. Handlungsfelder und Ansätze für eine beschäftigtenorientierte Gestaltung
- [[Stowasser_Sascha_2023]] - Künstliche Intelligenz (KI) und Arbeit: Leitfaden zur soziotechnischen Gestaltung
- [[OECD_2023]] - The Impact of AI on the Workplace: Evidence from OECD Case Studies
