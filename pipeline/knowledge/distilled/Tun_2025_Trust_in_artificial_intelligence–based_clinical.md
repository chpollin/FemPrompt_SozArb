---
title: "Trust in Artificial Intelligence-Based Clinical Decision Support Systems Among Health Care Workers: Systematic Review"
authors: ["Hein Minn Tun", "Hanif Abdul Rahman", "Lin Naing", "Owais Ahmed Malik"]
year: 2025
type: journalArticle
language: en
processed: 2026-02-05
source_file: Tun_2025_Trust_in_artificial_intelligence–based_clinical.md
confidence: 91
---

# Trust in Artificial Intelligence-Based Clinical Decision Support Systems Among Health Care Workers: Systematic Review

## Kernbefund

Acht zentrale Themen prägen das Vertrauen von Gesundheitsfachkräften in AI-CDSSs: Systemtransparenz, Training und Vertrautheit, Usability, klinische Zuverlässigkeit, Glaubwürdigkeit und Validierung, ethische Überlegungen, Human-Centric Design und Customization mit Kontrolle. Algorithmische Intransparenz und unzureichendes Training gelten als Hauptbarrieren.

## Forschungsfrage

Welche Faktoren beeinflussen das Vertrauen von Gesundheitsfachkräften in KI-basierte klinische Entscheidungsunterstützungssysteme und wie können diese Systeme vertrauenswürdiger gestaltet werden?

## Methodik

Systematischer Review; Mixed Methods (16 qualitative, 6 quantitative, 5 mixed-method Studien); Cochrane Collaboration Handbook und PRISMA 2020; Literatursuche in PubMed, Scopus, Google Scholar (Januar 2020 - November 2024); CASP-Tool für Qualitätsbewertung
**Datenbasis:** 27 eingeschlossene Studien; Sample-Größen von kleinen Fokusgruppen bis über 1000 Teilnehmer; überwiegend Krankenhaussettings; diverse Gesundheitsfachkräfte (Ärzte, Krankenschwestern, Apotheker, Spezialisten)

## Hauptargumente

- Vertrauen ist kein statisches Konzept, sondern entwickelt sich durch Interaktion und Erfahrung mit der Technologie; es erfordert drei Dimensionen: Glaube an Wahrheitsgehalt, Vertrauen in Commitments und Glaube an Kompetenz des Systems.
- Systemtransparenz und Erklärbarkeit sind zentral für Vertrauen; Kliniker benötigen Verständnis für die Funktionsweise des Systems, insbesondere die Rationale hinter Empfehlungen, um Vertrauen aufzubauen und algorithmen-induced Dehumanisierung zu vermeiden.
- Human-Centric Design mit Bewahrung von Kliniker-Autonomie und Einbeziehung aller Stakeholder (inkl. Patienten und Familien) ist essentiell; Customization für spezifische klinische Kontexte und ethische Überprüfung (Fairness, medizinisch-rechtliche Haftung) sind Erfolgsfaktoren.

## Kategorie-Evidenz

### Evidenz 1

Training and Familiarity als Schlüsselthema: 'highlighting the importance of knowledge sharing and user education' [Results]; Fokus auf Kliniker-Kompetenzen: 'Knowledge of AI' und 'Confidence in interpreting radiographs' als Einflussfaktoren [York et al].

### Evidenz 2

Breites KI-Spektrum behandelt: machine learning models, deep learning, reinforcement learning, large language models (ChatGPT); Klassifizierung, Prognose und Optimierungsalgorithmen; Fokus auf Clinical Decision Support Systems und deren algorithmische Funktionsweise.

### Evidenz 3

Algorithmic bias und Fehler werden thematisiert: 'algorithmic bias' und 'false positives/negatives' als Vertrauensbarrieren; Diverse klinische Kontexte und Validierung in unterschiedlichen Settings erwähnt; jedoch keine explizite Analyse sozialer Ungleichheiten.

### Evidenz 4

Diverse Gesundheitsfachkräfte: 'diverse health care workers, predominantly in hospitalized settings' inkl. Ärzte, Krankenschwestern, Apotheker, Spezialisten verschiedener Disziplinen; Empfehlungen für 'diverse demographics, cross-cultural perspectives, and contextual differences in trust across various health care professions'.

### Evidenz 5

Ethical Consideration als eines von 8 Schlüsselthemen: 'examining medicolegal liability, fairness, and adherence to ethical standards'; Fairness in algorithmic performance across diverse contexts; Calibration und Performance-Konsistenz als Vertrauensfaktoren.

## Assessment-Relevanz

**Domain Fit:** Das Paper hat mittlere Relevanz für die Schnittstelle KI/Soziale Arbeit: Der Fokus liegt auf klinische Gesundheitsberufe, nicht auf Soziale Arbeit; die Thematisierung von ethischen Überlegungen, Human-Centered Design, Diversität und Fairness sind jedoch übertragbar auf sozialpädagogische Kontexte und algorithmengestützte Entscheidungsfindung in Sozialen Diensten.

**Unique Contribution:** Dieses systematische Review bietet die erste umfassende Synthese von 27 Studien zu acht zentralen Vertrauensfaktoren in AI-CDSSs und liefert konkrete, umsetzbare Empfehlungen für die Gestaltung von Systemen, die klinisches Vertrauen fördern, statt es zu untergraben.

**Limitations:** Heterogenität der Studiendesigns und Mangel an spezifischen Vertrauensmessdaten begrenzen Meta-Analyse; Fokus auf Krankenhaussettings mit Überrepräsentation westlicher Länder; keine Analyse geschlechtsspezifischer oder intersektionaler Vertrauensunterschiede.

**Target Group:** KI-Entwickler und Health Tech-Unternehmen, Kliniker und Gesundheitsadministratoren, Policymaker im Healthcare, Forscher im Bereich Human-AI Interaction, Health Informatics Profis, indirekt relevant für Sozialarbeiter in digitalisierten Entscheidungskontexten

## Schlüsselreferenzen

- [[Vereschak_et_al_2020]] - Theoretical elements of trust in human-AI systems (vulnerability, positive expectations, attitude)
- [[Stacy_et_al_2024]] - QRhythm model for optimal rhythm management in atrial fibrillation
- [[Sivaraman_et_al_2023]] - AI Clinician: Reinforcement learning for sepsis treatment recommendations
- [[Burgess_et_al_2023]] - Healthcare AI treatment decision support design principles for clinician adoption
- [[Liu_et_al_2023]] - Using ChatGPT to optimize clinical decision support alerts
- [[Anjara_et_al_2023]] - Explainable AI for lung cancer relapse prediction using think-aloud protocols
- [[Jones_et_al_2024]] - Multinational study on clinician control and liability in ophthalmology AI-CDSS
- [[Nasarian_et_al_2024]] - Interpretable ML systems to enhance trust in healthcare and clinician-AI collaboration
- [[Labkoff_et_al_2024]] - Recommendations for responsible AI-enabled clinical decision support
- [[McKee_Wouters_2023]] - Challenges of regulating artificial intelligence in healthcare
