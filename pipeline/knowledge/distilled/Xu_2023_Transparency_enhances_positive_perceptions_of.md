---
title: "Transparency Enhances Positive Perceptions of Social Artificial Intelligence"
authors: ["Ying Xu", "Nora Bradford", "Radhika Garg"]
year: 2023
type: journalArticle
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Xu_2023_Transparency_enhances_positive_perceptions_of.md
confidence: 75
---

# Transparency Enhances Positive Perceptions of Social Artificial Intelligence

## Kernbefund

Transparenz führt zu positiven Wahrnehmungsveränderungen: Nutzer finden den Chatbot weniger gruselig, fühlen größere Nähe und nehmen ihn als sozial intelligenter wahr, wobei die Effektgrößen jedoch klein sind.

## Forschungsfrage

Wie beeinflussen transparente Erklärungen der Funktionsweise von Chatbots die Nutzerwahrnehmung dieser Systeme?

## Methodik

Empirisch - randomisiertes Experiment mit 914 Teilnehmern aus Amazon Mechanical Turk in zwei-mal-zwei experimentellen Bedingungen (Transparenz ja/nein, Framing als intelligente Entität vs. Maschine) plus Kontrollgruppe; Post-Observation Survey; Two-Way ANOVA und ANCOVA mit Covariaten (Alter, Prior AI Knowledge)
**Datenbasis:** n=914 Teilnehmer von Amazon Mechanical Turk; experimentelle Manipulationen mit nachfolgendem Online-Survey (Likert-Skalen für vier latente Variablen: Creepiness, Affinity, Social Intelligence, Agency)

## Hauptargumente

- Soziale Chatbots basieren auf emotionalen Bindungen, deren Design transparent sein sollte um positive Wahrnehmungen zu fördern und ethische Risiken wie Manipulation oder unangemessene Anhaftung zu minimieren.
- Die Opazität von KI-Systemen führt zu Unsicherheit und potenziellen negativen Reaktionen (Creepiness), die durch Offenlegung der Funktionsweise reduziert werden können - besonders bei Nutzern mit geringerem Prior-KI-Wissen.
- Bisherige Forschung zu Transparenz konzentriert sich auf Task-orientierte Systeme; Soziale KI verlangt andere Ansätze, da sie auf Beziehungsaufbau statt Aufgabenerfüllung fokussiert und Anthropomorphisierungstendenzen besonders prägend sind.

## Kategorie-Evidenz

### AI_Literacies

Transparenz erhöht die Selbsteinschätzung des Nutzerwissens über Chatbot-Mechanismen signifikant (F=64.86, p<0.001). Paper argumentiert, dass Nutzer bei Transparenz besseres Verständnis von KI-Fähigkeiten und Grenzen entwickeln: 'enabling users to better comprehend the output of AI systems'

### KI_Sonstige

Fokus auf Social Chatbots, deren Mechanismen, algorithmische Opazität, Black-Box-Problem, Explainable AI: 'Users are generally unaware of what is happening between their own inputs and the system's output'

### Soziale_Arbeit

Chatbots werden als potenzielle Unterstützungsinstrumente für emotionales Wohlbefinden positioniert: 'social chatbots could possibly enhance individuals' well-being, particularly when alternative interpersonal interactions are limited or inaccessible' - relevant für Care-Arbeit und Beratung

### Bias_Ungleichheit

Unterschiedliche Effekte basierend auf Prior AI Knowledge: 'transparency appeared to have a larger effect on increasing the perceived social intelligence among participants with lower prior AI knowledge' - adressiert digitale Ungleichheit

### Diversitaet

Sample-Charakterisierung nach Rasse/Ethnizität (82.82% White, 4.49% Asian/Pacific Islander, 7.77% Black/African American, 2.30% Hispanic/Latino), Geschlecht (64.2% Male, 35.4% Female), Bildungsabschluss und Einkommen dokumentiert; jedoch keine intersektionalen Analysen

### Fairness

Transparenz als Mechanismus zur fairen und ethisch vertretbaren KI-Gestaltung: 'the research community has actively advocated for AI transparency' um Manipulation zu minimieren und Nutzerempowerment zu fördern. Fairness-Aspekt in Gleichbehandlung verschiedener Nutzergruppen bei Transparenzbotschaften

## Assessment-Relevanz

**Domain Fit:** Das Paper ist relevant an der Schnittstelle KI und sozialen Diensten: Es untersucht ethisches Design von sozialen KI-Systemen, die potenziell vulnerablen Gruppen emotional unterstützen sollen. Die Frage nach fairer und transparenter KI-Gestaltung hat direkte Implikationen für sozialarbeiterische Praxis und Ethik.

**Unique Contribution:** Das Paper adressiert eine Forschungslücke durch systematische empirische Untersuchung von Transparenz-Effekten spezifisch bei sozialer (nicht task-orientierter) KI und operationalisiert Transparenz als Erklärung der generellen Funktionsweise statt Erklärung einzelner Decisions.

**Limitations:** Kleine Effektgrößen (partial eta square < 0.01), hypothetische Szenarien statt direkter Interaktion mit echtem Chatbot, Sample überwiegend weiß und hochgebildet (75% College-Abschluss+), Effekte möglicherweise nicht robust; fehlende Langzeit-Validierung und intersektionale Analysen

**Target Group:** KI-Entwickler und UX-Designer von sozialen Chatbots, Policymaker im Bereich KI-Regulierung, Sozialarbeiter und Care-Professionelle, die mit KI-Tools arbeiten möchten, Bildungsforschende zu AI Literacy, Ethiker im Bereich Human-AI Interaction, Verbraucherverbände

## Schlüsselreferenzen

- [[Brandtzaeg_Skjuve_Følstad_2022]] - My AI friend: how users of a social chatbot understand their human-AI friendship
- [[Williams_Briggs_Scheutz_2015]] - Covert robot-robot communication: human perceptions and implications for HRI
- [[van_Straten_Peter_Kühne_Barco_2020]] - Transparency about a robot's lack of human psychological capacities
- [[Vitale_et_al_2018]] - Be more transparent and users will like you: a robot privacy and user experience design experiment
- [[Wang_Benbasat_2007]] - Recommendation agents for electronic commerce: effects of explanation facilities on trusting beliefs
- [[Rader_Cotter_Cho_2018]] - Explanations as mechanisms for supporting algorithmic transparency
- [[Druga_Ko_2021]] - How do children's perceptions of machine intelligence change when training and coding smart programs
- [[Sharkey_Sharkey_2021]] - We need to talk about deception in social robotics
- [[Coeckelbergh_2022]] - Three responses to anthropomorphism in social robotics
- [[Lutz_TamòLarrieux_2021]] - Do privacy concerns about social robots affect use intentions
