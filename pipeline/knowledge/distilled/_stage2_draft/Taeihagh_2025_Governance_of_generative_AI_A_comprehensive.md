---
title: "Governance of Generative AI: A Comprehensive Framework"
authors: ["A. Taeihagh"]
year: 2025
type: journalArticle
language: en
categories:
  - AI_Literacies
  - Generative_KI
  - KI_Sonstige
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Taeihagh_2025_Governance_of_generative_AI_A_comprehensive.md
---

# Governance of Generative AI: A Comprehensive Framework

## Kernbefund

Traditionelle IT-Governance-Modelle und Regulierungsrahmen sind unzureichend für generative KI; es bedarf innovativer, inklusiver und komplexitätsbasierter Governance-Ansätze, die Stakeholder-Partizipation, Datenschutz, IPR, Bias-Reduktion und internationale Kooperation adressieren.

## Forschungsfrage

Wie können generative KI-Systeme durch adaptive, partizipative und proaktive Governance-Ansätze verantwortungsvoll reguliert werden, um gesellschaftliche Werte zu schützen und Risiken zu minimieren?

## Methodik

Theoretisch/Review – Systematische Analyse der Governance-Herausforderungen von generativer KI durch Literaturreview und Synthese von sieben Spezialartikeln einer Policy-Sonderausgabe
**Datenbasis:** Keine empirische Datenerhebung; konzeptionelle Synthese von sieben Peer-reviewed Artikeln und umfassender Literaturreview

## Hauptargumente

- Generative KI birgt einzigartige Risiken (Halluzination, Jailbreaking, Datenvergiftung, Bias-Verstärkung, Datenlecks, Desinformation), die nicht-entschärfbare Sicherheitsfragen für kritische Sektoren wie Gesundheit, Justiz und nationale Sicherheit aufwerfen.
- Die gegenwärtige Governance-Fragmentierung, Macht-Konzentration bei Big-Tech-Unternehmen und techokratische Ansätze ohne öffentliche Partizipation führen zu ungerechten Risiko-Allokationen, bei denen Profite privatisiert und Risiken externalisiert werden.
- Effektive Governance erfordert adaptive, partizipative Rahmenwerke mit Datenschutz-Reformen, IPR-Neugestaltung, Bias-Monitoring, öffentlicher Engagement, Capacity-Building in Behörden und bindende internationale Abkommen gegen autonome Waffensysteme und KI-induzierte Massenvernichtungswaffen.

## Kategorie-Evidenz

### AI_Literacies

Explizite Empfehlungen: 'Educate officials about AI benefits, challenges, and implications. Develop capacities to understand AI's impact on policymaking.' und 'Promote media literacy and educational campaigns about AI capabilities and risks.'

### Generative_KI

Gesamter Fokus auf generative KI-Modelle: 'generative AI systems that create new content (text, images, audio, or video) based on inputs, leveraging ML, particularly generative adversarial networks (GANs), variational autoencoders (VAEs), large language models (LLMs), and diffusion models'

### KI_Sonstige

Behandlung klassischer ML und algorithmischer Entscheidungssysteme: 'traditional rule-based AI' und 'algorithmic decision-making'

### Bias_Ungleichheit

Explizite Behandlung von Bias und Ungleichheit: 'if a model is trained on data that are not demographically representative, it might disproportionately underperform for those demographics' und 'bias amplification' sowie 'power imbalances' und 'Big Tech's influence exacerbated by generative AI developments'

### Diversitaet

Mehrfache Forderungen nach Inklusion und diversen Stakeholdern: 'Assemble diverse teams and engage stakeholders to build trust' und 'Use participatory methods to involve the public in AI policy decisions' sowie 'increased inclusivity' und Berücksichtigung marginalisierter Gruppen durch 'impacts on low-skilled workers'

### Fairness

Fairness-zentrale Governance-Empfehlungen: 'Develop tools and procedures to detect and address biases during training and deployment', 'Promote responsible innovation and ethical AI development', 'Institutionalize red teaming, impact assessments, and internal auditing' und 'Independent audits for models with high impact'

## Assessment-Relevanz

**Domain Fit:** Das Paper hat hohe Relevanz für die Schnittstelle AI/Soziale Arbeit durch seine Fokussierung auf gesellschaftliche Impacts, öffentliche Partizipation, Ungleichheit und vulnerable Gruppen. Es adressiert jedoch Soziale Arbeit nicht direkt, sondern aus einer Policy-Governance-Perspektive.

**Unique Contribution:** Komprehensive, integrierte Governance-Rahmenwerk für generative KI mit sieben Dimensionen (Datenschutz, IPR, Bias, Datenschutz, Desinformation, gesellschaftliche Impacts, Machtungleichgewichte, öffentliches Engagement, öffentlicher Sektor, internationale Kooperation), das technische, rechtliche, organisatorische, politische und soziale Aspekte vereint.

**Limitations:** Das Paper ist primär konzeptionell und synthesisch ohne empirische Validierung der vorgeschlagenen Governance-Ansätze; spezifische Implementierungsmechanismen und Messbarkeit von Erfolgskriterien sind unterentwickelt.

**Target Group:** Policymaker, Regierungsbeamte, AI-Governance-Experten, Regulatoren, Tech-Industrie-Führungskräfte, Civil-Society-Organisationen, Akademiker in Policy Studies und AI Ethics, internationale Organisationen; sekundär relevant für Sozialarbeiter im Kontext von AI-bedingten sozialen Impacts und vulnerable populations

## Schlüsselreferenzen

- [[Taeihagh_A_2021]] - Governance of artificial intelligence
- [[Chesterman_2025]] - Good models borrow, great models steal: Intellectual property rights and generative AI
- [[Janssen_M_2025]] - Responsible governance of generative AI: Complex adaptive systems perspective
- [[Khanal_S_Zhang_H_Taeihagh_A_2025]] - Why and how is the power of Big Tech increasing in the policy process?
- [[Ulnicane_I_2025]] - Governance fix? Power and politics in controversies about governing generative AI
- [[Judge_B_Nitzberg_M_Russell_S_2025]] - When code isn't law: rethinking regulation for artificial intelligence
- [[Cugurullo_Xu_2025]] - Social implications of generative AI and city brains
- [[Oder_N_Béland_D_2025]] - Artificial intelligence, emotional labor, and low-skilled workers
- [[Bender_E_Gebru_T_McMillanMajor_B_Mitchell_S_2021]] - On the Dangers of Stochastic Parrots (Training Data Issues)
- [[Abbas_A_Taeihagh_A_2024]] - Misinformation and synthetic media risks in generative AI
