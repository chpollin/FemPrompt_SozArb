---
title: "Engineers on responsibility: feminist approaches to who's responsible for ethical AI"
authors: ["Eleanor Drage", "Kerry McInerney", "Jude Browne"]
year: 2024
type: journalArticle
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
processed: 2026-02-05
source_file: Browne_2024_Engineers_on_responsibility_feminist_approaches.md
---

# Engineers on responsibility: feminist approaches to who's responsible for ethical AI

## Kernbefund

Verantwortung sollte nicht als statisches individuelles Merkmal verstanden werden, sondern als 'response-ability' – eine dynamische, kollektive Fähigkeit zur Rechenschaft, die durch organisationale Kulturen ermöglicht wird, die Care- und Wartungsarbeit wertschätzen und strukturelle Barrieren abbaut.

## Forschungsfrage

Wie verstehen KI-Praktiker Verantwortung im Kontext von KI-Entwicklung und -Einsatz, und wer sollte verantwortlich sein, wenn etwas schiefgeht?

## Methodik

Empirisch-qualitativ: 50 leitfadengestützte Interviews mit KI-Praktikern und Tech-Arbeitern in einem multinationalen Technologieunternehmen (2020-2021), interpretiert durch feministische politische Theorie
**Datenbasis:** n=ca. 50+ Interviews mit KI-Praktikern und Tech-Arbeitern an einem multinationalen Technologieunternehmen über 12 Monate (2020-2021)

## Hauptargumente

- Traditionelle, statische Modelle von individueller Verantwortung können nicht mit den dynamischen, fluiden Ökosystemen von KI-Entwicklung umgehen, in denen Systeme die Besitzer wechseln, Arbeitskräfte das Unternehmen verlassen und Produkte orphan werden.
- KI-Ingenieure werden durch Druck und 'Tunnel-Vision'-Fokus auf unmittelbare technische Leistung daran gehindert, holistische Verantwortung für Langzeiteffekte zu übernehmen; dies erfordert Umgestaltung von Arbeitskultur und Bewertung von Wartungsarbeit.
- Feministische Theorie (Haraway, Puig de la Bellacasa, Young, Butler) bietet einen konzeptionellen Rahmen, der Verantwortung als relationales, gegenseitig abhängiges Phänomen rekonzeptualisiert und die unsichtbaren Care- und Wartungsarbeiten – historisch feminisiert und marginalisiert – als zentral für ethische KI-Entwicklung anerkennt.

## Kategorie-Evidenz

### AI_Literacies

Paper untersucht 'practitioners' personal understandings of responsibility' und wie KI-Praktiker Kompetenz und Wissen über KI-Systeme entwickeln und anwenden: 'we are unable to access the bigger picture' & interviews with 'AI practitioners and tech workers'

### KI_Sonstige

Fokus auf 'algorithmic tools which are often, but not always, created through the use of machine learning techniques', black box problem, unexplainability, AI lifecycle management, algorithmic drift

### Soziale_Arbeit

Thematisiert Care-Arbeit als zentral: 'caring responsibilities are distinctly gendered and racialized forms of work' und verbindet dies mit Care-ethischen Konzepten, die für Soziale Arbeit relevant sind; Fokus auf Beziehungen, Abhängigkeit, Verantwortung für vulnerable Populationen

### Bias_Ungleichheit

Analysiert wie 'AI replicates, perpetuates, or exacerbates existing patterns of discrimination and injustice' (Amazon hiring tool, UK A-level algorithm); erwähnt 'gendered and racialized workers' und 'Global South', Gefängnisarbeit, strukturelle Benachteiligung

### Gender

Expliziter Gender-Fokus: 'Amazon's gender discriminatory AI-powered hiring tool', 'caring responsibilities are distinctly gendered and racialized forms of work', Analyse von Frauen in Tech, Geschlechtsdimension von invisibilisierter Arbeit

### Diversitaet

Untersucht Repräsentation und Marginalisierung: 'communities and individuals who are most likely to be harmed', intersektionale Perspektive auf Arbeit ('gendered and racialized workers'), Global South und Gefängnissysteme

### Feministisch

EXPLIZIT feministische Theorie als Kern: 'use feminist theory and methodological approaches', 'feminist perspectives on responsibility' (Maria Puig de la Bellacasa, Donna Haraway, Iris Marion Young, Judith Butler), 'feminist organizational studies', 'feminist STS', 'feminist political economy', 'Data Feminism' (D'Ignazio & Klein)

### Fairness

Adressiert Fairness in KI-Systemen und algorithmische Gerechtigkeit durch feministische Linse: 'what does ethical, fair, and responsible AI look like?' Kritik an oberflächlichen Fairness-Checks ('box-ticking ethics frameworks')

## Assessment-Relevanz

**Domain Fit:** Sehr hohe Relevanz für die Schnittstelle AI/Soziale Arbeit/Gender. Das Paper kombiniert explizit feministische Theorie mit KI-Ethik und adressiert strukturelle Verantwortung, Care-Arbeit und Marginalisierung – Kernthemen der Sozialen Arbeit. Es zeigt, wie invisibilisierte, gendered Arbeit (Datenbereinigung, Labeling, Wartung) die gesamte KI-Wirtschaft trägt.

**Unique Contribution:** Bringt feministische politische Philosophie und organisationale Studien in Konversation über KI-Ethik; rekonzeptualisiert Verantwortung von individueller Zurechnung zu relationaler 'response-ability' und wertet Care/Maintenance-Arbeit auf – eine bislang marginalisierte Perspektive in KI-Ethik-Literatur.

**Limitations:** Studie begrenzt auf einen multinationalen Tech-Konzern, Generalisierbakeit auf andere Industrien unklar; Abhängigkeit von Unternehmens-Wohlwollen zur Umsetzung von Empfehlungen; begrenzte Analyse von Power-Differentialen zwischen Interviews-Durchführenden und befragten Arbeitern.

**Target Group:** KI-Ethiker:innen, Organisationsentwickler:innen in Tech-Unternehmen, Sozialarbeiter:innen in Policy/Tech-Governance, Genderstudies-Forschende, Arbeitnehmer:innen-Vertreter:innen in Tech, CSR/Sustainability-Manager:innen, Hochschullehrende in KI-Ethik und Feminist STS

## Schlüsselreferenzen

- [[Haraway_Donna_2016]] - Staying with the Trouble: Making Kin in the Chthulucene
- [[Puig_de_la_Bellacasa_Maria_2012]] - Nothing comes without its World: Thinking with Care
- [[Young_Iris_Marion_2011]] - Responsibility for Justice
- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[Butler_Judith_2003]] - Violence, Mourning, Politics
- [[Braidotti_Rosi_2021]] - Posthuman Feminism and Gender Methodology
- [[Coeckelbergh_Mark_2020]] - Artificial Intelligence, Responsibility Attribution, and Relational Justification of Explainability
- [[Fraser_Nancy_2016]] - Contradictions of Capital and Care
- [[Anzaldúa_Gloria_1999]] - La Frontera/Borderlands
- [[Chen_Aileen_2019]] - Inmates in Finland are Training AI as Part of Prison Labor
