---
title: "Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)"
authors: ["Gesa Alena Linnemann", "Julian Löhe", "Beate Rottkemper"]
year: 2023
type: journalArticle
language: de
categories:
  - AI_Literacies
  - Generative_KI
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Linnemann_2023_Bedeutung_von_Künstlicher_Intelligenz_in_der.md
---

# Bedeutung von Künstlicher Intelligenz in der Sozialen Arbeit: Eine exemplarische arbeitsfeldübergreifende Betrachtung des Natural Language Processing (NLP)

## Kernbefund

NLP bietet sowohl Chancen (niederschwelliger Zugang, Teilhabe, erweiterte Wissensbasis) als auch erhebliche Risiken (Modularisierung der Profession, Reproduktion von Stereotypen und Diskriminierung, ethische Probleme) für die Soziale Arbeit; ein kritisch begleiteter Einsatz unter Wahrung von Menschenrechten und Transparenz ist erforderlich.

## Forschungsfrage

Welche Implikationen und Chancen sowie Risiken ergeben sich aus dem Einsatz von Natural Language Processing (NLP) für die Praxis und Profession der Sozialen Arbeit in verschiedenen Handlungsfeldern?

## Methodik

Theoretisch-konzeptionell: Systematische Analyse unter Anwendung von Staub-Bernasconis Handlungstheorie, Uses-and-Gratification-Ansatz und Media Equation Theory; exemplarische Betrachtung verschiedener Handlungsfelder (Beratung, Kinder- und Jugendhilfe, Altenhilfe); Analyse von Praxisprojekten.
**Datenbasis:** Keine empirischen Daten; Analyse von bestehenden Projekten (Caritas 'Lernende Systeme in der Beratung', MAEWIN, CASoTex, KiJuAssistenz) und theoretischer Literatur

## Hauptargumente

- NLP ist für die Soziale Arbeit von besonderer Relevanz, da kommunikative Prozesse fundamental für die Praxis sind; zugleich berührt der Einsatz von KI alle drei Mandate der Profession (Gesellschaft, Klient*innen, Profession selbst) nach Staub-Bernasconi.
- Chatbots und Sprachassistenten können niederschwellige Erstkontakte ermöglichen und Gratifikationen wie Verfügbarkeit, Interaktivität und Autonomie bieten, müssen aber transparent gemacht werden und dürfen persönliche Beratung nicht ersetzen.
- Algorithmische Entscheidungssysteme (Predictive Analytics, Entscheidungsunterstützung) können Wissensbasis erweitern und Effizienz erhöhen, erfordern aber kritische Kompetenz von Fachkräften und bergen Risiken der Diskriminierung, Bias-Reproduktion und Modularisierung genuiner Sozialarbeitsleistungen.

## Kategorie-Evidenz

### AI_Literacies

Ausdrückliche Betonung der Notwendigkeit von Fachkompetenz: 'Fachkräfte müssen dazu befähigt werden, diese Wahrscheinlichkeiten zu interpretieren' und 'Es ist essenziell für den Einsatz von Entscheidungsunterstützungssystemen in der Praxis, dass transparent gemacht wird, mit welcher Wahrscheinlichkeit ein Ergebnis passend ist.'

### Generative_KI

Explizite Diskussion von GPT-3 und ChatGPT: 'Das im Jahr 2020 veröffentlichte OpenAI GPT-3 nutzt DeepLearning-Applikationen und ist in der Lage, anhand von wenigen Input-Parametern qualitativ hochwertige Texte zu generieren' sowie 'ChatGPT' mit Verweis auf dessen Bestehen einer Jura-Prüfung 2023.

### KI_Sonstige

Umfassende Behandlung von Natural Language Processing, Machine Learning, Deep Learning, Künstlichen Neuronalen Netzwerken und Predictive Analytics als zentrale Technologien.

### Soziale_Arbeit

Expliziter Fokus auf alle Handlungsfelder: 'In verschiedenen Handlungsfeldern der Sozialen Arbeit wird der Einfluss von NLP exemplarisch dargestellt'; Analyse von Kinder- und Jugendhilfe, Altenhilfe, Beratung; Referenz zu Staub-Bernasconis Konzept der Menschenrechtsprofession.

### Bias_Ungleichheit

Warnung vor Reproduktion von Diskriminierung: 'stereotype Rollenbilder wiederholt werden' und 'Ohne interdisziplinäre Teams in der Entwicklung von Werkzeugen, die NLP nutzen, besteht die Gefahr der Reproduktion von Diskriminierung und sogar weiterer Radikalisierung'.

### Diversitaet

Thematisierung marginalisierter Gruppen durch NLP und Sprachassistenz: besondere Betrachtung älterer Menschen, von Einsamkeit betroffener Menschen, weniger digital affiner Hilfesuchender: 'grundsätzlich darf die digitale Kontaktaufnahme nicht die ausschließliche Form des Erstkontakts sein, da sonst weniger digital affine Hilfesuchende nicht mehr erreicht werden.'

### Fairness

Explizite Forderung nach Fairness im Sinne der Menschenrechte: 'Im Bereich NLP sind insbesondere das Verbot von Diskriminierung, der Schutz der Freiheitssphäre des Einzelnen und die Meinungs- und Informationsfreiheit zu beachten.'

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI und Soziale Arbeit: Das Paper bietet eine systematische, theoretisch fundierte Analyse des Einsatzes von NLP in verschiedenen sozialarbeiterischen Handlungsfeldern und diskutiert explizit die Spannung zwischen technologischen Chancen und professionalen sowie ethischen Standards der Menschenrechtsprofession.

**Unique Contribution:** Das Paper leistet einen seltenen deutschsprachigen, systématischen Beitrag zur KI-Ethik in der Sozialen Arbeit, indem es NLP-Technologien nicht abstrakt, sondern feldspezifisch (Beratung, Altenhilfe, Kinder- und Jugendhilfe) durch die Linse von Staub-Bernasconis Tripelmandat analysiert und sowohl Chancen als auch strukturelle Risiken der Professionalisierung adressiert.

**Limitations:** Das Paper ist rein konzeptionell-theoretisch ohne empirische Validierung der postulierten Chancen und Risiken in der Praxis; die Analyse von Gender-Bias bleibt oberflächlich und nutzt nicht explicitly feministische Theorien, obwohl Geschlechterdimensionen (insbesondere bei GPT-3 Bias) vorhanden sind.

**Target Group:** Primär: Sozialarbeiter*innen, Lehrende in Sozialer Arbeit, Fachkräfte in Beratung, Kinder- und Jugendhilfe sowie Altenhilfe; Sekundär: KI-Ethiker*innen, Policymaker im Sozialwesen, Studierende der Sozialen Arbeit und angrenzender Disziplinen

## Schlüsselreferenzen

- [[StaubBernasconi_2018]] - Soziale Arbeit als Handlungswissenschaft
- [[StaubBernasconi_2007]] - Soziale Arbeit: Dienstleistung oder Menschenrechtsprofession
- [[Nass_Brave_2005]] - Media Equation Theory
- [[Russell_Norvig_2021]] - Artificial Intelligence: A Modern Approach
- [[OpenAI_2020]] - GPT-3 Language Model
- [[Beranek_Hill_Sagebiel_2019]] - Digitalisierung und Soziale Arbeit - Diskursüberblick
- [[Schneider_Seelmeyer_2019]] - Challenges in Using Big Data for Decision Support Systems in Social Work
- [[Lucy_Bamman_2021]] - Gender and Representation Bias in GPT-3 Generated Stories
- [[McGuffie_Newhouse_2020]] - Radicalization Risks of GPT-3
- [[Fellmann_et_al_2020]] - Digitalisierung personennaher Dienstleistungen in der Kinder- und Jugendhilfe
