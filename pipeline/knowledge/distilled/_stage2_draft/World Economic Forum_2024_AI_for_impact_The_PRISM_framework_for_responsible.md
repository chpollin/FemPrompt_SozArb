---
title: "AI for Impact: The PRISM Framework for Responsible AI in Social Innovation"
authors: ["World Economic Forum", "EY", "Microsoft", "Schwab Foundation for Social Entrepreneurship"]
year: 2024
type: report
language: en
categories:
  - AI_Literacies
  - Generative_KI
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: World Economic Forum_2024_AI_for_impact_The_PRISM_framework_for_responsible.md
---

# AI for Impact: The PRISM Framework for Responsible AI in Social Innovation

## Kernbefund

Das PRISM Framework bietet einen iterativen, schichtenweisen Ansatz zur verantwortungsvollen KI-Einführung, der Organisationsbereitschaft über technologische Fähigkeit priorisiert und fünf kritische Capabilites and Risks (Ethics, Data, Business/Organization, Technology, Costs/Metrics) identifiziert.

## Forschungsfrage

Wie können soziale Innovatoren künstliche Intelligenz verantwortungsvoll und effektiv für soziale Auswirkungen integrieren?

## Methodik

Mixed-Methods: Empirisch (Analyse von über 300 sozialen Innovatoren, 22 tiefgehende Interviews, interaktive Workshops) kombiniert mit Literaturanalyse und Best-Practice-Synthese
**Datenbasis:** n=300+ Soziale Innovatoren (April 2024 Vorgängerstudie), 22 tiefgehende Interviews, mehrere interaktive Workshops mit Sozialunternehmen und Tech-Führungskräften

## Hauptargumente

- Soziale Innovatoren müssen mit niedrig-komplexen, niedrig-kostigen KI-Anwendungen beginnen und iterativ vorgehen, nicht mit großangelegten technologischen Implementierungen starten, um Risiken zu minimieren und Erfolg zu maximieren.
- Ethische Überlegungen (Fairness, Bias-Vermeidung, Transparenz, Accountability) sind kritisch für soziale Innovatoren, die mit vulnerablen und marginalisierten Gruppen arbeiten, da kommerzielle KI-Modelle oft mit Daten aus wohlhabenden Ländern trainiert wurden und lokale Kontexte nicht adäquat abbilden.
- Technology Leaders müssen aktiv mit sozialen Innovatoren zusammenarbeiten, um Transparenz, Explainability und Fairness in KI-Systemen zu verbessern, da proprietäre Modelle (ChatGPT, Gemini) den Zugang zu Algorithmen blockieren und ethische Implementierung erschweren.

## Kategorie-Evidenz

### AI_Literacies

Das gesamte PRISM Framework adressiert 'organizational readiness' und Kompetenzaufbau: 'The framework encourages organizations to start with low-risk, low-cost AI applications and stresses the importance of organizational readiness over mere technological capability.' Kapitel 2.3 behandelt Leadership Vision, Skills Development und Training Costs.

### Generative_KI

Mehrfache Beispiele generativer KI-Nutzung: 'Dimagi built a tool based on Voice Engine, a new offering from the technology organization for the creation of custom voices, and ChatGPT-4' und Diskussion von proprietary Modellen wie ChatGPT und Gemini für Transparenzprobleme.

### KI_Sonstige

Umfangreiche Abdeckung klassischer ML-Anwendungen: Predictive Analytics, Computer Vision (facial recognition), sentiment analysis, machine learning algorithms (MapBiomas), OCR-Tools für Digitalisierung.

### Soziale_Arbeit

Fokus auf soziale Innovatoren und deren Arbeit mit vulnerablen Populationen: 'As social innovators often work with vulnerable and marginalized groups, this is one of the key considerations.' Beispiele: SAS Brasil (Gesundheit), High Resolves (Bildung), LifeBank (Gesundheitssystem), Haqdarshak (ökonomische Empowerment), Recode (digitale Inklusion in Slums).

### Bias_Ungleichheit

Explizite Behandlung von Bias und struktureller Ungleichheit: 'AI is a mirror reflecting the data fed into it. When the reflection is distorted by biased data, the outcomes can perpetuate societal disparities.' Geographische Disparitäten: 'most commercially available models are trained on data from high-income countries, delivering sub-par results for low- and middle-income countries.' Gender Gap: 'just 25% of women-led social enterprises using AI compared to half in the broader sector.'

### Gender

Explizite Geschlechterdisparität identifiziert: 'Gender disparities persist, with just 25% of women-led social enterprises using AI compared to half in the broader sector.' Figure 5 zeigt Verteilung nach Gründerinnen und CEO-Geschlecht.

### Diversitaet

Betonung von Inklusivität und Repräsentation: 'to ensure that their AI systems act as lenses that correct, rather than amplify, biases' durch diverse Datenquellen. Geographische Diversität: 'There is no gap in implementation between low-/middle-income and high-income countries but a strong diversity in the sectors of implementation.' Adressierung marginalisierter Communities: Haqdarshak in Indien, RECODE in Brazil favelas, Swahili/Sheng-Sprachenunterstützung.

### Fairness

Algorithmische Fairness ist zentrales Kapitel (2.1 Ethics): Fairness and avoiding bias, Transparenz, Accountability. Fairness-Metriken und -Frameworks werden diskutiert: 'In applications like facial recognition, where historical data may have underrepresented certain demographics, diverse data samples may need to be included.' Fairness als Schlüssel für vertrauenswürdige Systeme.

## Assessment-Relevanz

**Domain Fit:** Hochrelevant für KI/Soziale Arbeit/Gender-Schnittstelle: Das Paper adressiert direkt die Implementierung von KI in sozialwirtschaftlichen Organisationen mit explizitem Fokus auf ethische Gerechtigkeit, Bias-Vermeidung und Geschlechterparität. Es verbindet technische KI-Literatur mit Theorie und Praxis sozialer Innovation.

**Unique Contribution:** Das PRISM Framework bietet einen praktischen, modularen Implementierungsrahmen spezifisch für soziale Innovatoren, der Organisationsbereitschaft priorisiert und die Klüfte zwischen Tech-Entwicklung und Impact-Organisationen in Global South/Middle Income Settings explizit adressiert.

**Limitations:** Keine explizite feministische Theorieentwicklung; Gender ist quantitativ dokumentiert (25% vs. 50%), aber nicht tiefgehend analysiert. Keine explizite Intersektionalitätsanalyse. Methodische Gewichtung zwischen qualitativen Interviews und quantitativer Datenanalyse nicht vollständig transparent.

**Target Group:** Soziale Innovatoren, Sozialunternehmer:innen, Nonprofit-Führungskräfte, KI-Entwickler:innen mit Social-Impact-Fokus, Policymaker im Bereich digitale Inklusion, internationale Entwicklungsorganisationen, Tech-Ethics-Praktiker:innen, Diversity & Inclusion Officer in Tech-Unternehmen

## Schlüsselreferenzen

- [[Latanya_Sweeney_2002]] - k-Anonymity: A model for protecting privacy
- [[World_Economic_Forum_AI_Governance_Alliance_2024]] - Presidio Framework
- [[LIME_Contributors_2016]] - Local Interpretable Model-Agnostic Explanations
- [[OpenAI_2024]] - Navigating the Challenges and Opportunities of Synthetic Voices
- [[MapBiomas_2023]] - Algorithm Theoretical Basis Document (ATBD)
- [[Buolamwini_Gebru_2018]] - Gender Shades (implizit durch Facial Recognition Bias-Diskussion)
