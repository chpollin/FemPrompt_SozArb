---
title: "Exploring Opportunities and Risks in Decision Support Technologies for Social Workers: An Empirical Study in the Field of Disabled People's Services"
authors: ["Diana Schneider", "Angelika Maier", "Philipp Cimiano", "Udo Seelmeyer"]
year: 2022
type: journalArticle
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Schneider_2022_Exploring_opportunities_and_risks_in_decision.md
---

# Exploring Opportunities and Risks in Decision Support Technologies for Social Workers: An Empirical Study in the Field of Disabled People's Services

## Kernbefund

DSSs mit Visualisierungen der Klient*innen-Entwicklung werden als unterstützend wahrgenommen; es besteht Bedarf für partizipative Entscheidungsfindung; technische und professionelle Zuverlässigkeit dürfen nicht verwechselt werden.

## Forschungsfrage

Wie können Fachkräfte der Sozialen Arbeit in der Teilhabeplanung für Menschen mit Behinderung durch Entscheidungsunterstützungssysteme (DSSs) unterstützt werden, und welche Erwartungen, Befürchtungen und ethischen Implikationen sind damit verbunden?

## Methodik

Mixed Methods: Empirisch qualitativ mit zwei Teilen - ESI Study (Interviews zu Erwartungen und Befürchtungen, n nicht spezifiziert) und User Study (Prototyp-Testing mit 5 Fachkräften). Prospektive Technologiebewertung mit Antizipationsmethoden.
**Datenbasis:** 22 Klient*innen-Dateien mit 295.812 Datensätzen von 2 Wohneinrichtungen; Interviews mit Fachkräften von Leistungserbringern und Teilhabebehörden; Prototyp-Teststudie mit 5 Sozialarbeiter*innen

## Hauptargumente

- Visuelle Darstellungen von Klient*innen-Entwicklungen durch KI-basierte DSSs können berufliche Reflexion fördern und einen Mehrwert bieten, insofern sie subjektive Perspektiven transparenter machen und die professionelle Urteilsbildung unterstützen.
- Gegenwärtige Vorstellungen von DSSs fokussieren primär auf Professional-Algorithmus-Interaktion und ignorieren die Notwendigkeit partizipativer Entscheidungsfindung mit Service-Nutzer*innen, was ein kritisches Defizit in der Konzeptentwicklung darstellt.
- Die in professionelle Dokumentation eingeflossenen Biases, Subjektivitäten und Datenqualitätsprobleme stellen grundsätzliche Herausforderungen dar und erfordern Datenkompetenz und kritisches Verständnis der Unterschiede zwischen technischer und professioneller Zuverlässigkeit.

## Kategorie-Evidenz

### AI_Literacies

Data literacy und Verständnis technischer Prozesse werden als erforderlich benannt: 'Keeping this crucial distinction in mind and accounting for it in daily work with algorithms requires data literacy and an understanding of the technical processes'

### KI_Sonstige

Fokus auf AI-basierte Vorhersagesysteme (LONA-Scoring), algorithmische Entscheidungssysteme und natürliche Sprachverarbeitung: 'The system relies on an artificial intelligence (AI) based system trained to predict levels of need for assistance (LONA) from textual documentations'

### Soziale_Arbeit

Expliziter Fokus auf Soziale Arbeit in Teilhabeplanung für Menschen mit Behinderung, professionelle Urteilsbildung und Fachkräfte-Kompetenzen: 'MAEWIN project, therefore, addresses the question of how professionals of social care providers could be supported in the context of SSP by DSSs'

### Bias_Ungleichheit

Kritische Analyse von Biases in Dokumentation und Datenbasis: 'documentation may contain hidden biases, biased perspectives, or prejudices' und Diskriminierungsrisiken von Algorithmen: 'systemic discrimination'

### Diversitaet

Fokus auf Menschen mit Behinderung als marginalisierte Gruppe und deren Partizipation in Entscheidungsprozessen: 'shared decision-making processes with the persons entitled to benefits'

### Fairness

Fairness-Konzepte in algorithmischen Entscheidungssystemen und Anforderung fairer Darstellung: 'data basis used by algorithms is quality controlled and free of biases caused by data reflecting the perceptions of specific stakeholders'

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit. Das Paper adressiert zentrale Fragen der Implementierung von KI-Systemen in einer kritischen Profession und untersucht Auswirkungen auf vulnerable Zielgruppen (Menschen mit Behinderung) und professionelle Praxis mit Fokus auf Partizipation.

**Unique Contribution:** Einzigartig ist die Beteiligung von Sozialarbeiter*innen als Antizipant*innen in frühen Entwicklungsphasen von DSSs kombiniert mit kritischer Analyse von Subjektivität und Bias in professioneller Dokumentation sowie die Forderung nach partizipativen (statt nur technokratischen) Entscheidungsmodellen.

**Limitations:** Kleine Stichprobe in User Study (n=5); fehlende explizite Perspektive von Service-Nutzer*innen (Menschen mit Behinderung) selbst; Geschlechter- und intersektionale Dimensionen werden nicht systematisch analysiert; Fokus auf Deutschland begrenzt Generalisierbarkeit.

**Target Group:** Sozialarbeiter*innen, Fachkräfte der Behindertenhilfe, KI-Entwickler*innen mit Anwendungsfokus Soziale Arbeit, Policymaker im Sozialsektor, Forscher*innen zu Technology Assessment und Verantwortungsvoller Innovation, Vertreter*innen von Behindertenorganisationen

## Schlüsselreferenzen

- [[Gillingham_2019]] - Decision support systems, social justice and algorithmic accountability in social work
- [[Crawford_2013]] - The hidden biases in big data
- [[Raji_2020]] - How our data encodes systematic racism
- [[Wachter_Mittelstadt_Floridi_2017]] - Transparent, explainable, and accountable AI
- [[Collingridge_1980]] - The social control of technology
- [[Braun_et_al_2020]] - Primer on an ethics of AI-based decision support systems in the clinic
- [[Schneider_Seelmeyer_2019]] - Challenges in using big data to develop decision support systems for social work in Germany
- [[Chiusi_et_al_2020]] - Automating society report 2020
