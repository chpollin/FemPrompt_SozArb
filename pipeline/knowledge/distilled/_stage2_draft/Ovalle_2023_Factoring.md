---
title: "Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness"
authors: ["Anaelia Ovalle", "Arjun Subramonian", "Gilbert Gee", "Vagrant Gautam", "Kai-Wei Chang"]
year: 2023
type: conferencePaper
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Bias_Ungleichheit
  - Diversitaet
  - Feministisch
  - Fairness
processed: 2026-02-05
source_file: Ovalle_2023_Factoring.md
---

# Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness

## Kernbefund

AI-Fairness-Forscher reduzieren Intersektionalität überwiegend auf die Optimierung von Fairness-Metriken über demografische Subgruppen, während sie kritische Aspekte wie Machtanalyse, sozialen Kontext und intersektionale Praxis vernachlässigen. Dies reproduziert koloniale Epistemologien und untergrä&bt die liberatorische Kraft der intersektionalen Theorie.

## Forschungsfrage

Wie wird Intersektionalität in der AI-Fairness-Literatur diskutiert und wo liegen die Lücken zwischen ihrer Konzeptualisierung und Operationalisierung für gerechte KI-Systeme?

## Methodik

Theoretisch/Review - Kritische Literaturanalyse von 30 AI-Fairness-Papieren basierend auf Collins und Bilge's sechs Intersektionalitäts-Tenets (soziale Gerechtigkeit, soziale Ungleichheit, Relationalität, Machtstrukturen, sozialer Kontext, Komplexität); deduktive und induktive Kodierung mit Interannotator-Reliabilität (Randolph's κ).
**Datenbasis:** n=30 AI-Fairness-Papiere (11 mit Triple-Annotation für Reliabilität, 19 mit Single-Annotation); Analyse basiert auf etablierter intersektionaler Theorie (primär Crenshaw, Collins, Bilge)

## Hauptargumente

- Intersektionalität ist kein technisches, sondern ein kritisches analytisches Konzept aus Black Feminist Theory zur Untersuchung interlocking systems of oppression; AI-Fairness-Forschung entfremdet diesen emanzipatorischen Anspruch durch ihre Reduktion auf statistische Subgruppen-Fairness.
- Koloniale Epistemologie prägt KI-Forschung strukturell und führt zur Auslöschung von Wissen marginalisierter Communities; intersektionale Praxis erfordert hingegen Partizipation von Betroffenen, Reflexivität und soziale Ortung der Forschenden selbst.
- Power wird in der AI-Fairness-Literatur technodeterministisch verengt (auf das System statt auf menschliche Gestalter fokussiert) oder ganz ignoriert (nur 53% erwähnen Power); echte intersektionale Praxis erfordert die Analyse struktureller, disziplinärer, kultureller und interpersonaler Machtdomänen.

## Kategorie-Evidenz

### AI_Literacies

Die Arbeit kritisiert die Epistemologien der KI-Forschung und fordert eine Transformation der Wissensproduktion und kritischen Reflexivität: 'intersectionality, by enabling researchers to observe and articulate disparities, may break the epistemic molds researchers are placed in so they may operate differently'

### KI_Sonstige

Umfassende Analyse der AI-Fairness-Literatur und ihrer algorithmischen Operationalisierungen (pre/in/post-processing, Fairness-Metriken, Subgroupenbildung, Bias-Quellen)

### Bias_Ungleichheit

Zentral ist die Kritik der fehlenden Auseinandersetzung mit strukturellen Ursachen von Ungleichheit: 'researchers prioritize intersectional subgroup fairness over the structures that give rise to unfairness to begin with'

### Diversitaet

Intersektionalität wird als Framework zur Analyse marginalisierter Gruppen und ihrer Verschränkung mehrfacher Dimensionen von Unterdrückung behandelt: 'groups associated with multiple, intersectional demographic attributes (e.g., Black women)'

### Feministisch

Explizite Verankerung in Black Feminist Theory (Crenshaw, Collins, hooks) und dekolonialer Theorie; Praxis wird als 'knowledge production' gegen 'epistemic violence' definiert: 'frameworks to articulate social inequalities have been integral to the survival of communities at the margins' - dies ist zentral für feministische Epistemologie

### Fairness

Kritische Analyse von Fairness-Metriken und deren Limitation: 'merely mentioning power does not entail engaging with it in depth'; Argument dass echte Fairness nur durch intersektionale Analyse möglich ist, die Machtstrukturen und sozialen Kontext einbezieht

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Gender Studies/Kritische Sozialtheorie. Das Paper verbindet AI Fairness kritisch mit intersektionaler und dekolonialer Theorie und hat implizite Bedeutung für Soziale Arbeit, da es Machtstrukturen und marginalisierte Communities in technischen Systemen analysiert.

**Unique Contribution:** Erstmalige systematische Mappung der Lücke zwischen intersektionaler Theorie (als kritisches Framework für Befreiung) und ihrer technischen Operationalisierung in AI-Fairness-Forschung, verbunden mit konkreten Empfehlungen zur Überwindung kolonialer Epistemologien in KI-Entwicklung.

**Limitations:** Fokus ausschließlich auf englischsprachige Literatur; geografisch konzentriert auf USA/Nordatlantik; keine Interviews mit marginialisierten Communities selbst; Transferierbarkeit auf andere technische Domänen unklar

**Target Group:** AI-Fairness-Forscher und KI-Ethiker (primär), Policymaker im Tech/AI-Bereich, dekoloniale und feministische Wissenschaftler, Technologie-Aktivisten, Software-Entwickler mit Gerechtigkeitskomitment. Potentiell relevant für Sozialarbeiter in Kontext algorithmischer Entscheidungssysteme in Sozialdiensten (Leistungszuteilung, Risikobewertung).

## Schlüsselreferenzen

- [[Crenshaw_Kimberlé_1989]] - Demarginalizing the Intersection of Race and Sex (Intersectionality Framework)
- [[Collins_Patricia_Hill_Bilge_Sirma_2016]] - Intersectionality (Core Tenets: social justice, social inequality, relationality, social power, social context, complexity)
- [[Buolamwini_Joy_Gebru_Timnit_2018]] - Gender Shades: Intersectional Accuracy Disparities in Gender Classification
- [[CostanzaChock_Sasha_2020]] - Design Justice: Community-Centered Approaches to Technology
- [[DIgnazio_Catherine_2020]] - Data Feminism (with Lauren Klein)
- [[Davis_Jenny_L_Kneese_Tamara_Snitow_Jeffrey_2021]] - Reparative and Historically Informed AI (cited as [37])
- [[Freeman_Alan_David_1978]] - Legitimizing Racial Discrimination through Antidiscrimination Law
- [[Mitchell_Shira_et_al_2021]] - Model Cards for Model Reporting (Transparency and Social Context)
- [[Kasy_Maximilian_Abebe_Rediet_2021]] - Algorithmic Fairness and the Social Contract
- [[Birhane_Abeba_et_al_2021]] - The Normative Crisis in AI Ethics (Power and Social Context Analysis)
