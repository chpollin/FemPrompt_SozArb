---
title: "Algorithmic discrimination: examining its types and regulatory measures with emphasis on US legal practices"
authors: ["Xukang Wang", "Ying Cheng Wu", "Xueliang Ji", "Hongpeng Fu"]
year: 2024
type: journalArticle
language: en
categories:
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Wang_2024_Algorithmic_discrimination_examining_its_types.md
---

# Algorithmic discrimination: examining its types and regulatory measures with emphasis on US legal practices

## Kernbefund

Das Paper identifiziert fünf primäre Typen algorithmischer Voreingenommenheit (Bias durch algorithmische Agenten, diskriminierende Feature-Selektion, Proxy-Diskriminierung, Disparate Impact, zielgerichtete Werbung) und kategorisiert US-Regulierungsrahmen in fünf Ansätze (principled regulation, preventive controls, consequential liability, self-regulation, heteronomy regulation).

## Forschungsfrage

Welche Typen von algorithmischer Diskriminierung existieren und welche regulatorischen Maßnahmen sind in den USA und international vorhanden, um diese zu bekämpfen?

## Methodik

Theoretisch/Mixed Methods - Systematische Literaturanalyse (85 Artikel), Analyse von Rechtsdokumenten und vergleichende Fallstudien über mehrere Sektoren und Länder
**Datenbasis:** Systematische Literaturanalyse von 85 peer-reviewed Artikeln aus ACM Digital Library, IEEE Xplore, LexisNexis, HeinOnline und Google Scholar; Analyse von Gerichtsfällen und Regulierungsdokumenten

## Hauptargumente

- Algorithmische Diskriminierung kann sich in mehreren verschiedenen Formen manifestieren - von explizit intendierter Diskriminierung bis zu unbewussten Verzerrungen in Trainingsdaten, Feature-Auswahl oder Modellgestaltung - und erfordert daher differenzierte regulatorische Ansätze.
- Bestehende US-Antidiskriminierungsgesetze sind unzureichend für die Regulierung algorithmischer Systeme; es werden proaktive Impact Assessments, Transparenzanforderungen und Auditierungsmechanismen benötigt, um systematische Diskriminierung zu verhindern.
- Juristische Überprüfung muss sowohl intentionale als auch unintentionale algorithmische Diskriminierung erfassen; unintentionale Diskriminierung sollte durch Analyse von Datenmustern, Impact-Assessment und Ursachenanalyse erkannt werden, um strukturelle Ungleichheiten zu adressieren.

## Kategorie-Evidenz

### KI_Sonstige

Das Paper konzentriert sich auf 'algorithmic decision-making systems' in Kriminalitätsprognose, Einstellung, Bildung und Kreditvergabe und behandelt klassische Machine Learning, nicht generative KI.

### Soziale_Arbeit

Explizite Behandlung von Algorithmen im Criminal Justice System ('judges to estimate the risk of reoffending'), Arbeitseinstellung und Bildung ('schools to choose whether to admit students'), die zentrale Domänen Sozialer Arbeit und ihrer Schnittstellen sind.

### Bias_Ungleichheit

Kernfokus des Papers: 'Algorithmic discrimination can manifest in various forms, such as bias by the algorithmic agents, biased feature selection... These different types of algorithmic bias can lead to unfair treatment and disparate impacts on protected groups, raising concerns about equal rights, due process, and social justice'

### Diversitaet

Paper diskutiert 'disparate impacts on protected groups' und bezieht sich auf verschiedene marginalisierte Gruppen in Kontexten wie Criminal Justice Risk Assessments und Hiring Algorithms, mit Bezug zu 'lack of diversity in the development teams' als Ursache.

### Fairness

Zentrales Thema durchgehend: 'algorithmic fairness, transparency, and accountability', spezifische Behandlung von Fairness-Metriken, Fairness Constraints in ML und 'algorithmic auditing and impact assessments' zur Messung und Gewährleistung von Fairness.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochrelevant für die Schnittstelle KI und Soziale Arbeit, da es konkrete algorithmische Systeme in Bereichen adressiert, die zentral für Soziale Arbeit sind (Criminal Justice, Employment, Education), und strukturelle Mechanismen der Diskriminierung analysiert, die marginalisierte Gruppen betreffen.

**Unique Contribution:** Der Hauptbeitrag liegt in der systematischen Taxonomie von fünf Typen algorithmischer Diskriminierung und der vergleichenden Analyse von US-Regulierungsrahmen mit internationalen Perspektiven, kombiniert mit praktischen Fallstudien zur Illustration realer Auswirkungen.

**Limitations:** Das Paper konzentriert sich primär auf den US-Kontext und das Rechtssystem; es fehlt eine explizit intersektionale oder feministische Analyse der Diskriminierungsmechanismen, und die Perspektive betroffener Communitys ist unterrepräsentiert.

**Target Group:** Policymaker, Jurist:innen, KI-Entwickler:innen, Regulierungsbehörden, Sozialarbeiter:innen in Justiz- und Sozialverwaltung, Forscher:innen in KI-Ethik und Algorithmic Fairness, Aktivist:innen im Bereich Algorithmic Justice

## Schlüsselreferenzen

- [[Selbst_and_Barocas_2016]] - Big Data's Disparate Impact
- [[Buolamwini_and_Gebru_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Kroll_et_al_2017]] - Accountable Algorithms
- [[Crawford_and_Schultz_2014]] - Big Data and Due Process
- [[Pasquale_2015]] - The Black Box Society
- [[ONeil_2017]] - Weapons of Math Destruction
- [[West_et_al_2019]] - Discriminating Systems: Gender, Race and Power in AI
- [[Reisman_et_al_2018]] - Algorithmic Impact Assessments: A Practical Framework for Public Agency
- [[Prince_and_Schwarcz_2019]] - Proxy Discrimination in the Age of Artificial Intelligence and Big Data
- [[Berk_et_al_2021]] - Fairness in Criminal Justice Risk Assessments: The State of the Art
