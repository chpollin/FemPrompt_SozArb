---
title: "EDPS TechDispatch on Explainable Artificial Intelligence"
authors: ["Vítor Bernardo"]
year: 2023
type: report
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Bias_Ungleichheit
  - Fairness
processed: 2026-02-05
source_file: European Data Protection Supervisor_2023_Explainable_Artificial_Intelligence.md
---

# EDPS TechDispatch on Explainable Artificial Intelligence

## Kernbefund

XAI ist ein essentielles Mittel zur Förderung von Transparenz, Rechenschaftspflicht und Fairness bei KI-Systemen, kann aber selbst neue Risiken schaffen und muss durch menschenzentrierte Design-Ansätze und kritische Reflexion flankiert werden.

## Forschungsfrage

Wie können KI-Systeme transparent und erklärbar gestaltet werden, um Datenschutz, Fairness und Vertrauen zu gewährleisten?

## Methodik

Theoretisch/Review - Analyse und Darstellung von Konzepten, Risiken und Best Practices der Explainable AI (XAI) im Kontext des Datenschutzes
**Datenbasis:** nicht empirisch - konzeptionelle und normative Analyse basierend auf Literatur, Rechtsprechung und Best Practice

## Hauptargumente

- Der 'Black-Box-Effekt' bei komplexen KI-Systemen führt zu Risiken für Individuen durch verborgene Diskriminierung, Bias und mangelnde Rechenschaftspflicht, besonders bei automatisierten Entscheidungen durch öffentliche Behörden.
- XAI kann durch Transparency, Interpretability und Explainability-Mechanismen Datenschutzprinzipien unterstützen und Compliance mit GDPR gewährleisten, muss aber sorgfältig umgesetzt werden.
- Die Implementierung von XAI birgt eigene Risiken: Misinterpretation, Sicherheitslücken, Disclosure von Geschäftsgeheimnissen und Überreliance auf Systeme - daher ist ein menschenzentrierter, kontextsensitiver Ansatz erforderlich.

## Kategorie-Evidenz

### AI_Literacies

Fokus auf Verständnis und kritische Reflexion von KI-Systemen durch verschiedene Stakeholder: 'XAI empowers individuals with understandable insights into how their personal data is being handled'

### KI_Sonstige

Breite Behandlung von ML, Deep Learning, neuronalen Netzwerken und algorithmischen Entscheidungssystemen: 'AI systems such as machine learning (ML) or deep learning (DL) use algorithms learned by their own process of training'

### Bias_Ungleichheit

Explizite Analyse von Diskriminierungsrisiken und Bias in KI: 'when AI is used to select job applicants, systems might inadvertently favour candidates from certain demographics or backgrounds due to biased training data'

### Fairness

Zentrale Behandlung von Fairness-Anforderungen und Fairness-Implementierung: 'the limitations of black box approaches should be considered when trying to assess the fairness of the models'

## Assessment-Relevanz

**Domain Fit:** Das Paper ist primär für Datenschutz-, KI-Governance und Tech-Policy relevant, nicht direkt für Soziale Arbeit. Es bietet jedoch wichtige Erkenntnisse für Sozialarbeiter:innen, die mit algorithmischen Systemen in Bedarfserkennung, Ressourcenallokation oder Fallmanagement arbeiten.

**Unique Contribution:** Die systematische Integration von technischen XAI-Ansätzen mit Datenschutzrecht (GDPR), Fairness-Anforderungen und menschenzentrierten Designprinzipien unter Berücksichtigung von Risiken der XAI-Implementierung selbst.

**Limitations:** Begrenzte Analyse spezifischer Sektoren (erwähnt Gesundheit, Finanzen, keine detaillierte Behandlung von Soziale-Arbeit-Kontexten); keine empirischen Fallstudien oder Evaluationen von XAI-Implementierungen

**Target Group:** Datenschutzbeauftragte, KI-Entwickler:innen, Policy-Maker, Regulatorische Behörden, Organisationen die KI-Systeme einsetzen, sekundär: Sozialarbeiter:innen die mit automatisierten Entscheidungssystemen arbeiten

## Schlüsselreferenzen

- [[Miller_T_H_2017]] - Explainable AI: Beware of inmates running the asylum
- [[Ribeiro_M_T_2016]] - Why should I trust you? Explaining predictions of any classifier (LIME)
- [[Gunning_D_S_2019]] - XAI-Explainable Artificial Intelligence
- [[Burrell_J_2016]] - How the machine 'thinks': Understanding opacity in machine learning algorithms
- [[Lepri_B_O_2018]] - Fair, transparent, and accountable algorithmic decision-making processes
- [[Lipton_Z_C_2018]] - The mythos of model interpretability
- [[Mittelstadt_B_R_2019]] - Explaining explanations in AI
- [[Kuppa_A_2021]] - Adversarial XAI methods in cybersecurity
- [[Peters_U_2023]] - Explainable AI lacks regulative reasons: why AI and human decision-making are not equally opaque
