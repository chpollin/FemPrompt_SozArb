---
title: "Feminist Data Set"
authors: ["Caroline Sinders"]
year: 2017
type: report
language: en
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
processed: 2026-02-05
source_file: Sinders_2017_Feminist_Data_Set.md
---

# Feminist Data Set

## Kernbefund

Ein kritisches Kunstprojekt demonstriert, dass feministische und intersektionale Perspektiven auf jeden Schritt der maschinellen Lernentwicklung angewendet werden können – von der gemeinschaftlichen Datenerfassung über ethische Arbeitsmodelle bis zur Gestaltung von Benutzeroberflächen – um Bias abzubauen und gerechtere KI-Systeme zu schaffen.

## Forschungsfrage

Wie kann jeder Schritt des KI-Entwicklungsprozesses – von Datenerfassung über Datenlabeling bis zur Modellentwicklung – durch eine intersektional-feministische Linse kritisch hinterfragt und neu gestaltet werden?

## Methodik

Mixed Methods: Praxis-basierte Kunstforschung kombiniert mit partizipatorischen Workshops, Design-Thinking-Übungen, kritischem Design und gemeinschaftlicher Datenerfassung
**Datenbasis:** Qualitativ: Multi-jähriges Projekt mit Workshop-Serien in London (2017), Berlin und anderen Orten; Community-basierte Datenerfassung von literarischen/künstlerischen Werken aus intersektional-feministischer Perspektive; keine quantitativen Metriken angegeben

## Hauptargumente

- Maschinelles Lernen und Algorithmen sind nicht neutral – sie reproduzieren und verstärken bestehende Machtverhältnisse, Bias und Diskriminierung. Daher müssen alle Schritte der KI-Entwicklung kritisch durch intersektional-feministische Perspektiven untersucht werden.
- Daten sind nicht objektive oder kalte Fakten, sondern höchst persönliche, intime Artefakte menschlicher Aktivität und sozialer Beziehungen. Daher sollte Datenerfassung ein gemeinschaftlicher, konsensualer und transparenter Prozess sein – ähnlich wie nachhaltige 'farm-to-table' Lebensmittelproduktion.
- Die aktuelle gig-economy Praxis von Amazon Mechanical Turk zur Datenlabeling-Arbeit ist nicht feministisch, ethisch oder intersektional. Echte Fairness erfordert Lohngleichheit, Transparenz, sichere Arbeitsplätze, Governance-Strukturen und Arbeitnehmer-Kommunikation.
- Kritisches Design, der Maker Movement und Arte Útil bieten Vorbilder, um Technologie-Entwicklung außerhalb kapitalistische Logik zu denken und technische Expertise als gemeinschaftliche, iterative Praxis zu demokratisieren.
- Gemeinschaften – nicht einzelne Technologie-Konzerne – sollten Macht über Datenerfassung, -verwendung und -interpretation haben. Daten-Ownership und Community-Input sind Schlüssel zu gerechterer KI.

## Kategorie-Evidenz

### AI_Literacies

Das Projekt entwickelt kritische Medienkompetenz und Technologieverständnis durch Workshops und öffentliche Vermittlung. Sinders schreibt: 'Every step of the AI process that includes data collection, data labeling, data training, selecting an algorithm to use... through intersectional feminism as an investigatory framework'

### KI_Sonstige

Fokus auf maschinelles Lernen, Datenmodellierung, Algorithmen, Chatbots und neuronale Netze. Detaillierte Untersuchung der KI-Pipeline von Datenerfassung bis zum Einsatz.

### Soziale_Arbeit

Das Projekt zielt auf Gerechtigkeit, Community-Empowerment und Harm Reduction ab – zentrale Themen der Sozialen Arbeit. Sinders: 'What would it look like to create technology that acts as harm reduction, that acts actively as critique' und betont Community-Mitsprache und Vulnerabilität von marginalisierten Gruppen.

### Bias_Ungleichheit

Explizite Fokussierung auf Bias in ML-Systemen (Prison Sentencing, Facial Recognition, Hiring, Social Media Algorithms). Dokumentation struktureller Diskriminierung. Sinders: 'Machine learning algorithms have also been used in biased and unjust prison sentencing, in facial detection (or lack thereof), in biased hiring practices that favor male applicants'

### Gender

Expliziter Gender-Fokus auf Frauenrepräsentation und geschlechtsspezifische Auswirkungen von Technologie. Beispiel: Amazon Recruiting Tool mit Bias gegen Frauen. Sinders betont auch Cis-Frauen vs. Nicht-Cis-Frauen und deren unterschiedliche Erfahrungen.

### Diversitaet

Starker Fokus auf intersektionale Perspektiven und marginalisierte Communities. Sinders: 'we need to think about power, context, and privilege in society' und 'data must reflect the community's ideas'. Explizite Erwähnung von Frauen of Color, trans Personen, queerer Communities, indigenen Aktivisten und anderen marginalisierten Gruppen.

### Feministisch

Das Projekt ist explizit in intersektionaler feministischer Theorie verankert. Direkter Bezug zu: Kimberlé Crenshaw (Intersektionalität), Donna Haraway (Cyborg Manifesto), Feminist Principles of the Internet, Xenofeminism, Data Feminism (implizit). Sinders nutzt feministische Methodologie (consent, agency, care, collective knowledge production) als Investigativ-Framework für jeden Schritt der KI-Entwicklung.

### Fairness

Fokus auf faire Arbeitsbedingungen (Lohngleichheit auf Mechanical Turk), Transparenz, Governance, Arbeitnehmerkommunikation und faire Datenverwendung. Sinders: 'A system that creates competition amongst laborers, that discourages a union, that pays pennies per repetitive task, and that creates nameless and hidden labor is not ethical, nor is it feminist.'

## Assessment-Relevanz

**Domain Fit:** Hochgradig relevant für die Schnittstelle KI/Soziale Arbeit/Gender. Das Paper verbindet kritische Perspektiven auf algorithmische Gerechtigkeit mit Sozialer Arbeit (Community Empowerment, Harm Reduction, vulnerable Populationen) und durchgehend mit intersektional-feministischer Theorie und Praxis. Es bietet konkrete Handlungsansätze, nicht nur Kritik.

**Unique Contribution:** Das Paper leistet einen innovativen Beitrag durch die Operationalisierung intersektional-feministischer Perspektiven auf die GESAMTE KI-Entwicklungs-Pipeline (nicht nur Bias-Kritik) und durch ein praktizierten Kunstprojekt, das gemeinschaftliche, ethische und transparente Alternativen zu bestehenden Systemen (z.B. Mechanical Turk) demonstriert.

**Limitations:** Das Paper ist hauptsächlich konzeptuell und künstlerisch, nicht quantitativ evaluierend; die empirische Datensammlung ist qualitativ und begrenzt auf Workshop-Teilnehmer; längerfristige Wirkungsanalyse der Interventionen wird nicht angegeben; technische Implementierung des geplanten feministischen Chatbots wird noch nicht detailliert beschrieben.

**Target Group:** KI-Entwickler und Data Scientists (zur kritischen Reflexion bestehender Praktiken), Sozialarbeiter und Community Worker (zur Integration von Technology Justice und kritischer Technologieperspektive in ihre Praxis), Feminist und Gender Studies Scholars (zur Anwendung intersektional-feministischer Theorie auf konkrete technische Domänen), Policy-Maker und Organisationen (zur Umgestaltung von Daten- und KI-Governance), Künstler und Aktivisten (als Modell für kritisches und praktisches politisches Arbeiten)

## Schlüsselreferenzen

- [[Crenshaw_Kimberlé_1991]] - Mapping the Margins: Intersectionality, Identity Politics, and Violence Against Women of Color
- [[Haraway_Donna_None]] - Cyborg Manifesto
- [[Feminist_Principles_of_the_Internet_Collective_2016]] - Feminist Principles of the Internet v. 2.0
- [[Dunne_Anthony_Raby_Fiona_2001]] - Design Noir: The Secret Life of Electronic Objects
- [[Critical_Engineering_Working_Group_Oliver_J_Savičić_G_Vasiliev_D_2011]] - The Critical Engineering Manifesto
- [[Bruguera_Tania_None]] - Arte Útil (Useful Art)
- [[Angwin_J_Larson_J_Mattu_S_Kirchner_L_2016]] - Machine Bias
- [[Thwaites_Thomas_None]] - The Toaster Project
- [[Malpass_Matt_2016]] - Critical Design in Context: History, Theory, and Practices
