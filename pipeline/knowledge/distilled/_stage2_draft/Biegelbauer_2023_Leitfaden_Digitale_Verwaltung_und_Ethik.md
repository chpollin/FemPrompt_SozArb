---
title: "Leitfaden Digitale Verwaltung und Ethik. Praxisleitfaden für KI in der Verwaltung, Version 1.0"
authors: ["Peter Biegelbauer", "Caroline Lackinger", "Sven Schlarb", "Edgar Subak", "Pia Weinlinger"]
year: 2023
type: report
language: de
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Biegelbauer_2023_Leitfaden_Digitale_Verwaltung_und_Ethik.md
---

# Leitfaden Digitale Verwaltung und Ethik. Praxisleitfaden für KI in der Verwaltung, Version 1.0

## Kernbefund

Ein menschenzentriertes KI-Governance-Modell für die öffentliche Verwaltung, das Rechtmäßigkeit als Minimalbedingung, aber ethische Prinzipien (Transparenz, Fairness, Sicherheit, Inklusion, Rechenschaftspflicht) als zentral für vertrauenswürdige KI positioniert.

## Forschungsfrage

Wie können Verwaltungsbedienstete KI-basierte Anwendungen ethisch, rechtlich und nachhaltig in der öffentlichen Verwaltung planen, entwickeln, beschaffen, einsetzen und evaluieren?

## Methodik

Theoretisch/Mixed – Literaturanalyse, Stakeholder-Workshops mit Verwaltungsbediensteten, Expert:innen-Konsultation; Entwicklung von praktischen Checklisten und Kriterienkatalogen
**Datenbasis:** Workshops mit Verwaltungsbediensteten (Zeitverlauf dokumentiert), Integration von EU-Normierungen (AI Act, DSGVO), österreichische KI-Strategie (AIM AT 2030), Analyse bestehender KI-Folgenabschätzungsinstrumente

## Hauptargumente

- Rechtliche Compliance allein ist unzureichend für ethische KI: Der Leitfaden argumentiert, dass Gesetzeseinhaltung notwendig, aber nicht hinreichend ist; ethische Prinzipien müssen von Anfang an ('Ethics by Design') in KI-Systeme integriert werden, insbesondere um Grundrechte zu schützen.
- KI-Anwendungen in der Verwaltung erfordern kontinuierliche Risikofolgenabschätzung und externe Überwachung: Besonders bei Hochrisiko-Systemen (Strafverfolgung, Migration, Sozialleistungen) müssen vor, während und nach der Implementierung systematische Bewertungen durchgeführt werden, um unerwünschte gesellschaftliche Auswirkungen zu vermeiden.
- KI-Literacies und digitale Souveränität sind Voraussetzung für menschenzentrierte Governance: Verwaltungsbedienstete benötigen grundlegende KI-Kompetenzen, um auf Augenhöhe mit Dienstleistern zu verhandeln, sensible Daten zu schützen und die Effektivität von KI-Systemen zu bewerten.

## Kategorie-Evidenz

### AI_Literacies

KI Literacy wird als eigenständige Maßnahme definiert: 'Förderung eines Grundverständnisses von KI-Anwendungen, deren Voraussetzungen und Anwendungen sowie deren Auswirkung auf Verwaltung, Staat und Gesellschaft als Grundbedingung'. Der Leitfaden fordert explizit: 'Durch welche Maßnahmen wird die KI-Kompetenz der Verwaltungsbediensteten gefördert' und 'Wie wird die KI-Kompetenz der breiten Öffentlichkeit [...] gefördert?'

### KI_Sonstige

Der Leitfaden behandelt vielfältige KI-Technologien: Maschinelles Lernen, neuronale Netze, Chatbots, Algorithmen, Predictive Analytics. Kapitel 3 'Technik: Was ist KI?' bietet grundlegende technische Erklärungen. Der AI Act wird detailliert analysiert mit seiner Risikopyramide für verschiedene KI-Systeme.

### Soziale_Arbeit

Die Verwaltung wird als Kontaktpunkt zwischen Bürgern und Staat mit sozialer Verantwortung positioniert: 'Vertrauen in öffentliche Institutionen kann bei negativen Auswirkungen von Verwaltungshandlungen rasch beschädigt werden'. Konkrete Auswirkungen auf vulnerable Gruppen werden thematisiert, z.B. in Bereichen Strafverfolgung, Migration, Infrastruktur, Sozialleistungen.

### Bias_Ungleichheit

Unvoreingenommenheit und Fairness sind eigenständiges Kriterium: 'Verwendung vielfältiger Daten und Modelle, um zu vermeiden, dass bestehende Vorurteile fortbestehen bzw. in der KI-Anwendung implizit mitwirken'. Die Checkliste fragt: 'Wurde sichergestellt, dass die KI-Anwendung keine Personen stigmatisieren oder diskriminieren kann? (Z. B. aufgrund von Geschlecht, ethnischer oder sozialer Herkunft, Alter, sexueller Ausrichtung, Religion oder Weltanschauung)'.

### Diversitaet

Barrierefreiheit und Inklusion werden als eigenständiges Kriterium verankert: 'Möglichkeit der Nutzung und Verfügbarkeit von KI-Technologien für Personen mit unterschiedlichen Fähigkeiten, Hintergründen und Kulturen'. Fragen zur Inklusion: 'Wie wird die KI-Anwendung für Menschen mit unterschiedlichen Fähigkeiten, Hintergründen und Kulturen zugänglich und integrativ gestaltet?'

### Fairness

Fairness ist explizites Fairness-Kriterium im EKIV-Katalog: 'Unvoreingenommenheit und Fairness: Verwendung vielfältiger Daten und Modelle, um zu vermeiden, dass bestehende Vorurteile fortbestehen'. Der Leitfaden fragt: 'Welche Kriterien werden verwendet, um festzustellen, ob die Anwendung fair ist?' und 'Wie wird sichergestellt, dass die zum Training der KI-Anwendung verwendeten Daten vielfältig und repräsentativ sind?'

## Assessment-Relevanz

**Domain Fit:** Hochrelevant für die Schnittstellenanalyse KI/Soziale Arbeit/öffentliche Dienste: Der Leitfaden adressiert explizit die Auswirkungen von KI auf vulnerable Zielgruppen der Verwaltung (Sozialleistungsempfänger, Migranten, Strafverfolgungsobjekte) und fordert menschenzentrierte Governance mit Inklusion und Fairness als Kernprinzipien.

**Unique Contribution:** Der deutschsprachige Praxisleitfaden übersetzt komplexe EU-Normierungen (AI Act, DSGVO, AIM AT 2030) in einen operationalisierbaren Kriterienkatalog (EKIV) mit konkreten Checklisten und Maßnahmensätzen für österreichische Verwaltungspraktiker:innen.

**Limitations:** Der Leitfaden ist primär normativ-empfehlend, basiert auf limitierter empirischer Datenerhebung (Workshop-Inputs dokumentiert, aber nicht systematisch evaluiert); fehlende Evidenz zur Effektivität der empfohlenen Maßnahmen in der Praxis; Gender und feministische Perspektiven werden nicht explizit berücksichtigt, obwohl diese bei KI-Bias zentral sind.

**Target Group:** Primär: Verwaltungsbedienstete, Manager:innen und Entwickler:innen in der österreichischen Bundesverwaltung. Sekundär: Policymaker:innen, KI-Beschaffer, Aufsichtsbehörden, breite Öffentlichkeit als betroffene Bürger:innen, Sozialarbeitende in Kontakt mit Verwaltungssystemen, Forschende zu Government Innovation und KI-Governance.

## Schlüsselreferenzen

- [[European_Commission_2021]] - AI Act - Proposal for a Regulation
- [[BMDW_und_BMK_2021]] - Artificial Intelligence Mission Austria 2030 (AIM AT 2030)
- [[Ebers_et_al_2021]] - Kritik am AI Act - Überregulierung und Grundrechtsschutz
- [[EDRi_European_Digital_Rights_2023]] - Fokus auf Grundrechte und Schutz von KI-System-Betroffenen
- [[Hidvegi_et_al_2021]] - Rechtebasierte Regulierung vs. risikobasierter Ansatz
- [[Lachmayer_2018]] - Datenschutz und Verwaltungsrecht in Österreich
- [[Access_Now_2023]] - NGO-Kritik an risikobasiertem AI Act Zugang
- [[Madiega_2022]] - EU AI Governance und Selbsteinschätzungsrisiken
