---
title: "The AI Act, gender equality and non-discrimination: what role for the AI office?"
authors: ["Fabian Lütz"]
year: 2024
type: journalArticle
language: en
processed: 2026-02-05
source_file: Lütz_2024_The_AI_Act,_gender_equality_and.md
confidence: 91
---

# The AI Act, gender equality and non-discrimination: what role for the AI office?

## Kernbefund

Der AI Act bietet einige Mechanismen zur Adressierung von Geschlechtergleichstellung und Diskriminierung durch Fundamental Rights Impact Assessments und Bias Audits, bleibt aber durch Ausnahmen und begrenzte Reichweite insuffizient. Eine umfassendere Zusammenarbeit zwischen AI Office, nationalen Gleichstellungsbehörden und internationalen Institutionen ist notwendig.

## Forschungsfrage

Inwiefern adressiert der EU AI Act angemessen Fragen der Geschlechtergleichstellung und Nichtdiskriminierung, und welche Rolle kann das AI Office dabei spielen?

## Methodik

Theoretisch/Review - Doctrinal legal analysis mit kritischer Evaluierung von EU-Regulierungsrahmen und deren Bestimmungen zum Schutz von Grundrechten
**Datenbasis:** Nicht empirisch - Dokumentenanalyse des finalen AI Act Textes (Council of the European Union 2024), EU-Richtlinien, Commission Decision zur AI Office, internationale Regelungsvorschläge (Council of Europe, UN)

## Hauptargumente

- Der AI Act klassifiziert bestimmte Anwendungsfälle (Recruitment, Bildung, Zugang zu Diensten) als hochriskant, wodurch Schutzmaßnahmen gegen Geschlechterdiskriminierung ermöglicht werden, aber kritische Ausnahmen (narrow procedural tasks, preparatory tasks) gefährden diese Schutzwirkung.
- Das AI Office als neue EU-Governance-Institution kann eine zentrale Rolle bei der Implementierung geschlechtergleichstellungsbezogener AI-Regulierung spielen, benötigt aber klare Kooperationsmechanismen mit bestehenden Gleichstellungsbehörden und Direktoraten-Generalstäben der Kommission.
- Auf internationaler Ebene (Council of Europe, UN) wird Geschlechtergleichstellung zunehmend in AI-Governance-Diskursen adressiert, jedoch bleibt die EU-Ansatz in diesen multilateralen Prozessen zentral für die Etablierung eines fundamentrechtsgestützten Standards.
- Geschlechterausgewogenheit in AI-Entwicklungsteams wird im AI Act anerkannt (Recital 165), wird aber als freiwillige Anforderung für Low-Risk-Systeme konzipiert und ist daher unzureichend für systematische Diversitätsverbesserungen in der AI-Branche.

## Kategorie-Evidenz

### Evidenz 1

The article discusses Large Language Models (LLMs) and Generative AI: 'Since Large Language Models (LLMs) and Generative AI entered the public discussion and legislative proposals, the topic of AI regulation has received increased public attention' (Introduction). Specific examples: 'Open AI's GPT-4' with discussion of model cards showing bias representations.

### Evidenz 2

Comprehensive analysis of AI Act's treatment of high-risk AI systems in recruitment, education, employment decisions, and algorithmic decision-making systems. Discussion of 'the classification of AI systems as high risk is conducted in accordance with Art. 6 AI Act' and various application domains.

### Evidenz 3

Central theme throughout: 'The term 'biases' makes seventeen appearances' in the AI Act. Detailed analysis of algorithmic discrimination: 'the risk of harm to health and safety, or an adverse impact on fundamental rights' and how 'some AI systems with potentially negative impacts for gender would not have these mandatory compliance obligations'.

### Evidenz 4

The paper consistently emphasizes gender equality as a fundamental right to be protected through AI regulation. Specific case example cited: 'An often-cited example concerns a recruitment algorithm used by a tech company which potentially had discriminatory effects on women.' Discussion of 'the lack of diversity among AI developers' as contributor to gender bias.

### Evidenz 5

Emphasis on inclusive and diverse design: 'inclusive and diverse design and development of AI systems, including attention to vulnerable persons and accessibility to persons with disability' (Recital 81). Discussion of diverse development teams and representation in decision-making systems.

### Evidenz 6

Analysis of fairness mechanisms: 'fundamental rights impact assessments and bias audits to reduce gender biases and discriminatory risk'. Discussion of 'fairness-aware' compliance obligations and tools like 'Equalized Odds, Demographic Parity' through the lens of algorithmic fairness.

## Assessment-Relevanz

**Domain Fit:** Hohes Relevanzpotenzial für die Schnittstelle KI und Geschlechtergerechtigkeit, mit Fokus auf policy-Ebene. Für Soziale Arbeit nur indirekt relevant, da keine explizite Behandlung sozialarbeiterischer Praxis oder Zielgruppen, sondern Fokus auf EU-Regulierung und institutionelle Governance.

**Unique Contribution:** Bietet erste umfassende rechtsdogmatische Analyse des EU AI Act durch die Linse von Geschlechtergleichstellung und Nichtdiskriminierungsrecht und positioniert europäische AI-Governance in internationalem Kontext (Council of Europe, UN).

**Limitations:** Rein rechtliche Analyse ohne empirische Daten zu tatsächlichen Diskriminierungsrisiken oder Implementierungserfolgen. Keine Daten zu bisherigen Algorithmus-Audits oder deren Effektivität. Fokus auf EU-Regulierung begrenzt Übertragbarkeit auf andere Jurisdiktionen.

**Target Group:** Rechtspolitiker:innen und Regulatoren, EU-Institutionen (insbesondere AI Office), nationale Gleichstellungsbehörden, AI-Governance-Forscher:innen, Verfechter:innen von Geschlechtergleichstellung in Tech, Legal Scholars im Bereich EU-Recht und Diskriminierungsschutz

## Schlüsselreferenzen

- [[Bolukbasi_Chang_Zou_Saligrama_Kalai_2016]] - Man is to computer programmer as woman is to homemaker? Debiasing word embeddings
- [[Criado_Perez_2019]] - Invisible Women: Exposing Data Bias in a World Designed for Men
- [[Broussard_2023]] - More than a Glitch: Confronting Race, Gender, and Ability Bias in Tech
- [[Malgieri_Pasquale_2024]] - Licensing high-risk artificial intelligence: toward ex ante justification for a disruptive technology
- [[Allen_Masters_2020]] - Artificial Intelligence: the right to protection from discrimination caused by algorithms, machine learning and automated decision-making
- [[Gerards_Borgesius_2022]] - Protected grounds and the system of non-discrimination law in the context of algorithmic decision-making and artificial intelligence
- [[Xenidis_Senden_2020]] - EU non-discrimination law in the era of artificial intelligence: mapping the challenges of algorithmic discrimination
- [[Council_of_Europe_2023]] - Study on the impact of artificial intelligence systems, their potential for promoting equality, including gender equality, and the risks they may cause in relation to non-discrimination
- [[AlonBarkat_Busuioc_2023]] - Human-AI interactions in public sector decision making: 'automation bias' and 'selective adherence' to algorithmic advice
- [[Mitchell_2019]] - Artificial Intelligence: A Guide for Thinking Humans
