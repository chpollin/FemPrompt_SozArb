---
title: "Avoiding Catastrophe Through Intersectionality in Global AI Governance"
authors: ["Laine McCrory"]
year: 2024
type: workingPaper
language: en
processed: 2026-02-05
source_file: McCrory_2024_Avoiding_catastrophe_through_intersectionality_in.md
confidence: 95
---

# Avoiding Catastrophe Through Intersectionality in Global AI Governance

## Kernbefund

Keine der sieben analysierten KI-Sicherheits-Initiativen erfüllt die intersektionalen und feministischen Standards des Frameworks; die KI-Sicherheitsbewegung versäumt es, aktuelle Schäden für marginalisierte Gruppen zu adressieren und diese mit zukünftigen existenziellen Risiken zu verbinden.

## Forschungsfrage

Wie können intersektionale und feministische Perspektiven in die globale KI-Sicherheitspolitik integriert werden, um existenzielle Risiken für marginalisierte Gruppen angemessen zu adressieren?

## Methodik

Theoretisch-analytisch: Entwicklung eines feministischen KI-Policy-Analyse-Frameworks mit fünf Themenbereichen (Intersektionalität, Kontext, Neutralität, Kontrolle, Macht) zur Bewertung von sieben internationalen KI-Sicherheits-Initiativen mittels qualitativ-analytischer Kodierung.
**Datenbasis:** Dokumentenanalyse von 7 internationalen KI-Sicherheits-Governance-Initiativen (UN-Resolutionen, OECD-Prinzipien, Asilomar Principles, Bletchley Declaration, Seoul Declaration, Frontier AI Safety Commitments, OECD Safe AI Principles)

## Hauptargumente

- Die KI-Sicherheitsbewegung konzentriert sich zu stark auf zukünftige existenzielle Risiken (AGI) und ignoriert dabei die bereits existierenden, disproportionalen Schäden von KI-Systemen für marginalisierte Gruppen (Frauen, Racial-ized People, wirtschaftlich benachteiligte Gruppen), die als ebenso existenziell wahrgenommen werden.
- Aktuelle KI-Sicherheits-Governance-Initiativen basieren auf universalistischen Annahmen von Risiko und Benefit, die die heterogenen Erfahrungen marginalisierter Gruppen ignorieren und deren Partizipation in Policy-Entwicklungsprozessen ausschließen, wodurch reproduzieren sie bestehende Machtstrukturen.
- Ein feministisches KI-Policy-Framework, das auf Intersektionalität, Kontextbewusstsein, Kritik an Neutralität, und Machtverschiebung basiert, kann als Audit-Tool dienen, um KI-Sicherheitspolitiken auf Accountability und meaningful participation zu überprüfen und existenzielle Risiken auf unterschiedlichen sozialen Ebenen anzuerkennen.

## Kategorie-Evidenz

### Evidenz 1

Paper diskutiert 'AI knowledge' und kritisiert OECD-Definition, die 'lived experiences and diverse knowledge' nicht einbezieht: 'This definition fails to incorporate lived experiences and diverse knowledge into the development of AI safety plans.'

### Evidenz 2

Fokus auf AI Safety, AGI, AI-Governance, existenzielle Risiken von KI-Systemen und deren Auswirkungen auf verschiedene Bevölkerungsgruppen.

### Evidenz 3

Paper integriert Feminist Policy Analysis Framework aus Sozialarbeit (McPhail 2003, Kanenberg 2013) und adressiert vulnerable Populations und marginalisierte Communitys als zentrale Zielgruppe.

### Evidenz 4

Zentral: 'Scholarship in critical data studies demonstrates how AI reinforces inequalities related to race, sexuality, class and gender' und 'AI regularly replicates broader social biases and power dynamics.'

### Evidenz 5

Kern des Papers: 'AI research is characterized by a diversity problem, facing not only a lack of diverse perspectives within technical development...but also a lack of representation in the framing of policy narratives' und intersektionale Analyse von Identitäten (Geschlecht, Rasse, Klasse, Sexualität, Fähigkeit, etc.).

### Evidenz 6

Explizite Verwendung feministischer Theorie (Kimberlé Crenshaw - Intersektionalität, D'Ignazio & Klein - Data Feminism, Beverly McPhail - Feminist Policy Analysis Framework, Patricia Hill Collins - outsider within). Framework ist explizit 'Feminist AI Policy Framework'.

### Evidenz 7

Diskussion von substantive versus formal equality: 'they fail to detail how these shares will be distributed according to equitable need (substantive equality) as opposed to provision of a single level of support and resources for all (formal equality).'

## Assessment-Relevanz

**Domain Fit:** Sehr hohe Relevanz für KI/Soziale Arbeit/Gender-Schnittstelle: Paper verbindet explizit feministische Policy-Analyse (Sozialarbeit-Tradition) mit KI-Governance-Kritik und adressiert marginalisierte Gruppen als zentrale Stakeholder, die von KI-Systemen disproportional geschädigt werden.

**Unique Contribution:** Entwicklung eines operationalisierbaren feministischen KI-Policy-Analyse-Frameworks und empirische Anwendung auf sieben internationale AI-Sicherheits-Initiativen, die zeigt, dass existenzielle KI-Risiken mit aktuellen strukturellen Harms marginalisierter Gruppen verbunden sein müssen.

**Limitations:** Dokumentenanalyse ohne Interviews mit Stakeholdern oder betroffenen Communitys; Framework-Scores basieren auf binären Bewertungen ohne detaillierte Gewichtung; begrenzte Anzahl analysierter Initiativen (n=7).

**Target Group:** KI-Policy-Maker und Governance-Spezialist:innen, feministische Technologie-Forscher:innen, Sozialarbeiter:innen und Care-Professionals, Aktivist:innen und Advocate:innen marginalisierter Gruppen, Kritische Data Studies Forscher:innen, Organisationen im Bereich AI Ethics und Fairness

## Schlüsselreferenzen

- [[Crenshaw_Kimberlé_1991]] - Mapping the Margins: Intersectionality, Identity Politics, and Violence against Women of Color
- [[DIgnazio_Catherine_Klein_Lauren_F_2020]] - Data Feminism
- [[McPhail_Beverly_A_2003]] - A Feminist Policy Analysis Framework: Through a Gendered Lens
- [[Buolamwini_Joy_Gebru_Timnit_2018]] - Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification
- [[Benjamin_Ruha_2019]] - Race after Technology: Abolitionist Tools for the New Jim Code
- [[Gebru_Timnit_Torres_Émile_P_2024]] - The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence
- [[Crawford_Kate_2021]] - The Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence
- [[Noble_Safiyah_Umoja_2018]] - Algorithms of Oppression: How Search Engines Reinforce Racism
- [[Eubanks_Virginia_2018]] - Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor
- [[Kanenberg_Heather_Leal_Roberta_Erich_Stephen_2020]] - Revising McPhail's Feminist Policy Analysis Framework: Updates for Use in Contemporary Social Policy Research
