---
title: "Tensions in digital welfare states: Three perspectives on care and control"
authors: ["Irina Zakharova", "Juliane Jarke", "Anne Kaun"]
year: 2024
type: journalArticle
language: en
categories:
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Gender
  - Diversitaet
  - Feministisch
  - Fairness
processed: 2026-02-05
source_file: Zakharova_2024_Tensions_in_digital_welfare_states_Three.md
confidence: 95
---

# Tensions in digital welfare states: Three perspectives on care and control

## Kernbefund

Digitale Wohlfahrtstechnologien verschieben das Gleichgewicht zwischen Care und Kontrolle zugunsten der Kontrolle und transformieren Care-Praktiken potenziell in schädliche Kontrollmaßnahmen. Ein analytisches Framework auf drei Ebenen (Werte, Infrastrukturen, Datenarbeit) ermöglicht die Analyse dieser Spannungen.

## Forschungsfrage

Wie manifestieren sich Spannungen zwischen Fürsorge (care) und Kontrolle in digitalen Wohlfahrtsstaaten, und wie können diese Spannungen auf den Ebenen von Werten, Infrastrukturen und Datenarbeit analysiert werden?

## Methodik

Theoretisch-konzeptionell mit empirischen Vignetten aus Deutschland und Schweden; qualitative Fallstudien und dokumentenanalyse in drei Welfare-Domänen (Altenpflege, Wohnen, Bildung)
**Datenbasis:** Drei empirische Vignetten basierend auf längerfristigen Forschungsprojekten der Autor:innen in Deutschland (Zakharova & Jarke) und Schweden (Kaun & Löfgren); qualitative Interviews, Systembeobachtungen, Dokumentenanalyse

## Hauptargumente

- Digitale Wohlfahrtstechnologien werden durch Logiken der Kontrolle, Überwachung und Effizienz geprägt, die mit Care-Versprechen rechtfertigt werden, aber letztlich sorgende Beziehungen gefährden.
- Auf der Ebene von Werten privilegieren digitale Systeme Standardisierung und Individualisierung, was die Heterogenität und Intersektionalität von Bedürfnissen unsichtbar macht und marginalisierte Gruppen (Migrant:innen, ältere Menschen, Frauen) überproportional betrifft.
- Infrastrukturelle und Datenarbeit (besonders niedrig bezahlte, weiblich geprägte Arbeit wie die von Schulsekrerärinnen) wird als unsichtbar und unterbewertet behandelt, während hochwertige technische Designarbeit privilegiert wird; dies reproduziert strukturelle Ungleichheiten.

## Kategorie-Evidenz

### KI_Sonstige

Algorithmen, digitale Infrastrukturen, Datenifikation, automatisierte Entscheidungssysteme in Wohlfahrtsadministration: 'Digital technologies, however, are often developed in line with a logic of control and dispositions around surveillance and efficiency'

### Soziale_Arbeit

Digitale Wohlfahrtsleistungen, Care-Arbeit, Altenbetreuung, Wohnungsversorgung, Schulverwaltung: 'welfare technologies use digital data in decisions on citizenship; welfare benefit eligibility assessment, calculation, and payments'

### Bias_Ungleichheit

Intersektionale Diskriminierung, Überwachung vulnerabler Gruppen, strukturelle Benachteiligung: 'vulnerable populations often emerge as testing grounds for new technologies relating to the intersection of class-based racial and citizenship dynamics'

### Gender

Unsichtbare, weiblich geprägte Datenarbeit, geschlechtsspezifische Arbeitsteilung: 'secretaries...were predominantly women...and often part-time working women...receive' niedrigere Löhne als männliche Datenspezialisten

### Diversitaet

Intersektionalität, marginalisierte Communities, mehrfach diskriminierte Gruppen: 'Intersectional perspectives further shed light on the multiple ways in which care is not only gendered, but is also provided and received according to other, overlapping socio-demographic and socio-economic categories'

### Feministisch

Explizite Anwendung feministischer Care-Theorie (Tronto, Puig de la Bellacasa, Sevenhuijsen), intersektionale feministische Perspektive: 'The concept and ethics of care has a long tradition in feminist and sociological thought' und 'we understand government care as a social capacity and activity involving the nurturing of all that is necessary for the welfare and flourishing of life'

### Fairness

Fairness im Zugang zu Care, gerechtfertigte Systeme, soziale Gerechtigkeit, algorithmische Ungerechtigkeit: 'we add to the literature concerned with social justice by shifting attention from big-scale ethics of digital technologies to the everyday lived experiences in-between state control and care'

## Assessment-Relevanz

**Domain Fit:** Sehr hohes Relevanz für Schnittstelle AI/Soziale Arbeit/Gender: Das Paper integriert explizit feministische Care-Theorie mit Kritik algorithmischer Systeme in Wohlfahrtsadministration und thematisiert Care-Arbeit als intersektional geprägte, geschlechtsspezifische Praxis, die durch Digitalisierung neu konfiguriert wird.

**Unique Contribution:** Der Beitrag liegt in der Synthesis von Care-Ethik und kritischen Daten-/AI-Studien sowie in einem dreischichtigen analytischen Framework (Werte-Infrastrukturen-Datenarbeit), das die Kontingenz und Kontextgebundenheit von Care in digitalen Wohlfahrtssystemen sichtbar macht.

**Limitations:** Begrenzte empirische Basis (drei Vignetten), regionale Fokussierung auf Deutschland und Schweden (nicht globaler Süden), begrenzte Detailtiefe in Fallstudien; keine systematische Vergleichbarkeit zwischen Wohlfahrtssystemen.

**Target Group:** Sozialarbeiter:innen und Care-Fachkräfte, KI-Ethiker:innen und kritische Daten-Wissenschaftler:innen, Policymaker in Wohlfahrtssystemen, Feminist AI/Digital Justice Scholars, Technologie-Designer:innen in public administration, Organisationen im Bereich Altenbetreuung, Wohnen und Bildung

## Schlüsselreferenzen

- [[Eubanks_Virginia_2017]] - Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor
- [[Tronto_Joan_C_2016]] - Who Cares? How to Reshape a Democratic Politics
- [[Puig_de_la_Bellacasa_María_2017]] - Matters of Care: Speculative Ethics in More Than Human Worlds
- [[Dencik_Lina_Kaun_Anne_2020]] - Datafication and the Welfare State
- [[Sevenhuijsen_Selma_2003]] - The Place of Care: The Relevance of the Feminist Ethic of Care for Social Policy
- [[CostanzaChock_Sasha_2020]] - Design Justice: Community-Led Practices to Build the Worlds We Need
- [[Emejulu_Akwugo_Bassel_Leah_2018]] - Austerity and the Politics of Becoming
- [[Allhutter_Doris_et_al_2020]] - Algorithmic Discrimination and Bias in Decision-Making Systems
- [[Zakharova_Irina_Jarke_Juliane_2022]] - Educational Technologies as Matters of Care
- [[The_Care_Collective_2020]] - The Care Manifesto: The Politics of Interdependence
