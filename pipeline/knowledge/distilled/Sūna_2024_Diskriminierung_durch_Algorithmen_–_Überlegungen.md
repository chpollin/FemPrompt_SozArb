---
title: "Diskriminierung durch Algorithmen – Überlegungen zur Stärkung KI-bezogener Kompetenzen"
authors: ["Laura Sūna", "Dagmar Hoffmann", "Anne Mollen"]
year: 2024
type: book
language: de
categories:
  - AI_Literacies
  - KI_Sonstige
  - Soziale_Arbeit
  - Bias_Ungleichheit
  - Diversitaet
  - Fairness
processed: 2026-02-05
source_file: Sūna_2024_Diskriminierung_durch_Algorithmen_–_Überlegungen.md
confidence: 94
---

# Diskriminierung durch Algorithmen – Überlegungen zur Stärkung KI-bezogener Kompetenzen

## Kernbefund

KI-bezogene Kompetenzen müssen drei Dimensionen umfassen (kognitiv, affektiv, handlungsbezogen), um algorithmen-basierte Diskriminierung zu erkennen und zu adressieren. Es besteht ein erhebliches Kompetenzdefizit und eine 'digitale Resignation' bei betroffenen Gruppen.

## Forschungsfrage

Wie können digital benachteiligte Gruppen für algorithmische Diskriminierung sensibilisiert und zu einem kompetenten Umgang mit KI-Systemen ermächtigt werden?

## Methodik

Theoretisch-konzeptionell mit Integration empirischer Befunde aus Studien (qualitative Fokusgruppen mit 25 Personen mit Migrationsgeschichte, sowie Sekundäranalyse bestehender Forschungsliteratur)
**Datenbasis:** Qualitative Studie: 25 Personen mit Migrationsgeschichte in 5 Fokusgruppen; Sekundärliteratur und Meta-Analysen bestehender Studien (MeMo:Ki 2021, Schober et al. 2022, Bozdag 2022)

## Hauptargumente

- Algorithmische Systeme reproduzieren und verstärken bestehende strukturelle Ungleichheiten durch drei ineinander greifende Mechanismen: verzerrte Trainingsdaten (Sample Bias), diskriminierende algorithmische Modelle (Proxy-Variablen), und diskriminierende Anwendung durch Automation Bias bei Entscheidungsträgern.
- Nutzer:innen, insbesondere aus marginalisierten Gruppen, nehmen algorithmische Diskriminierung oft nicht oder nur fragmentarisch wahr und entwickeln eine 'digitale Resignation', die ihre Handlungsfähigkeit einschränkt, während ihnen gleichzeitig Zugang zu den sie betreffenden Daten und Entscheidungskriterien fehlt.
- Medienmediopädagogische Arbeit auf drei Ebenen (informieren, sensibilisieren, ermächtigen) mit Fokus auf KI-Kompetenzen ist notwendig, muss aber durch regulatorische Anpassungen (AGG-Weiterentwicklung) und zivilgesellschaftliche Strukturen flankiert werden, um Betroffene nicht allein zu lasten.

## Kategorie-Evidenz

### AI_Literacies

KI-bezogene Kompetenzen umfassen: 'das Bewusstsein und die Wahrnehmung der Allgegenwärtigkeit von algorithmen-basierten und KI-getriebenen Prozessen' sowie 'die Fähigkeit, KI-geprägte Entscheidungen kritisch und affektiv zu bewerten und zu hinterfragen'. Gefordert wird 'umfassende medienpädagogische Arbeit' auf allen Lebensbereichen.

### KI_Sonstige

Fokus auf algorithmen-basierte Entscheidungssysteme, Empfehlungsalgorithmen, maschinelles Lernen und automatisierte Klassifikationssysteme in verschiedenen Anwendungsbereichen (Bildung, Arbeitsmarkt, Gesundheit, Justiz, predictive policing).

### Soziale_Arbeit

Zielgruppen sind Menschen mit Migrationsgeschichte, im höheren Lebensalter, mit niedrigem Bildungsniveau – klassische Adressaten Sozialer Arbeit. Kontext: 'Zugang zu Sozialleistungen' als besonders anfälliger Bereich. Beratungsstrukturen und zivilgesellschaftliche Unterstützungsangebote werden als notwendig erachtet.

### Bias_Ungleichheit

Zentrale These: 'diverse KI-basierte Systeme reproduzieren und verstärken Ungleichheit und Exklusion'. 'Strukturelle Ungleichheiten von Algorithmen werden teils sogar überbetont'. Spezifische Analyse von Mechanismen wie Sample Bias, Proxy-Variablen und Skalierungseffekten der Diskriminierung.

### Diversitaet

Expliziter Fokus auf marginalisierte Gruppen: 'Gruppen, die von (digitaler) Ungleichheit besonders betroffen sind, wie beispielsweise Migrant*innen, Frauen, Menschen im höheren Lebensalter oder mit niedrigem Bildungsniveau'. Intersektionale Perspektive: 'Diskriminierung kann aus der Kombination unterschiedlicher geschützter Merkmale entstehen'.

### Fairness

Algorithmen-basierte Diskriminierung wird als Fairness-Problem konzeptualisiert. 'Nutzer*innen werden aufgrund ihrer persönlichen Daten [...] ungerecht, unethisch oder einfach nur anders behandelt'. Fairness erfordert kritische Bewertung, Transparenz und Verantwortlichkeit von Systemen.

## Assessment-Relevanz

**Domain Fit:** Das Paper ist hochrelevant für die Schnittstelle KI/Soziale Arbeit/Diversität: Es adressiert vulnerable Gruppen (Migrant:innen, ältere Menschen, bildungsferne Personen), analysiert systematisch Diskriminierungsmechanismen in KI-Systemen und entwickelt einen medienpädagogischen Ansatz zur Befähigung betroffener Gruppen zu gesellschaftlicher Teilhabe.

**Unique Contribution:** Der Beitrag verbindet Diskriminierungsanalyse (drei Ebenen: Daten, Modell, Anwendung) mit KI-Kompetenzentwicklung in einem dreidimensionalen Modell (kognitiv-affektiv-handlungsbezogen) und betont die Notwendigkeit von regulatorischer und zivilgesellschaftlicher Flankierung neben Medienpädagogik.

**Limitations:** Empirische Basis auf relativ kleine qualitative Stichprobe (n=25) beschränkt; fehlende Evaluationen konkreter Interventionen zur Kompetenzteilung; begrenzte Analyse von Systemebenen-Lösungen jenseits individueller Kompetenzen.

**Target Group:** Medienpädagog:innen, Sozialarbeiter:innen, Policymaker im Bereich Antidiskriminierung und Digitalisierung, Fachkräfte in der Arbeit mit migrierten und prekären Zielgruppen, KI-Ethik-Expert:innen, Interessensvertreter:innen marginalisierter Gruppen

## Schlüsselreferenzen

- [[AlgorithmWatchCh_2023]] - Positionspapier - Schutz vor algorithmischer Diskriminierung
- [[Sūna_Laura_Hoffmann_Dagmar_2024]] - From AI imaginaries to AI literacy: Artificial intelligence technologies in everyday lives of migrants in Germany
- [[Rentsch_Susanne_2023]] - 'Computer sagt nein' - Gesellschaftliche Teilhabe und strukturelle Diskriminierung im Zeitalter Künstlicher Intelligenz
- [[Criado_Natalia_Such_Jose_M_2019]] - Digital Discrimination
- [[Lopez_Paola_2021]] - Diskriminierung durch Data Bias
- [[Schober_Maximilian_et_al_2022]] - 'Was ich like, kommt zu mir.' Kompetenzen von Jugendlichen im Umgang mit algorithmischen Empfehlungssystemen
- [[Bozdag_Çigdem_2022]] - Inclusive Media Education in the Diverse Classroom
- [[Gruber_Jonathan_Hargittai_Eszter_2023]] - The importance of algorithm skills for informed Internet use
- [[Heesen_Jessica_Reinhardt_Karoline_Schelenz_Laura_2021]] - Diskriminierung durch Algorithmen vermeiden
- [[Kalogeropoulos_Elena_et_al_2021]] - Wegweiser Digitale Debatten. Teil 2: Algorithmenvermittelte Diskriminierung
