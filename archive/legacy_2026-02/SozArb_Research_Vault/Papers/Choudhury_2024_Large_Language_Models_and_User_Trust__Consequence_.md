---
title: "Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Health Care Professionals"
zotero_key: HR4KR4YL
author_year: "Choudhury (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: journalArticle
language: nan
doi: "10.2196/56764"
url: "https://www.jmir.org/2024/1/e56764/"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 1
rel_bias: 3
rel_praxis: 2
rel_prof: 2
total_relevance: 9

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Practical Implementation"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-bias-high", "dim-praxis-medium", "dim-prof-medium"]

# Summary
has_summary: false
summary_file: ""

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Large Language Models and User Trust: Consequence of Self-Referential Learning Loop and the Deskilling of Health Care Professionals

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **9/15** (medium) |
| **Top Dimensions** | Bias Analysis, Practical Implementation |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 1/3 | ⭐ Low |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 2/3 | ⭐⭐ Medium |


## Abstract

Peer-reviewed viewpoint discussing integration of LLMs into healthcare requiring balance between trust and skepticism. Warns that "blind trust" in LLM recommendations can lead to automation bias and confirmation bias as clinicians may accept AI outputs uncritically. Argues that prompting for transparency in LLM reasoning enhances professionals' trust by making AI reasoning visible and verifiable. Emphasizes need for human oversight and bias mitigation to ensure LLMs complement rather than compromise expert decision-making.


## AI Summary

*No AI summary available. This paper was assessed but not yet processed through the summarization pipeline.*


## Links & Resources

- **DOI:** [10.2196/56764](https://doi.org/10.2196/56764)
- **URL:** https://www.jmir.org/2024/1/e56764/
- **Zotero:** [Open in Zotero](zotero://select/items/HR4KR4YL)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

