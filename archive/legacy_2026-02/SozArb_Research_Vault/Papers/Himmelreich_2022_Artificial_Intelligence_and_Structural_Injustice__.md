---
title: "Artificial Intelligence and Structural Injustice: Foundations for Equity, Values, and Responsibility"
zotero_key: RCD7NJM2
author_year: "Himmelreich (2022)"
authors: []

# Publication
publication_year: 2022.0
item_type: journalArticle
language: nan
doi: "nan"
url: "https://arxiv.org/abs/2205.02389"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 1
rel_prof: 1
total_relevance: 8

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Vulnerable Groups"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-medium", "dim-bias-high", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Himmelreich_2022_Artificial.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Artificial Intelligence and Structural Injustice: Foundations for Equity, Values, and Responsibility

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2022.0 |
| **Decision** | **Include** |
| **Total Relevance** | **8/15** (medium) |
| **Top Dimensions** | Bias Analysis, Vulnerable Groups |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

This work develops a structural injustice approach to AI governance based on Iris Marion Young's theory of structural injustice. The authors argue that structural injustice is a powerful conceptual tool that enables researchers and practitioners to identify, articulate, and potentially even anticipate AI bias. The approach includes both an analytical component (structural explanations) and an evaluative component (justice theory) and provides methodological and normative foundations for diversity, equity, and inclusion values.


## AI Summary

## Overview

This academic work by Himmelreich and Lim presents a philosophical framework for understanding and addressing AI bias through structural injustice theory, derived from philosopher Iris Marion Young's work. The authors argue that AI systems perpetuate pre-existing unjust social structures rather than creating bias independently. Emerging from contemporary global awareness of systemic racism, colonialism, and inequality across the Global North (US, Europe), the work positions AI governance as inseparable from broader justice concerns. The central claim is that structural injustice theory provides superior analytical and normative foundations for AI ethics compared to conventional harm-benefit analyses or abstract value statements.

## Main Findings

The authors establish several critical findings. First, structural injustice operates through both analytical components (explaining systemic mechanisms) and evaluative components (normative justice theory), providing dual explanatory and moral frameworks. Second, AI biases emerge from interaction between well-intentioned systems and fundamentally unjust social contexts, not individual malice. Third, structural injustice functions as a diagnostic tool for identifying, articulating, and anticipating AI biases before deployment. Fourth, the framework provides rigorous philosophical grounding for Diversity, Equity, and Inclusion initiatives, moving beyond rhetorical commitments. Fifth, responsibility for addressing structural injustice is distributed across individuals and organizations, independent of causal responsibility for injustice's existence. Finally, an open theoretical question remains: whether AI itself is becoming constitutive of society's structural fabric, potentially amplifying injustice systematically.

## Methodology/Approach

The authors employ comparative interdisciplinary philosophical analysis, explicitly contrasting the structural injustice approach against alternative governance frameworks (harm-benefit analyses, value-based approaches). The methodology integrates social science structural explanations with political philosophy and applied ethics, grounding abstract theory in concrete case studies of racial bias in AI systems. The approach draws from sociology, philosophy, and policy studies, examining how institutional arrangements and systemic processes illuminate AI's role in perpetuating injustice while simultaneously applying justice theory to evaluate these structures' legitimacy.

## Relevant Concepts

**Structural Injustice:** Injustice embedded in institutional practices and social structures through both analytical mechanisms (how systems operate) and evaluative dimensions (normative justice standards); operates through systemic patterns affecting particular groups.

**Iris Marion Young's Theory:** Foundational philosophical framework distinguishing structural from individual injustice, emphasizing how institutions perpetuate inequality through normal operations.

**Dual-Component Framework:** Structural injustice analysis combining analytical explanation (social science mechanisms) with evaluative judgment (justice theory).

**Algorithmic Bias:** Systematic errors in AI systems disproportionately harming particular groups, understood as emerging from structural rather than purely technical sources.

**Distributed Responsibility:** Moral obligation to address injustice shared across individuals and organizations, distinct from causal responsibility for creating injustice.

**Status Quo Injustice:** Recognition that existing arrangements embed historical inequalities (racism, colonialism, gender/class disparities) that AI risks perpetuating.

## Significance

This work represents a paradigm shift in AI ethics discourse, moving from individualistic to systemic responsibility frameworks. It challenges narrow technical approaches by demonstrating that algorithmic "objectivity" cannot overcome structural injustice. The significance extends globally: it provides policy-makers, practitioners, and researchers with conceptual tools for recognizing how AI governance connects to broader social justice movements addressing systemic racism and colonialism. By grounding DEI initiatives in rigorous philosophical theory, the framework offers methodological rigor to equity-focused governance. The work ultimately argues that responsible AI deployment requires understanding and addressing the unjust structures into which AI is embedded, while acknowledging that the extent of AI's constitutive role in society's structure remains an open theoretical question requiring further investigation.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://arxiv.org/abs/2205.02389
- **Zotero:** [Open in Zotero](zotero://select/items/RCD7NJM2)

## Related Concepts

- [[Concepts/Structural_Injustice|Structural Injustice]]
- [[Concepts/Iris_Marion_Youngs_Theory|Iris Marion Young's Theory]]
- [[Concepts/Dual_Component_Framework|Dual-Component Framework]]
- [[Concepts/Algorithmic_Bias|Algorithmic Bias]]
- [[Concepts/Distributed_Responsibility|Distributed Responsibility]]
- [[Concepts/Status_Quo_Injustice|Status Quo Injustice]]

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

