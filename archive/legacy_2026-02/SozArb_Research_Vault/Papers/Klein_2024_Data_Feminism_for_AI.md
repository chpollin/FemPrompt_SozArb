---
title: "Data feminism for AI"
zotero_key: IXCQLI27
author_year: "Klein (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: conferencePaper
language: nan
doi: "10.1145/3630106.3658543"
url: "https://doi.org/10.1145/3630106.3658543"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 2
rel_praxis: 2
rel_prof: 1
total_relevance: 9

# Categorization
relevance_category: medium
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-high", "dim-bias-medium", "dim-praxis-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Klein_2024_Data.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Data feminism for AI

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **9/15** (medium) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 2/3 | ⭐⭐ Medium |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

Extends the influential "Data Feminism" framework to AI research, presenting intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. Rearticulates original seven data feminism principles specifically for AI contexts and introduces two new principles addressing environmental impact and consent, providing concrete methodological guidance.


## AI Summary

## Overview

Klein and D'Ignazio's "Data Feminism for AI" extends their influential 2020 framework to address contemporary challenges in artificial intelligence development and deployment. Published at the 2024 ACM Conference on Fairness, Accountability, and Transparency, this paper argues that feminist analytical approaches are essential for identifying and mitigating structural inequalities embedded within AI systems. Motivated by a decade of evidence demonstrating how data power is wielded unequally by corporations, governments, and well-resourced institutions, the authors demonstrate that feminism—with its analytic focus on root causes of structural inequality—provides necessary tools for rebalancing power. The work responds to growing recognition that AI technologies, despite claims of objectivity and neutrality, systematically perpetuate extractive, exclusionary, and undemocratic practices that disproportionately harm marginalized communities.

## Main Findings

The paper demonstrates that feminist principles have achieved significant uptake across academic institutions and public sector organizations since the original Data Feminism publication, validating the framework's relevance and applicability. However, the authors identify that AI's distinctive characteristics—including unprecedented scale, algorithmic opacity, and far-reaching societal consequences—necessitate refinement and expansion of the original seven principles: examine power, challenge power, rethink binaries and hierarchies, elevate emotion and embodiment, consider context, embrace pluralism, and make labor visible. The paper introduces two new principles addressing environmental sustainability and informed consent, recognizing that comprehensive AI governance must account for ecological impacts and user agency. The authors establish three primary objectives: (1) accounting for unequal, undemocratic, extractive, and exclusionary forces in AI research and deployment; (2) identifying and mitigating predictable harms before unsafe, discriminatory, or oppressive systems reach deployment; and (3) inspiring creative, joyful, and collective approaches toward equitable, sustainable worlds where all can thrive.

## Methodology/Approach

Rather than conducting empirical research or technical analysis, the paper employs a normative theoretical framework grounded in intersectional feminist theory and critical data studies scholarship. The methodology integrates structural inequality analysis, power dynamics examination, and interdisciplinary perspectives spanning humanities, social sciences, and computing. The authors operationalize nine principles—seven rearticulated from Data Feminism with AI-specific applications, plus two new principles—into concrete, actionable guidelines for researchers, practitioners, policymakers, and technologists. This approach deliberately bridges disciplinary boundaries, positioning feminist scholarship as foundational to technical AI governance rather than supplementary to it. The framework prioritizes proactive harm prevention through feminist analysis applied before system deployment.

## Relevant Concepts

**Intersectional Feminism:** Analytical framework examining how multiple systems of oppression (gender, race, class, etc.) interconnect and compound inequalities within technological systems.

**Structural Inequality:** Systemic disadvantages embedded in institutional practices and power distributions that harm marginalized communities through AI deployment.

**Data Justice:** Principle ensuring equitable access, representation, and benefit-sharing in data collection, analysis, and application processes.

**Algorithmic Opacity:** The "black box" problem wherein AI decision-making processes remain incomprehensible to users and affected communities, obscuring potential biases.

**Epistemic Pluralism:** Recognition that multiple forms of knowledge and ways of knowing are valid and necessary for comprehensive understanding.

**Environmental Impact Principle:** New principle addressing ecological consequences of AI systems, including computational resource consumption and sustainability concerns.

**Consent Principle:** New principle ensuring informed, voluntary participation and agency of individuals and communities affected by AI systems.

## Significance

This work represents a paradigm shift in AI ethics discourse, moving beyond purely technical solutions toward socio-political analysis grounded in established feminist scholarship. By publishing at FAccT '24, a premier venue for computer science conversations on fairness and accountability, the paper legitimizes humanistic perspectives within mainstream AI governance discussions. The framework's demonstrated adoption across academia and public sectors indicates growing institutional recognition that addressing AI inequities requires fundamental rethinking of power structures, not merely algorithmic adjustments. The paper's emphasis on "joyful" and "collective" approaches distinguishes it from deficit-focused AI ethics, proposing affirmative visions of equitable technological futures. Ultimately, the work positions feminism as essential—not optional—for developing AI systems that enable collective thriving rather than perpetuating systemic oppression, while establishing concrete operational principles for practitioners across sectors.


## Links & Resources

- **DOI:** [10.1145/3630106.3658543](https://doi.org/10.1145/3630106.3658543)
- **URL:** https://doi.org/10.1145/3630106.3658543
- **Zotero:** [Open in Zotero](zotero://select/items/IXCQLI27)

## Related Concepts

- [[Concepts/Intersectional_Feminism|Intersectional Feminism]]
- [[Concepts/Structural_Inequality|Structural Inequality]]
- [[Concepts/Data_Justice|Data Justice]]
- [[Concepts/Algorithmic_Opacity|Algorithmic Opacity]]
- [[Concepts/Epistemic_Pluralism|Epistemic Pluralism]]
- [[Concepts/Environmental_Impact_Principle|Environmental Impact Principle]]
- [[Concepts/Consent_Principle|Consent Principle]]

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

