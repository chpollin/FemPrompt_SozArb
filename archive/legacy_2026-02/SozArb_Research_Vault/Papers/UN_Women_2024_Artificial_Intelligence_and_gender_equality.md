---
title: "Artificial Intelligence and gender equality"
zotero_key: A4REJRN2
author_year: "UN Women (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: report
language: nan
doi: "nan"
url: "https://www.unwomen.org/en/articles/explainer/artificial-intelligence-and-gender-equality"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 3
rel_praxis: 2
rel_prof: 1
total_relevance: 10

# Categorization
relevance_category: high
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "high-relevance", "dim-vulnerable-high", "dim-bias-high", "dim-praxis-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Women_2024_Artificial.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Artificial Intelligence and gender equality

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **10/15** (high) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

Comprehensive policy brief series analyzing how AI systems perpetuate gender inequalities while highlighting pathways for more equitable development. Documents that 44% of AI systems show gender bias, with 25% exhibiting both gender and racial bias, and provides evidence-based policy recommendations for addressing systematic underrepresentation and discriminatory outcomes.


## AI Summary

## Overview

This peer-reviewed paper by researchers at Epoch AI (with affiliations at University of Aberdeen, MIT CSAIL, Centre for the Governance of AI, and University of Tübingen) investigates a fundamental constraint facing artificial intelligence development: the potential exhaustion of publicly available human-generated text data for training large language models. The research addresses whether current LLM scaling trajectories can be sustained given finite data resources, or whether the field will encounter a critical bottleneck within this decade. By combining quantitative forecasting with analysis of existing datasets (RefinedWeb, C4, RedPajama) and established neural scaling laws, the authors provide both a timeline for data exhaustion and potential mitigation strategies. The work is significant because it bridges theoretical AI research with practical resource limitations, informing both technical development strategies and policy discussions around AI governance.

## Main Findings

The paper's central quantitative finding projects that the effective stock of publicly indexed human text—approximately 4×10¹⁴ tokens—will be fully utilized around 2028 under baseline assumptions, with a plausible range between 2026-2032 depending on model overtraining practices. This exhaustion point corresponds to approximately 5×10²⁸ FLOP of training compute for non-overtrained models; overtraining scenarios could accelerate exhaustion by several years. The research demonstrates that current LLM development trajectories, when plotted against available data supply, intersect at this median year (2028), indicating that scaling according to established neural scaling laws (Kaplan et al., 2020; Hoffmann et al., 2022) cannot continue indefinitely using only public human-generated text. However, the authors argue this constraint is not absolute; they identify three primary mitigation pathways: synthetic data generation (creating artificial training data through computational methods), transfer learning from data-rich specialized domains (leveraging domain-specific corpora), and improvements in data efficiency (achieving better performance with less data through algorithmic innovation). This dual finding—acknowledging real constraints while proposing solutions—positions the work as neither apocalyptic nor dismissive of genuine challenges.

## Methodology/Approach

The research employs a sophisticated dual-sided forecasting model integrating supply and demand analysis. The demand-side analysis projects future training dataset requirements by extrapolating observed LLM development patterns and applying established neural scaling laws, which mathematically relate model performance improvements to dataset expansion. The supply-side analysis quantifies the total stock of indexed public human text (data accessible through web indexing and curated corpora) by synthesizing historical internet growth data (Coffman & Odlyzko, 1998; Reinsel et al., 2018) with contemporary large-scale datasets. The methodology incorporates scenario analysis, including overtraining scenarios (training beyond theoretical optima) that could accelerate data exhaustion. Figure 1 provides visual synthesis, plotting projected dataset sizes against available stock to identify intersection points. This approach integrates historical data growth patterns with current AI development practices, creating a coherent forecasting framework suitable for policy and research planning.

## Relevant Concepts

**Neural Scaling Laws**: Mathematical relationships describing how model performance improves with increased training data, model size, and compute—fundamental to modern LLM development strategy and efficiency optimization.

**Effective Stock of Text**: The quantifiable amount of indexed, publicly available human-generated text suitable for LLM training, estimated at approximately 4×10¹⁴ tokens, derived from web pages and curated corpora.

**Data Exhaustion**: The projected point (circa 2028) at which demand for training data exceeds available supply under current development paradigms and scaling law assumptions.

**Synthetic Data Generation**: Creating artificial training data through computational methods to supplement or replace human-generated text, enabling continued scaling beyond natural data limits.

**Transfer Learning from Data-Rich Domains**: Leveraging specialized, high-quality datasets from specific fields (scientific literature, technical documentation) to improve model performance with limited general-purpose data.

**Data Efficiency Improvements**: Algorithmic and architectural innovations enabling models to achieve equivalent performance using smaller training datasets.

## Significance

This work significantly impacts AI development strategy, resource allocation decisions, and policy frameworks. It provides concrete timelines for addressing data constraints, enabling proactive research into alternative scaling methods before exhaustion occurs. The paper bridges technical AI research with governance implications, suggesting that resource scarcity—while real—may catalyze innovation rather than halt progress. By identifying specific, implementable mitigation strategies and quantifying uncertainty ranges (2026-2032), it reframes the data constraint as a solvable challenge requiring strategic planning. The research informs both industry development priorities and policy discussions around AI safety, resource governance, and the sustainability of current scaling paradigms.


## Links & Resources

- **DOI:** [nan](https://doi.org/nan)
- **URL:** https://www.unwomen.org/en/articles/explainer/artificial-intelligence-and-gender-equality
- **Zotero:** [Open in Zotero](zotero://select/items/A4REJRN2)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

