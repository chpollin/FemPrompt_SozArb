---
title: "Examining risks of racial biases in NLP tools for child protective services"
zotero_key: 5UGREN98
author_year: "Field (2023)"
authors: []

# Publication
publication_year: 2023.0
item_type: conferencePaper
language: nan
doi: "10.1145/3593013.3594094"
url: "nan"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 3
rel_bias: 3
rel_praxis: 1
rel_prof: 2
total_relevance: 10

# Categorization
relevance_category: high
top_dimensions: ["Vulnerable Groups", "Bias Analysis"]

# Tags
tags: ["paper", "include", "high-relevance", "dim-vulnerable-high", "dim-bias-high", "dim-prof-medium"]

# Summary
has_summary: false
summary_file: ""

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Examining risks of racial biases in NLP tools for child protective services

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2023.0 |
| **Decision** | **Include** |
| **Total Relevance** | **10/15** (high) |
| **Top Dimensions** | Vulnerable Groups, Bias Analysis |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 3/3 | ⭐⭐⭐ High |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 1/3 | ⭐ Low |
| Professional/Social Work Context | 2/3 | ⭐⭐ Medium |


## Abstract

Empirical study examining racial bias in natural language processing tools used to analyze child protective services case notes and make risk assessments. Demonstrates language models trained on case narratives exhibit systematic biases disadvantaging families of color. Testing multiple NLP architectures on real child welfare text data, finds models consistently predict higher risk scores for cases mentioning dialects or cultural contexts associated with Black and Latinx families, even when case severity is identical. Reveals how linguistic biases in administrative data get encoded into AI systems, creating automated discrimination.


## AI Summary

*No AI summary available. This paper was assessed but not yet processed through the summarization pipeline.*


## Links & Resources

- **DOI:** [10.1145/3593013.3594094](https://doi.org/10.1145/3593013.3594094)
- **URL:** nan
- **Zotero:** [Open in Zotero](zotero://select/items/5UGREN98)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

