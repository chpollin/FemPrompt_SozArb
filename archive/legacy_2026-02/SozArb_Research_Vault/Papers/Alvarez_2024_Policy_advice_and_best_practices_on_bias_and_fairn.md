---
title: "Policy advice and best practices on bias and fairness in AI"
zotero_key: V3TWQUZC
author_year: "Alvarez (2024)"
authors: []

# Publication
publication_year: 2024.0
item_type: journalArticle
language: nan
doi: "10.1007/s10676-024-09746-w"
url: "https://link.springer.com/article/10.1007/s10676-024-09746-w"

# Assessment
decision: Include
exclusion_reason: "nan"

# Relevance Scores (0-3)
rel_ai_komp: 1
rel_vulnerable: 2
rel_bias: 3
rel_praxis: 2
rel_prof: 1
total_relevance: 9

# Categorization
relevance_category: medium
top_dimensions: ["Bias Analysis", "Vulnerable Groups"]

# Tags
tags: ["paper", "include", "medium-relevance", "dim-vulnerable-medium", "dim-bias-high", "dim-praxis-medium", "has-summary"]

# Summary
has_summary: true
summary_file: "summary_Alvarez_2024_Policy.md"

# Metadata
date_added: 2025-11-10
source_tool: Manual
---

# Policy advice and best practices on bias and fairness in AI

## Quick Info

| Attribute | Value |
|-----------|-------|
| **Authors** | Unknown |
| **Year** | 2024.0 |
| **Decision** | **Include** |
| **Total Relevance** | **9/15** (medium) |
| **Top Dimensions** | Bias Analysis, Vulnerable Groups |


## Relevance Profile

| Dimension | Score | Assessment |
|-----------|-------|------------|
| AI Literacy & Competencies | 1/3 | ⭐ Low |
| Vulnerable Groups & Digital Equity | 2/3 | ⭐⭐ Medium |
| Bias & Discrimination Analysis | 3/3 | ⭐⭐⭐ High |
| Practical Implementation | 2/3 | ⭐⭐ Medium |
| Professional/Social Work Context | 1/3 | ⭐ Low |


## Abstract

This open-access paper provides a comprehensive overview of fairness in AI, bridging technical bias mitigation methods with legal and policy considerations. Alvarez et al. survey the state-of-the-art in fair AI techniques and review major policy initiatives and standards on algorithmic bias. A key contribution is the NoBIAS architecture introduced in the paper, which comprises a “Legal Layer” (focusing on EU non-discrimination law and human rights requirements) and a “Bias Management Layer” (covering bias understanding, mitigation, and accountability). The authors note that AI systems have produced real-world harms, including illegal discrimination against protected groups, and they highlight challenges such as intersectional discrimination that current EU law does not explicitly address. By organizing existing knowledge and best practices, the article guides researchers and practitioners in aligning technical solutions with ethical and legal norms – underscoring that managing AI bias requires not just algorithmic techniques but also adherence to equality principles and governance frameworks.


## AI Summary

## Overview

This 2024 paper, authored by 13 international researchers and published in April 2024, addresses a critical gap in AI governance by providing comprehensive guidance on bias and fairness in artificial intelligence systems. Grounded in the NoBIAS research project—a European initiative examining legal and technical dimensions of bias—the work responds to the exponential growth of AI applications in socially sensitive domains since the post-2010 AI renaissance. The paper serves dual purposes: offering a bird's-eye survey of fair-AI methods, resources, and policies for researchers and practitioners, and contributing original policy advice and best practices. The authors recognize that AI systems are not neutral tools but inherently value-laden technologies capable of producing real-world harms, particularly through both intentional and unintentional discrimination against legally protected social groups. This recognition necessitates integrated approaches combining technical innovation with legal frameworks and ethical considerations.

## Main Findings

The research identifies several critical insights: First, documented AI incident databases reveal tangible harms resulting from biased algorithmic systems, challenging widespread assumptions about algorithmic neutrality. Second, a substantial gap exists between rapid technical advances in AI development and underdeveloped comprehensive policy frameworks, particularly regarding operationalization of fairness principles. Third, effective bias management requires simultaneous integration of EU non-discrimination legislation with technical mitigation strategies—neither legal nor technical approaches alone suffice. Fourth, algorithmic systems create moral consequences, reinforce or undercut ethical principles, and enable or diminish stakeholder rights and dignity, requiring explicit value consideration. Fifth, the proliferation of fair-AI literature creates barriers for new researchers and practitioners seeking comprehensive understanding. Finally, structured guidance translating abstract fairness principles into actionable procedures, standards, and practices remains insufficiently developed in existing literature.

## Methodology/Approach

The paper employs a sophisticated dual-layer analytical framework derived from the NoBIAS project. The **Legal Layer** examines the European Union regulatory context and non-discrimination law, providing normative foundations for bias governance within EU legislation. The **Bias Management Layer** addresses three interconnected operations: understanding bias mechanisms, mitigating bias effects, and accounting for bias in system design and deployment. This multidisciplinary approach synthesizes perspectives from computer science, law, ethics, and policy studies across 13 international authors and multiple institutions. Rather than attempting exhaustive coverage of the extensive literature, the methodology strategically prioritizes survey papers and recent works, enabling comprehensive yet manageable guidance. This approach acknowledges the field's rapid expansion while maintaining accessibility for diverse audiences including researchers, practitioners, and policymakers.

## Relevant Concepts

**Algorithmic Bias**: Systematic errors in AI systems producing discriminatory outcomes, whether intentional or unintentional, affecting legally protected groups.

**Fairness**: Multifaceted concept addressing equitable treatment, non-discrimination compliance, and respect for stakeholder rights and dignity in algorithmic decision-making.

**Value-Laden Systems**: Technologies that inherently embody moral consequences, reinforce or undercut ethical principles, and enable or diminish stakeholder rights and dignity through design choices.

**Bias Management**: Systematic processes comprising three operations—understanding, mitigating, and accounting for bias—throughout AI system lifecycles.

**Policy Operationalization**: Translation of abstract fairness principles into concrete procedures, standards, and actionable practices suitable for organizational implementation.

**Bird's-Eye View**: Comprehensive, high-level perspective providing orientation across multidisciplinary literature and fragmented research domains.

## Significance

This work holds substantial significance for multiple stakeholders. For researchers, it provides essential orientation within an increasingly complex landscape, facilitating informed research directions and identifying underdeveloped areas. For practitioners, it offers practical guidance for implementing fair-AI principles within organizational contexts through structured frameworks. For policymakers, particularly within the EU, it bridges technical and legal domains, supporting evidence-based regulation development aligned with non-discrimination law. The paper's emphasis on integrating legal and technical perspectives reflects emerging consensus that responsible AI governance requires multidisciplinary collaboration. By proposing the NoBIAS architecture as a governance model combining legal and technical layers, the authors contribute to operationalizing fairness beyond theoretical discussion. The work ultimately advances the field's maturation, moving from isolated technical solutions toward comprehensive, integrated approaches to bias management that acknowledge AI's profound societal implications and legal obligations.


## Links & Resources

- **DOI:** [10.1007/s10676-024-09746-w](https://doi.org/10.1007/s10676-024-09746-w)
- **URL:** https://link.springer.com/article/10.1007/s10676-024-09746-w
- **Zotero:** [Open in Zotero](zotero://select/items/V3TWQUZC)

## Related Papers

*Use Obsidian graph view to explore papers with similar relevance profiles*

## Notes

*Add your research notes here*

