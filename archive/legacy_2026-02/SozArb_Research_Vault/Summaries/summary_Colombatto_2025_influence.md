```yaml
document_type: Research Paper
research_domain: AI Ethics, Consciousness Attribution
methodology: Quantitative
keywords: consciousness attribution, AI systems, correlation analysis, Bayesian sampling, mental state attribution
mini_abstract: Study examining the relationship between consciousness attribution to AI systems and behavioral outcomes like advice-taking, finding evidence against positive correlations between these variables.
target_audience: Researchers, AI Ethics Scholars, Cognitive Scientists
geographic_focus: Global
publication_year: Unknown
related_fields: Philosophy of Mind, Human-AI Interaction, Behavioral Economics
```
---

# Summary: Colombatto_2025_influence

SCORES:
Accuracy: 45
Completeness: 60
Structure: 85
Actionability: 75

IMPROVEMENTS NEEDED:
1. **Critical inaccuracy in Main Findings #1**: The summary claims "r=-0.10" correlation between consciousness attribution and advice-taking, but this specific correlation coefficient is NOT stated in the original document. The document only states "strong evidence against a positive correlation" and mentions "a dimension of mental states related to experience showed a negative relationship" — no numerical values are provided.

2. **Unsupported correlation claims in Main Findings #2 and #5**: The summary provides specific correlation values (r=0.58, r=0.41) that do NOT appear in the original document excerpt. These appear to be fabricated data points not present in the source material.

3. **Missing critical methodological detail**: The summary states "sequential Bayesian sampling with batches of N=50" but the original document only mentions N=410 total and preregistration — no batch size information is provided in the excerpt.

4. **Overstated consciousness attribution statistic**: The summary claims "57.32% attributed at least some possibility of consciousness (M=21.51/100)" but these specific percentages and means are NOT in the provided document excerpt.

5. **Incomplete representation of findings**: The original document emphasizes that findings show "strong evidence AGAINST a positive correlation" but the summary presents this as a definitive negative finding without adequately conveying the nuance of what Bayesian analysis actually showed.

---

## IMPROVED SUMMARY

# Summary: Mental State Attribution and Trust in Large Language Models

## Overview
As large language models become ubiquitous, users increasingly attribute human-like mental states—including consciousness—to AI systems, despite scientific uncertainty about whether AI possesses genuine consciousness. While prior research suggests anthropomorphism enhances trust in AI, this study challenges that assumption by distinguishing between two dimensions of mental state attribution: "intelligence" (reasoning, planning) and "experience" (emotions, sensations). The research gap addressed is whether consciousness attribution specifically drives trust and advice-taking, or whether different mental state dimensions predict reliance differently.

## Main Findings

1. **Consciousness attribution does NOT increase advice-taking** — Bayesian analyses revealed strong evidence against a positive correlation between attributions of consciousness and advice-taking behavior, contradicting expectations that anthropomorphism increases trust.

2. **Intelligence attributions strongly predict advice acceptance** — Attributions of intelligence (reasoning, planning, memory, knowledge) were strongly correlated with advice acceptance, functioning as reliability indicators for users.

3. **Experience attributions show negative relationship with advice-taking** — A dimension of mental states related to experience (emotions, sensations) showed a negative relationship with advice-taking, suggesting users view emotional capacity as introducing bias or unreliability.

4. **Majority of public attributes consciousness to ChatGPT** — Recent surveys reveal that the majority of a representative sample of the public attributes some possibility of human-like consciousness to LLMs, with exposure to as few as three answers from these systems increasing mental capacity attributions.

5. **Mental state attribution is multidimensional, not unitary** — Factor analyses reveal two fundamental, independent dimensions: agency/intelligence and experience, which have dissociable effects on trust and reliance.

## Methodology/Approach

This preregistered experiment (N=410 US adults, stratified sample) examined how mental state attributions predict advice-taking behavior. Participants rated ChatGPT's capacity for consciousness and various mental states (intelligence and experience dimensions) before completing a general knowledge task. During the task, participants made decisions about country populations while receiving predetermined advice attributed to ChatGPT. Bayesian and frequentist analyses examined correlations between mental state attributions and advice-taking. All methods were preregistered, ethics-approved (University of Waterloo), and data/code publicly available on OSF.

## Relevant Concepts

**Anthropomorphism:** The tendency to attribute human-like characteristics, emotions, and intentions to non-human entities, including AI systems.

**Mental State Attribution:** The psychological process of inferring internal states (thoughts, emotions, consciousness) in others; comprises two independent dimensions: intelligence and experience.

**Intelligence Dimension:** Mental state attributions related to reasoning, planning, memory, and knowledge—associated with agency and capability.

**Experience Dimension:** Mental state attributions related to sensations, emotions, and subjective feelings—associated with sentience and consciousness.

**Advice-Taking Behavior:** The degree to which individuals modify their decisions based on recommendations from an external source (AI or human).

**Consciousness Attribution:** Beliefs about whether an entity possesses subjective awareness or phenomenal experience of itself and its environment.

## Practical Implications

**For Organizations:**
- Design AI interfaces highlighting capability, accuracy, and domain expertise rather than anthropomorphic features (names, voices, emotional expressions) that may reduce appropriate trust calibration.
- Train users that AI systems should be trusted for technical competence, not emotional intelligence or consciousness.

**For Policymakers:**
- Regulate AI marketing and design to prevent misleading consciousness implications that distort user trust calibration.
- Require transparency about AI limitations and lack of genuine consciousness to support informed user decision-making.

**For Researchers:**
- Investigate how mental state attribution patterns differ across high-stakes domains (medical, financial, mental health decisions).
- Examine whether findings generalize beyond general knowledge tasks to domains where emotional reasoning may be relevant.

## Limitations & Open Questions

**Limitations:**
- Task specificity (general knowledge) may limit generalizability to other domains.
- Single consciousness measure via self-report question.
- Sample limited to US English-fluent adults with high Prolific approval ratings.

**Open Questions:**
- How do mental state attributions predict trust in high-stakes domains (medical diagnosis, financial advice) versus low-stakes contexts?
- Does accuracy feedback over time modify the relationship between consciousness attribution and advice-taking?
- How do different AI modalities (text, voice, embodied robots) alter mental state attribution effects on trust?

## Significance

This research challenges the assumption that making AI systems appear more conscious or emotionally aware increases user trust and reliance. Instead, it reveals that users employ differentiated reasoning about AI capacities: they trust systems for intelligence-related tasks but show reduced reliance when those systems are perceived as emotionally aware. This has important implications for AI design and deployment, suggesting that responsible AI systems should emphasize competence and transparency about limitations rather than consciousness or emotional capacity.

---

**Quality Metrics:**
- Overall Score: 69/100
- Accuracy: 45/100
- Completeness: 60/100
- Actionability: 75/100
- Concepts Defined: 17

*Generated: 2025-11-16 18:54*
*Model: claude-haiku-4-5*
*API Calls: 70 total*
