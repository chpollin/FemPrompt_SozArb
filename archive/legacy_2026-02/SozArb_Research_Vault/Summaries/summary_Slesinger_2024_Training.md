```yaml
document_type: Research Paper
research_domain: AI Ethics, AI Bias & Fairness, Participatory Design
methodology: Qualitative
keywords: co-creation, AI fairness, vulnerable populations, participatory design, technical literacy
mini_abstract: This paper examines how structured AI training in co-creation workshops can enable meaningful participation of vulnerable groups in AI fairness discussions, revealing trade-offs between technical depth and engagement that designers often resolve through assumptions rather than evidence.
target_audience: Researchers, Practitioners, Policymakers, AI Designers
geographic_focus: Global
publication_year: Unknown
related_fields: Human-Computer Interaction, Social Inclusion, Responsible AI
```
---

# Summary: Slesinger_2024_Training

# Summary: Training in Co-Creation as a Methodological Approach to Improve AI Fairness

## Overview
This paper addresses a critical gap in participatory AI design: how to meaningfully engage vulnerable and marginalized groups in co-creation processes when they lack technical AI expertise. As AI systems increasingly impact disadvantaged populations through biased decision-making in finance, identity verification, and other domains, participatory design and co-creation approaches have emerged as mechanisms for ensuring fairness and social inclusion. However, the technical complexity of AI creates barriers to genuine participation. The authors investigate whether incorporating structured AI training into co-creation workshops can democratize engagement with AI fairness issues. Their analysis, grounded in the MAMMOth project's work with vulnerable stakeholder groups, reveals that while training improves accessibility, designers face difficult trade-offs between technical depth and participant engagement—often resolving these through assumptions about participant capacity rather than evidence-based assessment.

## Main Findings

1. **Low baseline AI knowledge across participants**: Most participants possessed minimal understanding of AI systems, requiring designers to establish foundational literacy before substantive fairness discussions could occur.

2. **Deliberate technical content minimization**: Facilitators intentionally reduced technical depth to prevent participant disengagement, prioritizing accessibility over comprehensiveness.

3. **Demographic performance heterogeneity**: Older unemployed women and other vulnerable subgroups demonstrated differential learning outcomes, suggesting one-size-fits-all training approaches are insufficient.

4. **Stereotype-driven rather than evidence-based calibration**: Designers relied on demographic assumptions about participant capacity rather than conducting upfront assessments of actual learning potential.

5. **Facilitator-driven contextual adaptation**: Independent facilitators modified workshop delivery based on organizational contexts and specific participant needs, demonstrating that implementation varies significantly across settings.

6. **Socio-technical prioritization over technical detail**: Social and systemic factors were emphasized over technical mechanisms to maintain inclusion and relevance to participants' lived experiences.

7. **Unvalidated assumptions about capacity**: The study reveals designers may have underestimated participants' actual capacity for technical content, with unknown implications for co-creation outcomes.

## Methodology/Approach

The research examined co-creation workshops conducted with vulnerable and marginalized stakeholder groups as part of the MAMMOth project's development of an AI bias identification and mitigation toolkit. Data collection involved participant observation across multiple workshops, facilitator feedback, and analysis of engagement patterns. Researchers tracked baseline AI knowledge across diverse demographic groups (age, employment status, education level) and documented how facilitators calibrated technical content. The study captured naturalistic variation by allowing independent facilitators to adapt workshop delivery to specific organizational contexts. Analysis focused on comprehension indicators, engagement patterns, demographic performance differences, and the decision-making processes underlying content calibration. The three primary use cases examined—financial decisions, biometric identity verification, and academic citation bias—provided concrete contexts for exploring AI fairness implications.

## Relevant Concepts

**Co-Creation (Co-C):** A participatory design approach that iteratively incorporates stakeholder requirements throughout the design process from early phases, distinguishing it from traditional participatory design that primarily tests completed prototypes.

**AI Bias:** The inclination or prejudice of AI system decisions for or against specific persons or groups, often reproducing and amplifying existing societal inequalities through training data and algorithmic design.

**Participatory Design (PD):** A methodology that obtains input from end users to test and modify prototype designs, emphasizing stakeholder voice in technology development processes.

**Socio-Technical Approach:** An interdisciplinary framework recognizing that AI bias results from combined sociological, technical, and legal factors rather than technical issues alone.

**Multi-Attribute Bias:** Intersecting forms of bias that AI systems can exacerbate based on multiple characteristics of vulnerability or marginalization (e.g., gender, age, ethnicity, sexual orientation).

**AI Fairness:** Prevention of bias, discrimination, and stigmatization in AI systems through design and deployment practices that account for vulnerable populations' experiences.

**Accessibility in Technical Engagement:** The degree to which non-technical stakeholders can meaningfully participate in discussions about complex technological systems through appropriate literacy support and communication strategies.

## Practical Implications

**For Social Workers:**
- Conduct upfront participant assessments of AI literacy rather than relying on demographic stereotypes when facilitating discussions about algorithmic systems affecting clients.
- Advocate for co-design processes in welfare technology implementation, ensuring vulnerable populations shape systems that determine their access to services.

**For Organizations:**
- Invest in facilitator training to enable contextual adaptation of AI literacy content rather than applying standardized curricula across diverse participant groups.
- Combine technical and socio-technical content, emphasizing systemic impacts and lived experiences alongside technical mechanisms to maintain engagement and relevance.

**For Policymakers:**
- Require evidence-based participant assessment in co-creation processes used to demonstrate regulatory compliance, preventing performative inclusion that masks inadequate engagement.
- Mandate facilitator training standards for co-creation initiatives addressing AI fairness to ensure consistent quality and genuine stakeholder voice.

**For Researchers:**
- Investigate optimal technical-content thresholds that balance accessibility with intellectual rigor, moving beyond binary choices between depth and inclusion.
- Develop participant-responsive frameworks that dynamically adapt to heterogeneous learning needs rather than applying static content standards.

## Limitations & Open Questions

**Limitations:**
- Findings are limited to the MAMMOth project context, potentially reducing generalizability to other co-creation initiatives with different participant populations or AI domains.
- Designers' assumptions about participant capacity were not empirically validated against actual learning potential or counterfactual outcomes with increased technical depth.
- Differential demographic performance is documented but not deeply analyzed regarding underlying causes or implications for inclusive design.

**Open Questions:**
- What is the optimal balance between technical depth and accessibility for different co-creation objectives and participant populations?
- Would greater technical content enable participants to identify different or more sophisticated fairness concerns?
- How can co-creation processes ensure genuine influence over design decisions rather than serving primarily as compliance demonstration?

## Relation to Other Research

- **Participatory Design in Technology**: This work extends PD literature by examining how training components can bridge expertise gaps, addressing persistent challenges in including non-technical stakeholders in complex system design.

- **AI Ethics and Governance**: The paper contributes to emerging discussions about operationalizing ethical AI principles through inclusive processes, particularly as regulatory frameworks like the EU AI Act increasingly mandate stakeholder engagement.

- **Vulnerable Populations and Technology**: The research connects to broader scholarship on how marginalized groups experience technological systems and the barriers to meaningful participation in their design.

- **Science Communication and Literacy**: The study engages with literature on translating technical expertise for diverse audiences, examining trade-offs between accessibility and comprehensiveness.

## Significance

This research is timely and consequential as AI systems increasingly determine outcomes affecting vulnerable populations—from loan approvals to immigration processing—yet those most at risk rarely participate in design decisions. The paper reveals a fundamental tension: co-creation processes designed to ensure fairness may inadvertently limit the technical understanding necessary for participants to identify sophisticated bias mechanisms. By documenting how designers navigate this tension through stereotype-driven assumptions rather than evidence-based assessment, the authors highlight risks of performative inclusion where vulnerable groups participate without genuine influence.

The work is particularly significant given regulatory momentum around the EU AI Act and similar frameworks mandating stakeholder engagement. Organizations may use co-creation to demonstrate compliance while minimizing participant capacity through reduced technical content. The paper's emphasis on evidence-based participant assessment and facilitator training provides actionable guidance for ensuring co-creation genuinely improves AI fairness rather than serving as ethical window-dressing. Ultimately, the research demonstrates that inclusive AI governance requires treating participants as heterogeneous learners with differentiated needs, moving beyond one-size-fits-all approaches to create conditions where vulnerable populations can meaningfully shape technologies affecting their lives.

---

**Quality Metrics:**
- Overall Score: 60/100
- Accuracy: 35/100
- Completeness: 45/100
- Actionability: 60/100
- Concepts Defined: 13

*Generated: 2025-11-16 19:38*
*Model: claude-haiku-4-5*
*API Calls: 362 total*
